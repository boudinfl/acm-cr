@article{10.1145/2888422.2888445,
author = {Bogers, Toine and Koolen, Marijn},
title = {Report on RecSys 2015 Workshop on New Trends in Content-Based Recommender Systems},
year = {2016},
issue_date = {December 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2888422.2888445},
doi = {10.1145/2888422.2888445},
abstract = {This article reports on the CBRecSys 2015 workshop, the second edition of the workshop on new trends in content-based recommender systems, co-located with RecSys 2015 in Vienna, Austria. Content-based recommendation has been applied successfully in many different domains, but it has not seen the same level of attention as collaborative filtering techniques have. Nevertheless, there are many recommendation domains and applications where content and metadata play a key role, either in addition to or instead of ratings and implicit usage data. The CBRecSys workshop series provides a dedicated venue for work dedicated to all aspects of content-based recommender systems.},
journal = {SIGIR Forum},
month = jan,
pages = {141–146},
numpages = {6}
}

@article{10.1145/305110.305120,
author = {Kando, Noriko and Kageura, Kyo and Yoshioka, Masaharu and Oyama, Keizo},
title = {Phrase Processing Methods for Japanese Text Retrieval},
year = {1998},
issue_date = {Sept. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/305110.305120},
doi = {10.1145/305110.305120},
abstract = {This paper examines the effectiveness of different phrase identification and weighting methods for Japanese text retrieval in an operational information retrieval (IR) system, called NACSIS-IR. Based on our previous experiments, we used character-based indexing with positional information and word-or phrase-based query processing, which allowed us to implement sophisticated linguistic analysis on large-scale databases while maintaining adequate efficiency. The results of retrieval experiments on a large-scale Japanese test collection showed that the combination of enhanced phrase identification using patterns defined over part-of-speech tags and our algorithms Phrase2 and Phrase5 made a significant positive contribution to retrieval effectiveness. The paper also discusses indexing and phrase processing of Japanese or East Asian languages.},
journal = {SIGIR Forum},
month = sep,
pages = {23–28},
numpages = {6},
keywords = {word-based query segmentation, phrase processing, character-based indexing, Japanese text retrieval character-based indexing}
}

@article{10.1145/1394251.1394270,
author = {Elsweiler, David},
title = {Supporting Human Memory in Personal Information Management},
year = {2008},
issue_date = {June 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1394251.1394270},
doi = {10.1145/1394251.1394270},
abstract = {In their daily lives people constantly interact with a wide range of electronically stored information objects; email messages, web pages, digital images, video samples, etc. These objects come from different sources, are in different formats and can be stored in different locations, including on distributed devices such as mobile phones, PDAs and MP3 players. The wealth and diversity of digital information that people access and use makes it incredibly difficult for an individual to organise his / her information in such a way that it can be re-accessed and re-used when it is needed in the future. Personal information management (PIM) as a research field covers attempts to understand PIM behaviour and develop systems to help people manage and re-find their information effectively.Our research investigates PIM from the perspective of the psychology of memory. Re-finding information is different from finding information that has not been accessed before and involves different psychological processes. Whereas finding involves understanding an information need and recognising information that is relevant, re-finding relies on memory. When re-finding information, the user knows that the information they are looking for exists because they have seen it before. The details remembered are clues to help re-access the information, while the details forgotten represent the barrier to re-finding. However, current PIM tools require specific attributes of information objects to be remembered and consequently make it difficult to re-access and re-use information. This means that the problems associated with managing and re-finding personal information are related both to the limitations of human memory and to the failure of PIM tools to account for these limitations.Our research is based on the premise that PIM tools should support the function of memory and has three objectives: 1) To develop an increased understanding of the role memory plays in the management of personal information. What do people remember about their information objects, how do they use these recollections when re-finding, and what factors influence what people remember and use? 2) To design, implement and evaluate PIM tools that have been specifically designed to support characteristics of human memory. 3) To address the difficulties involved in performing PIM evaluations.The work is grounded by the theoretical understanding of how memory works. A review of appropriate cognitive psychology literature offers a means to critique existing PIM tools and a basis from which to start designing novel tools that support the function of memory. Building on this, our early experimental work compares PIM behaviour to everyday memory problems, examining the problems people encounter and the strategies they employ to prevent and recover from memory lapses. We uncover a range of memory problems and solutions and relate these to the memory difficulties experienced in a PIM context. By combining the psychology findings with the particpants' explanations for the behavioural changes they make to prevent and recover from memory lapses, we develop a set of design principles for PIM tools that are hypothesized to assist the user when re-finding. Using these principles we develop two novel re-finding interfaces - one for personal photographs and one for personal email messages and evaluate these using current tools as benchmarks.The evaluation work not only allows the interfaces themselves to be evaluated, but also offers the chance to learn about what the experimental participants remember about the information they need to re-find. In this respect, we discover that for both email messages and personal photographs, what people tend to remember is the context surrounding previous interactions with the sought after photograph(s) / email message(s). However, our findings suggest that people tend to have fuller recollections of the emails they need to re-find, with recollections for photographs being more fragmented. Another important finding from the email study is that people tend to remember different attributes of email messages in different situations and that the attributes remembered will depend on a number of factors, including the time that has elapsed since the information was last accessed, the amount of experience the participant has with re-finding, the number of email messages in their collection, the way that they file their email messages, and their preferred means of re-finding.The evaluation of the interfaces also allows several discoveries to be made regarding which features of the evaluated interfaces are supportive and which are restrictive, as well as the reasons why. The main finding, however, is that, like recollections, the interface features that help participants re-find change in different situations. Therefore, flexibility is crucial to PIM interfaces. It is important that PIM interfaces support multiple varieties of memory so that different memories can be used in different situations. The evaluations also highlight the usefulness of supporting visual memory, which few existing PIM tools and research prototypes support. Another finding is that it can be helpful when PIM interfaces supply cues to help people remember more about the information they need to find. However, again the evaluations reveal that different types of memory cues are useful in different situations. Therefore, it is important that the PIM tool designers consider the factors that our studies show to affect this: the type of information object being re-found, the tasks that cause people to re-find this type of object, and re-finding strategies that the participants may already have.The method of evaluation used is in itself a contribution to the field of PIM. A major limitation of the PIM research performed to date is that few tool evaluations have been performed. Several scholars have proposed that this situation stems from the difficulties involved in conducting evaluations. The difficulties include incorporating the personal connections people have with their own information in evaluations, creating balanced experimental designs, preparing experimental tasks, and protecting the privacy of participants. Based on a study of the types of task that cause people to re-find email messages and web pages, we propose, evaluate and then use a methodology for performing PIM evaluations that overcomes difficulties outlined above.Our work, therefore, offers contributions associated with each of our three objectives. We offer an increased understanding of the role of memory in PIM, provide insight into how PIM tools can be designed to support human memory, and propose a method of evaluation that allows PIM behaviour and interfaces to be studied with a laboratory-based approach.},
journal = {SIGIR Forum},
month = jun,
pages = {75–76},
numpages = {2}
}

@article{10.1145/1480506.1480523,
author = {Larson, Martha and Fernie, Kate and Oomen, Johan and Cigarran Recuero, Juan Miguel},
title = {Information Access to Cultural Heritage},
year = {2008},
issue_date = {December 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1480506.1480523},
doi = {10.1145/1480506.1480523},
abstract = {The workshop on Information Access to Cultural Heritage (IACH 2008) was held during the ECDL conference in Aarhus on the 18th September 2008. The workshop provided a venue to bring together academics carrying out research in the area of information access and practitioners working in the cultural heritage field. The aim was to encourage the exchange of ideas concerning the creation, curation, storage, retrieval and use of cultural heritage information. The day began with a keynote paper by Chris Batt, who looked to the future, challenging the audience to think of uses of technology to make sense of the landscape for users, shifting focus of information access to cultural heritage from search to find. The keynote was followed by a session on the European Digital Library with invited papers by Stefan Gradmann on the infrastructure of Europeana and by Rob Davies on work to develop the content of the Library in the EuropeanaLocal project. The proceedings continued with a series of papers on services being developed to provide access to cultural heritage collections and a wide range of media -- images, text, music and speech. A lively series of poster boasters followed and the day concluded with the poster session and a panel discussion on future directions. Given the attendance at the workshop and the good level of discussion throughout the day, we conclude that Information Access to Cultural Heritage is a growing area of research and promising area for exchange and collaboration between researchers and practitioners.},
journal = {SIGIR Forum},
month = nov,
pages = {90–95},
numpages = {6}
}

@article{10.1145/3053408.3053427,
author = {Fafalios, Pavlos},
title = {Exploiting Linked Data in Exploratory Search},
year = {2017},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3053408.3053427},
doi = {10.1145/3053408.3053427},
abstract = {In recent years we have witnessed an explosion in publishing data on the Web, mostly in the form of Linked Data. An important question is how typical users, who mainly use keyword search queries, can access and exploit this constantly increasing body of knowledge. Although existing interaction paradigms in Semantic Search hide their complexity behind easy-to-use interfaces, they have not managed to cover common search needs. At the same time, according to several studies, a large number of search tasks are of exploratory nature. However, in such tasks the traditional "ranked list" approach for interacting with the retrieved results is often inadequate.The objective of this thesis is to enable effective exploratory search services which can bridge the gap between the classic responses of non-semantic search systems (e.g., Professional Search Systems, Web Search Engines) and semantic information expressed in the form of Linked Open Data (LOD). Towards this direction, we introduce an approach in which named entities (like names of persons, locations, chemical substances, etc.) are exploited as the glue for automatically connecting documents (search results) with data and knowledge. We study an approach where this entity-based integration is performed at real-time, without any human intervention and without the need of prebuilt indexes. This allows the provision of "fresh" information, the easy configuration of this functionality according to the needs of the underlying search application, as well as its easy exploitation by existing search systems.The provision of the aforementioned functionality is challenging. At first, the LOD that are available on the Web are big, are distributed in many knowledge bases, are increased and updated continuously, and also cover many domains. Consequently, there is the need of an interoperability model that will allow the specification of the entities of interest as well as of the related and useful semantic data. In addition, the number of extractable entities from the search results can be very high and the same is true for the amount of semantic information that can be retrieved from the LOD for these entities (i.e., the number of their attributes and of their associations with other entities). Thus, there is also the need of methods that can estimate the important (for the search context) entities, attributes and associations.To cope with the above challenges, this thesis proposes a semantic analysis process in which the search results are connected with data and knowledge at real-time without any human intervention. For describing the entities of interest, as well as the related (and useful for the application context) semantic information, we propose a generic model for configuring a Named Entity Extraction (NEE) system, while for specifying the semantics of this model, we introduce an RDF/S vocabulary, called "Open NEE Configuration Model", which allows a NEE system to describe (and publish as LOD) its entity-mining capabilities. To enable associating the result of a NEE process with an applied configuration, we propose an extension of the Open Annotation Data Model which also allows publishing the annotation results as LOD. To examine the feasibility of this model, we developed the system X-Link which, contrary to existing NEE systems, allows its easy configuration by exploiting one or more semantic Knowledge Bases. To identify the important semantic information related to the search results, we introduce and study a ranking method that is based on the Random Walk model and which exploits the extracted entities and their connectivity. The exploitation of the selected semantic information is achieved either through the visualization of the related semantic graph and/or in the context of a faceted interaction model that allows the user to gradually restrict the search space. Besides, this thesis studied the exploitation of such graphs for re-ranking the list of retrieved results aiming to promote relevant but low-ranked hits.The dissertation reports extensive evaluation results of the proposed functionalities and methods. Regarding the system X-Link, a task-based evaluation with users showed its ease of configuration, while a case study illustrated the efficiency of the supported operations. The comparative evaluation of the proposed probabilistic scheme for ranking entities and semantic data showed that the proposed approach is more effective compared to other ranking approaches (producing a more than 20% better ranking). Regarding the presentation of the important entities (and of their associations), the conducted survey in a marine-related search context demonstrated that the majority of participants (more than 70%) prefer to see a graph representation of entities related to the retrieved results regardless of the type of the submitted query. The evaluation of the proposed probabilistic algorithm for re-ranking the retrieved search results (using TREC datasets related to the medical domain) showed that this approach can notably improve the list of results by promoting relevant hits in higher positions. Finally, the implementation and the experimental results of the proposed search process demonstrated its feasibility and efficiency, and also enabled us to reveal its limitations.},
journal = {SIGIR Forum},
month = feb,
pages = {104–105},
numpages = {2}
}

@article{10.1145/2641383.2641390,
author = {Agosti, Maristella and Fuhr, Norbert and Toms, Elaine and Vakkari, Pertti},
title = {Evaluation Methodologies in Information Retrieval Dagstuhl Seminar 13441},
year = {2014},
issue_date = {June 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2641383.2641390},
doi = {10.1145/2641383.2641390},
journal = {SIGIR Forum},
month = jun,
pages = {36–41},
numpages = {6}
}

@article{10.1145/2795403.2795414,
author = {Kazai, Gabriella and Hopfgartner, Frank and Kruschwitz, Udo and Meder, Michael},
title = {ECIR 2015 Workshop on Gamification for Information Retrieval (GamifIR'15)},
year = {2015},
issue_date = {June 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2795403.2795414},
doi = {10.1145/2795403.2795414},
abstract = {The second workshop on Gamification for Information Retrieval took place at ECIR 2015 in Vienna, Austria on the 29th of March. The workshop program included two invited keynote presentations, seven oral presentations of refereed papers, lots of mini discussion sessions and a fishbowl session. The presentations covered diverse topics from playing around with an eye tracker to a game with IR papers and even a game of scientific hangman, generating lively and fun discussions. The workshop was a crowdpinion experiment itself, gathering participants' momentary opinions via an Android app. One of the main themes of the day was the interplay of gamification aspects and incentives, where the key challenge is to align player motivations with the goal of the task. Any misalignment may lead to gamification as a tool being more damaging than useful with users' focus shifting from the task to gaming the system.},
journal = {SIGIR Forum},
month = jun,
pages = {41–49},
numpages = {9}
}

@article{10.1145/3308774.3308797,
author = {Fails, Jerry Alan and Pera, Maria Soledad and Kucirkova, Natalia},
title = {Building Community: Report on the 2nd International and Interdisciplinary Perspectives on Children &amp; Recommender Systems (KidRec) at IDC 2018},
year = {2019},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3308774.3308797},
doi = {10.1145/3308774.3308797},
abstract = {We discuss the outcomes of the 2nd Workshop of the International and Interdisciplinary Perspectives on Children &amp; Recommender Systems (KidRec 2018), co-located with the 2018 ACM Interaction Design and Children (IDC) Conference, which took place June 19-22 in Trondheim, Norway. The goal for this workshop was to explore research and industry efforts focused directly on or facilitating the algorithmic recommendation process for children. The diversity of attendees including K-12 teachers, educators, researchers in various areas of computer science, and industry participants-made it possible to continue to build community around this important topic and further discuss and outline the salient research questions and the next steps to promote more research in this area.},
journal = {SIGIR Forum},
month = jan,
pages = {138–144},
numpages = {7}
}

@article{10.1145/2422256.2422274,
author = {Lv, Yuanhua},
title = {Improving the Effectiveness of Language Modeling Approaches to Information Retrieval: Bridging the Theory-Effectiveness Gap},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2422256.2422274},
doi = {10.1145/2422256.2422274},
abstract = {Improving the effectiveness of general retrieval models has been a long-standing difficult challenge in information retrieval research, yet is also a fundamentally important task, because an improved general retrieval model would benefit every search engine. The language modeling approach to information retrieval has recently attracted much attention. In the language modeling approach, we assume that a query is a sample drawn from a language model: given a query Q and a document D, we compute the likelihood of "generating" query Q with a document language model estimated based on document D. We can then rank documents based on the likelihood of generating the query, i.e., query likelihood. On the one hand, with sound statistical foundation, the language modeling approach makes it easier to set and optimize retrieval parameters, and often outperforms traditional retrieval models. On the other hand, however, after more than one decade of research, the basic language modeling approach to retrieval still remains the same, mainly because the difficulty in accurately modeling the highly empirical notion of relevance within a standard statistical model has led to slow progress in optimizing language modeling approaches; this suggests that the theoretical framework of language models has a clear gap from what is needed to make a retrieval model empirically effective, a general problem we refer to as the "theory-effectiveness gap". We have identified the following theory-effectiveness gaps in current language modeling approaches.First, one critical common component in any language modeling approach is the document language model. Traditional document language models follow the bag-of-words assumption that assumes term independence and ignores the positions of the query terms in a document. For example, in a query "computer virus", the occurrences of two query terms may be close to each other in one document (likely to mean computer virus) while far apart in another document (not necessarily about computer virus), which makes a huge difference for indicating relevance but is largely underexplored, suggesting the existence of a theoryeffectiveness in standard document language models.Second, accurate estimation of query language models plays a critical role in the language modeling approach to information retrieval. Pseudo-relevance feedback (PRF) has proven very effective for improving query language models. The basic idea of PRF is to assume that a small number of top-ranked documents in the initial retrieval results are relevant and select from these documents useful terms to improve the query language model. However, existing PRF algorithms simply assume that all terms in a feedback document are equally useful, again ignoring term occurrence positions. They are often non-optimal, as a feedback document may cover multiple incoherent topics and thus contain many useless or even harmful terms. This shows a theory-effectiveness gap in estimating query language models based on PRF.Third, although pseudo-relevance feedback approaches to the estimation of query language models can help improve the average retrieval precision, many experiments have shown that PRF often hurts many individual queries; the risk of PRF limits its usefulness in real search engines -- another theory-effectiveness gap in query language models.Fourth, the language modeling approach scores a document mainly based on the query likelihood score. A previously unknown deficiency of the query likelihood scoring function is that it is not properly lower-bounded for long documents. As a result of this deficiency, long documents which do match the query term can often be scored unfairly as having a lower relevancy than shorter documents that do not contain the query term at all. For example, for the aforementioned query "computer virus", a long document matching both "computer" and "virus" can easily be ranked lower than a short document matching only "computer". This reveals a clear theory-effectiveness gap between the standard query likelihood scoring function and the optimal way of scoring documents.Fifth, the justification of using the basic query likelihood score for retrieval requires an unrealistic assumption, which states that the probability that a user who dislikes a document would use a query does not depend on the particular document. In reality, however, this assumption does not hold because a user who dislikes a document would more likely avoid using words in the document when posing a query. This theoretical gap between the basic query likelihood retrieval function and the notion of relevance suggests that the basic query likelihood function is a potentially non-optimal retrieval function.To bridge the above theory-effectiveness gaps between the theoretical framework of standard language models and the empirical application of information retrieval, in this dissertation, we clearly identified the causes of these gaps, and developed general methodologies to remove the causes from language models without destroying the statistical foundation and any other desirable properties of language models. Our explorations have delivered several more effective and robust general language modeling approaches, which can all be applied immediately to search engines to improve their ranking accuracy. Although this dissertation focuses on language models, most of the proposed methodologies are actually more general, and can also be applied to retrieval models other than language models to bridge their theory-effectiveness gap as well.This dissertation was completed at the Department of Computer Science at University of Illinois at Urbana-Champaign under the advise of Dr. ChengXiang Zhai. Dr. ChengXiang Zhai, Dr. Jiawei Han, Dr. Evgeniy Gabrilovich, and Dr. Miles Efron served as dissertation committee members. Available online at: https://www.ideals.illinois.edu/handle/2142/34306.},
journal = {SIGIR Forum},
month = dec,
pages = {112–113},
numpages = {2}
}

@article{10.1145/1067268.1067282,
author = {Crouch, Carolyn},
title = {Relevance Feedback at the INEX 2004 Workshop},
year = {2005},
issue_date = {June 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1067268.1067282},
doi = {10.1145/1067268.1067282},
abstract = {In 2004, the INitiative for the Evaluation of XML Retrieval (INEX), in its third year of investigations into various aspects of theoretical and applied structured retrieval, added a Relevance Feedback (RF) Track. The purpose of this Track is to explore issues related to the use of relevance feedback in a structured environment. Because the interim between the receipt of relevance assessments by Workshop participants and the due date of their papers was relatively short, the amount of time available for experiments was limited. However, three groups reported early experiments: Mass and Mandelbrod (Relevance Feedback for XML Retrieval); Mihajlovic, Ramirez, de Vries, Hiemstra, and Blok (TIJAH at INEX 2004 Modeling Phrases and Relevance Feedback); and Crouch, Majahan and Bellamkonda (Flexible Retrieval Based on the Vector Space Model).},
journal = {SIGIR Forum},
month = jun,
pages = {41–42},
numpages = {2}
}

@article{10.1145/263868.263873,
author = {Salton, Gerard},
title = {Expert Systems and Information Retrieval},
year = {1997},
issue_date = {Spring 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/263868.263873},
doi = {10.1145/263868.263873},
journal = {SIGIR Forum},
month = apr,
pages = {39–42},
numpages = {4}
}

@article{10.1145/1273221.1273229,
author = {Frommholz, Ingo and Larson, Ray},
title = {Report on the INEX 2006 Heterogeneous Collection Track},
year = {2007},
issue_date = {June 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1273221.1273229},
doi = {10.1145/1273221.1273229},
abstract = {XML collections that consist of subcollections from different sources pose a challenge with respect to syntactic, semantic and genre heterogeneity, because they are based on different DTDs or schemas, cover various topics and consist of diverse document types. This led to the establishment of the Heterogeneous Track at INEX 2006. The goal of the track was to set up a testbed consisting of several different and diverse collections and defining retrieval tasks and appropriate topics. These are the foundations for the Heterogeneous Track at INEX 2007, where the focus is on run submissions, relevance assessments and proper evaluation of the proposed methods dealing with a heterogeneous collection.},
journal = {SIGIR Forum},
month = jun,
pages = {75–78},
numpages = {4}
}

@article{10.1145/2093346.2093363,
author = {Castillo, Carlos and Gyongyi, Zoltan and Jatowt, Adam and Tanaka, Katsumi},
title = {Report on the Joint WICOW/AIRWeb Workshop on Web Quality (WebQuality 2011)},
year = {2012},
issue_date = {December 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2093346.2093363},
doi = {10.1145/2093346.2093363},
abstract = {The Joint WICOW/AIRWeb Workshop on Web Quality (WebQuality 2011) was held in conjunction with the 20th International World Wide Web Conference in Hyderabad, India on the 28th March 2011. Seven full-papers presentations and a keynote talk were delivered in three sessions. This report briefly summarizes the workshop.},
journal = {SIGIR Forum},
month = jan,
pages = {99–101},
numpages = {3}
}

@article{10.1145/2215676.2215683,
author = {Agosti, Maristella and Catarci, Tiziana and Ferro, Nicola and M\"{u}ller, Henning and Santucci, Giuseppe},
title = {PROMISE Winter School 2012 Information Retrieval Meets Information Visualization},
year = {2012},
issue_date = {June 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2215676.2215683},
doi = {10.1145/2215676.2215683},
journal = {SIGIR Forum},
month = may,
pages = {65–70},
numpages = {6}
}

@article{10.1145/1394251.1394267,
author = {Castillo, Carlos and Chellapilla, Kumar and Davison, Brian D.},
title = {Adversarial Information Retrieval on the Web (AIRWeb 2007)},
year = {2008},
issue_date = {June 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1394251.1394267},
doi = {10.1145/1394251.1394267},
abstract = {The ubiquitous use of search engines to discover and access Web content shows clearly the success of information retrieval algorithms. However, unlike controlled collections, the vast majority of Web pages lack an authority asserting their quality. This openness of the Web has been the key to its rapid growth and success, but this openness is also a major source of new adversarial challenges for information retrieval methods.},
journal = {SIGIR Forum},
month = jun,
pages = {68–72},
numpages = {5}
}

@article{10.1145/1147197.1147202,
author = {Jones, Christopher B. and Purves, Ross},
title = {GIR'05 2005 ACM Workshop on Geographical Information Retrieval},
year = {2006},
issue_date = {June 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1147197.1147202},
doi = {10.1145/1147197.1147202},
abstract = {Geographical information retrieval (GIR) is concerned with the problems of finding information resources that relate to particular geographical locations. Until recently most web search engines have treated geographical terminology within user queries in the same way as other terminology. This can often result in failure to find relevant documents and in the retrieval of irrelevant documents. There are several reasons for this. For example, there are many different places with the same name, so unless the query contains a unique set of geographical terms, documents referring to the wrong place may be retrieved. There are many uses of place names in the names of people and organisations with the consequence that search depending on naive exact matching of terms may retrieve such documents even though they may not relate to the named place. It is also the case that queries may include spatial prepositions, such as near or outside, which will not be interpreted intelligently by the search engine. Thus relevant documents may not be found because the user's query did not contain explicit references to the places that match the query expression, in the sense of being, for example, near, inside or north of a named place. It is also the case that conventional search engines lack other desirable facilities for geographical search such as relevance ranking that takes account of geographical proximity and the ability to use interactive maps to specify a query and to visualise the results.},
journal = {SIGIR Forum},
month = jun,
pages = {34–37},
numpages = {4}
}

@article{10.1145/2492189.2492195,
author = {Murdock, Vanessa and Clarke, Charles L.A. and Kamps, Jaap and Karlgren, Jussi},
title = {Report on the Workshop on Search and Exploration of X-Rated Information (SEXI 2013)},
year = {2012},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2492189.2492195},
doi = {10.1145/2492189.2492195},
abstract = {The Workshop on Search and Exploration of X-Rated Information (SEXI) was presented for the first time at the Conference on Web Search and Data Mining (WSDM) 2013 in Rome, Italy. It represents a first attempt to study adult content from the perspective of the research communities in Web Search and Data Mining. To this end, five short papers were presented covering different research questions in searching and evaluating adult content on the Web, with two invited talks from experts in adult content from the fields of evolutionary psychology and media studies. The day ended with a panel that included the two invited speakers, and an expert in human trafficking on the Web.},
journal = {SIGIR Forum},
month = jun,
pages = {31–37},
numpages = {7}
}

@article{10.1145/3308774.3308800,
author = {Ghosh, Saptarshi and Ghosh, Kripabandhu and Ganguly, Debasis and Chakraborty, Tanmoy and Jones, Gareth J. F. and Moens, Marie-Francine},
title = {Report on the Second Workshop on Exploitation of Social Media for Emergency Relief and Preparedness (SMERP 2018) at the Web Conference (WWW) 2018},
year = {2019},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3308774.3308800},
doi = {10.1145/3308774.3308800},
abstract = {The Second Workshop on Exploitation of Social Media for Emergency Relief and Preparedness (SMERP) was held in conjunction with The Web Conference (WWW) 2018 at Lyon, France. A primary aim of the workshop was to promote multi-modal and multi-view information retrieval from the social media content in disaster situations. The workshop programme included keynote talks, a peer-reviewed paper track, and a panel discussion on the relevant research problems in the scope of the workshop.},
journal = {SIGIR Forum},
month = jan,
pages = {163–168},
numpages = {6}
}

@article{10.1145/3130332.3130346,
author = {Ibrahim, Muhammad},
title = {Scalability and Performance of Random Forest Based Learning-to-Rank for Information Retrieval},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/3130332.3130346},
doi = {10.1145/3130332.3130346},
abstract = {For a query submitted by a user, the goal of an information retrieval system is to return a list of documents which are highly relevant with respect to that query. Traditionally different scoring methods, ranging from simple heuristic models to probabilistic models, have been used for this task. Recently researchers have started to use supervised machine learning techniques for solving this problem which is then called the learning-to-rank (LtR) problem. Many supervised learning methods have been tested so far with empirical success over conventional methods [4]The random forest is a relatively simple but effective and efficient learning algorithm which aggregates the predictions of a large number of independent and variant base learners, namely decision trees. Its major benefits over other state-of-the-art methods include inherent parallelizability, ease of tuning and competitive performance. These benefits attract researchers across various disciplines where a random forest is a very popular choice. However, for LtR task, the random forest has not been thoroughly investigated. In this research, we investigate the random forest based LtR algorithms. We aim at improving the efficiency, effectiveness, and understanding of these algorithms. With respect to the first goal, we employ undersampling techniques and leverage the inherent structure of a random forest to achieve better scalability, especially for highly imbalanced datasets [2]. We also reduce the correlation among the trees to reduce learning time and to improve performance [3]. With respect to the second goal, we investigate various objective functions ranging from completely randomized splitting criterion to so-called listwise splitting [1]. We also conduct a thorough study on random forest based pointwise algorithms. With respect to the third goal, we develop methods for estimating the bias and variance of rank-learning algorithms, and examine their empirical behavior against parameters of the learning algorithm},
journal = {SIGIR Forum},
month = aug,
pages = {73–74},
numpages = {2}
}

@article{10.1145/3308774.3308787,
author = {Dodson, Samuel and Zimmerman, Steven},
title = {Autumn School for Information Retrieval and Information Foraging (ASIRF 2017)},
year = {2019},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3308774.3308787},
doi = {10.1145/3308774.3308787},
abstract = {The Autumn School for Information Retrieval and Information Foraging (ASIRF) was held October 1-6, 2017 in Wadern, Germany. The school provided students with a review of topics in information retrieval and information behavior through lectures, student presentations, and a student project. ASIRF attracted thirty-one participants, from Asia, Europe, and North and South America.},
journal = {SIGIR Forum},
month = jan,
pages = {83–86},
numpages = {4}
}

@article{10.1145/1988852.1988860,
author = {Stein, Benno and Potthast, Martin and Rosso, Paolo and Barr\'{o}n-Cede\~{n}o, Alberto and Stamatatos, Efstathios and Koppel, Moshe},
title = {Fourth International Workshop on Uncovering Plagiarism, Authorship, and Social Software Misuse},
year = {2011},
issue_date = {June 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1988852.1988860},
doi = {10.1145/1988852.1988860},
abstract = {The Fourth International Workshop on Uncovering Plagiarism, Authorship, and Social Software Misuse (PAN10) was held in conjunction with the 2010 Conference on Multilingual and Multimodal Information Access Evaluation (CLEF-10) in Padua, Italy. The workshop was organized as a competition covering two tasks: plagiarism detection and Wikipedia vandalism detection. This report gives a short overview of the plagiarism detection task. Detailed analyses of both tasks have been published as CLEF Notebook Papers [3, 6], which can be downloaded at www.webis.de/publications.},
journal = {SIGIR Forum},
month = may,
pages = {45–48},
numpages = {4}
}

@article{10.1145/1988852.1988859,
author = {Boscarino, Corrado and Hofmann, Katja and Jijkoun, Valentin and Meij, Edgar and de Rijke, Maarten and Weerkamp, Wouter},
title = {DIR 2011: The Eleventh Dutch-Belgian Information Retrieval Workshop},
year = {2011},
issue_date = {June 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1988852.1988859},
doi = {10.1145/1988852.1988859},
abstract = {The 11th edition of the annual Dutch-Belgian Information Retrieval workshop (DIR 2011) took place on February 4 in Amsterdam. It was organized by the University of Amsterdam and the Centrum Wiskunde &amp; Informatica. The focus of this year's workshop was on interaction, with the goal of facilitating and increasing interaction, especially within the local research community, and between industry and academia. The scientific program included demos, research papers, and compressed contributions. The keynotes by Nick Belkin and Gabriella Kazai provided intriguing outlooks on the future of IR evaluation.},
journal = {SIGIR Forum},
month = may,
pages = {42–44},
numpages = {3}
}

@article{10.1145/3130332.3130338,
author = {Ghosh, Saptarshi and Ghosh, Kripabandhu and Ganguly, Debasis and Chakraborty, Tanmoy and Jones, Gareth J.F. and Moens, Marie-Francine},
title = {ECIR 2017 Workshop on Exploitation of Social Media for Emergency Relief and Preparedness (SMERP 2017)},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/3130332.3130338},
doi = {10.1145/3130332.3130338},
abstract = {The first international workshop on Exploitation of Social Media for Emergency Relief and Preparedness (SMERP) was held in conjunction with the 2017 European Conference on Information Retrieval (ECIR) in Aberdeen, Scotland, UK. The aim of the workshop was to explore various technologies for extracting useful information from social media content in disaster situations. The workshop included a peer-reviewed research paper track, a data challenge, two keynote talks, and discussion sessions on the relevant open research challenges. This report presents an overview of the workshop, including the motivations behind organizing the workshop, and summaries of the research papers and keynote talks at the workshop. We also reflect on the future directions as inferred from discussion sessions during the workshop},
journal = {SIGIR Forum},
month = aug,
pages = {36–41},
numpages = {6}
}

@article{10.1145/1924475.1924500,
author = {Trieschnigg, Dolf},
title = {Proof of Concept: Concept-Based Biomedical Information Retrieval},
year = {2011},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1924475.1924500},
doi = {10.1145/1924475.1924500},
abstract = {In this thesis we investigate the possibility to integrate domain-specific knowledge into biomedical information retrieval (IR). Recent decades have shown a fast growing interest in biomedical research, reflected by an exponential growth in scientific literature. An important problem for biomedical IR is dealing with the complex and inconsistent terminology encountered in biomedical publications. Dealing with the terminology problem requires domain knowledge stored in terminological resources: controlled indexing vocabularies and thesauri. The integration of this knowledge is, however, far from trivial.The first research theme investigates heuristics for obtaining word-based representations from biomedical text for robust retrieval. We investigated the effect of choices in document preprocessing heuristics on retrieval effectiveness. Document preprocessing heuristics such as stop word removal, stemming, and breakpoint identification and normalization were shown to strongly affect retrieval performance. An effective combination of heuristics was identified to obtain a word-based representation from text for the remainder of this thesis.The second research theme deals with concept-based retrieval. We compared a word-based to a concept-based representation and determined to what extent a manual concept-based representation can be automatically obtained from text. Retrieval based on only concepts was demonstrated to be significantly less effective than word-based retrieval. This deteriorated performance could be explained by errors in the classification process, limitations of the concept vocabularies and limited exhaustiveness of the concept-based document representations. Retrieval based on a combination of word-based and automatically obtained concept-based query representations did significantly improve word-only retrieval.In the third and last research theme we propose a cross-lingual framework for monolingual biomedical IR. In this framework, the integration of a concept-based representation is viewed as a cross-lingual matching problem involving a word-based and concept-based representation language. This framework gives us the opportunity to adopt a large set of established crosslingual information retrieval methods and techniques for this domain. Experiments with basic term-to-term translation models demonstrate that this approach can significantly improve word-based retrieval.Directions for future work are using these concepts for communication between user and retrieval system, extending upon the translation models and extending CLIR-enhanced concept-based retrieval outside the biomedical domain.Available online from http://purl.utwente.nl/publications/72481.},
journal = {SIGIR Forum},
month = jan,
pages = {89},
numpages = {1}
}

@article{10.1145/1147197.1147212,
author = {Doucet, Antoine},
title = {Advanced Document Description, a Sequential Approach},
year = {2006},
issue_date = {June 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1147197.1147212},
doi = {10.1145/1147197.1147212},
abstract = {This dissertation addresses the problems of the extraction, selection and exploitation of word sequences, with a particular focus on the applicability to document collections of any type and written in any language.},
journal = {SIGIR Forum},
month = jun,
pages = {71–72},
numpages = {2},
keywords = {document retrieval, information retrieval, sequential patterns, multi-word units, lexical cohesion, collocations, text data mining, maximal frequent sequences, phrases, information systems, n-grams, automatic indexing, term dependence}
}

@article{10.1145/1480506.1480520,
author = {Murdock, Vanessa and Lalmas, Mounia},
title = {Workshop on Aggregated Search},
year = {2008},
issue_date = {December 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1480506.1480520},
doi = {10.1145/1480506.1480520},
abstract = {The Workshop on Aggregated seeks to define the research problems for aggregated search results, and to build a community of researchers working in this emerging area. Aggregated search addresses the issues of how to select and rank resources, how to present them to a user in such a way that information can be found efficiently and effectively. The aim of the workshop was to encourage discussion and the exchange of ideas about the directions for aggregated search. The workshop presented prototype systems, user studies of existing systems, as well as papers about component technologies.},
journal = {SIGIR Forum},
month = nov,
pages = {80–83},
numpages = {4}
}

@article{10.1145/584449.584455,
author = {Hammer, Joachim},
title = {Report on the ACM Fourth International Workshop on Data Warehousing and OLAP (DOLAP 2001)},
year = {2002},
issue_date = {04/01/2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/584449.584455},
doi = {10.1145/584449.584455},
journal = {SIGIR Forum},
month = apr,
pages = {14–17},
numpages = {4}
}

@article{10.1145/1328964.1328984,
author = {Sanderson, Mark and Sakai, Tetsuya and Kando, Noriko},
title = {EVIA 2007: The First International Workshop on Evaluating Information Access},
year = {2007},
issue_date = {December 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1328964.1328984},
doi = {10.1145/1328964.1328984},
abstract = {The first workshop on Evaluating Information Access was held at the National Institute of Informatics, Tokyo, Japan on May 15th, 2007. It was composed of a five invited speakers and two sessions of refereed papers and posters.},
journal = {SIGIR Forum},
month = dec,
pages = {109–111},
numpages = {3}
}

@article{10.1145/2964797.2964819,
author = {Zhao, Xiaoxue},
title = {Cold-Start Collaborative Filtering},
year = {2016},
issue_date = {June 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2964797.2964819},
doi = {10.1145/2964797.2964819},
abstract = {Collaborative Filtering (CF) is a technique to generate personalised recommendations for a user from a collection of correlated preferences in the past. In general, the effectiveness of CF greatly depends on the amount of available information about the target user and the target item. The cold-start problem, which describes the difficulty of making recommendations when the users or the items are new, remains a great challenge for CF. Traditionally, this problem is tackled by resorting to an additional interview process to establish the user (item) profile before making any recommendations. During this process the user's information need is not addressed. In this thesis, however, we argue that recommendations would be preferably provided right from the beginning. And the goal of solving the cold-start problem should be maximising the overall recommendation utility during all interactions with the recommender system. In other words, we should not distinguish between the informationgathering and recommendation-making phases, but seamlessly integrate them together. This mechanism naturally addresses the cold-start problem as any user (item) can immediately receive sequential recommendations without providing extra information beforehand.This thesis solves the cold-start problem in an interactive setting by focusing on four interconnected aspects. First, we consider a continuous sequential recommendation process with CF and relate it to the exploitation-exploration (EE) trade-off. By employing probabilistic matrix factorization, we obtain a structured decision space and are thus able to leverage several EE algorithms, such as Thompson sampling and upper confidence bounds, to select items. Second, we extend the sequential recommendation process to a batch mode where multiple recommendations are made at each interaction stage. We specifically discuss the case of two consecutive interaction stages, and model it with the partially observable Markov decision process (POMDP) to obtain its exact theoretical solution. Through an indepth analysis of the POMDP value iteration solution, we identify that an exact solution can be abstracted as selecting users (items) that are not only highly relevant to the target according to the initial-stage information, but also highly correlated with other potential users (items) for the next stage. Third, we consider the intra-stage recommendation optimisation and focus on the problem of personalised item diversification. We reformulate the latent factor models using the mean-variance analysis from the portfolio theory in economics. The resulting portfolio ranking algorithm naturally captures the user's interest range and the uncertainty of the user preference by employing the variance of the learned user latent factors, leading to a diversified item list adapted to the individual user. And, finally, we relate the diversification algorithm back to the interactive process by considering inter-stage joint portfolio diversification, where the recommendations are optimised jointly with the user's past preference records.The pdf version of my thesis is available for download at http://discovery.ucl.ac.uk/1474118/.},
journal = {SIGIR Forum},
month = jun,
pages = {99–100},
numpages = {2}
}

@article{10.1145/1480506.1480528,
author = {Esuli, Andrea},
title = {Automatic Generation of Lexical Resources for Opinion Mining: Models, Algorithms and Applications},
year = {2008},
issue_date = {December 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1480506.1480528},
doi = {10.1145/1480506.1480528},
abstract = {Opinion mining is a recent discipline at the crossroads of Information Retrieval and of Computational Linguistics which is concerned not with the topic a document is about, but with the opinion it expresses. It has a rich set of applications, ranging from tracking users' opinions about products or about political candidates as expressed in online forums, to customer relationship management.},
journal = {SIGIR Forum},
month = nov,
pages = {105–106},
numpages = {2}
}

@article{10.1145/792550.792571,
author = {Zhai, ChengXiang},
title = {Risk Minimization and Language Modeling in Text Retrieval Dissertation Abstract},
year = {2002},
issue_date = {Fall 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/792550.792571},
doi = {10.1145/792550.792571},
journal = {SIGIR Forum},
month = sep,
pages = {100–101},
numpages = {2}
}

@article{10.1145/2422256.2422273,
author = {Bendersky, Michael},
title = {Information Retrieval with Query Hypergraphs},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2422256.2422273},
doi = {10.1145/2422256.2422273},
journal = {SIGIR Forum},
month = dec,
pages = {111},
numpages = {1}
}

@article{10.1145/2888422.2888447,
author = {Dalvi, Bhavana Bharat},
title = {Constrained Semi-Supervised Learning in the Presence of Unanticipated Classes},
year = {2016},
issue_date = {December 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2888422.2888447},
doi = {10.1145/2888422.2888447},
abstract = {Traditional semi-supervised learning (SSL) techniques consider the missing labels of unlabeled datapoints as latent/unobserved variables, and model these variables, and the parameters of the model, using techniques like Expectation Maximization (EM). Such semisupervised learning techniques are widely used for Automatic Knowledge Base Construction (AKBC) tasks.We consider two extensions to traditional SSL methods which make it more suitable for a variety of AKBC tasks. First, we consider jointly assigning multiple labels to each instance, with a flexible scheme for encoding constraints between assigned labels: this makes it possible, for instance, to assign labels at multiple levels from a hierarchy. Second, we account for another type of latent variable, in the form of unobserved classes. In open-domain webscale information extraction problems, it is an unrealistic assumption that the class ontology or topic hierarchy we are using is complete. Our proposed framework combines structural search for the best class hierarchy with SSL, reducing the semantic drift associated with erroneously grouping unanticipated classes with expected classes. Together, these extensions allow a single framework to handle a large number of knowledge extraction tasks, including macro-reading, noun-phrase classification, word sense disambiguation, alignment of KBs to wikipedia or on-line glossaries, and ontology extension.To summarize, this thesis argues that many AKBC tasks which have previously been addressed separately can be viewed as instances of single abstract problem: multiview semisupervised learning with an incomplete class hierarchy. In this thesis we present a generic EM framework for solving this abstract task.},
journal = {SIGIR Forum},
month = jan,
pages = {147},
numpages = {1}
}

@article{10.1145/1273221.1273233,
author = {Lu, Jie},
title = {Full-Text Federated Search in Peer-to-Peer Networks},
year = {2007},
issue_date = {June 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1273221.1273233},
doi = {10.1145/1273221.1273233},
abstract = {Peer-to-peer (P2P) networks integrate autonomous computing resources without requiring a central coordinating authority, which makes them a potentially robust and scalable model for providing federated search capability to large-scale networks of text digital libraries. However, P2P networks have so far mostly used simple search techniques based on document names or controlled-vocabulary terms, and provided very limited support for full-text search of document contents.},
journal = {SIGIR Forum},
month = jun,
pages = {121},
numpages = {1}
}

@article{10.1145/1095469.1095473,
title = {Review of "Dictionary of Information Technology, by Dennis Longley and Mitchael Shain", John Wiley and Sons, 1982},
year = {1983},
issue_date = {Fall-Winter 1983-84},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095469.1095473},
doi = {10.1145/1095469.1095473},
abstract = {The North-Holland Publishing Company offers a free copy of their Computer Publications Survey 1983. This 112 page booklet contains summaries of about 180 books and 34 journals. For a free copy write to North-Holland Publishing Company, Attn. Mr. J. Dirtmaat, P.O. Box 1991, 1000 BZ Amsterdam, The Netherlands.},
journal = {SIGIR Forum},
month = sep,
pages = {43},
numpages = {1}
}

@article{10.1145/381984.381986,
author = {Huibers, T. W. C. and Lalmas, M. and van Rijsbergen, C. J.},
title = {Information Retrieval and Situation Theory},
year = {1996},
issue_date = {April 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/381984.381986},
doi = {10.1145/381984.381986},
abstract = {In 1986, Van Rijsbergen suggested a model of an information retrieval system based on logic. We have advocated in earlier work that a logical approach should be based on a theory of information, Situation Theory, which provides a powerful range of concepts, and is useful for modelling documents and queries for the purpose of information retrieval. We also showed that Situation Theory provides a framework to represent different types of information retrieval models, thus allowing speculation on their properties and their characterization language. This paper is an essay to convince the reader that Situation Theory presents many characteristics that are both adequate and appropriate for the modelling and the study of information retrieval.},
journal = {SIGIR Forum},
month = apr,
pages = {11–25},
numpages = {15}
}

@article{10.1145/2964797.2964818,
author = {Whiting, Stewart},
title = {Temporal Dynamics in Information Retrieval},
year = {2016},
issue_date = {June 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2964797.2964818},
doi = {10.1145/2964797.2964818},
abstract = {Since time is an omnipresent feature of our existence, many elements of time are embedded in information itself, and related behaviours such as creation, seeking and utilisation. In IR, time can distinguish the interpretation of information, and influence the intentions and expectations of users' information seeking activity. Many time-based patterns and trends - namely temporal dynamics - are evident in streams of information behaviour by individuals and crowds. A temporal dynamic refers to a periodic regularity, or, a one-off or irregular past, present or future of a particular element (e.g., word, topic or query popularity) - driven by predictable and unpredictable time-based events and phenomena.Several challenges and opportunities related to temporal dynamics emerge in IR. This thesis explores temporal dynamics from the perspective of (i) query popularity and meaning, and (ii) word use and relationships over time. In particular, I consider how real-time temporal dynamics in information seeking should be supported for consistent user satisfaction over time, and moreover, how previously observed temporal dynamics offer a complementary dimension which can be exploited to inform more effective IR systems.Uncertainty about user expectations is a perennial problem for IR systems, further confounded by changes over time. Addressing this, IR systems can either assist the user to submit an effective query (e.g., error-free and descriptive), or better anticipate what the user is most likely to want in relevance ranking. I first explore methods to always help users formulate queries with time-aware query auto-completion capable of suggesting both recent and always popular queries. I propose and evaluate several novel approaches, and demonstrate state-of-the-art performance of up to +9.2% improvement above existing baselines for diverse search scenarios in different languages. Furthermore, I explore the impact of temporal dynamics on the motives behind users' information seeking, and thus how relevance itself is subject to temporal dynamics. I find the most likely meaning of ambiguous queries is affected over short and long-term periods (e.g., hours to months) by several periodic and oneoff event-driven temporal dynamics. Finally, I find that for many event-driven multi-faceted queries, relevance can often be inferred by modelling the temporal dynamics of changes in related information.IR approaches are typically based on methods which characterize the nature of information through the statistical distributions of words and phrases. I model and exploit the temporal dimension of the collection, captured by temporal dynamics, in these established IR approaches. I explore how the temporal dynamic similarity of word and phrase use in a collection can be exploited to infer temporal semantic relationships between the terms. I propose an approach to uncover a query topic's "chronotype" terms -- that is, its most distinctive and temporally interdependent terms, based on a mix of temporal and non-temporal evidence. Experiments demonstrate that exploiting chronotype terms in temporal query expansion leads to significantly improved retrieval performance in several time-based collections.Temporal dynamics provide both a challenge and an opportunity for IR systems. Overall, this thesis demonstrates that temporal dynamics can be used to derive tacit structure and meaning of information and information behaviour, which is valuable for improving timeaware IR system effectiveness.},
journal = {SIGIR Forum},
month = jun,
pages = {97–98},
numpages = {2}
}

@article{10.1145/2964797.2964817,
author = {Schuth, Anne},
title = {Search Engines That Learn from Their Users},
year = {2016},
issue_date = {June 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2964797.2964817},
doi = {10.1145/2964797.2964817},
abstract = {More than half the world's population uses web search engines, resulting in over half a billion queries every single day. For many people, web search engines such as Baidu, Bing, Google, and Yandex are among the first resources they go to when a question arises. Moreover, for many search engines have become the most trusted route to information, more so even than traditional media such as newspapers, news websites or news channels on television. What web search engines present people with greatly influences what they believe to be true and consequently it influences their thoughts, opinions, decisions, and the actions they take. With this in mind two things are important, from an information retrieval research perspective. First, it is important to understand how well search engines (rankers) perform and secondly this knowledge should be used to improve them. This thesis is about these two topics: evaluation of search engines and learning search engines.In the first part of this thesis we investigate how user interactions with search engines can be used to evaluate search engines. In particular, we introduce a new online evaluation paradigm called multileaving that extends upon interleaving. With multileaving, many rankers can be compared at once by combining document lists from these rankers into a single result list and attributing user interactions with this list to the rankers. Then we investigate the relation between A/B testing and interleaved comparison methods. Both studies lead to much higher sensitivity of the evaluation methods, meaning that fewer user interactions are required to arrive at reliable conclusions. This has the important implication that fewer users need to be exposed to the results from possibly inferior search engines.In the second part of this thesis we turn to online learning to rank. We learn from the evaluation methods introduced and extended upon in the first part. We learn the parameters of base rankers based on user interactions. Then we use the multileaving methods as feedback in our learning method, leading to much faster convergence than existing methods. Again, the important implication is that fewer users need to be exposed to possibly inferior search engines as they adapt more quickly to changes in user preferences. The last part of this thesis is of a different nature than the earlier two parts. As opposed to the earlier chapters, we no longer study algorithms. Progress in information retrieval research has always been driven by a combination of algorithms, shared resources, and evaluation.In the last part we focus on the latter two. We introduce a new shared resource and a new evaluation paradigm. Firstly, we propose Lerot. Lerot is an online evaluation framework that allows us to simulate users interacting with a search engine. Our implementation has been released as open source software and is currently being used by researchers around the world. Secondly we introduce OpenSearch, a new evaluation paradigm involving real users of real search engines. We describe an implementation of this paradigm that has already been widely adopted by the research community through challenges at CLEF and TREC.},
journal = {SIGIR Forum},
month = jun,
pages = {95–96},
numpages = {2}
}

@article{10.1145/2492189.2492201,
author = {Jonassen, Simon},
title = {Efficient Query Processing in Distributed Search Engines},
year = {2012},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2492189.2492201},
doi = {10.1145/2492189.2492201},
abstract = {Web search engines have to deal with a rapidly increasing amount of information, high query loads and tight performance constraints. The success of a search engine depends on the speed with which it answers queries (efficiency) and the quality of its answers (effectiveness). These two metrics have a large impact on the operational costs of the search engine and the overall user satisfaction, which determine the revenue of the search engine. In this context, any improvement in query processing efficiency can reduce the operational costs and improve user satisfaction, hence improve the overall benefit.In this thesis, we elaborate on query processing efficiency, address several problems within partitioned query processing, pruning and caching and propose several novel techniques:First, we look at term-wise partitioned indexes and address the main limitations of the state-of-the-art query processing methods. Our first approach combines the advantage of pipelined and traditional (non-pipelined) query processing. This approach assumes one disk access per posting list and traditional term-at-a-time processing. For the second approach, we follow an alternative direction and look at document-at-a-time processing of sub-queries and skipping. Subsequently, we present several skipping extensions to pipelined query processing, which as we show can improve the query processing performance and/or the quality of results. Then, we extend one of these methods with intra-query parallelism, which as we show can improve the performance at low query loads.Second, we look at skipping and pruning optimizations designed for a monolithic index. We present an efficient self-skipping inverted index designed for modern index compression methods and several query processing optimizations. We show that these optimizations can provide a significant speed-up compared to a full (non-pruned) evaluation and reduce the performance gap between disjunctive (OR) and conjunctive (AND) queries. We also propose a linear programming optimization that can further improve the I/O, decompression and computation efficiency of Max-Score.Third, we elaborate on caching in Web search engines in two independent contributions. First, we present an analytical model that finds the optimal split in a static memory-based two-level cache. Second, we present several strategies for selecting, ordering and scheduling prefetch queries and demonstrate that these can improve the efficiency and effectiveness of Web search engines.We carefully evaluate our ideas either using a real implementation or by simulation using real-world text collections and query logs. Most of the proposed techniques are found to improve the state-of-the-art in the conducted empirical studies. However, the implications and applicability of these techniques in practice need further evaluation in real-life settings.This dissertation was completed at the Department of Computer and Information Science at the Norwegian University of Science and Technology (NTNU) under advise of Prof. Svein Erik Bratsberg, Dr. \O{}ystein Torbj\o{}rnsen and Dr. Magnus Lie Hetland. Some of the work was done in collaboration with Yahoo! Research Barcelona and mentored by Prof. Ricardo Baeza-Yates and Dr. B. Barla Cambazoglu. Prof. Alistair Moffat (University of Melbourne), Dr. Christina Lioma (University of Copenhagen) and Prof. Kjell Bratsbergsengen (NTNU) served as dissertation committee member.Available online at: http://www.idi.ntnu.no/research/doctor_theses/simonj.pdf.},
journal = {SIGIR Forum},
month = jun,
pages = {60–61},
numpages = {2}
}

@article{10.1145/1067268.1067276,
author = {Chen, Shu-Ching and Shyu, Mei-Ling},
title = {The Second ACM International Workshop on Multimedia Databases (MMDB 2004) Held at ACM CIKM 2004},
year = {2005},
issue_date = {June 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1067268.1067276},
doi = {10.1145/1067268.1067276},
abstract = {The Second ACM International Workshop on Multimedia Databases was held in Washington, DC, USA, November 13, 2004. Its aim is to bring together university researchers, scientists, industry professionals, software engineers and graduate students who need to become acquainted with new theories and technologies in multimedia databases, and to all those who wish to gain a detailed technical understanding of what multimedia databases involve.},
journal = {SIGIR Forum},
month = jun,
pages = {26–30},
numpages = {5}
}

@article{10.1145/1670598.1670609,
author = {Sakai, Tetsuya and Sanderson, Mark and Kando, Noriko},
title = {EVIA 2008: The Second International Workshop on Evaluating Information Access},
year = {2009},
issue_date = {June 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1670598.1670609},
doi = {10.1145/1670598.1670609},
abstract = {The Second International Workshop on Evaluating Information Access (EVIA 2008) was held at the National Institute of Informatics, Tokyo, Japan on December 16th, 2008. It was composed of sessions covering various aspects of information access evaluation and featured eleven refereed regular and short papers and two unrefereed very short" papers.},
journal = {SIGIR Forum},
month = jun,
pages = {56–62},
numpages = {7}
}

@article{10.1145/1328964.1328989,
author = {Leidner, Jochen L.},
title = {Toponym Resolution in Text: Annotation, Evaluation and Applications of Spatial Grounding},
year = {2007},
issue_date = {December 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1328964.1328989},
doi = {10.1145/1328964.1328989},
abstract = {In Information Extraction (IE), processing of named entities in text has traditionally been seen as a two-step process comprising a flat text span recognition sub-task and an atomic classification sub-task; relating the text span to a model of the world has been ignored by evaluations such as DARPA/NIST's MUC or ACE. However, spatial and temporal expressions refer to events in space-time, and the grounding of events is a precondition for accurate reasoning. Thus, automatic grounding can improve many applications such as automatic map drawing (e.g. for choosing a focus) and question answering (e.g., for questions like How far is London from Edinburgh, given a story in which both occur and can be resolved). Whereas temporal grounding has received considerable attention in the recent Past [2, 3], robust spatial grounding has long been neglected. Concentrating on geographic names for populated places, I define the task of automatic Toponym Resolution (TR) as computing the mapping from occurrences of names for places as found in a text to a representation of the extensional semantics of the location referred to (its referent), such as a geographic latitude/longitude footprint. The task of mapping from names to locations is hard due to insufficient and noisy databases, and a large degree of ambiguity: common words need to be distinguished from proper names (geo/non-geo ambiguity), and the mapping between names and locations is ambiguous London can refer to the capital of the UK or to London, Ontario, Canada, or to about forty other Londons on earth). In addition, names of places and the boundaries referred to change over time, and databases are incomplete.},
journal = {SIGIR Forum},
month = dec,
pages = {124–126},
numpages = {3}
}

@article{10.1145/1067268.1067284,
author = {Geva, Shlomo and Sahama, Tony},
title = {The NLP Task at INEX 2004},
year = {2005},
issue_date = {June 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1067268.1067284},
doi = {10.1145/1067268.1067284},
abstract = {The INEX workshop is concerned with Evaluating the effectiveness of XML retrieval systems. In 2004 a natural language query task was added to the INEX Ad hoc track. Standard INEX Ad hoc topic titles are specified in NEXI -- a simplified and restricted subset of XPath, with a similar feel, and yet with a distinct IR flavour and interpretation. The syntax of NEXI is rigid and it imposes some limitations on the kind of information need that it can faithfully capture. At INEX 2004 the NLP question to be answered was simple -- is it practical to use a natural language query that is the equivalent of the formal NEXI title? The results of this experiment are reported and some information on the future direction of the NLP task is presented.},
journal = {SIGIR Forum},
month = jun,
pages = {50–53},
numpages = {4}
}

@article{10.1145/1113343.1113359,
author = {Petratos, Panagiotis},
title = {A Heuristic Information Retrieval Study: An Investigation of Methods for Enhanced Searching of Distributed Data Objects Exploiting Bidirectional Relevance Feedback},
year = {2005},
issue_date = {December 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1113343.1113359},
doi = {10.1145/1113343.1113359},
journal = {SIGIR Forum},
month = dec,
pages = {58},
numpages = {1}
}

@article{10.1145/43936.43937,
author = {Meadow, Charles T.},
title = {Comment on Some Recent Comments on Information Retrieval},
year = {1988},
issue_date = {Fall 1987/Winter 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/43936.43937},
doi = {10.1145/43936.43937},
abstract = {This paper presents some opinions on how the human user's understanding of the content and meaning of records and of the criteria for reterieval must be considered in formulating a complete theory of information reterieval.},
journal = {SIGIR Forum},
month = jan,
pages = {5–8},
numpages = {4}
}

@article{10.1145/1924475.1924496,
author = {Hopfgartner, Frank},
title = {Personalised Video Retrieval: Application of Implicit Feedback and Semantic User Profiles},
year = {2011},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1924475.1924496},
doi = {10.1145/1924475.1924496},
abstract = {A challenging problem in the user profiling domain is to create profiles of users of retrieval systems. This problem even exacerbates in the multimedia domain. Due to the Semantic Gap, the difference between low-level data representation of videos and the higher concepts users associate with videos, it is not trivial to understand the content of multimedia documents and to find other documents that the users might be interested in. A promising approach to ease this problem is to set multimedia documents into their semantic contexts. The semantic context can lead to a better understanding of the personal interests. Knowing the context of a video is useful for recommending users videos that match their information need. By exploiting these contexts, videos can also be linked to other, contextually related videos. From a user profiling point of view, these links can be of high value to recommend semantically related videos, hence creating a semantic-based user profile. This thesis introduces a semantic user profiling approach for news video retrieval, which exploits a generic ontology to put news stories into its context.Major challenges which inhibit the creation of such semantic user profiles are the identification of user's long-term interests and the adaptation of retrieval results based on these personal interests. Most personalisation services rely on users explicitly specifying preferences, a common approach in the text retrieval domain. By giving explicit feedback, users are forced to update their need, which can be problematic when their information need is vague. Furthermore, users tend not to provide enough feedback on which to base an adaptive retrieval algorithm. Deviating from the method of explicitly asking the user to rate the relevance of retrieval results, the use of implicit feedback techniques helps by learning user interests unobtrusively. The main advantage is that users are relieved from providing feedback. A disadvantage is that information gathered using implicit techniques is less accurate than information based on explicit feedback.},
journal = {SIGIR Forum},
month = jan,
pages = {84–85},
numpages = {2}
}

@article{10.1145/2888422.2888449,
author = {Qureshi, Muhammad Atif},
title = {Utilising Wikipedia for Text Mining Applications},
year = {2016},
issue_date = {December 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2888422.2888449},
doi = {10.1145/2888422.2888449},
abstract = {The process whereby inferences are made from textual data is broadly referred to as text mining. In order to ensure the quality and effectiveness of the derived inferences, several approaches have been proposed for different text mining applications. Among these applications, classifying a piece of text into pre-defined classes through the utilisation of training data falls into supervised approaches while arranging related documents or terms into clusters falls into unsupervised approaches. In both these approaches, processing is undertaken at the level of documents to make sense of text within those documents. Recent research efforts have begun exploring the role of knowledge bases in solving the various problems that arise in the domain of text mining. Of all the knowledge bases, Wikipedia on account of being one of the largest human-curated, online encyclopaedia has proven to be one of the most valuable resources in dealing with various problems in the domain of text mining. However, previous Wikipedia-based research efforts have not taken both Wikipedia categories and Wikipedia articles together as a source of information.This thesis serves as a first step in eliminating this gap and throughout the contributions made in this thesis, we have shown the effectiveness of Wikipedia category-article structure for various text mining tasks. Wikipedia categories are organized in a taxonomical manner serving as semantic tags for Wikipedia articles and this provides a strong abstraction and expressive mode of knowledge representation. In this thesis, we explore the effectiveness of this mode of Wikipedia's expression (i.e., the category-article structure) via its application in the domains of text classification, subjectivity analysis (via a notion of "perspective" in news search), and keyword extraction.First, we show the effectiveness of exploiting Wikipedia for two classification tasks i.e., 1- classifying the tweets1 being relevant/irrelevant to an entity or brand, 2- classifying the tweets into different topical dimensions such as tweets related with workplace, innovation, etc. To do so, we define the notion of relatedness between the text in tweet and the information embedded within the Wikipedia category-article structure. Then, we present an application in the area of news search by using the same notion of relatedness to show more information related to each search result highlighting the amount perspective or subjective bias in each returned result towards a certain opinion, topical drift, etc. Finally, we present a keyword extraction strategy using community detection over the Wikipedia categories to discover related keywords arranged in different communities.The relationship between Wikipedia categories and articles is explored via a textual phrase matching framework whereby the starting point is textual phrases that match Wikipedia articles' titles/redirects. The Wikipedia articles for which a match occurs are then utilised by extraction of their associated categories, and these Wikipedia categories are used to derive various structural measures such as those relating to taxonomical depth and Wikipedia articles they contain. These measures are utilised in our proposed text classification, subjectivity analysis, and keyword extraction framework and the performance is analysed via extensive experimental evaluations. These experimental evaluations undertake comparisons with standard text mining approaches in the literature and our Wikipedia framework based on its category-article structure outperforms the standard text mining techniques.},
journal = {SIGIR Forum},
month = jan,
pages = {150–151},
numpages = {2}
}

@article{10.1145/2492189.2492206,
author = {Zuccon, Guido},
title = {Document Ranking with Quantum Probabilities},
year = {2012},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2492189.2492206},
doi = {10.1145/2492189.2492206},
abstract = {In this thesis we investigate the use of quantum probability theory for ranking documents. Quantum probability theory is used to estimate the probability of relevance of a document given a user's query. We posit that quantum probability theory can lead to a better estimation of the probability of a document being relevant to a user's query than the common IR approach, i. e. the Probability Ranking Principle (PRP), which is based upon Kolmogorovian probability theory. Following our hypothesis, we formulate an analogy between the document retrieval scenario and a physical scenario, that of the double slit experiment. Through the analogy, we propose a novel ranking approach, the quantum probability ranking principle (qPRP). Key to our proposal is the presence of quantum interference. Mathematically, this is the statistical deviation between empirical observations and expected values predicted by the Kolmogorovian rule of additivity of probabilities of disjoint events in configurations such that of the double slit experiment. While PRP explicitly assumes that the relevancy of a document is independent of that of other documents, we suggest that qPRP implicitly models interdependent document relevance through quantum interference and thus is suited to those document ranking tasks where the independence assumption fails. Throughout the thesis, we also suggest how quantum interference can be estimated for effective document ranking.To validate our proposal and to gain more insights about approaches for document ranking, we (1) analyse PRP, qPRP and other ranking approaches, exposing the assumptions underlying their ranking criteria and formulating the conditions for the optimality of the two ranking principles, (2) empirically compare three ranking principles (i. e. PRP, interactive PRP, and qPRP) and two state-of-the-art ranking strategies in two retrieval scenarios, those of ad-hoc retrieval and diversity retrieval, (3) analytically contrast the ranking criteria of the examined approaches, exposing similarities and differences, (4) study the ranking behaviours of approaches alternative to PRP in terms of the kinematics they impose on relevant documents, i. e. by considering the extent and direction of the movements of relevant documents across the ranking recorded when comparing PRP against its alternatives.Our findings show that the effectiveness of the examined ranking approaches strongly depends upon the evaluation context. In the traditional evaluation context of ad-hoc retrieval, PRP is empirically shown to be better than or comparable to alternative ranking approaches. However, when evaluation contexts that account for interdependent document relevance are examined (i. e. when the relevance of a document is assessed also with respect to other retrieved documents, as it is the case in the diversity retrieval scenario), the use of quantum probability theory and thus of qPRP is shown to improve retrieval and ranking effectiveness over the traditional PRP and alternative ranking strategies, such as Maximal Marginal Relevance, Portfolio theory, and Interactive PRP.This work represents a significant step forward regarding the use of quantum theory in information retrieval. It demonstrates that the application of quantum theory to problems within information retrieval can lead to improvements both in modelling power and retrieval effectiveness, allowing the constructions of models that capture the complexity of information retrieval situations.Furthermore, the thesis opens up a number of lines of future research. These include investigating estimations and approximations of quantum interference in qPRP, exploiting complex numbers for the representation of documents and queries, and applying the concepts underlying qPRP to tasks other than document ranking. This dissertation was completed at School of Computing Science, University of Glasgow under the advise of Dr. Leif Azzopardi and Prof. Keith van Rijsbergen. Prof. Norbert Fuhr, Dr. Iadh Ounis, and Dr. John O'Donnell served as dissertation committee members. For the full dissertation, visit: http://theses.gla.ac.uk/3463.},
journal = {SIGIR Forum},
month = jun,
pages = {69–70},
numpages = {2}
}

@article{10.1145/1095325.1095326,
author = {Schuster, S. A. and Ozkarahan, E. A. and Smith, K. C.},
title = {Abstracts},
year = {1976},
issue_date = {Winter 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095325.1095326},
doi = {10.1145/1095325.1095326},
abstract = {The Relational Associative Processor (RAP) is an experimental "backend" cellular processor for implementing data base management systems. RAP is particularly well suited to supporting Codd's relational model of data. The capacity of a RAP device implemented with current IC and memory technology can be estimated to contain 10E8 to 10E9 bits of associatively processable data. Because many data bases are larger, a virtual memory environment for RAP has been proposed and its performance simulated. The environment incorporates conventional memories for bulk storage and a single RAP processor - both controlled by a general purpose front-end computer. The system requires that the entire relational data base be divided into pages of size equal to one RAP cell memory. A buffer memory is added to RAP to permit the overlap of paging with processing. It has been found that user environments containing small relations or queries exhibiting either long processing times relative to paging requirements or some "locality" (defined as the degree to which sequences of queries reference some relations more than others) can efficiently page data between large data bases and data base machines without significant losses in performance.},
journal = {SIGIR Forum},
month = dec,
pages = {6–11},
numpages = {6}
}

@article{10.1145/1480506.1480529,
author = {Freund, Luanne},
title = {Exploiting Task-Document Relations in Support of Information Retrieval in the Workplace},
year = {2008},
issue_date = {December 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1480506.1480529},
doi = {10.1145/1480506.1480529},
abstract = {Increasingly, workplace information seeking takes place in digital information environments and is reliant upon search systems. Existing systems are designed to retrieve information that is relevant to the query, but are not capable of identifying information that is well-suited to the context and situation of a search. This is a problem for professionals who often are searching for a small amount of useful information that can be applied to a problem or task, and have limited time to browse through large sets of results. This inability of search systems to discriminate between topically relevant and useful documents is one of the core problems in information retrieval.},
journal = {SIGIR Forum},
month = nov,
pages = {107},
numpages = {1}
}

@article{10.1145/1328964.1328990,
author = {Murdock, Vanessa},
title = {Aspects of Sentence Retrieval},
year = {2007},
issue_date = {December 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1328964.1328990},
doi = {10.1145/1328964.1328990},
abstract = {Sentence Retrieval is the task of retrieving a relevant sentence in response to a query, a question, or a reference sentence. Tasks such as question answering, summarization, novelty detection, and information provenance make use of a sentence-retrieval module as a preprocessing step. The performance of these systems is dependent on the quality of the sentence-retrieval module. Other tasks such as information extraction and machine translation operate on sentences, either using them as training data, or as the unit of input or output (or both), and may benefit from sentence retrieval to build a training corpus, or as a post-processing step.},
journal = {SIGIR Forum},
month = dec,
pages = {127},
numpages = {1}
}

@article{10.1145/381258.381260,
author = {Voorhees, Ellen M.},
title = {Report on TREC-9},
year = {2000},
issue_date = {Fall 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/381258.381260},
doi = {10.1145/381258.381260},
journal = {SIGIR Forum},
month = sep,
pages = {1–8},
numpages = {8}
}

@article{10.1145/3274784.3274801,
author = {Jorge, Al\'{\i}pio and Campos, Ricardo and Jatowt, Adam and Nunes, S\'{e}rgio and Rocha, Concei\c{c}\~{a}o and Cordeiro, Jo\~{a}o Paulo and Pasquali, Arian and Mangaravite, Vitor},
title = {ECIR 2018: Text2Story Workshop - Narrative Extraction from Texts},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/3274784.3274801},
doi = {10.1145/3274784.3274801},
abstract = {The 1st International Workshop on Narrative Extraction from Texts (Text2Story 2018) was held in conjunction with the 40th European Conference on Information Retrieval, ECIR 2018, Grenoble on the 26 th March 2018. The workshop aimed to help foster the collaboration of researchers on a wide range of multidisciplinary issues related to the text-to-narrativestructure. The program consisted of two keynote talks, six research presentations, a poster session and a slot for demo presentations. This report briefly summarizes the workshop. More information about the workshop is available at http://text2story18.inesctec.pt},
journal = {SIGIR Forum},
month = aug,
pages = {150–152},
numpages = {3}
}

@article{10.1145/1394251.1394262,
author = {Alonso, Omar and Zaragoza, Hugo},
title = {Exploiting Semantic Annotations in Information Retrieval: ESAIR '08},
year = {2008},
issue_date = {June 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1394251.1394262},
doi = {10.1145/1394251.1394262},
abstract = {The following report summarizes the highlights of the first workshop on exploiting semantic annotations in information retrieval (ESAIR '08). The workshop format included paper and demo presentations as well as breakout sessions and a panel discussion.},
journal = {SIGIR Forum},
month = jun,
pages = {55–58},
numpages = {4}
}

@article{10.1145/1147197.1147203,
author = {Nottelmann, Henrik and Aberer, Karl and Callan, Jamie and Nejdl, Wolfgang},
title = {The CIKM 2005 Workshop on Information Retrieval in Peer-to-Peer Networks},
year = {2006},
issue_date = {June 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1147197.1147203},
doi = {10.1145/1147197.1147203},
abstract = {Peer-to-peer (P2P) networks have emerged as a popular way to build large scale information systems by using the principle of resource sharing. The P2P paradigm holds many promises, e.g. scalability, failure resilience and increased autonomy of nodes. For these reasons P2P seems also to be an interesting architectural paradigm for realizing large scale information retrieval systems. However, search methods in P2P networks are still mostly limited to simple keyword queries and the use of advanced retrieval models is in its infancy.},
journal = {SIGIR Forum},
month = jun,
pages = {38–40},
numpages = {3}
}

@article{10.1145/2093346.2093362,
author = {Agosti, Maristella and De Luca, Ernesto William and Lawless, S\'{e}amus and Leveling, Johannes},
title = {PMHR 2011: The First Workshop on Personalised Multilingual Hypertext Retrieval},
year = {2012},
issue_date = {December 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2093346.2093362},
doi = {10.1145/2093346.2093362},
journal = {SIGIR Forum},
month = jan,
pages = {94–98},
numpages = {5}
}

@article{10.1145/3053408.3053429,
author = {Sappelli, Maya},
title = {Knowledge Work in Context: User Centered Knowledge Worker Support},
year = {2017},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3053408.3053429},
doi = {10.1145/3053408.3053429},
abstract = {There is an increase in stress during the job. This can lead to health issues such as burn-out for employees. In the SWELL project (http://www.swell-project.net) we investigate intelligent ICT solutions that can support knowledge workers to achieve a healthy way of living at work and at home.One of the causes of stress at work is the problem of 'information overload'. The availability of smartphones and tables with continuous internet access causes individuals to become overwhelmed with information. It becomes more difficult to separate work and home, but also to find the information you need to execute your work properly.A possible solution to this problem is to make application more 'context-aware'. This means that the application understands what a person is doing, such that it can provide the optimal support at the optimal time. This is the underlying motivation for this thesis.This thesis consists of three parts. In the first part we discuss the question "How can we design, develop and evaluate context-aware methods that make knowledge work more effective and efficient?" To answer this question, we have observed knowledge workers during their activities and collected data about their behavior. From these we can conclude that many intentions and goals of the knowledge worker are implicit, and cannot be recognized easily [1,4]. We can, however, get a feeling of the knowledge worker's intentions by observing his interactions with the computer (i.e. key presses and mouse activity). The challenge in this type of data is that it contains a significant amount of noise.In the second part of the thesis we model the context that is necessary to support the knowledge worker in a context-aware manner. The context model is dynamic and driven by events in the surroundings of the knowledge worker. The knowledge worker is in the center of the model, but the context also influences the knowledge worker himself. The context can be observed with sensors that are independent from the knowledge worker, but the interpretation of the context can only be achieved in combination with the knowledge worker.In this part we also describe the Contextual Interactive Activation Model (CIA) that can recognize the context of the knowledge worker automatically based on his or her interactions with the computer [2]. Based purely on data, without intervention by a user, it can already recognize the user's context. Enhanced with only a few example it can also identify the context, meaning that it can put a label on it, for example project 'Dissertation'.In the final part of the thesis we describe algorithms that support knowledge workers while requiring little user input. One of the application is the categorization of e-mail messages, for example based on whether they need to be replied to or not, or based on which project the message belongs to. For this later categorization problem, we use an adapted version of CIA [2]. The advantage of CIA is that it requires less training examples than existing methods. In another application we use CIA to find documents without the need for a query [5]. We describe the requirements for evaluation of these kind of recommendation systems and conclude that a multidimensional evaluation is important. Each method has its own benefits and issues and the best method is dependent on the user's priorities.The main limitation of the thesis is that it is explorative in nature. Little data was available to test our methods and hypotheses; therefore, the conclusions cannot be generalized easily. This illustrates the need to collect more datasets that reflect the complexity of the knowledge worker, his tasks and his context. Future research need to investigate the effect of using context-aware applications on the knowledge worker's well-being. One of the remaining question is which supporting application to use at which time. In an ideal case we can combine these methods and application to support the knowledge worker in such a way that he or she is not required to put in a lot of effort.},
journal = {SIGIR Forum},
month = feb,
pages = {107–108},
numpages = {2}
}

@article{10.1145/2964797.2964811,
author = {Calumby, Rodrigo Tripodi},
title = {Diversity-Oriented Multimodal and Interactive Information Retrieval},
year = {2016},
issue_date = {June 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2964797.2964811},
doi = {10.1145/2964797.2964811},
abstract = {Information retrieval methods, especially considering multimedia data, have evolved towards the integration of multiple sources of evidence in the analysis of the relevance of the items considering a given user search task. In this context, for attenuating the semantic gap between low-level features extracted from the content of the digital objects and high-level semantic concepts (objects, categories, etc.) and making the systems adaptive to different user needs, interactive models have brought the user closer to the retrieval loop allowing user-system interaction mainly through implicit or explicit relevance feedback. Analogously, diversity promotion has emerged as an alternative for tackling ambiguous or underspecified queries. Additionally, several works have addressed the issue of minimizing the required user effort on providing relevance assessments while keeping an acceptable overall effectivenessThis thesis discusses, proposes, and experimentally analyzes multimodal and interactive diversity-oriented information retrieval methods. This work, comprehensively covers the interactive information retrieval literature and also discusses about recent advances, the great research challenges, and promising research opportunities. We have proposed and evaluated two relevancediversity trade-off enhancement work-flows, which integrate multiple information from images, such as: visual features, textual metadata, geographic information, and user credibility descriptors. In turn, as an integration of interactive retrieval and diversity promotion techniques, for maximizing the coverage of multiple query interpretations/aspects and speeding up the information transfer between the user and the system, we have proposed and evaluated a multimodal online learning-to-rank method trained with relevance feedback over diversified resultsOur experimental analysis shows that the joint usage of multiple information sources positively impacted the relevance-diversity balancing algorithms. Our results also suggest that the integration of multimodal-relevance-based filtering and reranking is effective on improving result relevance and also boosts diversity promotion methods. Beyond it, with a thorough experimental analysis we have investigated several research questions related to the possibility of improving result diversity and keeping or even improving relevance in interactive search sessions. Moreover, we analyze how much the diversification effort affects overall search session results and how different diversification approaches behave for the different data modalities. By analyzing the overall and per feedback iteration effectiveness, we show that introducing diversity may harm initial results whereas it significantly enhances the overall session effectiveness not only considering the relevance and diversity, but also how early the user is exposed to the same amount of relevant items and diversity},
journal = {SIGIR Forum},
month = jun,
pages = {86},
numpages = {1}
}

@article{10.1145/1067268.1067297,
author = {White, Ryen W.},
title = {Implicit Feedback for Interactive Information Retrieval},
year = {2005},
issue_date = {June 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1067268.1067297},
doi = {10.1145/1067268.1067297},
abstract = {Searchers can find the construction of query statements for submission to Information Retrieval (IR) systems a problematic activity. These problems are confounded by uncertainty about the information they are searching for, or an unfamiliarity with the retrieval system being used or collection being searched. On the World Wide Web these problems are potentially more acute as searchers receive little or no training in how to search effectively. Relevance feedback (RF) techniques allow searchers to directly communicate what information is relevant and help them construct improved query statements. However, the techniques require explicit relevance assessments that intrude on searchers' primary lines of activity and as such, searchers may be unwilling to provide this feedback. Implicit feedback systems are unobtrusive and make inferences of what is relevant based on searcher interaction. They gather information to better represent searcher needs whilst minimising the burden of explicitly reformulating queries or directly providing relevance information.},
journal = {SIGIR Forum},
month = jun,
pages = {70},
numpages = {1}
}

@article{10.1145/986278.986283,
author = {Fukumoto, Junichi and Kato, Tsuneaki and Masui, Fumito},
title = {An Evaluation of Question Answering Challenge (QAC-1) at the NTCIR Workshop 3},
year = {2004},
issue_date = {June 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/986278.986283},
doi = {10.1145/986278.986283},
journal = {SIGIR Forum},
month = jul,
pages = {25–28},
numpages = {4}
}

@article{10.1145/207556.207560,
author = {Grandi, Fabio},
title = {On the Signature Weight in “Multiple” <i>m</i> Signature Files},
year = {1995},
issue_date = {Spring 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/207556.207560},
doi = {10.1145/207556.207560},
abstract = {This paper deals with the estimation of the signature weight as generated by the superimposed coding technique adopted in "multiple" m signature files. The estimation is needed for performance evaluation of such organizations used for information retrieval applications. In particular, simple formulas for the probability density function, the expected value and the variance of the signature weight are presented.The presented formulas can be derived following a general methodology we called the γ-transform approach in a previous work, which results much more simple than the method used by other authors for the derivation of the density function. Equivalence of the results is also shown.},
journal = {SIGIR Forum},
month = mar,
pages = {20–25},
numpages = {6},
keywords = {y-transform, superimposed coding, information retrieval, discrete probability, signature files, estimation}
}

@article{10.1145/122665.122668,
author = {Bruza, P. D. and van der Weide, T. P.},
title = {The Modelling and Retrieval of Documents Using Index Expressions},
year = {1991},
issue_date = {Fall 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/122665.122668},
doi = {10.1145/122665.122668},
abstract = {In this paper we introduce Index Expressions as a means for modelling document content. From an index expression the the Power Index Expression can be derived, which is a powerful instrument for information retrieval. We describe the characterization of documents in the style of formal logic. The content of a document is then modelled by a set of axioms, of which the document is a model. Relating a document to a query is done by proving the query from the axioms of that document. We introduce three rules of inference. If such a proof is not possible, the relevance of the document for the query is derived by plausible deduction. We introduce two inference rules for plausible deduction.},
journal = {SIGIR Forum},
month = sep,
pages = {91–103},
numpages = {13}
}

@article{10.1145/1480506.1480530,
author = {Thomas, Paul},
title = {Server Characterisation and Selection for Personal Metasearch},
year = {2008},
issue_date = {December 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1480506.1480530},
doi = {10.1145/1480506.1480530},
abstract = {A single search interface to all a person's digital resources, such as email archives, corporate databases, websites, and subscription services, is appealing but a central index of all private, corporate, subscription and web data is impractical. A metasearch approach can instead integrate any number of existing search services over a variety of data.},
journal = {SIGIR Forum},
month = nov,
pages = {108–109},
numpages = {2}
}

@article{10.1145/2093346.2093367,
author = {Zhang, Junte},
title = {System Evaluation of Archival Description and Access},
year = {2012},
issue_date = {December 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2093346.2093367},
doi = {10.1145/2093346.2093367},
abstract = {How do archives provide access to their records and let users search? The answer is archival description. Encoded Archival Description (EAD) in Extensible Markup Language (XML) is the de facto technical standard for "electronic" archival descriptions. It is now used to bridge the gulf between tangible records in archives and digital objects on the World WideWeb. These descriptions are finding aids, which are tools to search and find information about, or references to, archival records. The archival finding aids in EAD are left to searchers (out of sight and contact) to explore in unknown ways: how do searchers interact with these finding aids, and what type of retrieval system is needed to support them.The approach is to apply XML retrieval techniques to the EAD finding aids, develop system evaluation of EAD retrieval, and study information seeking behavior of archival search. The main information retrieval (IR) contributions are the system evaluation of an important "real" and domain-specific search task, a study on the usage of transaction logs for deriving domain-specific test collections, an analysis of search behavior in yet unexplored structured documents, and tailoring IR evaluation to specific searcher stereotypes.The first study involves the design and implementation of the archival search engine README. The README system attempts to incorporate current technologies with the archival structure in finding aids---such as XML retrieval---and simultaneously to uphold the archival principles where this structure is based upon. The system is the proof of concept. Having established this baseline, the next study explores and tests the construction of an IR test collection. A test collection is a key component in IR evaluation. The basis of this test collection are the queries and clicks on archival descriptions that can be found in the search log files of the National Archives of the Netherlands. There is no readily-available test collection for evaluating the accuracy of the retrieval of archival descriptions of records by an archival search engine. Manually creating such a collection is expensive. The study shows that automatically creating a test collection seems viable.Archival principles---such as provenance and original order---are deeply rooted in the arrangement and subsequent description of archival records. These principles have been cast on EAD finding aids as well. The investigation continues by shedding new light on them in a system evaluation. Additionally, the experiments probe XML retrieval-specific issues, such as the retrieval of certain elements. The study concludes by reflecting on the README archival search engine, which is the baseline of the probes in this dissertation. How effective are certain archival principles for archival access in this digital age.Using the archival search log files, the research focus shifts to the arrangement of records in EAD and user search behaviors using this arrangement. The sub-document clicks within the finding aids point to the online interaction of users within "electronic" archival descriptions of records. The analysis of the interactions comprises of quantifying the search behavior. This results in a state diagram that captures different information search behaviors of different people. By analyzing real-world interaction, the discussion on the use of the finding aid in this digital age as access tool becomes more complete. The result is more understanding of online archival search behavior within EAD finding aids, which can be used to improve a search system adapted to existing "electronic" archival description.Finally, the system evaluation deals with tailoring a search engine to the different user stereotypes, namely "expert" and 'novice' groups based on the number of times that a user re-uses the system. The results show that although there are significant differences in terms of search behavior, this does not necessarily mean that for more effective retrieval of archival descriptions, the system needs to be adapted to improve access for these different user groups.The doctoral dissertation is available online at http://dare.uva.nl/record/395154.},
journal = {SIGIR Forum},
month = jan,
pages = {109–110},
numpages = {2}
}

@article{10.1145/1924475.1924497,
author = {Ke, Weimao},
title = {Scalability of Findability: Decentralized Search and Retrieval in Large Information Networks},
year = {2011},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1924475.1924497},
doi = {10.1145/1924475.1924497},
abstract = {Amid the rapid growth of information today is the increasing challenge for people to survive and navigate its magnitude. Dynamics and heterogeneity of large information spaces such as the Web challenge information retrieval in these environments. Collection of information in advance and centralization of IR operations are hardly possible because systems are dynamic and information is distributed.While monolithic search systems continue to struggle with scalability problems of today, the future of search likely requires a decentralized architecture where many information systems can participate. As individual systems interconnect to form a global structure, finding relevant information in distributed environments transforms into a problem concerning not only information retrieval but also complex networks. Understanding network connectivity will provide guidance on how decentralized search and retrieval methods can function in these information spaces.The dissertation studies one aspect of scalability challenges facing classic information retrieval models and presents a decentralized, organic view of information systems pertaining to search in large scale networks. It focuses on the impact of network structure on search performance and investigates a phenomenon we refer to as the Clustering Paradox, in which the topology of interconnected systems imposes a scalability limit. Experiments involving large scale benchmark collections provide evidence on the Clustering Paradox in the IR context. In an increasingly large, distributed environment, decentralized searches for relevant information can continue to function well only when systems interconnect in certain ways. Relying on partial indexes of distributed systems, some level of network clustering enables very efficient and effective discovery of relevant information in large scale networks. Increasing or reducing network clustering degrades search performances. Given this specific level of network clustering, search time is well explained by a poly-logarithmic relation to network size, indicating a high scalability potential for searching in a continuously growing information space.},
journal = {SIGIR Forum},
month = jan,
pages = {86},
numpages = {1}
}

@article{10.1145/1924475.1924494,
author = {Aly, Robin},
title = {Modeling Representation Uncertainty in Concept-Based Multimedia Retrieval},
year = {2011},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1924475.1924494},
doi = {10.1145/1924475.1924494},
abstract = {Representing multimedia documents by means of concepts labels attached to parts of these documents has great potential for improving retrieval performance. The reason is that concepts are independent from how users refer to them and from the modality in which they occur. For example, a Flower and une Fleur refers to the same concept and a singing bird can appear in an image or an audio recording. The question whether a concept occurs in a multimedia document is answered by a concept detector. However, as building concept detectors is difficult the current detection performance is low which causes the retrieval engine to be uncertain about the actual document representation.This thesis proposes the Uncertain Document Representation Ranking (URR) Framework which deals with this uncertainty by transferring the principles of the Portfolio Selection Theory in finance where the future win of a share is uncertain to the concept-based retrieval problem. Similarly to the distribution of future wins, the retrieval framework considers multiple possible concept-based document representations for each document resulting in multiple possible scores, which is the main scientific contribution of this thesis. Given an existing retrieval function for a certain representation, documents are ranked by the expected score plus an expression of the score's variance.From the general URR framework, we derive ranking models for shot and video segment retrieval. The shot retrieval and the video segment model re-use the probability of relevance and a language modeling ranking function respectively, basing themselves on decades of text retrieval research. We show in experiments that the models significantly improve performance over several strong baselines in five TRECVid collections.Furthermore, current performance of concept-based multimedia retrieval is low. A major reason for this is the performance of the concept detectors on which the simulation is based. Therefore, we predict the influence of improved concept detectors on general concept-based retrieval performance using Monte Carlo simulations. We find that more effort is needed to improve concept detectors, but it is realistic for concept-based retrieval to reach performance suitable for large-scale, real-life applications in the future.Available at http://doc.utwente.nl/72019/ (or http://robin.aly.de, with errata).},
journal = {SIGIR Forum},
month = jan,
pages = {82},
numpages = {1}
}

@article{10.1145/3308774.3308804,
author = {Lipani, Aldo},
title = {On Biases in Information Retrieval Models and Evaluation},
year = {2019},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3308774.3308804},
doi = {10.1145/3308774.3308804},
abstract = {The advent of the modern information technology has benefited society as the digitization of content increased over the last half-century. While the processing capability of our species has remained unchanged, the information available to us has been notably increasing. In this overload of information, Information Retrieval (IR) has been playing a prominent role by developing systems capable of separating relevant information from the rest. This separation, however, is a difficult task rooted in the complexity of understanding of what is and what is not relevant. To manage this complexity, IR has developed a strong empirical nature, which has led to the development of grounded retrieval models, resulting in the development of retrieval systems empirically designed to be biased towards relevant information. However, other biases have been observed, which counteract retrieval performance. In this thesis, the reduction of retrieval systems to filters of information, or sampling processes, has allowed us to systematically investigate these biases.},
journal = {SIGIR Forum},
month = jan,
pages = {172–173},
numpages = {2}
}

@article{10.1145/3190580.3190605,
author = {Catena, Matteo},
title = {Energy Efficiency in Large Scale Information Retrieval Systems},
year = {2018},
issue_date = {December 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/3190580.3190605},
doi = {10.1145/3190580.3190605},
abstract = {Web search engines are large scale information retrieval systems, which provide easy access to information on the Web. High performance query processing is fundamental for the success of such systems. In fact, web search engines can receive billions of queries per day. Additionally, the issuing users are often impatient and expect sub-second response times to their queries (e.g., 500 ms). For such reasons, search companies adopt distributed query processing strategies to cope with huge volumes of incoming queries and to provide sub-second response times. Web search engines perform distributed query processing on computer clusters composed by thousands of computers and hosted in large data centers. While data center facilities enable large-scale online services, they also raise economical and environmental concerns. Therefore, an important problem to address is how to reduce the energy expenditure of data centers. Moreover, another problem to tackle is how to reduce carbon dioxide emissions and the negative impact of the data centers on the environment. A large part of the energy consumption of a data center could be accounted to inefficiencies in its cooling and power supply systems. However, search companies already adopt state-of-the art techniques to reduce the energy wastage of such systems, leaving little room for more improvements in those areas. Therefore, new approaches are necessary to mitigate the environmental impact and the energy expenditure of web search engines. One option is to reduce the energy consumption of computing resources to mitigate the energy expenditure and carbon footprint of a search company. In particular, reducing the energy consumption of CPUs represents an attractive venue for web search engines. Currently, CPU cores frequencies are typically managed by operating system components, called frequency governors. We propose to delegate the CPU power management from the OS frequency governors to the query processing application [2]. Such search engine-specific governors can reduce up to 24% a server power consumption, with only limited (but uncontrollable) drawbacks in the quality of search results with respect to a system running at maximum CPU frequency. Since users can hardly notice response times that are faster than their expectations we advise that web search engine should not process queries faster than user expectations and, consequently, we propose the Predictive Energy Saving Online Scheduling (PESOS) algorithm, to select the most appropriate CPU frequency to process a query by its deadline, on a per-core basis [3]. PESOS can reduce the CPU energy consumption of a query processing server from 24% up to 48% when compared to a high performance system running at maximum CPU core frequency. To reduce the carbon footprint of web search engines, another option consists in using green energy to partially power their data centers. Stemming from these observations, we propose a new query forwarding algorithm that exploits both the green energy sources available at different data centers and the differences in market energy prices [1]. The proposed solution maintains a high query throughput, while reducing by up to 25% the energy operational costs of multi-center search engines.},
journal = {SIGIR Forum},
month = feb,
pages = {159–160},
numpages = {2}
}

@article{10.1145/2568388.2568411,
author = {Campos, Ricardo},
title = {Disambiguating Implicit Temporal Queries for Temporal Information Retrieval Applications},
year = {2013},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2568388.2568411},
doi = {10.1145/2568388.2568411},
journal = {SIGIR Forum},
month = jan,
pages = {137–138},
numpages = {2}
}

@article{10.1145/2492189.2492205,
author = {Santos, Rodrygo L.T.},
title = {Explicit Web Search Result Diversification},
year = {2012},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2492189.2492205},
doi = {10.1145/2492189.2492205},
abstract = {Queries submitted to a web search engine are typically short and often ambiguous. With the enormous size of the Web, a misunderstanding of the information need underlying an ambiguous query can misguide the search engine, ultimately leading the user to abandon the originally submitted query. In order to overcome this problem, a sensible approach is to diversify the documents retrieved for the user's query. As a result, the likelihood that at least one of these documents will satisfy the user's actual information need is increased.In this thesis, we argue that an ambiguous query should be seen as representing not one, but multiple information needs. Based upon this premise, we propose xQuAD---Explicit Query Aspect Diversification, a novel probabilistic framework for search result diversification. In particular, the xQuAD framework naturally models several dimensions of the search result diversification problem in a principled yet practical manner. To this end, the framework represents the possible information needs underlying a query as a set of keyword-based sub-queries. Moreover, xQuAD accounts for the overall coverage of each retrieved document with respect to the identified sub-queries, so as to rank highly diverse documents first. In addition, it accounts for how well each sub-query is covered by the other retrieved documents, so as to promote novelty--and hence penalise redundancy---in the ranking. The framework also models the importance of each of the identified sub-queries, so as to appropriately cater for the interests of the user population when diversifying the retrieved documents. Finally, since not all queries are equally ambiguous, the xQuAD framework caters for the ambiguity level of different queries, so as to appropriately trade-off relevance for diversity on a per-query basis.The xQuAD framework is general and can be used to instantiate several diversification models, including the most prominent models described in the literature. In particular, within xQuAD, each of the aforementioned dimensions of the search result diversification problem can be tackled in a variety of ways. In this thesis, as additional contributions besides the xQuAD framework, we introduce novel machine learning approaches for addressing each of these dimensions. These include a learning to rank approach for identifying effective subqueries as query suggestions mined from a query log, an intent-aware approach for choosing the ranking models most likely to be effective for estimating the coverage and novelty of multiple documents with respect to a sub-query, and a selective approach for automatically predicting how much to diversify the documents retrieved for each individual query. In addition, we perform the first empirical analysis of the role of novelty as a diversification strategy for web search.As demonstrated throughout this thesis, the principles underlying the xQuAD framework are general, sound, and effective. In particular, to validate the contributions of this thesis, we thoroughly assess the effectiveness of xQuAD under the standard experimentation paradigm provided by the diversity task of the TREC 2009, 2010, and 2011 Web tracks. The results of this investigation demonstrate the effectiveness of our proposed framework. Indeed, xQuAD attains consistent and significant improvements in comparison to the most effective diversification approaches in the literature, and across a range of experimental conditions, comprising multiple input rankings, multiple sub-query generation and coverage estimation mechanisms, as well as queries with multiple levels of ambiguity. Altogether, these results corroborate the state-of-the-art diversification performance of xQuAD.Available online at http://theses.gla.ac.uk/4106/.},
journal = {SIGIR Forum},
month = jun,
pages = {67–68},
numpages = {2}
}

@article{10.1145/1924475.1924501,
author = {Verberne, Suzan},
title = {In Search of the Why: Developing a System for Answering Why-Questions},
year = {2011},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1924475.1924501},
doi = {10.1145/1924475.1924501},
abstract = {The problem of automatically answering natural language questions by pinpointing exact answers in a large text (web) corpus has been studied since the mid 1990s. Most research has been directed at answering factoid questions: questions that expect a short, clearly identifiable answer; usually a named entity such as a person name, location or year. In this dissertation, we have focused on the problem of answering why-questions (why-QA). Whyquestions require a different approach than factoid questions because their answers tend to be longer and more complex. Our main research question was: "What are the possibilities and limitations of an approach to why-QA that uses linguistic information in addition to text retrieval techniques?We first experimented with a simple bag-of-words approach on a set of open-domain whyquestions and Wikipedia as answer corpus. With Lemur as retrieval engine and TF-IDF as ranking model, we were able to retrieve a correct answer passage in the top-10 for 45% of the questions. The most important limitation of the bag-of-words approach for why-QA is that the structure of the questions and the candidate answers is not taken into account. We studied a number of levels of linguistic information on both the side of the question and the side of the answer passage in order to find out which type of information is the most important for answering why-questions.We implemented a re-ranking module that incorporates knowledge about the syntactic structure of why-questions and the document context of the answers. With this module, we were able to improve significantly over the already quite reasonable bag-of-words baseline. After we optimized the feature combination in a learning-to-rank set-up, our system reached an MRR of 0.35 with a success@10 score of 57%. These scores were reached with only eight overlap features, one of which was the baseline ranker TF-IDF and the others were based on linguistic information (e.g. question focus, cue words and WordNet Similarity) and document structure (e.g. document title and the position of the answer passage in the document).For solving the remaining 43% of the questions, we found that more is needed than classic NLP. Our conclusion is that why-QA deserves renewed attention from the field of artificial intelligence.The dissertation is available online at http://lands.let.ru.nl/~sverbern/.},
journal = {SIGIR Forum},
month = jan,
pages = {90},
numpages = {1}
}

@article{10.1145/511144.511148,
author = {Lewis, David D. and Sebastiani, Fabrizio},
title = {Report on the Workshop on Operational Text Classification Systems (OTC-01)},
year = {2001},
issue_date = {Fall 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/511144.511148},
doi = {10.1145/511144.511148},
journal = {SIGIR Forum},
month = sep,
pages = {8–11},
numpages = {4}
}

@article{10.1145/2422256.2422275,
author = {Radinsky, Kira},
title = {Learning to Predict the Future Using Web Knowledge and Dynamics},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2422256.2422275},
doi = {10.1145/2422256.2422275},
abstract = {Mark Twain famously said that "the past does not repeat itself, but it rhymes." In the spirit of this reflection, we present novel algorithms and methods for leveraging large-scale digital histories and human knowledge mined from the Web to make real-time predictions about the likelihoods of future human and natural events of interest.The Web is a dynamic being, with constantly updating content, which is entangled with sophisticated user behaviors and interactions. Some of these behaviors have the ability to convey current trends in the present, e.g., economical growth (predicting automobile sales based on query volume [6]), popular movies [4], and political unrest [1, 3, 5]. We mine the ever-changing Web content and user Web behavior. We show that, not only the dynamics itself can be predicted, but also that it can be used for future real-world event prediction. We mine decades of news reports (1851 - 2010) from the New York Times (NYT), and describe how we can learn to predict the future by generalizing sets of concrete transitions in sequences of reported news events. In addition to the news corpora, we leverage data from freely available Web resources, including Wikipedia, FreeBase, OpenCyc, and GeoNames, via the LinkedData platform [2]. The goal is to build predictive models that generalize from specific sets of sequences of events to provide likelihoods of future outcomes, based on patterns of evidence observed in near-term Web activities. We propose the methods as a means of generating actionable forecasts in advance of the occurrence of target events in the world.This thesis is one of the first works to demonstrate general, unrestricted artificial-intelligence prediction capacity. We present methods derived from heterogeneous Web sources to make knowledge-intensive reasoning about causality and future event prediction, using both automatic feature extraction and novel algorithms for generalizing over historical examples.},
journal = {SIGIR Forum},
month = dec,
pages = {114–115},
numpages = {2}
}

@article{10.1145/3308774.3308805,
author = {Maistro, Maria},
title = {Exploiting User Signals and Stochastic Models to Improve Information Retrieval Systems and Evaluation},
year = {2019},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3308774.3308805},
doi = {10.1145/3308774.3308805},
abstract = {Progress and innovation are driven by experiments, but experimentation is useless without an objective evaluation measure that allow researchers to detect the improvements and identify the successful strategies. Due to the experimental nature of Information Retrieval (IR), accurately interpreting the result of a system in terms of user satisfaction is fundamental to push the research in the correct direction. Therefore, measuring systems effectiveness continues to be an active area of research and discussion in the scientific community. It is also the case of this thesis, whose leitmotiv is an investigation of effectiveness measures exploited in different aspects of IR.},
journal = {SIGIR Forum},
month = jan,
pages = {174–175},
numpages = {2}
}

@article{10.1145/2964797.2964814,
author = {Kong, Weize},
title = {Extending Faceted Search to the Open-Domain Web},
year = {2016},
issue_date = {June 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2964797.2964814},
doi = {10.1145/2964797.2964814},
abstract = {Faceted search enables users to navigate a multi-dimensional information space by combining keyword search with drill-down options in each facets. For example, when searching "computer monitor" in an e-commerce site, users can select brands and monitor types from the the provided facets {"Samsung", "Dell", "Acer", ...} and {"LET-Lit", "LCD", "OLED",...}. It has been used successfully for many vertical applications, including e-commerce and digital libraries. However, this idea is not well explored for general web search in an opendomain setting, even though it holds great potential for assisting multi-faceted queries and exploratory search.The goal of this work is to explore this potential by extending faceted search into the opendomain web setting, which we call Faceted Web Search. We address three fundamental issues in Faceted Web Search, namely: how to automatically generate facets (facet generation); how to re-organize search results with users' selections on facets (facet feedback); and how to evaluate generated facets and entire Faceted Web Search systems.In conventional faceted search, facets are generated in advance for an entire corpus either manually or semi-automatically, and then recommended for particular queries in most of the previous work. However, this approach is difficult to extend to the entire web due to the web's large and heterogeneous nature. We instead propose a query-dependent approach, which extracts facets for queries from their web search results. We further improve our facet generation model under a more practical scenario, where users care more about precision of presented facets than recall.The dominant facet feedback method in conventional faceted search is Boolean filtering, which filters search results by users' selections on facets. However, our investigation shows Boolean filtering is too strict when extended to the open-domain setting. Thus, we propose soft ranking models for Faceted Web Search, which expand original queries with users' selections on facets to re-rank search results. Our experiments show that the soft ranking models are more effective than Boolean filtering models for Faceted Web Search.To evaluate Faceted Web Search, we propose both intrinsic evaluation, which evaluates facet generation on its own, and extrinsic evaluation, which evaluates an entire Faceted Web Search system by its utility in assisting search clarification. We also design a method for building reusable test collections for such evaluations. Our experiments show that using the Faceted Web Search interface can significantly improve the original ranking if allowed sufficient time for user feedback on facets.},
journal = {SIGIR Forum},
month = jun,
pages = {90–91},
numpages = {2}
}

@article{10.1145/122665.122667,
author = {Maarek, Yo\"{e}lle S.},
title = {Software Library Construction from an IR Perspective},
year = {1991},
issue_date = {Fall 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/122665.122667},
doi = {10.1145/122665.122667},
abstract = {The two basic requirements for achieving software reuse are: (1) to provide a sufficient number of components over a spectrum of domains that can be reused as is (black-box reuse) or easily adapted (white-box reuse), and (2) to organize components such that code close to the users' needs is easy to locate. Many attempts have been made at addressing the first issue, (e.g. UNIX) however, as far as the second requirement is concerned very few library systems are available or attractive enough to make actual reuse faster than rewriting from scratch.With the increasing size of natural-language documentation in modern software component collections, there is a growing interest in applying IR techniques to the construction of software libraries. For instance recent tools such as INFoEXPLORER for the IBM RS/6000 series, or ANSWERBOOK for Sun Sparc workstations, provide standard IR techniques for searching on-line documentation. However, due to the nature of software documentation and of reuse requirements, some specific IR techniques can be devised to significantly enhance retrieval effectiveness.In this paper, we identify the necessary requirements to be met by the software collection in order to apply an IR approach, and we describe the specificity of reuse as compared to other applications. As an example, we describe GuRu, an information storage and retrieval system for reuse. This system is only briefly described as it has already presented elsewhere, and we rather concentrate on showing how GuRu satisfies the specific needs of reuse. GURU is currently used at the IBM T.J. Watson Research Center by a growing pool of users. We also provide an experimental test collection with relevance judgments for the AIx 3 command set to be used as a starting ground for evaluating retrieval effectiveness in reuse applications. Finally, we compare GURU's indexing scheme to two other schemes using this test collection.},
journal = {SIGIR Forum},
month = sep,
pages = {8–18},
numpages = {11}
}

@article{10.1145/2215676.2215692,
author = {Sushmita, Shanu},
title = {Study of Result Presentation and Interaction for Aggregated Search},
year = {2012},
issue_date = {June 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2215676.2215692},
doi = {10.1145/2215676.2215692},
abstract = {"Searching" on web has become an integral part of today's world, and many people rely on it when looking for information. The amount and the diversity of information available on the Web have also increased dramatically. Due to which, search engine companies are making constant efforts in order to make this information accessible to the people effectively. Not only there is an increase in the amount and diversity of information available online, users are now often seeking information on broader topics. Users seeking information on broad topics, gather information from various information sources (e.g., image, video, news, blog, etc). For such information requests, not only web results but results from different document genre and multimedia contents are also becoming relevant. For instance, users' looking for information on "Glasgow" might be interested in web results about Glasgow, Map of Glasgow, Images of Glasgow, News of Glasgow, and so on.Aggregated search aims to provide access to this diverse information in a unified manner by aggregating results from different information sources on a single result page; hence making information gathering process easier for broad topics. This thesis aimed to explore aggregated search from the users perspective.The thesis first and foremost focused on understanding and describing the phenomena related to the users' search process in the context of aggregated search. The goal was to participate in building theories and in understanding constraints, as well as providing insights into the interface design.While the thematic (or topical) relevance of documents is important, this thesis argued that the "source type" (source-orientation) might also be an important dimension in the relevance space for investigating aggregated search. Therefore, relevance is multi-dimensional (topical and sourceorientated) within the context of aggregated search. Results from the study suggested that the effect of the source-orientation was a significant factor in an aggregated search scenario, hence adding another dimension to the relevance space within the aggregated search scenario. The thesis further presented a method, which combines rule base and machine learning techniques to identify source-orientation behind a user query.Furthermore, after analyzing log data from a search engine company and conducting user study experiments, several design issues that may arise with respect to the aggregated search interface were identified. In order to address these issues, suitable design guidelines that can be beneficial from the interface perspective were also suggested.Overall, the thesis aimed to explore the emerging aggregated search from users' perspective, since it is a very important for front-end technologies. An additional goal was to provide empirical evidence regarding how aggregated search influence users searching behavior, and identified some of the key challenges in aggregated search.Available online at: http://theses.gla.ac.uk/3289/.},
journal = {SIGIR Forum},
month = may,
pages = {86–87},
numpages = {2}
}

@article{10.1145/1988852.1988872,
author = {Koolen, Marijn},
title = {The Meaning of Structure: The Value of Link Evidence for Information Retrieval},
year = {2011},
issue_date = {June 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1988852.1988872},
doi = {10.1145/1988852.1988872},
abstract = {How can search engines use the hyperlinks between documents to determine which documents are the most relevant for a search query? Some search engines use links to determine popularity, where the underlying idea is that the number of links pointing to a document (Web page) is a measure of its popularity. Another aspect of links is they provide a signal that two documents have related content. After all, a link is a reference. If a document A is relevant for a search query, then documents linked to A are possibly also relevant. Link information could possibly contain evidence for the topical relevance of a document.The value of link evidence for ir was investigated through the trec Web Tracks of 1999--2004. First through the traditional ad hoc search methodology, with disappointing results. When ad hoc search was considered an inappropriate model for Web search, attention moved to moreWeb-centric search tasks such as navigational search, with great success. Home pages and other importantWeb pages tend to be pages with many incoming links, and link evidence such as indegree counts and PageRank proved highly effective.The question of why links are not useful for measuring topical relevance was never answered. The goal of this thesis is to give a more precise and complete account of the value of link evidence for information retrieval. This is first investigated using the English Wikipedia, because it is available in its entirety, including all the links, and comes with a large, highquality test collection in the form of the inex Ad Hoc collection of 2006--2007. As an encyclopedia, Wikipedia is a natural collection to study topical relevance search tasks.Link information can be derived from the link graph of the entire collection--giving global, query-independent information--or from a subset of the link graph derived from the top results for a given query produced by a text-based retrieval system, giving local, queryindependent link information. PageRank is often computed on the global link graph, while algorithms like hits are typically used on the local links of the top-ranked results.We find that for ad hoc search on the inex 2006 Wikipedia collection, local link evidence leads to significant performance improvements. Incoming and outgoing link information is equally effective; the direction of the links does not affect their value for ad hoc search. We compare this to Web-centric search tasks on the trec 2004 Web track collection and to the ad hoc task on the trec 2009 Web track collection. For Web-centric search tasks, such as home page and named page finding, incoming link evidence is more effective than outgoing link evidence, and global link evidence is more effective than local link evidence. The value of link evidence for Web-centric search is to identify popular and authoritative pages, and the link direction determines the value. For ad hoc search on the more recent ClueWeb09 collection, global outgoing link evidence is very effective, but turns out to favour Wikipedia pages, which are densely interlinked. If we remove Wikipedia from the ClueWeb09 collection, local link evidence is more effective than global link evidence, and incoming and outgoing link evidence are equally effective. We also find that site-internal links are more effective for ad hoc search than site-external links. To determine the impact of link density, we conduct filtering experiments, which show that link density has a minimal impact on the effectiveness of global link evidence. For local link evidence, removing links gradually reduces the impact of link evidence, but even with a small number of links, link evidence is still effective. We also experiment with filtering links based on the semantic relatedness of the link documents and find that links between semantically related pages are more effective for identifying topically relevant documents than links between unrelated pages.Further experiments on the inex Wikipedia collection show that the amount of local link evidence is related to the amount of relevant text in documents, and the fraction of local link evidence (the percentage of the global links incident to a document that are present in the local link graph) is related to the fraction of text in a document that is relevant.With these findings, the value of link information for ranking search results has become clearer and more complete. Link information can be evidence for both popularity and topical relevance. The meaning of information derived from the link structure is determined by the direction of the links, the topical relation between the linked documents and the selection of links that is used as evidence.Available at http://staff.science.uva.nl/~mhakoole/2011/kool:mean11.pdf.},
journal = {SIGIR Forum},
month = may,
pages = {78–79},
numpages = {2}
}

@article{10.1145/2701583.2701601,
author = {Koopman, Bevan},
title = {Semantic Search as Inference: Applications in Health Informatics},
year = {2014},
issue_date = {December 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2701583.2701601},
doi = {10.1145/2701583.2701601},
abstract = {In this thesis, we present models for semantic search: Information Retrieval (IR) models that elicit the meaning behind the words found in documents and queries rather than simply matching keywords. This is achieved by the integration of structured domain knowledge and data-driven information retrieval methods.The research is set within health informatics to tackle the unique challenges within this domain; specifically, how to bridge the 'semantic gap'; that is, how to overcome the mismatch between raw medical data and the way human beings interpret it. Bridging the semantic gap involves addressing two issues: semantics; that is, aligning the meaning or concepts behind words found in documents and queries; and leveraging inference, which utilises semantics to infer relevant information.Three semantic search models -- all utilising concept-based rather than term-based representations---are developed; these include: the Bag-of-concepts model, which utilises concepts from the SNOMED CT medical ontology as its underlying representation; the Graph-based Concept Weighting model, which captures concept dependence and importance in a novel weighting function; and the core contribution of the thesis, the Graph INference model (GIN): a unified theoretical model of semantic search as inference, achieved by the integration of structured domain knowledge (ontologies) and statistical, information retrieval methods. It is the GIN that provides the necessary mechanism for inference to bridge the semantic gap. All three models are empirically evaluated using clinical queries and a real-world collection of clinical records taken from the TREC Medical Records Track (MedTrack).Our evaluation shows that the use of concept-based representations in the Bag-of-concepts model leads to improved retrieval effectiveness. When concepts are combined within the Graph-based ConceptWeighting model, further improvements are possible. The evaluation of GIN highlighted that its inference mechanism is suited to hard queries -- those that perform poorly on a term-based system. In-depth analysis also revealed that the GIN returned many new documents not retrieved by term-based systems and therefore never evaluated for relevance as part of the TREC MedTrack. This highlights that using current IR test collections, where semantic search systems did not contribute to the pool, may underestimate the effectiveness of semantic search systems.This work represents a significant step forward in the integration of structured domain knowledge and data-driven information retrieval methods. Furthermore, the thesis provides an understanding of inference -- when and how it should be applied for effective semantic search. It shows that queries with certain characteristics benefit from inference, while others do not. The detailed investigation into the evaluation of semantic search systems shows how current IR test collections may underestimate effectiveness of such systems and new techniques for evaluation are suggested. The Graph Inference model, although developed within the medical domain, is generally defined and has implications in other areas, including web search, where an emerging research trend is to utilise structured knowledge resources for more effective semantic search.},
journal = {SIGIR Forum},
month = dec,
pages = {116–117},
numpages = {2}
}

@article{10.1145/1147197.1147211,
author = {Azzopardi, Leif},
title = {Incorporating Context within the Language Modeling Approach for <i>Ad Hoc</i> Information Retrieval},
year = {2006},
issue_date = {June 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1147197.1147211},
doi = {10.1145/1147197.1147211},
abstract = {Using context to improve retrieval performance is a current challenge within the discipline and presents a major challenge to the research community. In this thesis, the context of documents formed via semantic associations is utilized within the Language Modeling (LM) approach for ad hoc Information Retrieval.},
journal = {SIGIR Forum},
month = jun,
pages = {70},
numpages = {1}
}

@article{10.1145/1670564.1670582,
author = {Liu, Ying-Hsang},
title = {The Impact of MeSH (Medical Subject Headings) Terms on Information Seeking Effectiveness},
year = {2009},
issue_date = {December 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1670564.1670582},
doi = {10.1145/1670564.1670582},
abstract = {To what extent do MeSH (Medical Subject Headings) terms improve search effectiveness of different kinds of users? We observed four different kinds of searchers using an experimental information retrieval (IR) system: (1) search novices; (2) domain experts; (3) search experts and (4) medical librarians. The information needs were a subset of the relatively difficult topics originally created for the Text REtrieval Conference (TREC). By experimental design, we used 20 search topics in an IR user experiment to alleviate search topic variability. Effectiveness of retrieval was based on the relevance judgments set provided by TREC. Thirty-two participants searched either using a version of the system in which abstracts and MeSH terms were displayed or another version in which they had to formulate their own terms based only on the display of abstracts. We found that MeSH terms were more useful for domain experts than for search experts in terms of the precision measure, even though domain experts did not perceive that MeSH terms were useful. We speculate that because of the technical topics, only the domain experts had the knowledge to understand and therefore make use of the MeSH terms. The primary contributions of this research are: (1) assessment of relative impact of searchers characteristics of domain knowledge and search training on search effectiveness and (2) design and methodology for assessing the usefulness of controlled vocabulary. The effort to create MeSH terms is worthwhile for domain experts' searches on technical topics.},
journal = {SIGIR Forum},
month = dec,
pages = {88},
numpages = {1}
}

@article{10.1145/331403.331406,
author = {Sakai, Tetsuya and Kitani, Tsuyoshi and Ogawa, Yasushi and Ishikawa, Tetsuya and Kimoto, Haruo and Keshi, Ikuo and Toyoura, Jun and Fukushima, Toshikazu and Matsui, Kunio and Ueda, Yoshihiro and Tokunaga, Takenobu and Tsuruoka, Hiroshi and Nakawatase, Hidekazu and Agata, Teru and Kando, Noriko},
title = {BMIR-J2: A Test Collection for Evaluation of Japanese Information Retrieval Systems},
year = {1999},
issue_date = {Fall 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/331403.331406},
doi = {10.1145/331403.331406},
abstract = {BMIR-J2 is the first complete test collection generally available for evaluating Japanese information retrieval systems. BMIR-J2 features include a novel division of search requests based on various functions required to perform successful retrieval. BMIR-J2 and its smaller predecessor BMIR-J1 were constructed by a volunteer-based working group under the Information Processing Society of Japan. We hope that BMIR-J2 will come into wide use and that it will foster the development of Japanese IR systems.},
journal = {SIGIR Forum},
month = sep,
pages = {13–17},
numpages = {5}
}

@article{10.1145/1670598.1670614,
author = {Ashoori, Elham},
title = {Using Topic Shifts in Content-Oriented XML Retrieval},
year = {2009},
issue_date = {June 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1670598.1670614},
doi = {10.1145/1670598.1670614},
abstract = {Content-oriented XML retrieval systems support access to XML repositories by retrieving, in response to user queries, XML document components (XML elements) instead of whole documents. The retrieved XML elements should not only contain information relevant to the query, but also should be specific to the given query (i.e. do not discuss other irrelevant topics).To score XML elements according to how relevant and specific they are given a query, the content and logical structure of XML documents have been widely used. This thesis aims to examine a new source of evidence deriving from the semantic decomposition of XML documents. We consider that XML documents can be semantically decomposed through the application of a topic segmentation algorithm. Using the semantic decomposition and the logical structure of XML documents, we define the notion of topic shifts in an XML element. We then formalise the number of topic shifts to reflect the element's relevance, and more particularly its specificness, to the given user's query.This thesis investigates the use of topic shifts in content-oriented XML retrieval, which is mainly involved in retrieving information from semi-structured (XML) documents. First, we examine the characteristics of XML elements reflected by their number of topic shifts. Second, we use the number of topic shifts to estimate the relevance of the elements in the collection. Finally, we use topic shifts to provide a focused access to XML documents, which aims to determine not only relevant elements, but those at the right level of granularity.The main contributions of this thesis are the introduction of topic shifts in the context of content-oriented XML retrieval and the extensive evaluation of the ways this evidence can be employed in retrieving XML elements. This thesis demonstrates that topic shifts in XML elements constitute a useful source of evidence for both improving the ranking of XML elements, and determining elements at the right level of granularity in content-oriented XML retrieval.The thesis is available online at http://elham.ashoori.org/publications/phd-thesis.pdf.},
journal = {SIGIR Forum},
month = jun,
pages = {70},
numpages = {1}
}

@article{10.1145/2888422.2888450,
author = {Yeniterzi, Reyyan},
title = {Effective and Efficient Approaches to Retrieving and Using Expertise in Social Media},
year = {2016},
issue_date = {December 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2888422.2888450},
doi = {10.1145/2888422.2888450},
abstract = {The recent popularity of social media is changing the way people share and acquire knowledge. Companies started using intra-organizational social media applications in order to improve the communication and collaboration among employees. In addition to their professional use, people have been using these sites in their personal lives for information acquisition purposes, such as community question answering (CQA) sites for their questions. In such environments the interactions do not always occur between users who know each other well enough to assess expertise of one another or trust the accuracy of their created content. This dissertation solves this problem by estimating topic-specific expertise scores of users which can be also used to improve the expertise related applications in social medi.Expert retrieval has been widely studied using organizational documents; however, theadditional structure and information available in social media provide the opportunity to improve the developed expert finding approaches. Such additional information includes the availability of different types of user created content, the underlying social network structure constructed from the interactions among users, such as commenting or replying, and the available temporal information coming from the timestamped user interactions. This available information is explored and approaches which use this information for more effective expertise estimation have been proposed. In particular, the main contributions of this dissertation can be summarized as follows: Content-based Retrieval: What to search for and where to search are two important factors in retrieval tasks. This dissertation focused on these questions for the expert finding task in CQA sites. Available and different types of content-based evidence are explored to find effective and also approach independent representations for both the information need (query) and user expertise. The proposed representations returned statistically significant improvements when tested with different expert retrieval algorithms.Authority Estimation: Web page authority estimation approaches have been widely adapted to user interaction networks which are constructed by using the interactions between users. Understanding the interaction and structure behind these user graphs showed us some of the limitations of these adaptations when applied to these networks. Based on these analyses, more topic-specific authority graph construction and estimation approaches, which provided consistent improvements in both accuracy and efficiency, are proposed.Temporal Modeling: Humans are dynamic in nature with changing levels of interest, expertise and availability. In order to model this dynamic nature of users, we explored the available timestamp information within social media. With using that information, a more dynamic expert identification approach, which takes into account the recent topic-specific interest of users as well as their availability, is proposed. This move from static to dynamic modeling of expertise returned statistically significant improvements, due to more effective modeling of expertise of the constantly changing users.These proposed approaches are combined in an expert identification system which has been tested on an intra-organizational blog data and a popular community question answering site's data, for three expertise estimation related tasks: identification of topic-specific expert bloggers, routing questions to users who can provide accurate and timely replies, and ranking replies based on responders question specific expertise. Statistically significant improvements are observed in all three tasks. In addition to improving the effectiveness of expert identification applications in social media, the proposed approaches are also more efficient which makes the proposed expert finding system applicable to real time environments.},
journal = {SIGIR Forum},
month = jan,
pages = {152–153},
numpages = {2}
}

@article{10.1145/1988852.1988869,
author = {Du, Jia Tina},
title = {Multitasking, Cognitive Coordination and Cognitive Shifts during Web Searching},
year = {2011},
issue_date = {June 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1988852.1988869},
doi = {10.1145/1988852.1988869},
abstract = {Enlightened by the cognitive psychology literature demonstrating that multitasking behavior is correlated closely to humans' cognitive processing and coordinationcapabilities, this doctoral thesis explores the nature and relationship of multitasking, cognitive coordination, and cognitive shifts during Web searching. A combination of data collection techniques including pre- and post-questionnaires, think-aloud protocols, search logs, observations and semi-structured interviews were employed to observe how 42 postgraduate students cognitively coordinated Web searches when multitasking across 126 real-life information problems.Results show that Web searching is a dynamic interaction between users and Web search systems during which multiple information problems ordering, evolving information problems generating, searching task switching, task and mental coordinating occur, and at a deeper level, cognitive shifts take place. The explicit task level coordination is closely linked to multitasking behavior. The implicit cognitive level coordination is related to the task coordination process; this includes the evolution of information problem development and search task switching. Coordination mechanisms directly result in the shifts of cognitive states including strategy, evaluation, and view states which further affect users' holistic shifts in information problem understanding and knowledge contribution.Based on the findings, a Web search model integrating multitasking, cognitive coordination and cognitive shifts (MCC model) is presented. Cognitive coordination as humans' vital capability under conscious control plays a nexus role in supporting multitasking Web searches and invoking the occurrence of shifts in cognition. The results extend multitasking research and Web search models in the field by examining and integrating underlying cognitive and coordination support mechanisms. Design recommendations for adaptive search systems are also put forward based on the characteristics and relationship of users' behaviors in multitasking, cognitive coordination and shifting.},
journal = {SIGIR Forum},
month = may,
pages = {74},
numpages = {1}
}

@article{10.1145/986278.986300,
author = {Pomerantz, Jeffrey},
title = {Question Taxonomies for Digital Reference},
year = {2004},
issue_date = {June 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/986278.986300},
doi = {10.1145/986278.986300},
journal = {SIGIR Forum},
month = jul,
pages = {79},
numpages = {1}
}

@article{10.1145/986278.986299,
author = {Nanas, Nikolaos},
title = {Towards Nootropia: A Non-Linear Approach to Adaptive Document Filtering},
year = {2004},
issue_date = {June 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/986278.986299},
doi = {10.1145/986278.986299},
journal = {SIGIR Forum},
month = jul,
pages = {78},
numpages = {1}
}

@article{10.1145/381258.381264,
author = {Kluev, V.},
title = {Compiling Document Collections from the Internet},
year = {2000},
issue_date = {Fall 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/381258.381264},
doi = {10.1145/381258.381264},
abstract = {Presently domain specific search engines are becoming popular because they offer greater accuracy, when compared to general purpose search engines. In this study, a method for collecting domain specific documents from the net was developed for the purpose of improving search results. The main thrust of our approach is to use several metrics to estimate the relevance of every automatically discovered document by a crawler regarding a topic of interest. This type of search resulted in two important findings. First, the time required for manual analysis of document content by the crawler was significantly reduced; second, the content quality of selected documents was improved. These results suggest that the rough estimation of precision and recall calculated in this study offer great promise.},
journal = {SIGIR Forum},
month = sep,
pages = {9–14},
numpages = {6},
keywords = {relevance information, search engine, search context, data collection}
}

@article{10.1145/3190580.3190608,
author = {Kopeinik, Simone},
title = {Applying Cognitive Learner Models for Recommender Systems in Sparse Data Learning Environments},
year = {2018},
issue_date = {December 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/3190580.3190608},
doi = {10.1145/3190580.3190608},
abstract = {In recent years, various recommendation algorithms have been proposed to support learners in technology-enhanced learning environments. Such algorithms have proven to be quite effective in big-data learning settings (massive open online courses), yet successful applications in other informal and formal learning settings are rare. Common challenges include data sparsity, the lack of sufficiently flexible learner and domain models, and the difficulty of including pedagogical goals into recommendation strategies. Computational models of human cognition and learning are, in principle, well positioned to help meet these challenges, yet the effectiveness of cognitive models in educational recommender systems remains poorly understood to this date. This thesis contributes to this strand of research by investigating i) two cognitive learner models (CbKST and SUSTAIN) for resource recommendations that qualify for sparse user data by following theory-driven top down approaches, and ii) two tag recommendation strategies based on models of human cognition (BLL and MINERVA2) that support the creation of learning content meta-data. The results of four online and offline experiments in different learning contexts indicate that a recommendation approach based on the CbKST, a well-founded structural model of knowledge representation, can improve the users? perceived learning experience in formal learning settings. In informal settings, SUSTAIN, a human category learning model, is shown to succeed in representing dynamic, interest based learning interactions and to improve Collaborative Filtering for resource recommendations. The investigation of the two proposed tag recommender strategies underlined their ability to generate accurate suggestions (BLL) and in collaborative settings, their potential to promote the development of shared vocabulary (MINERVA2). This thesis shows that the application of computational models of human cognition holds promise for the design of recommender mechanisms and, at the same time, for gaining a deeper understanding of interaction dynamics in virtual learning systems.},
journal = {SIGIR Forum},
month = feb,
pages = {165},
numpages = {1}
}

@article{10.1145/2641383.2641393,
author = {Brand\~{a}o, Wladmir Cardoso},
title = {Exploiting Entities for Query Expansion},
year = {2014},
issue_date = {June 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2641383.2641393},
doi = {10.1145/2641383.2641393},
abstract = {A substantial fraction of web search queries contain references to entities, such as persons, organizations, and locations. This signi cant presence of named entities in queries provides an opportunity for web search engines to improve their understanding of the user's information need.In this thesis, we investigate the entity-oriented query expansion process. Particularly, we propose two novel and effective query expansion approaches that exploit semantic sources of evidence to devise discriminative term features, and machine learning techniques to effectively combine these features in order to rank candidate expansion terms. As a result, not only do we select effective expansion terms, but we also weigh these terms according to their predicted effectiveness. In addition, since our query expansion approaches consider Wikipedia infoboxes as a source of candidate expansion terms, a frequent obstacle is that only about 20% of Wikipedia articles have an infobox. To overcome this problem we propose WAVE, a self-supervised approach to autonomously generate infoboxes for Wikipedia articles.First, we propose UQEE, an unsupervised entity-oriented query expansion approach, which effectively selects expansion terms using taxonomic features devised by the semantic structure implicitly provided by infobox templates. We show that query expansion using infoboxes presents a better trade-off between retrieval performance and query latency. Moreover, we demonstrate that the automatically generated infoboxes provided by WAVE are as effective as manually generated infoboxes for query expansion. Lastly, we propose L2EE, a learning to rank approach for entity-oriented query expansion, which considers semantic evidence encoded in the content of Wikipedia article fields, and automatically labels training examples proportionally to their observed retrieval effectiveness.Experiments on three TREC web test collections attest the effectiveness of L2EE, with significant gains compared to UQEE and state-of-the-art pseudo-relevance feedback and entity-oriented pseudo-relevance feedback approaches.},
journal = {SIGIR Forum},
month = jun,
pages = {43},
numpages = {1}
}

@article{10.1145/2641383.2641394,
author = {Marcheggiani, Diego},
title = {Beyond Linear Chain: A Journey through Conditional Random Fields for Information Extraction from Text},
year = {2014},
issue_date = {June 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2641383.2641394},
doi = {10.1145/2641383.2641394},
abstract = {Information Extraction (IE) is a field at the crossroads of IR and NLP that studies methods for extracting information from text in such a way that this information can be used to populate a structured information repository. The main methods by means of which IE has been tackled rely on supervised learning;the best-performing such methods belong to the class of probabilistic graphical models, and, in particular, to the class of Conditional Random Fields (CRFs). In this thesis we investigate two major aspects related to textual IE via CRFs: (a) the creation of CRFs models that can outperform the commonly adopted linear- chain CRFs, and the creation of methods for ensuring the quality of training data and for assessing the impact of training data quality on the accuracy of CRFs systems for IE.We start by facing the task of IE from medical documents written in the Italian language. We propose two novel approaches: (i) a cascaded, two-stage method composed by two layers of CRFs, and (ii) a confidence-weighted ensemble method that combines standard linear-chain CRFs and the proposed two-stage method. Both the proposed models are shown to outperform a standard linear-chain CRFs system.We then investigate aspect-oriented sentence-level opinion mining from product reviews, that consists in predicting, for all sentences in the review, whether the sentence expresses a positive, neutral, or negative opinion (or no opinion at all) about a specific aspect of the product. We propose a set of increasingly powerful models based on CRFs, including a hierarchical multi-label CRFs scheme that jointly models the overall opinion expressed in a product review and the set of aspect-specific opinions expressed in each of its sentences. The proposed CRFs models are shown to obtain better results than linear-chain CRFs.We then study the impact that the quality of training data has on the accuracy of an IE system via experiments performed on a dataset in which inter-coder agreement data are available. Finally, we investigate active learning techniques for a type of semi-supervised CRFs specifically devised for partially labeled sequences. We show that margin-based strategies always obtain the best results on the four tasks we have tested them on.},
journal = {SIGIR Forum},
month = jun,
pages = {44},
numpages = {1}
}

@article{10.1145/2215676.2215691,
author = {Kanhabua, Nattiya},
title = {Time-Aware Approaches to Information Retrieval},
year = {2012},
issue_date = {June 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2215676.2215691},
doi = {10.1145/2215676.2215691},
abstract = {In this thesis, we address major challenges in searching temporal document collections. In such collections, documents are created and/or edited over time. Examples of temporal document collections are web archives, news archives, blogs, personal emails and enterprise documents. Unfortunately, traditional IR approaches based on term-matching only can give unsatisfactory results when searching temporal document collections. The reason for this is twofold: the contents of documents are strongly time-dependent, i.e., documents are about events happened at particular time periods, and a query representing an information need can be time-dependent as well, i.e., a temporal query.Our contributions in this thesis are different time-aware approaches within three topics in IR: content analysis, query analysis, and retrieval and ranking models. In particular, we aim at improving the retrieval effectiveness by 1) analyzing the contents of temporal document collections, 2) performing an analysis of temporal queries, and 3) explicitly modeling the time dimension into retrieval and ranking.Leveraging the time dimension in ranking can improve the retrieval effectiveness if information about the creation or publication time of documents is available. In this thesis, we analyze the contents of documents in order to determine the time of non-timestamped documents using temporal language models. We subsequently employ the temporal language models for determining the time of implicit temporal queries, and the determined time is used for re-ranking search results in order to improve the retrieval effectiveness.We study the effect of terminology changes over time and propose an approach to handling terminology changes using time-based synonyms. In addition, we propose different methods for predicting the effectiveness of temporal queries, so that a particular query enhancement technique can be performed to improve the overall performance. When the time dimension is incorporated into ranking, documents will be ranked according to both textual and temporal similarity. In this case, time uncertainty should also be taken into account. Thus, we propose a ranking model that considers the time uncertainty, and improve ranking by combining multiple features using learning-to-rank techniques.Through extensive evaluation, we show that our proposed time-aware approaches outperform traditional retrieval methods and improve the retrieval effectiveness in searching temporal document collections.Available online at: http://www.idi.ntnu.no/research/doctor_theses/nattiya.pdf.},
journal = {SIGIR Forum},
month = may,
pages = {85},
numpages = {1}
}

@article{10.1145/1013230.511820,
author = {Croft, W. B. and Wolf, R. and Thompson, R.},
title = {A Network Organization Used for Document Retrieval},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511820},
doi = {10.1145/1013230.511820},
abstract = {A network organization for implementing a document retrieval system is proposed. This organization has significant advantages in terms of the range of searches that can be used when compared to either inverted or clustered file organizations. Algorithms for generating and maintaining the network are described together with experiments designed to test their efficiency and effectiveness.},
journal = {SIGIR Forum},
month = jun,
pages = {178–188},
numpages = {11}
}

@inproceedings{10.1145/511793.511820,
author = {Croft, W. B. and Wolf, R. and Thompson, R.},
title = {A Network Organization Used for Document Retrieval},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511820},
doi = {10.1145/511793.511820},
abstract = {A network organization for implementing a document retrieval system is proposed. This organization has significant advantages in terms of the range of searches that can be used when compared to either inverted or clustered file organizations. Algorithms for generating and maintaining the network are described together with experiments designed to test their efficiency and effectiveness.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {178–188},
numpages = {11},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/2795403.2795418,
author = {Freire, Ana},
title = {Query Scheduling Techniques and Power-Latency Trade-off Model for Large-Scale Search Engines},
year = {2015},
issue_date = {June 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2795403.2795418},
doi = {10.1145/2795403.2795418},
abstract = {Web search engines have to deal with a huge increase of information, demanded by high incoming query traffic. This situation has driven companies to build large, geographically distributed data centres housing thousands of servers and consuming enormous amounts of electricity. At this scale, even minor efficiency improvements may result in large financial and power savings.This thesis represents a novel contribution to the state-of-the-art of Query Scheduling and Green Information Retrieval (Green IR), by assisting large-scale data centres to build more efficient and environmentally-friendly search engines.The main contributions of this work are the following: Query Scheduling. We introduce query efficiency predictors as suitable estimators to improve Query Scheduling. We estimate the processing time of the queries waiting in each query server and we calculate an approximate time that a new query must spend in each queue. Based on this estimation, the fastest query server is selected.Green IR. Once we have developed new methods to improve the average response time of a search engine, we focus on reducing the power consumption of the whole system. This thesis proposes a mathematical model that establishes a trade-off between latency and power consumption. This model attempts to automatically adapt the number of active servers in the system based on the fluctuations of a daily query traffic flow.Queueing Theory. We prove the limitation of Queueing Theory models for estimating the latency in search engines. As a consequence, we develop our trade-off model by predicting the latency using historical data. Results show the good performance of this approach.IR evaluation. We attest that Simulation platforms are suitable for IR experimentation. We support this conclusion by establishing an exhaustive analysis of the current IR evaluation platforms..},
journal = {SIGIR Forum},
month = jun,
pages = {66},
numpages = {1}
}

@article{10.1145/2568388.2568412,
author = {Diaz-Aviles, Ernesto},
title = {Living Analytics Methods for the Social Web},
year = {2013},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2568388.2568412},
doi = {10.1145/2568388.2568412},
abstract = {The collective effervescence of social media production has been enjoying a great deal of success in recent years. The hundred of millions of users who are actively participating in the Social Web are exposed to ever-growing amounts of sites, relationships, and information.This work contributes state-of-the-art methods and techniques to the emerging field of Living Analytics, whose main goal is to capture people interactions in real-time and to analyze these data in order to relieve information overload. We introduce intelligent filtering approaches that exploit social interactions, multidimensional relationships, metadata, and other data becoming ubiquitous in the social web, in order to discover and recommend the most relevant and attractive information that meets users' individual needs. In particular, the contributions of this work fall into mainly two categories.(i) Recommender Systems: We present novel algorithms that advance the state-of-the-art in Online Collaborative Filtering. Moreover, we propose an approach based on Swarm Intelligence to directly optimize ranking functions for item recommendations. New approaches to address the cold-start problem in social recommender systems are also part of our contributions. In addition, we also offer a personalized ranking algorithm for Epidemic Intelligence.(ii) Collective Intelligence: Our contributions in the field of computational social science are twofold. First, we explore how social media streams can be exploited for Epidemic Intelligence and show its potential for early warning detection and outbreak analysis and control. Second, we show how the real-time nature of social media streams can be leveraged to take the pulse of political emotions.In total, the methods and studies included in this work constitute an analytics toolbox to help understand and analyze the social web.},
journal = {SIGIR Forum},
month = jan,
pages = {139},
numpages = {1},
keywords = {machine learning, collaborative filtering, social media}
}

@article{10.1145/1670598.1670617,
author = {Szl\'{a}vik, Zolt\'{a}n},
title = {Content and Structure Summarisation for Accessing XML Documents},
year = {2009},
issue_date = {June 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1670598.1670617},
doi = {10.1145/1670598.1670617},
abstract = {As the availability of structured documents is constantly increasing, retrieval systems able to return document portions are being developed. Structured documents, usually formatted in XML, may consist of large numbers of document portions, often organised into a hierarchical logical structure. With the high number of document portions, it is necessary to direct the attention of users of retrieval systems towards the most important document portions, and also, to give overviews of the structure of documents, in other words, to show document portions in context. This thesis investigates summarisation as a means to help searchers of XML retrieval systems in the process of accessing the contents of document portions. Two types of summarisation are investigated.First, summaries of the textual contents of document portions, called XML elements, are studied in a user-based environment. Traditionally, summarisation is associated with whole documents or document sets, but rarely with document portions. As summaries of documents have been proved to be useful in whole document retrieval, it is considered worthwhile to investigate summaries of document portions in XML element retrieval. Summaries of elements are presented to searchers in the context of other elements from the document. The textual summaries of elements also reflect the searchers' information needs: they are query based.The second type of summarisation investigated in this thesis is called structure summarisation. The automatic generation of tables of contents, as structure summaries, is described and examined. ToC generation is studied either when searchers' queries are available (query based structure summarisation) or otherwise (query independent structure summarisation).The work presented in this thesis has made several contributions to the fields of summarisation and interactive XML retrieval.The thesis is available online at http://www.dcs.qmul.ac.uk/~zolley/thesis.html.},
journal = {SIGIR Forum},
month = jun,
pages = {74},
numpages = {1}
}

@article{10.1145/2701583.2701602,
author = {Papadakos, Panagiotis},
title = {Interactive Exploration of Multi-Dimensional Information Spaces with Preference Support},
year = {2014},
issue_date = {December 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2701583.2701602},
doi = {10.1145/2701583.2701602},
abstract = {Users access large amounts of information resources mainly through search functions, where they type a few keywords and the web search or query engine returns a linear list of hits. While this is often satisfactory for focalized search, it does not provide enough support for exploratory information needs. Faceted and Dynamic Taxonomies (FDT) is a highly prevalent model for exploratory search, which allows users to get an overview of the information space and offer them various groupings of the results based on their attributes, metadata, or other dynamically mined information, enabling them to gradually restrict their focus through clicks and locate low ranked resources. The enrichment of such mechanisms with preferences could be proven useful for exploratory tasks. However, the current preference-based approaches seem to ignore the fact that users should be acquainted with the information space and the available choices for describing effectively their preferences.In this dissertation we extend the interaction model of FDT with preference actions that allow users to express their preferences interactively, gradually, and in a simple way. We introduce a preference framework appropriate for information spaces comprising resources described by attributes whose values can be hierarchically valued and/or multi-valued. We define the language, its semantics and the required algorithms. The framework supports preference inheritance in the hierarchies, automatic conflict resolution, as well as preference composition. Subsequently, we enrich the FDT model with preference actions and we propose logical optimizations and methods for exploiting the intrinsic characteristics of the FDT-based interaction, aiming at making it applicable to large amounts of information. We present the design and the implementation of the web-based system Hippalus, which realizes the extended interaction model. Regarding user benefits, we theoretically analyze user gain in terms of the number and difficulty of choices, and we describe and analyze three user-based evaluations. The first investigates the degree of effectiveness of preferences when users are not aware of the available choices. We found that only 20% of the users managed to express effective preferences without knowing the available choices. The second comparatively evaluates FDT with other exploratory models, and shows that the majority of users preferred FDT, was more satisfied by FDT and achieved higher rates of task completion with FDT. The last one evaluates the preference-enriched FDT as realized by Hippalus. The results were impressive. Even in a very small dataset, with the preference-enriched FDT all users successfully completed all tasks in 1/3 of the time and with 1/3 of the actions in comparison to the plain FDT. Moreover all of the users preferred the preference-enriched interfac.Available: http://www.ics.forth.gr/_publications/Papadakos_Dissertation.pdf.},
journal = {SIGIR Forum},
month = dec,
pages = {118},
numpages = {1}
}

@article{10.1145/1480506.1480526,
author = {Balog, Krisztian},
title = {People Search in the Enterprise},
year = {2008},
issue_date = {December 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1480506.1480526},
doi = {10.1145/1480506.1480526},
abstract = {The enormous increase in recent years in the amount of information available online has led to a renewed interest in a broad range of IR-related areas that go beyond plain document retrieval. Some of this new attention has fallen on a subset of IR tasks, in particular on entity retrieval tasks. This emerging area differs from traditional document retrieval in a number of ways. Entities are not represented directly (as retrievable units such as documents), and we need to identify them "indirectly" through occurrences in documents. This brings new, exciting challenges to the fields of Information Retrieval and Information Extraction. In this thesis we focus on one particular type of entity: people.},
journal = {SIGIR Forum},
month = nov,
pages = {103},
numpages = {1}
}

@article{10.1145/3053408.3053428,
author = {Gossen, Tatiana},
title = {Targeted Search Engines for Children: Search User Interfaces and Information-Seeking Behaviour},
year = {2017},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3053408.3053428},
doi = {10.1145/3053408.3053428},
abstract = {Children are a fast growing user group on the Internet. Among different online activities, children use web search engines in order to gather information related to their personal interests and school activities. Children's knowledge, cognitive abilities and fine motor skills are different from those of adults. Therefore, they may experience difficulties with search engines that are built using standard information retrieval algorithms and search interfaces for adults. Special or targeted search engines for children are essential in order to better support children in their search tasks. Therefore, the goal of this thesis is to design appropriate search engines for children with a focus on the search user interface. However, this is not an easy task to accomplish. Not only are children's abilities different from the abilities of adults, children also undergo relatively fast changes in their abilities.The specific and dynamically changing characteristics of young users pose a great challenge. In order to address this challenge, first, the specifics of information retrieval for young users are analysed. Second, open issues are identified in user studies with children using logfile analysis and eye-tracking. The conceptual challenges in the design of user interfaces regarding search engines for children are derived based on the findings of one's own and previous user studies as well as theories of human development. Third, user interfaces of search engines that address these conceptual challenges are designed, prototypically implemented and evaluated in user studies with children following a user-centered design. Specifically, the proposed user interfaces of the search engine address the changing characteristics of the users by providing a means of adaptation. Furthermore, a novel type of search result visualisation for children with cartoon style characters is developed which takes the children's preference for visual information into account. Both approaches were very positively received by children during evaluation. Children rated different user interface aspects of the search user interface prototypes as good, e.g., the adaptation of the search user interface towards user wishes and the helpfulness of the cartoon style characters during search. Finally, this thesis provides criteria and guidelines on how to design user interfaces of search engines for children.},
journal = {SIGIR Forum},
month = feb,
pages = {106},
numpages = {1}
}

@article{10.1145/2795403.2795421,
author = {Trevisiol, Michele},
title = {Exploiting Implicit User Activity for Media Recommendation},
year = {2015},
issue_date = {June 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2795403.2795421},
doi = {10.1145/2795403.2795421},
abstract = {This thesis explores in depth how to exploit the user browsing behavior, and in particular the referrer URL, to understand the interest of the users. The aim is, first, to understand the preferences of the users from their navigation patterns, i.e., from the implicit actions of the users. Then, to exploit this information to personalize the content offered by the service provider. The key findings from our studies allowed us to propose innovative solutions to perform recommendation and ranking of media content. We show how the browsing logs are extremely meaningful also for cold-start problem -- estimating the preferences of newcomers.},
journal = {SIGIR Forum},
month = jun,
pages = {70},
numpages = {1}
}

@article{10.1145/986278.986298,
author = {Kelly, Diane},
title = {Understanding Implicit Feedback and Document Preference: A Naturalistic User Study},
year = {2004},
issue_date = {June 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/986278.986298},
doi = {10.1145/986278.986298},
journal = {SIGIR Forum},
month = jul,
pages = {77},
numpages = {1}
}

@article{10.1145/2422256.2422276,
author = {Tigelaar, Almer S.},
title = {Peer-to-Peer Information Retrieval},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2422256.2422276},
doi = {10.1145/2422256.2422276},
journal = {SIGIR Forum},
month = dec,
pages = {116},
numpages = {1}
}

@article{10.1145/3308774.3308802,
author = {Cohan, Arman},
title = {Text Summarization and Categorization for Scientific and Health-Related Data},
year = {2019},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3308774.3308802},
doi = {10.1145/3308774.3308802},
abstract = {The increasing amount of unstructured health-related data has created a need for intelligent processing, summarizing, and categorizing these data to extract knowledge from them. My research goal in this dissertation is to develop Natural Language Processing (NLP) and Information Retrieval (IR) methods for better processing and understanding health-related textual information to promote health care and wellbeing of individuals.},
journal = {SIGIR Forum},
month = jan,
pages = {169},
numpages = {1}
}

@article{10.1145/2795403.2795419,
author = {Moreno, Jose G.},
title = {Text-Based Ephemeral Clustering for Web Image Retrieval on Mobile Devices},
year = {2015},
issue_date = {June 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2795403.2795419},
doi = {10.1145/2795403.2795419},
abstract = {Text-Based Ephemeral Clustering for Web Image Retrieval on Mobile Devices.Our specific contributions in this dissertation are: two algorithms, two datasets and an evaluation tool. The Dual C-means algorithm is the main product of these. Dual C-means can be seen as a generalization of our previous proposal the AGK-means. Both algorithms are based on word-word similarity metrics and on the classical K-means algorithm. A new dataset for a complete evaluation of search results clustering (SRC) algorithms is developed and presented. Similarly, a new Web image dataset is developed and used together with a new metric to measure the users' effort when a set of Web images is explored. Finally, we developed an evaluation tool for the SRC problem, in which we have implemented several classical and recent SRC metrics.In order to validate our hypothesis, we performed a great deal of different experiments with the datasets mentioned above. Three valuable characteristics are evaluated in the proposed algorithms. First, clustering quality, in which classical and recent evaluation metrics are considered. Secondly, the labelling quality of each cluster is evaluated to make sure that all possible query intents are covered. Thirdly and finally, we evaluate the user's effort in exploring the clustered results presented as horizontal image strips. For these three, we use several datasets- some of which are built to evaluate individual or combinations of these characteristics.We have made our conclusions on the numerous factors discussed in this dissertation. In essence, the proposed Dual C-means algorithm, is capable of obtaining proper clustering partitions and simultaneously ensuring high quality labels. When images are displayed on a mobile device's interface, our results indicate that the users' effort to explore the Web image results is reduced.},
journal = {SIGIR Forum},
month = jun,
pages = {67},
numpages = {1}
}

@article{10.1145/1670598.1670616,
author = {Macdonald, Craig},
title = {The Voting Model for People Search},
year = {2009},
issue_date = {June 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1670598.1670616},
doi = {10.1145/1670598.1670616},
abstract = {An expert search engine aims to assist users with their expertise need - instead of ranking documents, possible candidate experts in an enterprise organisation with relevant expertise are suggested in response to a query. This thesis investigates people search tasks such as expert search, and how persons can be ranked in response to a query, such that those with relevant expertise to the query are ranked first. The expertise areas of the persons are represented by documentary evidence of expertise, known as candidate profiles. The statement of this research work is that people search tasks in general and expert search in particular can be successfully and effectively modelled using a voting paradigm.},
journal = {SIGIR Forum},
month = jun,
pages = {73},
numpages = {1}
}

@article{10.1145/1067268.1067298,
author = {Ye, Jiamin},
title = {Aggregated Feature Video Retrieval for MPEG-7 via Clustering},
year = {2005},
issue_date = {June 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1067268.1067298},
doi = {10.1145/1067268.1067298},
abstract = {MPEG-7 is a generic standard used to encode information about multimedia content and often, different MPEG-7 Descriptor Schemas are instantiated for different representations of a shot such as text annotations and visual features. Our work focuses on two main areas, the first is devising a method for combining text annotations and visual features into one single MPEG-7 description and the second is defining how best to carry out text and non-text queries for retrieval via a combined description.},
journal = {SIGIR Forum},
month = jun,
pages = {71},
numpages = {1}
}

@article{10.1145/2093346.2093366,
author = {Kaptein, Rianne},
title = {Effective Focused Retrieval by Exploiting Query Context and Document Structure},
year = {2012},
issue_date = {December 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2093346.2093366},
doi = {10.1145/2093346.2093366},
abstract = {The classic IR model of the search process consists of three elements: query, documents and search results. A user looking to fulfil an information need formulates a query usually consisting of a small set of keywords summarising the information need. The goal of an IR system is to retrieve documents containing information which might be useful or relevant to the user. Throughout the search process there is a loss of focus, because keyword queries entered by users often do not suitably summarise their complex information needs, and IR systems do not sufficiently interpret the contents of documents, leading to result lists containing irrelevant and redundant information. The main research objective of this thesis is to exploit query context and document structure to provide for more focused retrieval.The short keyword query used as input to the retrieval system can be supplemented with topic categories from structured Web resources such as DMOZ and Wikipedia. Topic categories can be used as query context to retrieve documents that are not only relevant to the query but also belong to a relevant topic category. Category information is especially useful for the task of entity ranking where the user is searching for a certain type of entity such as companies or persons. Category information can help to improve the search results by promoting in the ranking pages belonging to relevant topic categories, or categories similar to the relevant categories. By following external links and searching for the retrieved Wikipedia entities in a general Web collection, we can also exploit the structure of Wikipedia to rank entities on the general Web. Wikipedia, in contrast to the general Web, does not contain much redundant information. This absence of redundant information can be exploited by using Wikipedia as a pivot to search the general Web.A typical query returns thousands or millions of documents, but searchers hardly ever look beyond the first result page. Since space on the result page is limited, we can show only a few documents in the result list. Word clouds can be used to summarise groups of documents into a set of keywords which allows users to quickly get a grasp on the underlying data. Instead of using user-assigned tags we generate word clouds from the textual contents of documents themselves as well as the anchor text ofWeb documents. Improvements over word clouds that are created using simple term frequency counting include using a parsimonious term weighting scheme, including bigrams and biasing the word cloud towards the query. We find that word clouds can to a certain degree quickly convey the topic and relevance of a set of search results. Available online at: http://dare.uva.nl/record/39569.},
journal = {SIGIR Forum},
month = jan,
pages = {108},
numpages = {1}
}

@article{10.1145/1067268.1067286,
author = {Browne, Paul},
title = {Video Information Retrieval Using Objects and Ostensive Relevance Feedback},
year = {2005},
issue_date = {June 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1067268.1067286},
doi = {10.1145/1067268.1067286},
abstract = {The thesis discusses and evaluates a model of video information retrieval that incorporates a variation of Relevance Feedback and facilitates object-based interaction and ranking. Object-based feature search for video IR is one of the main novel aspects of this work.},
journal = {SIGIR Forum},
month = jun,
pages = {54},
numpages = {1}
}

@article{10.1145/2641383.2641392,
author = {Berardi, Giacomo},
title = {Semi-Automated Text Classification},
year = {2014},
issue_date = {June 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2641383.2641392},
doi = {10.1145/2641383.2641392},
abstract = {There is currently a high demand for information systems that automatically analyze textual data, since many organizations, both private and public, need to process large amounts of such data as part of their daily routine, an activity that cannot be performed by means of human work only. One of the answers to this need is text classification (TC), the task of automatically labelling textual documents from a domain D with thematic categories from a predefined set C. Modern text classification systems have reached high efficiency standards, but cannot always guarantee the labelling accuracy that applications demand. When the level of accuracy that can be obtained is insufficient, one may revert to processes in which classification is performed via a combination of automated activity and human effort.One such process is semi-automated text classification (SATC), which we define as the task of ranking a set D of automatically labelled textual documents in such a way that, if a human annotator validates (i.e., inspects and corrects where appropriate) the documents in a top-ranked portion of D with the goal of increasing the overall labelling accuracy of D, the expected such increase is maximized. An obvious strategy is to rank D so that the documents that the classifier has labelled with the lowest confidence are top-ranked. In this dissertation we show that this strategy is suboptimal. We develop new utility-theoretic ranking methods based on the notion of validation gain, defined as the improvement in classification efectiveness that would derive by validating a given automatically labelled document. We also propose new effectiveness measures for SATC-oriented ranking methods, based on the expected reduction in classification error brought about by partially validating a ranked list generated by a given ranking method. We report the results of experiments showing that, with respect to the baseline method above, and according to the proposed measures, our utility-theoretic ranking methods can achieve substantially higher expected reductions in classification error. We therefore explore the task of SATC and the potential of our methods, in multiple text classification contexts.This dissertation is, to the best of our knowledge, the first to systematically address the task of semi-automated text classification.},
journal = {SIGIR Forum},
month = jun,
pages = {42},
numpages = {1}
}

@article{10.1145/2492189.2492203,
author = {Neumayer, Robert},
title = {Semantic and Distributed Entity Search in the Web of Data},
year = {2012},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2492189.2492203},
doi = {10.1145/2492189.2492203},
abstract = {Both the growth and ubiquitous character of the Internet have had a profound effect on how we access and consume data and information. More recently, the Semantic Web, an extension of the current Web has come increasingly relevant due to its widespread adoption.The Web of Data (WoD) is an extension of the current web, where not only documents are interlinked by means of hyperlinks but also data in terms of predicates. Specifically, it describes objects, entities or "things" in terms of their attributes and their relationships, using RDF data (and often is used equivalently to Linked Data). Given its growth, there is a strong need for making this wealth of knowledge accessible by keyword search (the de-facto standard paradigm for accessing information online).The goal of this thesis is to provide new techniques for accessing this data, i.e., to leverage its full potential to end users. We therefore address the following four main issues: a) how can the Web of Data be searched by means of keyword search?, b) what sets apart search in the WoD from traditional web search?, c) how can these elements be used in a sound and effective way?, and d) How can the techniques be adapted to a distributed environment?To this end, we develop techniques for effectively searching WoD sources. We build upon and formalise existing entity modelling approaches within a generative language modelling framework, and compare them experimentally using standard test collections. We show that these models outperform the current state-of-the-art in terms of retrieval effectiveness, however, this is done at the cost of abandoning a large part of the semantics behind the data. We propose a novel entity model capable of preserving the semantics associated with entities, without sacrificing retrieval effectiveness. We further show how these approaches can be applied in the distributed context, both with low (federated search) and high numbers (Peer-to-peer or P2P) of independent repositories, collections, or nodes.The main contributions are as follows: We develop a hybrid approach to search in the Web of Data, using elements from traditional information retrieval and structured retrieval alike.We formalise our approaches in a language model setting.We discuss and analyse based on our empirical evaluation and provide insights into the entity search problem..},
journal = {SIGIR Forum},
month = jun,
pages = {64},
numpages = {1}
}

@article{10.1145/1328964.1328988,
author = {Gabrilovich, Evgeniy},
title = {Feature Generation for Textual Information Retrieval Using World Knowledge},
year = {2007},
issue_date = {December 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1328964.1328988},
doi = {10.1145/1328964.1328988},
abstract = {Imagine an automatic news filtering system that tracks company news. Given the news item "FDA approves ciprofloxacin for victims of anthrax inhalation", how can the system know that the drug mentioned is an antibiotic produced by Bayer? Or consider an information professional searching for data on RFID technology -- how can a computer understand that the item "Wal-Mart supply chain goes real time" is relevant for the search? Algorithms we present can do just that.},
journal = {SIGIR Forum},
month = dec,
pages = {123},
numpages = {1}
}

@article{10.1145/2568388.2568413,
author = {Hofmann, Katja},
title = {Fast and Reliable Online Learning to Rank for Information Retrieval},
year = {2013},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/2568388.2568413},
doi = {10.1145/2568388.2568413},
journal = {SIGIR Forum},
month = jan,
pages = {140},
numpages = {1}
}

@article{10.1145/1480506.1480527,
author = {Carterette, Benjamin A.},
title = {Low-Cost and Robust Evaluation of Information Retrieval Systems},
year = {2008},
issue_date = {December 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1480506.1480527},
doi = {10.1145/1480506.1480527},
abstract = {Research in Information Retrieval has progressed against a background of rapidly increasing corpus size and heterogeneity, with every advance in technology quickly followed by a desire to organize and search more unstructured, more heterogeneous, and even bigger corpora. But as retrieval problems get larger and more complicated, evaluating the ranking performance of a retrieval engine gets harder: evaluation requires human judgments of the relevance of documents to queries, and for very large corpora the cost of acquiring these judgments may be insurmountable. This cost limits the types of problems researchers can study as well as the data they can be studied on.We present methods for understanding performance differences between retrieval engines in the presence of missing and noisy relevance judgments. The work introduces a model of the cost of experimentation that incorporates the cost of human judgments as well as the cost of drawing incorrect conclusions about differences between engines in both the training and testing phases of engine development. Through adopting a view of evaluation that is more concerned with distributions over performance differences rather than estimates of absolute performance, the expected cost can be minimized so as to reliably differentiate between engines with less than 1% of the human effort that has been used in past experiments.},
journal = {SIGIR Forum},
month = nov,
pages = {104},
numpages = {1}
}

@article{10.1145/2964797.2964815,
author = {Liu, Xitong},
title = {Entity Centric Information Retrieval},
year = {2016},
issue_date = {June 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2964797.2964815},
doi = {10.1145/2964797.2964815},
abstract = {In the past decade, the prosperity of the World Wide Web has led to fast explosion of information, and there is a long-standing demand on how to access such a huge volume of information effectively and efficiently. Information Retrieval (IR) aims to tackle the challenge by exploring approaches to obtain relevant information items (e.g., documents) relevant to a given information need (e.g., query) from a huge collection of textual data (e.g., the Web). Named entity (e.g., person, location, product, event, organization) is a type of term compound widely existing in textual data. Recent advances in Information Extraction make it possible to extract entities from large volume of free text efficiently, and the research community are actively exploring whether entities would contribute to the retrieval effectiveness.In this thesis, we investigate how to leverage entities to improve retrieval in several directions. We start with finding entities with certain semantic relation, which aims at retrieving entities and their associated attributes to meet user's information need directly. This is different from traditional search paradigm in which only documents are retrieved. Entity retrieval is performed by first retrieving a list of documents and then extracting entities from those documents. We propose a novel probabilistic framework which leverages supporting documents as bridge to model the relevance between query and entities and rank entities accordingly.On the other side, we also explore how to leverage entities to improve effectiveness of ad hoc document retrieval in two directions. The first direction is entity-centric query expansion. We find related entities of query, and perform query expansion using the names and relations of related entities. Significant improvements over several state-of-the-art feedback models could be observed on multiple data collections. Besides, we explore another direction: entity-centric relevance modeling. We propose a novel retrieval approach, i.e., Latent Entity Space (LES), which models the relevance by leveraging entity profiles to represent semantic content of documents and queries. Experimental results over several TREC collections show that LES is effective on capturing latent semantic content and can significantly improve the search accuracy of several state-of-the-art retrieval models for entity-bearing queries.This thesis presents a series of research efforts on entity centric information retrieval in several directions, and reveals promising potential of entities on improving the retrieval effectiveness. With the fast curation of high-quality knowledge base, more information about entities could be easily accessed and integrated into retrieval models. We hope our work could serve as guideline for future work on leveraging entities to improve information retrieval in more applications.},
journal = {SIGIR Forum},
month = jun,
pages = {92},
numpages = {1}
}

@article{10.1145/2215676.2215690,
author = {He, Jiyin},
title = {Exploring Topic Structure: Coherence, Diversity and Relatedness},
year = {2012},
issue_date = {June 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2215676.2215690},
doi = {10.1145/2215676.2215690},
abstract = {The use of topical information has long been studied in the context of information retrieval. For example, grouping search results into topical categories enables more effective information presentation to users, while grouping documents in a collection can lead to efficient information access. We define a topic as the main theme or subject contained in a (set of) document(s). While topics provide information about the subjects contained in a document, the structure of topics provides information such as the degree to which a set of documents is focused on certain topic (or set of topics), topical diversity among documents, and semantic relatedness of topics.The work of this thesis focuses on modeling the structure of topics present in a (set of) document(s), with the goal of effectively using it in information retrieval. In particular, we consider a number of IR tasks where the notion of relevance is beyond "aboutness" and topic structure plays an important role in satisfying users' information need. The following research themes are addressed, in three parts: (1) topic coherence, (2) diversity and the cluster hypothesis, and (3) relating topics present in different representations.With respect to the first research theme, we develop a coherence measure that effectively captures topical coherence of a set of documents. The proposed measure is applied to two IR tasks, namely, blog feed retrieval and query performance prediction.In the second part of the thesis, we explore the impact of topic structure on effectively presenting retrieval results, with a focus on the scenario of result diversification. We re-visit the cluster hypothesis with respect to ambiguous or multi-faceted queries and investigate the effectiveness of query-specific clustering in result diversification.Topics can be represented in different ways, e.g., using clusters, using definitions from a thesaurus, using statistics of term frequencies, etc. In the third part of the thesis, we study the problem of relating topics represented in different forms within the context of automatic link generation. We identify a set of significant terms from a source text, link those terms to their corresponding entries in a knowledge base in such a way that the source text is annotated with background information available in the knowledge base. We conduct a case study in automatically generating links from narrative radiology reports to Wikipedia. Such links are expected to help users understand the medical terminology and thereby increase the value of the reports. Here we evaluate state-of-the-art link generation systems and propose an approach that improves over state-of-the-art systems on radiology data.Available online at http://dare.uva.nl/record/377895.},
journal = {SIGIR Forum},
month = may,
pages = {84},
numpages = {1}
}

@article{10.1145/2215676.2215688,
author = {Bashir, Shariq},
title = {Evaluating Retrieval Models Using Retrievability Measurement},
year = {2012},
issue_date = {June 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2215676.2215688},
doi = {10.1145/2215676.2215688},
abstract = {Evaluation is the main driving force in research, development and applications related to information retrieval (IR). In the traditional IR evaluation paradigm a list of query topics along with their relevance judgments are given. The main limitation of this kind of evaluation paradigm is that it focuses almost exclusively on a small set of judged documents and does not consider what influence the given retrieval models have on accessing all the relevant information in the collection. This is particularly important for recall oriented retrieval applications where we want to ensure that that everything relevant has been found.In this thesis we analyze the effectiveness of retrieval models from the documents retrievability point of view. We focus particularly on the retrieval bias of different retrieval models, and try to examine to what extent this bias restricts the users in retrieving relevant information. We explore this research with the help of three factors. First, we analyze the relationship between different characteristics of queries and retrievability. This is important from the query generation point of view, since in case of exhaustive queries, it is practically infeasible to complete retrievability approximation in reasonable time. The strong correlation between retrievability and query characteristics allows us to approximate the retrievability score accurately with the help of a query subset without processing an exhaustive number of queries. After this, we examine to what extent the retrievability and other IR effectiveness measures are related to each other. This specifically helps us to understand to what extent it is possible to automatically rank the effectiveness of retrieval models on the basis of their retrieval bias. This also offers a basis for optimizing retrieval systems for specific collections without the need to provide manually annotated ground truth. This is particularly useful for those retrieval domains where it is difficult to obtain a sufficient amount of relevance judgments. At the end we investigate and devise different retrieval strategies for mitigating the effect of low retrievability of documents. These include collection partitioning and query expansion on the basis of improved pseudo relevance feedback selection.The work present in this thesis provides an a novel approach for the evaluation and optimization of retrieval models particularly for recall oriented retrieval domains, where the focus is on retrieving all relevant information but not just retrieving a subset of relevant information. Available online at: http://www.ifs.tuwien.ac.at/~bashir/shariqbashir_phd_thesis.pdf.},
journal = {SIGIR Forum},
month = may,
pages = {81},
numpages = {1}
}

@article{10.1145/1095489.1095491,
author = {Kalan, James E.},
title = {Cryogenic Programming},
year = {1971},
issue_date = {Summer 1971},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095489.1095491},
doi = {10.1145/1095489.1095491},
abstract = {The past twenty years has witnessed an incredible growth in computer computing capability. Indeed, the million-fold increase in multiplication speeds alone have made possible the efficient solution to seemingly impossible problems. A quite theoretical question is that of determining the limit, if one exists, of possible hardware performance. A <u>realistic response</u> is how to extend it.},
journal = {SIGIR Forum},
month = jul,
pages = {15–17},
numpages = {3}
}

@article{10.1145/1189702.1189717,
author = {Siddiqui, Tanveer J},
title = {Intelligent Techniques for Effective Information Retrieval: (A Conceptual Graph Based Approach)},
year = {2006},
issue_date = {December 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1189702.1189717},
doi = {10.1145/1189702.1189717},
abstract = {With the explosive growth of information, it is becoming increasingly difficult to retrieve the relevant documents with statistical means only. This begets new challenges to IR community and motivates researchers to look for intelligent Information Retrieval (IR) systems that search and/or filter information automatically based on some higher level of understanding are required. This higher level of understanding can only be achieved through processing of text based on semantics, which is not possible by considering a document as a "bag of words". We make a humble effort in this direction by investigating techniques that attempt to utilize semantics to improve effectiveness in IR. The hypothesis is that with an improved representation of documents and by incorporating limited semantic knowledge, it is possible to improve the effectiveness of an IR system.We propose the use of Conceptual Graph (CG) formalism for representing text. The level of semantic details to be captured within conceptual graphs and the type of relations used to relate concepts depend on the nature of the application and the domain in which it is to be used. The objective of any IR system is to classify documents as relevant and non-relevant with respect to a standing query. A detailed and accurate semantic analysis is not required for this task. This fact distinguishes IR from other natural language processing related tasks such as machine translation, question answering, text summarization, etc. Further, the amount of text with which an IR system has to deal with is so huge that it becomes impractical to carry out such analysis. So we take a middle ground by investigating techniques that make use of limited semantic knowledge that can be easily exacted from the text in the CG representation. The techniques investigated in this thesis make use of CG-based model in conjunction with the statistical vector space model. The two models thus complement each other allowing us to take the benefits of the long and established research efforts in the statistical models and versatility of semantic models.The statistical model used in the experimental work is the most widely followed vector space model. We investigate performance of this model with different combinations of term weighting schemes for documents and queries, yielding seven different retrieval models, on the CACM-3204 collection. The best performing case, we achieved was with 'augmented normalized tem frequency' and 'raw term frequency with length normalization' components for document and query terms respectively, where inverse document frequency component is incorporated in both. The eleven-point average precision score (11-AvgP) score for the base model was 0.2961 (averaged over 64 queries).To get CG-based representation of a document, we build conceptual graph for each sentence in the document. A small subset of basic relations has been used for constructing conceptual graphs. These relations have been extracted based on syntactic patterns. A manually constructed partial concept type hierarchy has been used. This restricts us from performing large-scale experimentation automatically. As an alternative to this, we maintain a set of terms replaceable for each other and use some simple heuristics to capture structural variations. Queries undergo more detailed processing as compared to documents. The conceptual graphs obtained thus are stored in the form of triplets. The CG representation used is easily scalable and lends itself for fine-tuning easily according to the needs of many different NLP applications.This thesis argues that conceptual graphs can be used as a precision tool. A hybrid information retrieval model is proposed to back up this argument. This model is essentially a two-stage retrieval model that first uses vector space model to quickly downsize the document collection and then uses CG-based model to do the final ranking. A manually constructed partial concept type hierarchy has been used. The experimental investigations have been made on CACM-3204, a collection called CGDOC, which is a small document collection designed by us and on the top ten results retrieved from LYCOS search engine. A significant improvement over the baseline performance has been observed for a subset of CACM queries.Next, a query expansion technique based on relevance feedback has been presented. This technique attempts to reduce the 'query drift' through the use of conceptual graph based representation of document in the expansion process. Two relevance feedback strategies have been proposed and evaluated. Both the strategies resulted in a significant improvement over the baseline performance for a subset of CACM queries.The motivation for the next technique evaluated by us lies in our belief that relation matching can be used to improve retrieval effectiveness. The roots of this belief lie in the fact that the semantics of terms can only be understood in the context they are being used. Relation matching provides a means to capture this context. To investigate the effectiveness of our technique we propose a retrieval model that integrates relation and keyword matching. There can be no better way to capture the relationships than the use of conceptual graphs and hence the CG based model, with certain enhancements and modification, remains an integral part of this work. A set of replaceable terms instead of type hierarchy has been used. Some simple heuristics along with the transitivity of relations have been used to capture structural variations. For identifying relational similarity between the query and the document, we propose new CG similarity measures. These measures have been used in the retrieval process along with the usual term similarity measures. The results obtained have shown a significant improvement (7.37%) in retrieval performance.The results of this thesis demonstrate that by improving document/query representation and by incorporating more information from within the document and the query into the retrieval process, the effectiveness of the information retrieval is enhanced. The major findings can be summarizes as:• The use of conceptual graphs as a knowledge representation formalism offers many advantages in IR. The general model, presented in this thesis, for creating conceptual graph from natural language text can be easily extended to capture more semantics if domain specific information is available.• Two stage retrieval models can be quite effective in improving retrieval performance.• Relation matching can be integrated successfully with existing statistical retrieval model to improve retrieval effectiveness.• New CG similarity measures proposed in the thesis offer flexibility in defining textual units that make them useful for many different applications.• Simple heuristics can be used to capture structural variations.• Queries, instead of documents can be targeted for semantic interpretation.},
journal = {SIGIR Forum},
month = dec,
pages = {73–74},
numpages = {2}
}

@article{10.1145/986278.986294,
author = {Can, Fazli},
title = {Review of "Mining the Web: Discovering Knowledge from Hypertext Data" by Soumen Chakrabati. Morgan Kaufman 2003.},
year = {2004},
issue_date = {June 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/986278.986294},
doi = {10.1145/986278.986294},
journal = {SIGIR Forum},
month = jul,
pages = {73–74},
numpages = {2}
}

@article{10.1145/381984.381988,
author = {Groman, Robert C.},
title = {Elsevier Science's Home Page: Sign of the Times},
year = {1996},
issue_date = {April 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/381984.381988},
doi = {10.1145/381984.381988},
journal = {SIGIR Forum},
month = apr,
pages = {42},
numpages = {2}
}

@article{10.1145/1988852.1988871,
author = {Huurnink, Bouke},
title = {Search in Audiovisual Broadcast Archives},
year = {2011},
issue_date = {June 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1988852.1988871},
doi = {10.1145/1988852.1988871},
abstract = {Documentary makers, journalists, news editors, and other media professionals routinely require previously recorded audiovisual material for new productions. For example, a news editor might wish to reuse footage shot by overseas services for the evening news, or a documentary maker might require shots of Christmas trees recorded over the decades. Important sources for reusable broadcasts are audiovisual broadcast archives, which preserve and manage audiovisual material. With digitization, media professional can be given online access to video. This increases ease of access, but increases the need for search capabilities tailored for the media professional. Search in audiovisual broadcast archives, then, is the subject of this thesis.We begin by investigating the search behavior of media professionals in current daily practice. To this end we perform a large-scale log analysis of their search actions at a national audiovisual broadcast archive. Our analysis characterizes not only the searches of media professionals, but also their purchasing behavior. In order to model the observed behavior we follow our log analysis with a simulation experiment. Here we investigate simulation methods for recreating the searches and purchases recorded in the archive to create evaluation testbeds.In the second half of the thesis we turn to investigate the use of state-of-art methods for retrieval with automatically generated content metadata from video, Specifically we focus on their application for improving audiovisual fragment search in the audiovisual broadcast archive. We use logged searches and purchases to define new test collections for retrieval evaluation. These are used as the basis for experiments aimed at solving specific problems that are faced when searching with automatically generated descriptions of video content. Finally, we combine state-of-the-art methods with the current daily practice of the archive, and investigate their potential combined impact on search in audiovisual broadcast archives.The contributions of this thesis include the characterization of searching and purchasing behaviour of media professionals at a large audiovisual broadcast archive, and a framework for simulating their logged queries and purchases. Contributions in the second half of the thesis include an in-depth user study of how text queries should be mapped to visual concepts, a retrieval model that accounts for the temporal mismatch between the speech and visual tracks in audiovisual material, and a set of experiments demonstrating the effectiveness of automatically generated content metadata for improving retrieval in the audiovisual broadcast archive.The thesis can be accessed at http://dare.uva.nl/record/358972.},
journal = {SIGIR Forum},
month = may,
pages = {77},
numpages = {1}
}

@article{10.1145/381984.381985,
author = {Fox, Edward A.},
title = {Lab Report Special Section: Virginia Tech Department of Computer Science Information Access Laboratory},
year = {1996},
issue_date = {April 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/381984.381985},
doi = {10.1145/381984.381985},
journal = {SIGIR Forum},
month = apr,
pages = {3–10},
numpages = {8}
}

@article{10.1145/1013234.803145,
author = {Noreault, Terry and Mcgill, Michael},
title = {SIRE},
year = {1978},
issue_date = {May 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013234.803145},
doi = {10.1145/1013234.803145},
abstract = {SIRE (Syracuse Information Retrieval Experiment) is an interactive bibliographic retrieval system. It was developed at the School of Information Studies at Syracuse University. It is implemented in SAIL (Stanford Artificial Intelligence Language), an ALGOL like language, on a DEC KL-10. SIRE presently has two data bases; 1) one issue of Physics Abstracts with 7146 documents; and 2) a sign language linguistics data base from Gallaudet College with 490 documents.},
journal = {SIGIR Forum},
month = may,
pages = {178–179},
numpages = {2}
}

@inproceedings{10.1145/800096.803145,
author = {Noreault, Terry and Mcgill, Michael},
title = {SIRE},
year = {1978},
isbn = {9781450374026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800096.803145},
doi = {10.1145/800096.803145},
abstract = {SIRE (Syracuse Information Retrieval Experiment) is an interactive bibliographic retrieval system. It was developed at the School of Information Studies at Syracuse University. It is implemented in SAIL (Stanford Artificial Intelligence Language), an ALGOL like language, on a DEC KL-10. SIRE presently has two data bases; 1) one issue of Physics Abstracts with 7146 documents; and 2) a sign language linguistics data base from Gallaudet College with 490 documents.},
booktitle = {Proceedings of the 1st Annual International ACM SIGIR Conference on Information Storage and Retrieval},
pages = {178–179},
numpages = {2},
series = {SIGIR '78}
}

@article{10.1145/1842890.1842895,
author = {Doherty, Aiden R. and Gurrin, Cathal and Jones, Gareth J.F. and Smeaton, Alan F.},
title = {Information Access for Personal Media Archives},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1842890.1842895},
doi = {10.1145/1842890.1842895},
abstract = {It is now possible to archive much of our life experiences in digital form using a variety of sources, e.g. blogs written, tweets made, photographs taken, etc. Information can be captured from a myriad of personal information devices. In this workshop, researchers from diverse disciplines discussed how we can advance towards the goal of effective capture, retrieval and exploration of e-memories. Proposed solutions included advanced textile sensors to capture new data, P2P methods to store this data, and personal reflection applications to review this data. Much discussion centered around search and navigation strategies, interactive interfaces, and the cognitive basis in using digitally captured information as memorabilia.},
journal = {SIGIR Forum},
month = aug,
pages = {33–37},
numpages = {5}
}

@article{10.1145/1924475.1924499,
author = {Shah, Chirag},
title = {A Framework for Supporting User-Centric Collaborative Information Seeking},
year = {2011},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1924475.1924499},
doi = {10.1145/1924475.1924499},
abstract = {Collaboration is often required or encouraged for activities that are too complex or difficult to deal with for an individual. Many situations involving information seeking also call for people working together. Despite its natural appeal and situational necessity, collaboration in information seeking is an understudied domain. The nature of the available information and its role in our lives have changed significantly, but the methods and tools that are used to access and share that information in collaboration have remained largely unaltered. This dissertation is an attempt to develop a new framework for collaborative information seeking (CIS) with a focus on user-centric system designs. To develop this framework, existing practices for doing collaboration, along with motivations and methods, are studied. This initial investigation and a review of literature are followed by a series of carefully created design studies, helping us develop a prototype CIS system, Coagmento. This system is then used for a large-scale laboratory experiment with a focus on studying the role and the impact of awareness in CIS projects. Through this study, it is shown that appropriate support for group awareness can help collaborators be more productive, engaged, and aware in collaboration without burdening them with additional load. Using the lessons derived from the literature as well as the set of studies presented in this dissertation, a novel framework for CIS is proposed. Such a framework could help us develop, study, and evaluate CIS systems with a more comprehensive understanding of various CIS processes, and the users of these systems.Dissertation available online at: http://comminfo.rutgers.edu/~chirags/papers/Shah_Dissertation.pdf.},
journal = {SIGIR Forum},
month = jan,
pages = {88},
numpages = {1}
}

@article{10.1145/3190580.3190609,
author = {Kowald, Dominik},
title = {Modeling Activation Processes in Human Memory to Improve Tag Recommendations},
year = {2018},
issue_date = {December 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/3190580.3190609},
doi = {10.1145/3190580.3190609},
abstract = {Social tagging systems enable users to collaboratively assign freely chosen keywords (i.e., tags) to resources (e.g., Web links). In order to support users in finding descriptive tags, tag recommendation algorithms have been proposed. One issue of current state-of-the-art tag recommendation algorithms is that they are often designed in a purely data-driven way and thus, lack a thorough understanding of the cognitive processes that play a role when people assign tags to resources. A prominent example is the activation equation of the cognitive architecture ACT-R, which formalizes activation processes in human memory to determine if a specific memory unit (e.g., a word or tag) will be needed in a specific context. It is the aim of this thesis to investigate if a cognitive-inspired approach, which models activation processes in human memory, can improve tag recommendations. For this, the relation between activation processes in human memory and usage practices of tags is studied, which reveals that (i) past usage frequency, (ii) recency, and (iii) semantic context cues are important factors when people reuse tags. Based on this, a cognitive-inspired tag recommendation approach termed BLLAC+MPr is developed based on the activation equation of ACT-R. An extensive evaluation using six real-world folksonomy datasets shows that BLLAC+MPr outperforms current state-of-the-art tag recommendation algorithms with respect to various evaluation metrics. Finally, BLLAC+MPr is utilized for hashtag recommendations in Twitter to demonstrate its generalizability in related areas of tag-based recommender systems. The findings of this thesis demonstrate that activation processes in human memory can be utilized to improve not only social tag recommendations but also hashtag recommendations. This opens up a number of possible research strands for future work, such as the design of cognitive-inspired resource recommender systems.},
journal = {SIGIR Forum},
month = feb,
pages = {166},
numpages = {1}
}

@article{10.1145/1095387.1095388,
author = {McGill, Michael},
title = {Information Retrieval Activities at the School of Information Studies Syracuse University},
year = {1980},
issue_date = {Spring 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095387.1095388},
doi = {10.1145/1095387.1095388},
abstract = {The School of Information Studies of Syracuse University was known as the School of Library Science until 1974. This name change signalled a shift in emphasis from the traditional study of the library and library activities to a concern with the needs, uses, acquisition, organization, storage and retrieval of information. It also indicated a shift toward a research environment. Since 1974 the School has moved from essentially no outside research income to a fairly stable base of approximately $500, 000 per year. Research activities now include topics such as the study of ranking algorithms in information retrieval systems; the development and study of a health information sharing project; a study of the user-search intermediary question negotiation process; and a study of the impact of the representation of documents in an information retrieval system.},
journal = {SIGIR Forum},
month = apr,
pages = {13–16},
numpages = {4}
}

@article{10.1145/1394251.1394271,
author = {Metzler, Donald},
title = {Beyond Bags of Words: Effectively Modeling Dependence and Features in Information Retrieval},
year = {2008},
issue_date = {June 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1394251.1394271},
doi = {10.1145/1394251.1394271},
abstract = {Current state of the art information retrieval models treat documents and queries as bags of words. There have been many attempts to go beyond this simple representation. Unfortunately, few have shown consistent improvements in retrieval effectiveness across a wide range of tasks and data sets. Here, we propose a new statistical model for information retrieval based on Markov random fields. The proposed model goes beyond the bag of words assumption by allowing dependencies between terms to be incorporated into the model. This allows for a variety of textual and non-textual features to be easily combined under the umbrella of a single model. Within this framework, we explore the theoretical issues involved, parameter estimation, feature selection, and query expansion. We give experimental results from a number of information retrieval tasks, such as ad hoc retrieval and web search.},
journal = {SIGIR Forum},
month = jun,
pages = {77},
numpages = {1}
}

@article{10.1145/948716.948719,
author = {Croft, Bruce and Callan, Jamie and Lafferty, John},
title = {Workshop on Language Modeling and Information Retrieval},
year = {2001},
issue_date = {Spring 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/948716.948719},
doi = {10.1145/948716.948719},
journal = {SIGIR Forum},
month = apr,
pages = {4–6},
numpages = {3}
}

@article{10.1145/1988852.1988868,
author = {Demartini, Gianluca},
title = {From People to Entities: Typed Search in the Enterprise and the Web},
year = {2011},
issue_date = {June 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1988852.1988868},
doi = {10.1145/1988852.1988868},
abstract = {The exponential growth of digital information available in Enterprises and on the Web creates the need for search tools that can respond to the most sophisticated informational needs. Retrieving relevant documents is not enough anymore and finding entities rather than textual resources provides great support to the user both on the Web and in Enterprises. Many user tasks would be simplified if Search Engines would support typed search, and return entities instead of just Web pages. For example, an executive who tries to solve a problem needs to find people in the company who are knowledgeable about a certain topic. Aggregation of information spread over different documents is a key aspect in this process.Finding experts is a problem mostly considered in the Enterprise setting where teams for new projects need to be built and problems need to be solved by the right persons. In the first part of the thesis, we propose a model for expert finding based on the well consolidated vector space model for Information Retrieval and investigate its effectiveness.We can define Entity Retrieval by generalizing the expert finding problem to any entity. In Entity Retrieval the goal is to rank entities according to their relevance to a query (e.g., "Countries where I can pay in Euro"); the set of entities to be ranked is assumed to be loosely defined by a generic category, given in the query itself (e.g., countries), or by some example entities (e.g., Italy, Germany, France). In the second part of the thesis, we investigate different methods based on Semantic Web and Natural Language Processing techniques for solving these tasks both in Wikipedia and, generally, on the Web. Evaluation is a critical aspect of Information Retrieval. We contributed to the field of Information Retrieval evaluation by organizing an evaluation initiative for Entity Retrieval.Opinions and other relevant information about entities can be provided by different sources in different contexts. News articles report about events where entities are involved. In such setting the temporal dimension is critical as news stories develop over time and new entities appear in the story and others are not relevant anymore. In the third part of this thesis, we study the problem of Entity Retrieval for news applications and the importance of the news trail history (i.e., past related articles) to determine the relevant entities in current articles. We also study opinion evolution about entities. In the last years, the blogosphere has become a vital part of the Web, covering a variety of different points of view and opinions on political and event-related topics such as immigration, election campaigns, or economic developments. We propose a method for automatically extracting public opinion about specific entities from the blogosphere.Available online at http://www.gianlucademartini.net/research/phd/.},
journal = {SIGIR Forum},
month = may,
pages = {73},
numpages = {1}
}

@article{10.1145/1394251.1394266,
author = {Tait, John},
title = {Information Retrieval Facility Symposium in Vienna},
year = {2008},
issue_date = {June 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1394251.1394266},
doi = {10.1145/1394251.1394266},
abstract = {On November 8-9, 2007 the new Information Retrieval Facility (www.ir-facility.org) held its first annual Symposium in Vienna. The focus of the symposium was patent retrieval, and it was attended by 125 experts in Information Retrieval, Intellectual Property Management and related areas. Delegates came from Korea, Hong Kong, Singapore, Australia, Canada, the US and 10 European Countries. In terms of organisations, delegates came from Universities, Patent Offices (EPO, WIPO) and from commercial organisations ranging from majors like Shell and GlaxoSmithKline to one and two person consultancies.},
journal = {SIGIR Forum},
month = jun,
pages = {67},
numpages = {1}
}

@article{10.1145/1095505.1095506,
title = {Response to "Stratification"},
year = {1973},
issue_date = {Spring 1973},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095505.1095506},
doi = {10.1145/1095505.1095506},
journal = {SIGIR Forum},
month = apr,
pages = {17–18},
numpages = {2}
}

@article{10.1145/1273221.1273232,
author = {Si, Luo},
title = {Federated Search of Text Search Engines in Uncooperative Environments},
year = {2007},
issue_date = {June 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1273221.1273232},
doi = {10.1145/1273221.1273232},
abstract = {Conventional search engines like Google provide access to Web information that can be acquired easily by crawling hyperlinks. However, a large amount of information cannot be copied arbitrarily by conventional search engines. This type of hidden information, which is very valuable, can only be accessed via an alternative search model other than the centralized retrieval model used by conventional search engines.},
journal = {SIGIR Forum},
month = jun,
pages = {120},
numpages = {1}
}

@article{10.1145/1113343.1113358,
author = {Zhang, Yi},
title = {Bayesian Graphical Models for Adaptive Filtering},
year = {2005},
issue_date = {December 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1113343.1113358},
doi = {10.1145/1113343.1113358},
journal = {SIGIR Forum},
month = dec,
pages = {57},
numpages = {1}
}

@article{10.1145/1067268.1067296,
author = {Westerveld, Thijs},
title = {Using Generative Probabilistic Models for Multimedia Retrieval},
year = {2005},
issue_date = {June 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1067268.1067296},
doi = {10.1145/1067268.1067296},
abstract = {This thesis discusses information retrieval from multimedia archives, focusing on documents containing visual material. We investigate search and retrieval in collections of images and video, where video is defined as a sequence of still images. No assumptions are made with respect to the content of the documents; we concentrate on retrieval from generic, heterogeneous multimedia collections. In this research area a user's query typically consists of one or more example images and the implicit request is: "Find images similar to this one." In addition the query may contain a textual description of the information need. The research presented here addresses three issues within this area.},
journal = {SIGIR Forum},
month = jun,
pages = {69},
numpages = {1}
}

@article{10.1145/30075.30076,
author = {Salton, G.},
title = {Expert Systems and Information Retrieval},
year = {1987},
issue_date = {March 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/30075.30076},
doi = {10.1145/30075.30076},
abstract = {The existing bibliographic retrieval systems are too complex to permit direct on-line access by untrained end users. Expert system approaches have been introduced in the hope of simplifying the document indexing, search and retrieval operations and rendering these operations accessible to end users. The expert system approach is examined briefly in this note and the conclusion is reached that expert systems are unlikely to provide much relief in ordinary retrieval environments. Simpler and more effective retrieval systems than those currently in use can be implemented by falling back on methodologies proposed and evaluated over twenty years ago that operate without expert system intervention.},
journal = {SIGIR Forum},
month = mar,
pages = {3–9},
numpages = {7}
}

@article{10.1145/1013881.802695,
author = {Kibler, Tom R.},
title = {APCAM (A Practical Cellular Associative Memory)},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802695},
doi = {10.1145/1013881.802695},
abstract = {This paper discusses about APCAM. APCAM was designed as a practical intelligent parallel search disk for support of relational data base systems. The aim was not to provide a complete relational engine but to provide a machine which would search large volumes of data and perform projections and restrictions along with helping with sorting.},
journal = {SIGIR Forum},
month = mar,
pages = {82–83},
numpages = {2}
}

@inproceedings{10.1145/800083.802695,
author = {Kibler, Tom R.},
title = {APCAM (A Practical Cellular Associative Memory)},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802695},
doi = {10.1145/800083.802695},
abstract = {This paper discusses about APCAM. APCAM was designed as a practical intelligent parallel search disk for support of relational data base systems. The aim was not to provide a complete relational engine but to provide a machine which would search large volumes of data and perform projections and restrictions along with helping with sorting.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {82–83},
numpages = {2},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1067268.1067292,
author = {Martinet, Jean},
title = {A Relational Vector-Space Model of Information Retrieval Adapted to Images},
year = {2005},
issue_date = {June 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1067268.1067292},
doi = {10.1145/1067268.1067292},
abstract = {The increase of digital image acquisition devices, combined to the growth of the Web, requires the definition of Information Retrieval (IR) models and systems providing fast access to images searched by users among large amounts of data.},
journal = {SIGIR Forum},
month = jun,
pages = {62},
numpages = {1}
}

@article{10.1145/1067268.1067289,
author = {Doraisamy, Shyamala},
title = {Polyphonic Music Retrieval: The n-Gram Approach},
year = {2005},
issue_date = {June 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1067268.1067289},
doi = {10.1145/1067268.1067289},
abstract = {This Music Information Retrieval (MIR) study investigates the use of n-grams and textual Information Retrieval (IR) approaches for the retrieval and access of polyphonic music data. IR, synonymous with text IR, implies the task of retrieving documents or texts with information content that is relevant to a user's information need.},
journal = {SIGIR Forum},
month = jun,
pages = {58},
numpages = {1}
}

@article{10.1145/986278.986297,
author = {Hedlund, Turid},
title = {Dictionary-Based Cross-Language Information Retrieval: Principles, System Design and Evaluation},
year = {2004},
issue_date = {June 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/986278.986297},
doi = {10.1145/986278.986297},
journal = {SIGIR Forum},
month = jul,
pages = {76},
numpages = {1}
}

@article{10.1145/1067268.1067291,
author = {Kraaij, Wessel},
title = {Variations on Language Modeling for Information Retrieval},
year = {2005},
issue_date = {June 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1067268.1067291},
doi = {10.1145/1067268.1067291},
abstract = {Search engine technology builds on theoretical and empirical research results in the area of information retrieval (IR). This dissertation makes a contribution to the field of language modeling (LM) for IR, which views both queries and documents as instances of a unigram language model and defines the matching function between a query and each document as the probability that the query terms are generated by the document language model. The work described is concerned with three research issues.},
journal = {SIGIR Forum},
month = jun,
pages = {61},
numpages = {1}
}

@article{10.1145/2492189.2492200,
author = {Albakour, M-Dyaa},
title = {Adaptive Domain Modelling for Information Retrieval},
year = {2012},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2492189.2492200},
doi = {10.1145/2492189.2492200},
abstract = {Modern search engines employ a number of interactive features to assist users in exploring the document collection and expressing their information needs. Providing these features require knowledge about the document collection in the domain, i.e. a domain model. These models may be difficult to obtain and even if they are available, they may become out of date when the document collection changes or the users start to view the domain differently. In this thesis we propose to use implicit feedback left by users while they interact with search engines to build domain models that evolve over time. These models can adapt to changes in the domain as reflected in the search trend of the user population.We validate these models in two different IR tasks. The major application is query recommendation where previous studies focused on Web search in general or did not consider the temporal aspect of recommendations. Our models address these issues as they are targeted to specific domains such as enterprise search or digital libraries. We furthermore devise an automatic evaluation methodology that allows us to perform extensive evaluation of our adaptive models and observe their performance over time. Using query logs collected from two academic institutions, the evaluation framework assesses the impact of different factors on their performance.The second application of these models is query session retrieval. The query session retrieval problem extends the traditional ad-hoc retrieval by taking into account the previous user interactions with the retrieval system within the same session when answering the query. In this context rather than explicitly providing the user with relevant queries to their information needs, our adaptive models implicitly derive query expansions relevant to the user information needs as identified in the sessions by mapping the session to similar sessions inferred from the models.},
journal = {SIGIR Forum},
month = jun,
pages = {59},
numpages = {1}
}

@article{10.1145/1067268.1067295,
author = {Stokoe, Christopher M.},
title = {Automated Word Sense Disambiguation for Web Information Retrieval},
year = {2005},
issue_date = {June 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1067268.1067295},
doi = {10.1145/1067268.1067295},
abstract = {A word in the English language is considered ambiguous if, regardless of context, it can have more than one possible interpretation or meaning. Many words exhibit lexical ambiguity suggesting that it has the potential to impact upon the performance of text retrieval systems. This may be particularly true in the case of web retrieval given the hypothesis that short queries may not provide sufficient context to adequately differentiate between opposing meanings of constituent words. Word sense disambiguation is an active field of study which seeks to create software which automatically resolves ambiguity through mapping word use to meaning. In this study the author examined the use of word sense disambiguation in order to resolve ambiguity within an IR collection. The motivation behind this work was to demonstrate the potential for increased retrieval effectiveness as a result of performing word sense disambiguation.},
journal = {SIGIR Forum},
month = jun,
pages = {68},
numpages = {1}
}

@article{10.1145/1067268.1067288,
author = {Chau, Michael},
title = {Searching and Mining the Web for Personalized and Specialized Information},
year = {2005},
issue_date = {June 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1067268.1067288},
doi = {10.1145/1067268.1067288},
abstract = {With the rapid growth of the Web, users are often faced with the problem of information overload and find it difficult to search for relevant and useful information on the Web. Besides general-purpose search engines, there exist some alternative approaches that can help users perform searches on the Web more effectively and efficiently. Personalized search agents and specialized search engines are two such approaches. The goal of this research is to investigate how machine learning and artificial intelligence techniques can be used to improve these approaches.},
journal = {SIGIR Forum},
month = jun,
pages = {57},
numpages = {1}
}

@article{10.1145/1924475.1924498,
author = {Liu, Jingjing},
title = {Personalizing Information Retrieval Using Task Stage, Topic Knowledge, and Task Products},
year = {2011},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1924475.1924498},
doi = {10.1145/1924475.1924498},
abstract = {Personalization of information retrieval tailors search towards individual users to meet their particular information needs by taking into account information about users and their contexts, often through implicit sources of evidence such as user behaviors and contextual factors. The current study looks particularly at users' dwelling behavior, measured by the time that they spend on documents; and several contextual factors: the stage of users' work tasks, task type, users' knowledge of task topics, to explore whether or not taking account of task stage, task type, and topic knowledge could help predict document usefulness from the time that users spend on the documents. This study also investigates whether or not expanding queries with important terms extracted from task products and useful pages improves search performance. To these ends, a controlled lab experiment was conducted with 24 student participants, each coming three times in a two-week period to work on three subtasks in a general work task. Data were collected by logging software that recorded user-system interaction and questionnaires that elicited users' background information and perceptions on a number of aspects. Observations in the study and examinations of the data found that the time users spent on documents could have three different types: total display time, total dwell time, and decision time, which had different roles in working as a reliable indicator of document usefulness. Task stage was found to help interpret certain types of time as reliable indicators of document usefulness in certain task types, so was topic knowledge, and the latter played a more significant role when both were available. This study contributes to a better understanding of how information seeking behaviors, specifically, time that users spend on documents, can be used as implicit evidence of document usefulness, as well as how contextual factors of task stage, topic knowledge, and task type can help interpret time as an indicator of usefulness. These findings have theoretical and practical implications for using behaviors and contextual factors in the development of personalization systems. Future studies are suggested on making use of these findings as well as research on related issues.},
journal = {SIGIR Forum},
month = jan,
pages = {87},
numpages = {1}
}

@article{10.1145/986278.986296,
author = {Diekema, Anne R.},
title = {Translation Events in Cross-Language Information Retrieval},
year = {2004},
issue_date = {June 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/986278.986296},
doi = {10.1145/986278.986296},
journal = {SIGIR Forum},
month = jul,
pages = {75},
numpages = {1}
}

@article{10.1145/2215676.2215687,
author = {Athenikos, Sofia J.},
title = {Enabling Entity Retrieval by Exploiting Wikipedia as a Semantic Knowledge Source},
year = {2012},
issue_date = {June 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/2215676.2215687},
doi = {10.1145/2215676.2215687},
abstract = {This dissertation research, PanAnthropon FilmWorld, aims to demonstrate direct retrieval of entities and related facts by exploiting Wikipedia as a semantic knowledge source, with the film domain as its proof-of-concept domain of application. To this end, a semantic knowledge base concerning the film domain has been constructed with the data extracted/derived from 10,640 Wikipedia pages on films and additional pages on film awards. The knowledge base currently contains 209,266 entities and 2,345,931 entity-centric facts. Both the knowledge base and the corresponding semantic search interface are based on the coherent classification of entities. Entity-centric facts are also consistently represented as <entity, attribute,="" value,="" note=""> tuples. The semantic search interface (http://dlib.ischool.drexel.edu:8080/sofia/PA/) supports multiple types of semantic search functions, which go beyond the traditional keyword-based search function, including the main General Entity Retrieval Query (GERQ) function, which is concerned with retrieving all entities that match the specified entity type, subtype, and semantic conditions and thus corresponds to the main research problem. Two types of evaluation have been performed in order to evaluate (1) the quality of information extraction and (2) the effectiveness of information retrieval using the semantic interface. The first type of evaluation has been performed by inspecting 11,495 film-centric facts concerning 100 films. The results have confirmed high data quality with 99.96% average precision and 99.84% average recall. The second type of evaluation has been performed by conducting an experiment with human subjects. The experiment involved having the subjects perform a retrieval task by using both the PanAnthropon interface and the Internet Movie Database (IMDb) interface and comparing their task performance between the two interfaces. The results have confirmed higher effectiveness of the PanAnthropon interface vs. the IMDb interface (83.11% vs. 40.78% average precision; 83.55% vs. 40.26% average recall). Moreover, the subjects' responses to the post-task questionnaire indicate that the subjects found the PanAnthropon interface to be highly usable and easily understandable as well as highly effective. The main contribution from this research therefore consists in achieving the set research goal, namely, demonstrating the utility and feasibility of semantics-based direct entity retrieval.},
journal = {SIGIR Forum},
month = may,
pages = {80},
numpages = {1}
}</entity,>

@article{10.1145/75335.75479,
author = {Salton, G. and Smith, M.},
title = {On the Application of Syntactic Methodologies in Automatic Text Analysis},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75479},
doi = {10.1145/75335.75479},
abstract = {This study summarizes various linguistic approaches proposed for document analysis in information retrieval environments. Included are standard syntactic methods to generate complex content identifiers, and the use of semantic know-how obtained from machine-readable dictionaries and from specially constructed knowledge bases. A particular syntactic analysis methodology is also outlined and its usefulness for the automatic construction of book indexes is examined.},
journal = {SIGIR Forum},
month = may,
pages = {137–150},
numpages = {14}
}

@inproceedings{10.1145/75334.75479,
author = {Salton, G. and Smith, M.},
title = {On the Application of Syntactic Methodologies in Automatic Text Analysis},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75479},
doi = {10.1145/75334.75479},
abstract = {This study summarizes various linguistic approaches proposed for document analysis in information retrieval environments. Included are standard syntactic methods to generate complex content identifiers, and the use of semantic know-how obtained from machine-readable dictionaries and from specially constructed knowledge bases. A particular syntactic analysis methodology is also outlined and its usefulness for the automatic construction of book indexes is examined.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {137–150},
numpages = {14},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/986278.986301,
author = {Shiri, Ali Asghar},
title = {End-User Interaction with Thesaurus-Enhanced Search Interfaces: An Evaluation of Search Term Selection for Query Expansion},
year = {2004},
issue_date = {June 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/986278.986301},
doi = {10.1145/986278.986301},
journal = {SIGIR Forum},
month = jul,
pages = {80},
numpages = {1}
}

@article{10.1145/373593.373597,
author = {Robertson, Stephen},
title = {Salton Award Lecture on Theoretical Argument in Information Retrieval},
year = {2000},
issue_date = {April 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/373593.373597},
doi = {10.1145/373593.373597},
journal = {SIGIR Forum},
month = apr,
pages = {1–10},
numpages = {10}
}

@article{10.1145/281250.281253,
author = {Jansen, Bernard J. and Spink, Amanda and Bateman, Judy and Saracevic, Tefko},
title = {Real Life Information Retrieval: A Study of User Queries on the Web},
year = {1998},
issue_date = {Spring 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/281250.281253},
doi = {10.1145/281250.281253},
abstract = {We analyzed transaction logs of a set of 51,473 queries posed by 18,113 users of Excite, a major Internet search service. We provide data on: (i) queries --- the number of search terms, and the use of logic and modifiers, (ii) sessions --- changes in queries during a session, number of pages viewed, and use of relevance feedback, and (iii) terms --- their rank/frequency distribution and the most highly used search terms. Common mistakes are also observed. Implications are discussed.},
journal = {SIGIR Forum},
month = apr,
pages = {5–17},
numpages = {13}
}

@article{10.1145/1013230.511806,
author = {Raghavan, Vijay V. and Shi, Hong-pao and Yu, C. T.},
title = {Evaluation of the 2-Poisson Model as a Basis for Using Term Frequency Data in Searching},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511806},
doi = {10.1145/1013230.511806},
abstract = {The early work on the probabilistic models of retrieval assumed that the document representation is binary, indicating only the presence or absence of index terms. The 2-Poisson (TP) model which was proposed as a model of how the occurrence frequency of specialty words in a collection is distributed, has since been used to develop retrieval strategies that incorporate term frequency information. This work investigates the use of the TP model, in this context, further. It is shown that the search effectiveness, when no relevance information is assumed, can be further enhanced by using this model. Furthermore, when the term weights proposed in this work are used in conjunction with weights known as term significance weights, the results are very encouraging.},
journal = {SIGIR Forum},
month = jun,
pages = {88–100},
numpages = {13}
}

@inproceedings{10.1145/511793.511806,
author = {Raghavan, Vijay V. and Shi, Hong-pao and Yu, C. T.},
title = {Evaluation of the 2-Poisson Model as a Basis for Using Term Frequency Data in Searching},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511806},
doi = {10.1145/511793.511806},
abstract = {The early work on the probabilistic models of retrieval assumed that the document representation is binary, indicating only the presence or absence of index terms. The 2-Poisson (TP) model which was proposed as a model of how the occurrence frequency of specialty words in a collection is distributed, has since been used to develop retrieval strategies that incorporate term frequency information. This work investigates the use of the TP model, in this context, further. It is shown that the search effectiveness, when no relevance information is assumed, can be further enhanced by using this model. Furthermore, when the term weights proposed in this work are used in conjunction with weights known as term significance weights, the results are very encouraging.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {88–100},
numpages = {13},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/146565.146568,
author = {Croft, W. Bruce},
title = {The University of Massachusetts TIPSTER Project},
year = {1992},
issue_date = {Fall 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/146565.146568},
doi = {10.1145/146565.146568},
abstract = {The TIPSTER project in the Information Retrieval Laboratory of the Computer Science Department, University of Massachusetts, Amherst (which includes MCC and David Lewis of the University of Chicago as subcontractors), is focusing on the following goals:• Improving the effectiveness of information retrieval techniques for large, full-text databases,• Improving the effectiveness of routing techniques appropriate for long-term information needs, and• Demonstrating the effectiveness of these retrieval and routing techniques for Japanese full-text databases.},
journal = {SIGIR Forum},
month = oct,
pages = {29–33},
numpages = {5}
}

@article{10.1145/146565.146566,
author = {Duval, E. and Olivi\'{e}, H.},
title = {Towards the Integration of a Query Mechanism and Navigation for Retrieval of Data on Multimedia Documents},
year = {1992},
issue_date = {Fall 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/146565.146566},
doi = {10.1145/146565.146566},
abstract = {Traditionally, two paradigms are discerned with respect to data retrieval [3, 17]:1. A query mechanism enables the user to express conditions that characterize the data he is looking for. The Data Base Management System (DBMS) is responsible for retrieval of the data that satisfy these conditions.2. Navigation or browsing can be used to investigate the content of the database by following links between related data.We will start with a discussion of these paradigms in the first two sections. We will then explore how both approaches can be combined. Finally, a practical implementation of the advocated approach will be presented. The implemented prototype supports access to a database on multimedia material. A more elaborated discussion of our ideas and results in this area can be found in [16].},
journal = {SIGIR Forum},
month = oct,
pages = {8–25},
numpages = {18}
}

@article{10.1145/305110.305112,
author = {Kirsch, Steven},
title = {Infoseek's Experiences Searching the Internet},
year = {1998},
issue_date = {Sept. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/305110.305112},
doi = {10.1145/305110.305112},
journal = {SIGIR Forum},
month = sep,
pages = {3–7},
numpages = {5}
}

@article{10.1145/1013228.511767,
author = {Smeaton, A. F. and van Rijsbergen, C. J.},
title = {The Nearest Neighbour Problem in Information Retrieval: An Algorithm Using Upperbounds},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511767},
doi = {10.1145/1013228.511767},
journal = {SIGIR Forum},
month = may,
pages = {83–87},
numpages = {5}
}

@inproceedings{10.1145/511754.511767,
author = {Smeaton, A. F. and van Rijsbergen, C. J.},
title = {The Nearest Neighbour Problem in Information Retrieval: An Algorithm Using Upperbounds},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511767},
doi = {10.1145/511754.511767},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {83–87},
numpages = {5},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013230.511830,
author = {Salton, G.},
title = {Some Research Problems in Automatic Information Retrieval},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511830},
doi = {10.1145/1013230.511830},
abstract = {Information retrieval components are currently incorporated in several types of information systems, including bibliographic retrieval systems, data base management systems and question-answering systems. Some of the problems arising in the real-time environment in which these systems operate are briefly discussed. Certain recent advances in information retrieval research are then mentioned, including the formulation of new probabilistic retrieval models, and the development of automatic document analysis and Boolean query processing techniques.},
journal = {SIGIR Forum},
month = jun,
pages = {252–263},
numpages = {12}
}

@inproceedings{10.1145/511793.511830,
author = {Salton, G.},
title = {Some Research Problems in Automatic Information Retrieval},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511830},
doi = {10.1145/511793.511830},
abstract = {Information retrieval components are currently incorporated in several types of information systems, including bibliographic retrieval systems, data base management systems and question-answering systems. Some of the problems arising in the real-time environment in which these systems operate are briefly discussed. Certain recent advances in information retrieval research are then mentioned, including the formulation of new probabilistic retrieval models, and the development of automatic document analysis and Boolean query processing techniques.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {252–263},
numpages = {12},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1095454.1095455,
title = {Abstracts of Presentations Made at ACM '81},
year = {1982},
issue_date = {Winter 1982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095454.1095455},
doi = {10.1145/1095454.1095455},
abstract = {Information files of all kinds are now in common use--personnel records, parts inventories, customer account information, business correspondence, document holdings in libraries, patient records in hospitals, and so on. Information retrieval systems are designed to help analyze and describe the items stored in a file, to organize them and search among them, and finally to retrieve them in response to a user's query.Designing and using a retrieval system involves four major activities: information analysis, information organization and search, query formulation, and information retrieval and dissemination. The tutorial and panel discussion are designed to examine the current developments in the field and to point the way to the future. The emphasis in the discussion will be placed on modern online retrieval services, automatic indexing and abstracting and novel text matching systems.},
journal = {SIGIR Forum},
month = jan,
pages = {5–8},
numpages = {4}
}

@article{10.1145/1013228.511760,
author = {Croft, W. Bruce},
title = {Incorporating Different Search Models into One Document Retrieval System},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511760},
doi = {10.1145/1013228.511760},
abstract = {Many effective search strategies derived from different models are available for document retrieval systems. However, it does not appear that there is a single most effective strategy. Instead, different strategies perform optimally under different conditions. This paper outlines the design of an adaptive document retrieval system that chooses the best search strategy for a particular situation and user. In order to be able to support a variety of search strategies, a general network representation of the documents and terms in the database is proposed. This network representation leads to efficient methods of generating and using document and term classifications.One of the most desirable features of an adaptive system would be the ability to learn from experience. A method of incorporating this learning ability into the system is described. The adaptive control strategy for choosing search strategies enables the system to base its actions on a number of factors, including a model of the current user.Finally, some ideas for a flexible interface for casual users are suggested. Part of this interface is the heuristic search, which is used when searches based on formal models have failed. The heuristic search provides a browsing capability for the user.},
journal = {SIGIR Forum},
month = may,
pages = {40–45},
numpages = {6}
}

@inproceedings{10.1145/511754.511760,
author = {Croft, W. Bruce},
title = {Incorporating Different Search Models into One Document Retrieval System},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511760},
doi = {10.1145/511754.511760},
abstract = {Many effective search strategies derived from different models are available for document retrieval systems. However, it does not appear that there is a single most effective strategy. Instead, different strategies perform optimally under different conditions. This paper outlines the design of an adaptive document retrieval system that chooses the best search strategy for a particular situation and user. In order to be able to support a variety of search strategies, a general network representation of the documents and terms in the database is proposed. This network representation leads to efficient methods of generating and using document and term classifications.One of the most desirable features of an adaptive system would be the ability to learn from experience. A method of incorporating this learning ability into the system is described. The adaptive control strategy for choosing search strategies enables the system to base its actions on a number of factors, including a model of the current user.Finally, some ideas for a flexible interface for casual users are suggested. Part of this interface is the heuristic search, which is used when searches based on formal models have failed. The heuristic search provides a browsing capability for the user.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {40–45},
numpages = {6},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/965643.810248,
author = {Lipovski, G. J.},
title = {On Imaginary Fields, Token Transfers and Floating Codes in Intelligent Secondary Memories},
year = {1977},
issue_date = {May 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/965643.810248},
doi = {10.1145/965643.810248},
abstract = {In analyzing two implemented intelligent secondary memories, CASSM and RAP, we recognize a common mechanism which is here called an imaginary field. The mechanism can be generalized to suggest further design possibilities. It further explains the complex and controversial CASSM mechanism, “pointer transfer” in terms of separate but related principles—imaginary fields, token transfers, and floating codes—such that further designs can utilize some or all of the techniques.},
journal = {SIGIR Forum},
month = jan,
pages = {17–22},
numpages = {6}
}

@inproceedings{10.1145/800180.810248,
author = {Lipovski, G. J.},
title = {On Imaginary Fields, Token Transfers and Floating Codes in Intelligent Secondary Memories},
year = {1977},
isbn = {9781450374804},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800180.810248},
doi = {10.1145/800180.810248},
abstract = {In analyzing two implemented intelligent secondary memories, CASSM and RAP, we recognize a common mechanism which is here called an imaginary field. The mechanism can be generalized to suggest further design possibilities. It further explains the complex and controversial CASSM mechanism, “pointer transfer” in terms of separate but related principles—imaginary fields, token transfers, and floating codes—such that further designs can utilize some or all of the techniques.},
booktitle = {Proceedings of the 3rd Workshop on Computer Architecture : Non-Numeric Processing},
pages = {17–22},
numpages = {6},
series = {CAW '77}
}

@article{10.1145/1095360.1095364,
author = {Jones, Karen Sparck},
title = {Modern On-Line Systems: Challenges to Research},
year = {1979},
issue_date = {Winter 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095360.1095364},
doi = {10.1145/1095360.1095364},
abstract = {Automatic information retrieval, that is document retrieval, was an early concern in computing. It might, however, be thought that since modern on-line systems have more than achieved the technological aims of the original workers in the field, there is no further need for research. I shall argue that this is not the case.},
journal = {SIGIR Forum},
month = jan,
pages = {15–25},
numpages = {11}
}

@article{10.1145/75335.75361,
author = {Frakes, W. B.},
title = {Information Retrieval and Software Reuse},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75361},
doi = {10.1145/75335.75361},
abstract = {Software reuse is widely believed to be the most promising technology for improving software quality and productivity. There are many technical and non-technical problems to be solved, however, before widespread reuse of software lifecycle objects becomes a reality. One class of problem concerns the classification, storage, and retrieval of reusable components. Panel members will discuss these problems and some approaches to solving them.},
journal = {SIGIR Forum},
month = may,
pages = {251–256},
numpages = {6}
}

@inproceedings{10.1145/75334.75361,
author = {Frakes, W. B.},
title = {Information Retrieval and Software Reuse},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75361},
doi = {10.1145/75334.75361},
abstract = {Software reuse is widely believed to be the most promising technology for improving software quality and productivity. There are many technical and non-technical problems to be solved, however, before widespread reuse of software lifecycle objects becomes a reality. One class of problem concerns the classification, storage, and retrieval of reusable components. Panel members will discuss these problems and some approaches to solving them.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {251–256},
numpages = {6},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/195498.195502,
author = {Gudivada, Venkat N.},
title = {TESSA—an Image Testbed for Evaluating 2-D Spatial Similarity Algorithms},
year = {1994},
issue_date = {Fall 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/195498.195502},
doi = {10.1145/195498.195502},
abstract = {In multimedia database applications, a major class of users' requests require retrieving those images in the database that are spatially similar to the query image. To process such queries, a spatial similarity algorithm is required. A spatial similarity algorithm assesses the degree to which the spatial relationships among the domain objects in a database image conform to those specified in the query image. The recent ubiquitous interest in multimedia information systems has spurred a great interest in spatial similarity algorithms. A standard testbed of images is required not only to systematically evaluate these algorithms but also to compare and contrast them. However, there is no such testbed of images available for this purpose.In this paper, we describe a collection of images, referred to as TESSA, as a testbed for investigating the robustness of spatial similarity algorithms and their further use in evaluating the retrieval effectiveness of these algorithms. The TESSA collection comprises 160 images and are produced by generating 15 variants of each of the 10 original images. Image variants are produced by scale, rotation, and translation, and by an arbitrary composition of these three transformations. The variants are designed to inquire into the robustness of spatial similarity algorithms. To facilitate their further use in evaluating the retrieval effectiveness, each image in TESSA is considered as a query in turn, and an expert is asked to provide a rank ordering of the TESSA images with respect to the query image vis-a-vis expert provided rank ordering. System provided rank ordering for a query image is the rank ordering of TESSA images induced by a spatial similarity algorithm with respect to the query. Retrieval effectiveness of spatial similarity algorithms is then characterized by using Rnorm measure. This measure is based on both the expert and system provided rank orderings.},
journal = {SIGIR Forum},
month = sep,
pages = {17–36},
numpages = {20}
}

@article{10.1145/75335.75336,
author = {Smith, P. J. and Shute, S. J. and Galdes, D.},
title = {In Search of Knowledge-Based Search Tactics},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75336},
doi = {10.1145/75335.75336},
abstract = {Knowledge-based search tactics are discussed in terms of their role in the functioning of a semantically-based search system for bibliographic information retrieval. This prototype system, EP-X, actively assists users in defining or refining their topics of interest. It does so by applying search tactics to a knowledge-base describing topics in a particular domain and a database describing the contents of individual documents.This paper reviews the empirical studies that lead to the two central concepts implemented in EP-X:
Semantically-based search;Knowledge-based search tactics.},
journal = {SIGIR Forum},
month = may,
pages = {3–10},
numpages = {8}
}

@inbook{10.1145/75334.75336,
author = {Smith, P. J. and Shute, S. J. and Galdes, D.},
title = {In Search of Knowledge-Based Search Tactics},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75336},
abstract = {Knowledge-based search tactics are discussed in terms of their role in the functioning of a semantically-based search system for bibliographic information retrieval. This prototype system, EP-X, actively assists users in defining or refining their topics of interest. It does so by applying search tactics to a knowledge-base describing topics in a particular domain and a database describing the contents of individual documents.This paper reviews the empirical studies that lead to the two central concepts implemented in EP-X:
Semantically-based search;Knowledge-based search tactics.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3–10},
numpages = {8}
}

@article{10.1145/75335.75354,
author = {Berrut, C. and Chiaramella, Y.},
title = {Indexing Medical Reports in a Multimedia Environment: The RIME Experimental Approach},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75354},
doi = {10.1145/75335.75354},
abstract = {This paper focuses on the RIME system aimed to the indexing of medical reports in a multimedia environment. This particular application is viewed as representative of a large set of still unanswered needs of large communities of users: domain experts dealing with on-line specialized documentation such as software engineers, medical specialists and so on. In this application textual information appears as an interesting media to access related pictures in the data base. After the presentation of the application and a study of the particular corpus involved we define a semantic model for the documents which is based on a Conceptual Language. Then we detail the indexing process and its various linguistic components which perform the translation of every medical report according to this semantic model.},
journal = {SIGIR Forum},
month = may,
pages = {187–197},
numpages = {11}
}

@inproceedings{10.1145/75334.75354,
author = {Berrut, C. and Chiaramella, Y.},
title = {Indexing Medical Reports in a Multimedia Environment: The RIME Experimental Approach},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75354},
doi = {10.1145/75334.75354},
abstract = {This paper focuses on the RIME system aimed to the indexing of medical reports in a multimedia environment. This particular application is viewed as representative of a large set of still unanswered needs of large communities of users: domain experts dealing with on-line specialized documentation such as software engineers, medical specialists and so on. In this application textual information appears as an interesting media to access related pictures in the data base. After the presentation of the application and a study of the particular corpus involved we define a semantic model for the documents which is based on a Conceptual Language. Then we detail the indexing process and its various linguistic components which perform the translation of every medical report according to this semantic model.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {187–197},
numpages = {11},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/43936.1096826,
author = {Salton, Gerald},
title = {ABSTRACTS (Chosen by G. Salton from Recent Issues of Journals in the Retrieval Area.)},
year = {1988},
issue_date = {Fall 1987/Winter 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/43936.1096826},
doi = {10.1145/43936.1096826},
abstract = {GRANT is an expert system for finding sources of funding given research proposals. Its search method - constrained spreading activation - makes inferences about the goals of the user and thus finds information that the user did not explicitly request but that is likely to be useful. The architecture of GRANT and the implementation of constrained spreading activation are described, and GRANT's performance is evaluated.},
journal = {SIGIR Forum},
month = jan,
pages = {29–37},
numpages = {9}
}

@article{10.1145/54347.54348,
author = {Harman, D. and Benson, D. and Fitzpatrick, L. and Huntzinger, R. and Goldstein, C.},
title = {IRX: An Information Retrieval System for Experimentation and User Applications},
year = {1988},
issue_date = {Spring/Summer 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/54347.54348},
doi = {10.1145/54347.54348},
abstract = {IRX is a text retrieval system designed to be a testbed for conducting information retrieval research on statistically-based retrieval strategies in either batch or interactive modes. The modular structure of IRX has permitted major changes in components of the system (e.g., ranking algorithms, parsers, interfaces; without redesign. As an interactive system IRX is in use at the Johns Hopkins University and the Lister Hill Center providing access to databases in human and molecular genetics.},
journal = {SIGIR Forum},
month = may,
pages = {2–10},
numpages = {9}
}

@article{10.1145/263868.263871,
author = {Salton, G.},
title = {A Blueprint for Automatic Indexing},
year = {1997},
issue_date = {Spring 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/263868.263871},
doi = {10.1145/263868.263871},
abstract = {This note summarizes some of the currently available insights in automatic indexing. The emphasis is on aspects that are expected to be useful in practical automatic indexing applications. The discussion is necessarily cursory, but the references will lead interested readers to a deeper treatment of the indexing problem.},
journal = {SIGIR Forum},
month = apr,
pages = {23–36},
numpages = {14}
}

@article{10.1145/122642.122644,
author = {Sparck Jones, Karen},
title = {Notes and References on Early Automatic Classification Work},
year = {1991},
issue_date = {Spring 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/122642.122644},
doi = {10.1145/122642.122644},
abstract = {This informal note was prompted by discussions and questions at the 1990 AAAI Spring Symposium on Text-Based Intelligent Systems (cf Jacobs 1990). There is a growing interest in access to, and the use of, large scale full-text databases for a variety of purposes, and in the application of classification methods to organise the mass of data involved (see e.g. Church and Hanks 1990). A good deal of work has been done in this field in the past, but it is little known, and some of the early research literature is not very accessible. Classification is an area in which it is easy to make plausible but mistaken assumptions, and as this certainly holds for classification in retrieval, there is a good deal that can be usefully learnt from past experience, most of which was hard won from careful thought and grinding experiment. This paper is intended as an introduction to this initial work on automatic classification, to help those now becoming interested in classification to avoid unnecessarily repeating heavy effort or, more especially, reinventing square wheels. It should also be noted that automatic classification and related (e.g. seriation) methods have been extensively developed for biological applications in particular, but have been more variously applied, and that much of this work may be relevant in the broad area of machine learning.It must be emphasised that as this paper is focussed on early work on automatic classification, particularly for information retrieval, and is designed primarily to lead into this research and its literature, it does not attempt a critical evaluation of the overall results established by now, or of the current state of the art. However it should be pointed out that in the retrieval context in general, as opposed to the wider one of classification as a whole, there has been comparatively little work since the seventies, largely for the reasons indicated in the paper. More recent work in any case refers heavily to earlier research, so this note can be taken as an entry point to the research of the last decade for which some references are given at the end of the note.},
journal = {SIGIR Forum},
month = may,
pages = {10–17},
numpages = {8}
}

@article{10.1145/1013232.511714,
author = {Wiersba, R. K.},
title = {The Role of Information Retrieval in the Second Computer Revolution},
year = {1979},
issue_date = {September 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013232.511714},
doi = {10.1145/1013232.511714},
abstract = {Information retrieval is conceptually fundamental in human communication as well as in man-computer communication. Computing and Information Retrieval professionals have the opportunity to apply information retrieval techniques within the second computer revolution to foster a new potential revolution in education, brought about by the advent of the personal computer.},
journal = {SIGIR Forum},
month = sep,
pages = {52–58},
numpages = {7}
}

@inproceedings{10.1145/511706.511714,
author = {Wiersba, R. K.},
title = {The Role of Information Retrieval in the Second Computer Revolution},
year = {1979},
isbn = {9781450373456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511706.511714},
doi = {10.1145/511706.511714},
abstract = {Information retrieval is conceptually fundamental in human communication as well as in man-computer communication. Computing and Information Retrieval professionals have the opportunity to apply information retrieval techniques within the second computer revolution to foster a new potential revolution in education, brought about by the advent of the personal computer.},
booktitle = {Proceedings of the 2nd Annual International ACM SIGIR Conference on Information Storage and Retrieval: Information Implications into the Eighties},
pages = {52–58},
numpages = {7},
location = {Dallas, Texas},
series = {SIGIR '79}
}

@article{10.1145/1013232.511712,
author = {Miller, Leslie},
title = {Document Representation Models for Retrieval Systems},
year = {1979},
issue_date = {September 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013232.511712},
doi = {10.1145/1013232.511712},
abstract = {Document retrieval system models are presented. Measures to rank the closeness of documents to a query are given. Algorithms to calculate the measures for graph and partition models are provided.},
journal = {SIGIR Forum},
month = sep,
pages = {41–44},
numpages = {4}
}

@inproceedings{10.1145/511706.511712,
author = {Miller, Leslie},
title = {Document Representation Models for Retrieval Systems},
year = {1979},
isbn = {9781450373456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511706.511712},
doi = {10.1145/511706.511712},
abstract = {Document retrieval system models are presented. Measures to rank the closeness of documents to a query are given. Algorithms to calculate the measures for graph and partition models are provided.},
booktitle = {Proceedings of the 2nd Annual International ACM SIGIR Conference on Information Storage and Retrieval: Information Implications into the Eighties},
pages = {41–44},
numpages = {4},
location = {Dallas, Texas},
series = {SIGIR '79}
}

@article{10.1145/983026.983000,
author = {Korfhage, R. R. and Day, W. H. E. and Beck, L. L. and Appelbe, W. F.},
title = {Data Physics: An Unorthodox View of Data and Its Implications in Data Processors},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983000},
doi = {10.1145/983026.983000},
journal = {SIGIR Forum},
month = aug,
pages = {1–7},
numpages = {7}
}

@article{10.1145/24634.24635,
author = {Van Rijsbergen, C J},
title = {A New Theoretical Framework for Information Retrieval},
year = {1986},
issue_date = {Sept.-March 1986-1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/24634.24635},
doi = {10.1145/24634.24635},
abstract = {A new framework based on a non-classical logic is proposed for investigating IR. The paper motivates the use of a particular conditional logic as the 'right' logic for IR. A new principle, the logical uncertainty principle, is proposed, to deal with the inherent uncertainty associated with applicable inferences.},
journal = {SIGIR Forum},
month = sep,
pages = {23–29},
numpages = {7}
}

@article{10.1145/1013234.803135,
author = {Hill, Edward},
title = {Analysis of an Inverted Data Base Structure},
year = {1978},
issue_date = {May 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013234.803135},
doi = {10.1145/1013234.803135},
abstract = {An inverted data base organization is analyzed. The inverted directory is viewed realistically as another large data base. Algorithms and formulations are derived to estimate the average number of accesses for insertion, retrieval and deletion of items from the data base. An average load time is also presented for the inverted data base.},
journal = {SIGIR Forum},
month = may,
pages = {37–64},
numpages = {28},
keywords = {Inverted file organization, Information storage and retrieval, Data base performance}
}

@inproceedings{10.1145/800096.803135,
author = {Hill, Edward},
title = {Analysis of an Inverted Data Base Structure},
year = {1978},
isbn = {9781450374026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800096.803135},
doi = {10.1145/800096.803135},
abstract = {An inverted data base organization is analyzed. The inverted directory is viewed realistically as another large data base. Algorithms and formulations are derived to estimate the average number of accesses for insertion, retrieval and deletion of items from the data base. An average load time is also presented for the inverted data base.},
booktitle = {Proceedings of the 1st Annual International ACM SIGIR Conference on Information Storage and Retrieval},
pages = {37–64},
numpages = {28},
keywords = {Data base performance, Inverted file organization, Information storage and retrieval},
series = {SIGIR '78}
}

@article{10.1145/1095475.1095477,
author = {Salton, G.},
title = {Some Characteristics of Future Information Systems},
year = {1985},
issue_date = {Fall 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095475.1095477},
doi = {10.1145/1095475.1095477},
abstract = {The existing information systems are characterized by sophisticated hardware designs and relatively unforgiving software support. One may expect that future information systems will provide a unified approach to several different types of information processing tasks, as well as more user-friendly processing environments. Some of the requirements of future information systems are described in this note and various advances in retrieval system design are examined, including automatic indexing, automatic query formulation, and extended Boolean query processing.},
journal = {SIGIR Forum},
month = sep,
pages = {28–39},
numpages = {12}
}

@article{10.1145/1013228.511770,
author = {Smith, Linda C.},
title = {Representation Issues in Information Retrieval System Design},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511770},
doi = {10.1145/1013228.511770},
abstract = {The representation problem confronting information retrieval system designers is outlined in terms of three issues: what to represent, forms of representation, and functions of representation. Questions raised by each of these issues are identified and selected research projects which have begun to explore these questions are described.},
journal = {SIGIR Forum},
month = may,
pages = {100–105},
numpages = {6}
}

@inproceedings{10.1145/511754.511770,
author = {Smith, Linda C.},
title = {Representation Issues in Information Retrieval System Design},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511770},
doi = {10.1145/511754.511770},
abstract = {The representation problem confronting information retrieval system designers is outlined in terms of three issues: what to represent, forms of representation, and functions of representation. Questions raised by each of these issues are identified and selected research projects which have begun to explore these questions are described.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {100–105},
numpages = {6},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/331403.331405,
author = {Silverstein, Craig and Marais, Hannes and Henzinger, Monika and Moricz, Michael},
title = {Analysis of a Very Large Web Search Engine Query Log},
year = {1999},
issue_date = {Fall 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/331403.331405},
doi = {10.1145/331403.331405},
abstract = {In this paper we present an analysis of an AltaVista Search Engine query log consisting of approximately 1 billion entries for search requests over a period of six weeks. This represents almost 285 million user sessions, each an attempt to fill a single information need. We present an analysis of individual queries, query duplication, and query sessions. We also present results of a correlation analysis of the log entries, studying the interaction of terms within queries. Our data supports the conjecture that web users differ significantly from the user assumed in the standard information retrieval literature. Specifically, we show that web users type in short queries, mostly look at the first 10 results only, and seldom modify the query. This suggests that traditional information retrieval techniques may not work well for answering web search requests. The correlation analysis showed that the most highly correlated items are constituents of phrases. This result indicates it may be useful for search engines to consider search terms as parts of phrases even if the user did not explicitly specify them as such.},
journal = {SIGIR Forum},
month = sep,
pages = {6–12},
numpages = {7}
}

@article{10.1145/381984.381987,
author = {Wong, Jacqueline W. T. and Kan, W. K. and Young, Gilbert},
title = {ACTION: Automatic Classification for Full-Text Documents},
year = {1996},
issue_date = {April 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/381984.381987},
doi = {10.1145/381984.381987},
abstract = {An important step in building up the document database of a full-text retrieval system is to classify each document under one or more classes according to the topical domains that the document discusses. This is commonly referred to as classification. Automatic classification attempts to replace human classifiers by using computers to automate this process. Automatic classification has two major components: (1) the classification scheme which defines the available classes under which a document can be classified and their inter-relationships; and (2) the classification algorithm which defines the rules and procedures for assigning one or more classes defined in the classification scheme to a document.In this paper, we present an automatic classification approach called ACTION. The design goal of ACTION is to achieve the appropriate balance between specificity and exhaustivity, which are important metrics for assessing an automatic classification approach. The key idea of ACTION is a scheme for measuring the significance of each keyword in a given document. The scheme not only takes into account the occurrence frequency of a keyword, but also the logical relationships between the available classes.},
journal = {SIGIR Forum},
month = apr,
pages = {26–41},
numpages = {16},
keywords = {document analysis, information retrieval systems, automatic classification, full-text retrieval systems}
}

@article{10.1145/1095479.1095480,
author = {Salton, G.},
title = {A Blueprint for Automatic Boolean Query Processing},
year = {1982},
issue_date = {Fall 1982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095479.1095480},
doi = {10.1145/1095479.1095480},
abstract = {Conventional information retrieval systems use Boolean query formulations and inverted file technologies for search and retrieval purposes. The need to construct complex Boolean queries in order to obtain the benefit of the existing retrieval operations constitutes a substantial burden for the users. In most environments trained search intermediaries are used to facilitate the communication between system and user.In this note a new Boolean retrieval environment is outlined in which the queries are automatically constructed from the original natural language query formulations provided by the users. Any available <u>Boolean</u> query formulations can also be improved automatically by using the natural language text of previously retrieved documents identified as relevant during previous searches. The automatic queries can be formulated in a standard Boolean system, or in an extended system in which the interpretation of the Boolean operators <u>and</u> and <u>or</u> is relaxed. In either case. the automatic Boolean manipulations produce better retrieval output than conventional retrieval operations based on manually prepared query statements.},
journal = {SIGIR Forum},
month = sep,
pages = {6–24},
numpages = {19}
}

@article{10.1145/1095483.1095484,
author = {Gey, Fredric and Chan, Wingkei},
title = {Comparing Vector Space Retrieval with the RUBRIC Expert System},
year = {1988},
issue_date = {Fall 1988/Winter 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095483.1095484},
doi = {10.1145/1095483.1095484},
abstract = {RUBRIC is an expert system for full-text information retrieval. The underlying model for RUBRIC's information retrieval process is based upon fuzzy set theory. The RUBRIC developers have compared RUBRIC to the boolean retrieval model, which it subsumes. This study compares RUBRIC to the Vector Space Model for information retrieval, using RUBRIC's own test collection of thirty news articles from the Reuters News Service and their test search for articles which satisfy the information need to find out about "violent acts of terrorism." Results indicate that the vector space model is comparable to RUBRIC for relevant documents, while RUBRIC performs better at retrieving marginally relevant documents.},
journal = {SIGIR Forum},
month = sep,
pages = {5–11},
numpages = {7}
}

@article{10.1145/945546.945548,
author = {Frakes, William B. and Fox, Christopher J.},
title = {Strength and Similarity of Affix Removal Stemming Algorithms},
year = {2003},
issue_date = {Spring 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/945546.945548},
doi = {10.1145/945546.945548},
abstract = {This study evaluated the strength of, and similarity among, four affix removal stemming algorithms. Strength and similarity were evaluated in different ways, including new metrics based on the Hamming distance measure. Data was collected on stemmer outputs for a list of 49,656 English words derived from the UNIX spelling dictionary and the Moby corpus. Conclusions about the relative strength and similarity of the four stemming algorithms are reported.},
journal = {SIGIR Forum},
month = apr,
pages = {26–30},
numpages = {5}
}

@article{10.1145/983026.983003,
author = {Otis, Allen J. and Copeland, George P.},
title = {Editing Requirements for Data Base Applications and Their Implementation on the INDY Backend Kernel},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983003},
doi = {10.1145/983026.983003},
abstract = {An extrapolation of user and hardware cost trends indicate that future systems should provide more complete functionality, simplicity of use, and reliability by increasing the amount of hardware present in the system. For data base systems, this can be done by providing very high level data languages and by implementing them directly in hardware. These goals are realized with a simple hardware arrangement called INDY, which uses inexpensive memory technologies (such as charge coupled devices, magnetic bubbles, or discs). This paper first discusses the data definition and editing requirements of data languages. Then the implementation of these requirements on the INDY backend kernel is described. Finally, a comparison is made of the various memory technologies for suitability to INDY.},
journal = {SIGIR Forum},
month = aug,
pages = {18–29},
numpages = {12}
}

@article{10.1145/75335.75347,
author = {Wyle, M. F. and Frei, h. P.},
title = {Retrieving Highly Dynamic Widely Distributed Information},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75347},
doi = {10.1145/75335.75347},
abstract = {Wide area networks provide a variety of information sources which can be exploited only by appropriate information retrieval techniques such as repeated automatic query of remote databases and bulletin boards. Distinctive features of the content and access methods of information on wide area nets are discussed from an IR perspective. The development, algorithms, and analysis of a functioning system are also presented.},
journal = {SIGIR Forum},
month = may,
pages = {108–115},
numpages = {8}
}

@inproceedings{10.1145/75334.75347,
author = {Wyle, M. F. and Frei, h. P.},
title = {Retrieving Highly Dynamic Widely Distributed Information},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75347},
doi = {10.1145/75334.75347},
abstract = {Wide area networks provide a variety of information sources which can be exploited only by appropriate information retrieval techniques such as repeated automatic query of remote databases and bulletin boards. Distinctive features of the content and access methods of information on wide area nets are discussed from an IR perspective. The development, algorithms, and analysis of a functioning system are also presented.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {108–115},
numpages = {8},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/24634.1096831,
author = {Fox, Edward and Wyle, Mitchell},
title = {Annotated Bibliography Relating to Automatic Indexing in Information Retrieval},
year = {1986},
issue_date = {Sept.-March 1986-1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/24634.1096831},
doi = {10.1145/24634.1096831},
journal = {SIGIR Forum},
month = sep,
pages = {51–60},
numpages = {10}
}

@article{10.1145/945546.945547,
author = {Fall, C. J. and T\"{o}rcsv\'{a}ri, A. and Benzineb, K. and Karetka, G.},
title = {Automated Categorization in the International Patent Classification},
year = {2003},
issue_date = {Spring 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/945546.945547},
doi = {10.1145/945546.945547},
abstract = {A new reference collection of patent documents for training and testing automated categorization systems is established and described in detail. This collection is tailored for automating the attribution of international patent classification codes to patent applications and is made publicly available for future research work. We report the results of applying a variety of machine learning algorithms to the automated categorization of English-language patent documents. This procedure involves a complex hierarchical taxonomy, within which we classify documents into 114 classes and 451 subclasses. Several measures of categorization success are described and evaluated. We investigate how best to resolve the training problems related to the attribution of multiple classification codes to each patent document.},
journal = {SIGIR Forum},
month = apr,
pages = {10–25},
numpages = {16},
keywords = {support vector machines, IPC taxonomy, patent, automated categorization}
}

@article{10.1145/983026.983002,
author = {Copeland, George P.},
title = {String Storage and Searching for Data Base Applications: Implementation on the INDY Backend Kernel},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983002},
doi = {10.1145/983026.983002},
abstract = {User and hardware cost trends dictate that data base systems should provide more complete functionality, simplicity of use, and reliability by increasing the amount of hardware present in the system. These goals are accomplished with a simple hardware arrangement within a one-dimensional cellular storage system called INDY. The INDY backend kernel is intended as a powerful tool for implementing all data models. The INDY cellular storage array is intended to provide functionality that is difficult to implement efficiently using a conventional hardware arrangement. It allows a simple implementation of improved data independence at high speeds. INDY simultaneously satisfies the time windows of future hardware technologies and user requirements.The importance of strings as a mechanism for defining abstract data types for data base languages is discussed in more detail in another paper. In that paper, a language called STRING is introduced which allows names of data objects to be semantically defined as variable-length strings and compared based on string pattern membership. This paper is concerned with the implementation of string storage and searching required by the STRING language. Implementation of higher level structures and searching requirements (such as sets, rows, tables and hierarchies) on the INDY kernel is treated elsewhere.},
journal = {SIGIR Forum},
month = aug,
pages = {8–17},
numpages = {10}
}

@article{10.1145/1095460.1095461,
author = {Raghavan, Vijay V.},
title = {Approaches for Measuring the Stability of Clustering Methods},
year = {1982},
issue_date = {Summer 1982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095460.1095461},
doi = {10.1145/1095460.1095461},
abstract = {Among the significant factors in assessing the suitability of a clustering technique to a given application is its stability; that is, how sensitive the algorithm is to perturbations in the input data. A number of techniques that appear to be suitable for measuring the stability of clustering have been published in the literature. When these techniques are closely examined, a number of generic approaches emerge. This note reviews these approaches and provides a classification of the various techniques appearing in the literature in terms of the approaches identified.},
journal = {SIGIR Forum},
month = jul,
pages = {6–20},
numpages = {15}
}

@article{10.1145/74697.74703,
author = {Harmon, D. and Candela, G.},
title = {A Very Fast Prototype Retrieval System Using Statistical Ranking},
year = {1989},
issue_date = {Spring 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/74697.74703},
doi = {10.1145/74697.74703},
abstract = {The most striking result in working with Professor Gerald Salton over 20 years ago on the comparison between the SMART system and the MEDLARS system [Salton69] was the fact that whereas Boolean retrieval (MEDLARS) did very well or very poorly, the SMART system always seemed to find some of the relevant records. All of us working at Cornell University during that time wanted to run a full-scale comparison between these systems to demonstrate what was to us the clear superiority of a ranking retrieval system, but this was not possible due to lack of funding and other problems.},
journal = {SIGIR Forum},
month = apr,
pages = {100–110},
numpages = {11}
}

@article{10.1145/983026.983019,
author = {Sadowski, Paul J. and Schuster, S. A.},
title = {Exploiting Parallelism in a Relational Associative Processor},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983019},
doi = {10.1145/983026.983019},
abstract = {The Relational Associative Processor (RAP) is a special purpose non-numeric back-end processor used in supporting general Data Base Management Systems. In particular, it is ideally suited for supporting a relational data base. The architecture and instruction set of RAP are discussed in this context. It is the purpose of this paper to show that RAP performance can be enhanced considerably by more fully exploiting its parallel nature. It is shown that a greater degree of concurrent activity will result in better overall performance. An operating system executive to support this high level of concurrency is proposed and modelled using simulation techniques. Both the analytic and simulation results support the value of the proposals.},
journal = {SIGIR Forum},
month = aug,
pages = {99–109},
numpages = {11}
}

@article{10.1145/1013230.511810,
author = {Can, Fazli and Ozkarahan, Esen A.},
title = {A Clustering Scheme},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511810},
doi = {10.1145/1013230.511810},
abstract = {In this paper, a new clustering algorithm has been described. The algorithm proposed determines both the number of clusters in a collection, and the number of elements in each cluster before beginning the final clustering process. The complexity assessment of the algorithm and the implementation issues are also emphasized.},
journal = {SIGIR Forum},
month = jun,
pages = {115–121},
numpages = {7},
keywords = {document retrieval, analysis of algorithms, document clustering}
}

@inproceedings{10.1145/511793.511810,
author = {Can, Fazli and Ozkarahan, Esen A.},
title = {A Clustering Scheme},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511810},
doi = {10.1145/511793.511810},
abstract = {In this paper, a new clustering algorithm has been described. The algorithm proposed determines both the number of clusters in a collection, and the number of elements in each cluster before beginning the final clustering process. The complexity assessment of the algorithm and the implementation issues are also emphasized.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {115–121},
numpages = {7},
keywords = {document clustering, document retrieval, analysis of algorithms},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/263868.263870,
author = {Lesk, Mike and Harman, Donna and Fox, Edward A. and Wu, Harry and Buckley, Chris},
title = {The SMART Lab Report},
year = {1997},
issue_date = {Spring 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/263868.263870},
doi = {10.1145/263868.263870},
journal = {SIGIR Forum},
month = apr,
pages = {2–22},
numpages = {21}
}

@article{10.1145/74697.1096800,
author = {Salton, Gerald},
title = {ABSTRACTS (Chosen by G. Salton from Recent Issues of Journals in the Retrieval Area.)},
year = {1989},
issue_date = {Spring 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/74697.1096800},
doi = {10.1145/74697.1096800},
journal = {SIGIR Forum},
month = apr,
pages = {123–138},
numpages = {16}
}

@article{10.1145/74697.74700,
author = {Baeza-Yates, R. A.},
title = {Algorithms for String Searching},
year = {1989},
issue_date = {Spring 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/74697.74700},
doi = {10.1145/74697.74700},
abstract = {We survey several algorithms for searching a string in a piece of text. We include theoretical and empirical results, as well as the actual code of each algorithm. An extensive bibliography is also included.},
journal = {SIGIR Forum},
month = apr,
pages = {34–58},
numpages = {25}
}

@article{10.1145/24634.1096830,
author = {Salton, Gerard},
title = {Abstracts of Articles in the Information Retrieval Area Selected by Gerard Salton},
year = {1986},
issue_date = {Sept.-March 1986-1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/24634.1096830},
doi = {10.1145/24634.1096830},
journal = {SIGIR Forum},
month = sep,
pages = {39–50},
numpages = {12}
}

@article{10.1145/1095515.1095516,
author = {Minker, Jack},
title = {Information Storage and Retrieval: A Survey and Functional Description},
year = {1977},
issue_date = {Fall 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095515.1095516},
doi = {10.1145/1095515.1095516},
abstract = {Information Storage and Retrieval (IS&amp;R) encompasses a broad scope of topics ranging from basic techniques for accessing data to sophisticated approaches for the analysis of natural language text and the deduction of information. Within the field, three general areas of investigation can be distinguished not only by their subject matter but also by the types of individuals presently interested in them:(1) Document retrieval,(2) Generalized data management, and(3) Question-answering.A functional description which applies to each of the three areas is presented together with a survey of work being conducted. The similarities and differences of the three areas of IS&amp;R are described. Typical systems which incorporate many of the functions and techniques are described in the appendix.},
journal = {SIGIR Forum},
month = sep,
pages = {12–108},
numpages = {97},
keywords = {deductive search, automatic indexing, information retrieval, data management, theorem proving, data structures, question-answering, relational data systems, natural language, problem solving}
}

@article{10.1145/331403.331408,
author = {Harper, David J.},
title = {Report on CIR99, the 2nd UK Conference on “The Challenge of Image Retrieval”},
year = {1999},
issue_date = {Fall 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/331403.331408},
doi = {10.1145/331403.331408},
journal = {SIGIR Forum},
month = sep,
pages = {20–22},
numpages = {3}
}

@article{10.1145/254590.606643,
author = {Davenport, David},
title = {Book Review: Information Retrieval." A Health Care Perspective, William Hersh, Springer-Verlag, 1996},
year = {1996},
issue_date = {Fall 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/254590.606643},
doi = {10.1145/254590.606643},
journal = {SIGIR Forum},
month = sep,
pages = {14–15},
numpages = {2}
}

@article{10.1145/219587.219593,
author = {Zezula, Pavel and Ciaccia, Paolo and Tiberio, Paolo},
title = {Key-Based Partitioned Bit-Sliced Signature File},
year = {1995},
issue_date = {Fall 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/219587.219593},
doi = {10.1145/219587.219593},
abstract = {A new signature file organization is proposed as a combination of two orthogonal partitioning strategies, the key-based and the bit-sliced, respectively. The design results from theoretical analysis of these elementary approaches in which performance is analytically studied respecting a simplified abstract storage structure model. The new organization is able to achieve very high search performance for queries containing arbitrary number of query terms - bit-sliced (key-based) organization is good only for queries containing few (many) terms, quite bad performance is obtained in the other cases. Update performance is also discussed and a generalization of the method, able to adjust the trade-off between the search efficiency and the maintenance costs, is put forward for consideration. The proposal is also compared with similar approaches in the field of signature files.},
journal = {SIGIR Forum},
month = sep,
pages = {20–34},
numpages = {15}
}

@article{10.1145/174263.174264,
author = {Tian, Zhiyu and Tong, Shibai and Yang, Shiyuan},
title = {A New Hashing Function: Statistical Behaviour and Algorithm},
year = {1993},
issue_date = {Spring 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/174263.174264},
doi = {10.1145/174263.174264},
abstract = {Existing hashing functions have various limitations. In this paper a new hashing function is proposed, which divides the range of the key-values into some equal segments, and maps the key-values in each segment linearly into the whole range of the address. The paper analyzes the statistical behavior of the function, and points out that, theoretically, by increasing the number of segments, the distribution of the resulting hash values can always approach uniform, if the key-values can be regarded as continuous. Two methods for obtaining the number of segments, the deterministic and the probabilistic, along with the algorithm, are also proposed.},
journal = {SIGIR Forum},
month = mar,
pages = {3–13},
numpages = {11},
keywords = {hashing function, direct access file, data structure, key-value, hash value}
}

@article{10.1145/122642.1096779,
author = {Humphrey, Susanne M.},
title = {Selected IR-Related Dissertation Abstracts},
year = {1991},
issue_date = {Spring 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/122642.1096779},
doi = {10.1145/122642.1096779},
abstract = {The following are citations selected by title and abstract as being related to Information Retrieval (IR), resulting from a computer search, using BRS Information Technologies, of the Dissertation Abstracts Online database produced by University Microfilms International (UMI). Included are UMI order number, title, author, degree, year, institution; number of pages, one or more Dissertation Abstracts International (DAI) subject descriptors chosen by the author, and abstract. Unless otherwise specified, paper or microform copies of dissertations may be ordered from University Microfilms International, Dissertation Copies, Post Office Box 1764, Ann Arbor, MI 48106; telephone for U.S. (except Michigan, Hawaii, Alaska): 1-800-521-3042, for Canada: 1-800-268-6090. Price lists and other ordering and shipping information are in the introduction to the published DAI. An alternate source for copies is sometimes provided. Dissertation titles and abstracts contained here are published with permission of University Microfilms International, publishers of Dissertation Abstracts International (copyright by University Microfilms International), and may not be reproduced without their prior permission.},
journal = {SIGIR Forum},
month = may,
pages = {26–60},
numpages = {35}
}

@article{10.1145/101306.101307,
author = {Bruza, P. D. and van der Weide, Th. P.},
title = {Assessing the Quality of Hypertext Views},
year = {1990},
issue_date = {Fall 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/101306.101307},
doi = {10.1145/101306.101307},
abstract = {In this article the problem of assessing the quality of hypertext views is considered. This is done in terms of a formal model of hypertext in which the view is a central aspect. The objects in a view are described in terms of so called index expressions which are a powerful object characterization mechanism. These characterizations are manipulated by a calculus, which allows quantification of notions such as cohesion and relevance. These latter are useful criteria for judging the quality of a view.},
journal = {SIGIR Forum},
month = nov,
pages = {6–25},
numpages = {20}
}

@article{10.1145/74697.1096798,
author = {Singer, Robin},
title = {Crafting Knowledge Based Systems Expert Systems Made Realistic by Waiters and Nielson (Wiley Interscience, 1988)},
year = {1989},
issue_date = {Spring 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/74697.1096798},
doi = {10.1145/74697.1096798},
abstract = {When professional recruiters post sexy advertisements to lure engineers and computer scientists to their agencies, they often claim to know of exciting new jobs in Expert Systems. For several years, Artificial Intelligence and its subspeciality, Expert Systems, have been among the "hottest" of the "hot" computer fields. The cynical observer might suspect that Walters and Nielson, and Wiley Interscience, authors and publisher respectively of "Crafting Knowledge Based Systems, Expert Systems Made Realistic" were attempting to capitalize on this overwhelming Expert Systems craze.},
journal = {SIGIR Forum},
month = apr,
pages = {111–113},
numpages = {3}
}

@article{10.1145/43936.1096827,
author = {Humphrey, Susanne M.},
title = {Selected IR-Related Dissertation Abstracts},
year = {1988},
issue_date = {Fall 1987/Winter 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/43936.1096827},
doi = {10.1145/43936.1096827},
abstract = {The following are citations selected by title and abstract as being related to Information Retrieval (IR), resulting from a computer search, using the BRS Information Technologies retrieval service, of the Dissertation Abstracts International (DAI) database produced by University Microfilms International.},
journal = {SIGIR Forum},
month = jan,
pages = {38–51},
numpages = {14}
}

@article{10.1145/30075.30078,
author = {Fox, Edward A.},
title = {Workshop on Distributed Expert-Based Information Systems: A Perspective},
year = {1987},
issue_date = {March 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/30075.30078},
doi = {10.1145/30075.30078},
journal = {SIGIR Forum},
month = mar,
pages = {18–20},
numpages = {3}
}

@article{10.1145/15497.15498,
author = {Goldfarb, Lev},
title = {Metric Data Models and Associated Search Strategies},
year = {1986},
issue_date = {Spring-Summer 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/15497.15498},
doi = {10.1145/15497.15498},
abstract = {I believe that the concept of a metric (or a dissimilarity measure) defined on a set of records is one of the most fundamental concepts related to information retrieval, although historically, the first science to introduce this concept as a basic one was, perhaps, numerical taxonomy. In the metric model the concept of the most relevant record should be interpreted as that of the closest (with respect to the chosen metric) record.},
journal = {SIGIR Forum},
month = may,
pages = {7–11},
numpages = {5}
}

@article{10.1145/16287.1096836,
author = {Raghavan, V.},
title = {ABSTRACTS 25 (Chosen by Vo Raghavan from Recent Issues of Journals in the Retrieval Area)},
year = {1986},
issue_date = {Winter 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/16287.1096836},
doi = {10.1145/16287.1096836},
abstract = {In this article, a general mathematical framework for information retrieval models is presented, giving more insight into the evaluation mechanisms that may be used in IR. In this framework a number of requirements for operators improving recall and precision are investigated. It is shown that these requirements can be satisfied by using descriptor weights and one combination operator only. Moreover, information items and queries - virtual items - can be treated in exactly the same way, reflecting the fact, that they both are descriptions of a number of concepts. Evaluation is performed by formulating similarity homomorphisms from query descriptions to retrieval status values that allow ranking items accordingly. For good comparisons, however, ranking must be done by the achieved proportion of perfect similarity rather than by similary itself. In term independence models, this normalization process may satisfy the homomorphism requirement of algebra under certain conditions, but it contradicts the requirement in the term dependence case. Nevertheless, by demanding separability for the unnormalized part of the evaluation measure, it can be guaranteed that the query is evaluated to each item descriptor by descriptor, and the normalization value must be calculated only once for the whole query, using the query as a whole. Also, for each real item, the normalization value must have been calculated only once, using the item as a whole.},
journal = {SIGIR Forum},
month = jan,
pages = {25–31},
numpages = {7}
}

@article{10.1145/3263608,
author = {Tague, Jean},
title = {Session Details: Session 10: Search Techniques},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263608},
doi = {10.1145/3263608},
journal = {SIGIR Forum},
month = jun,
numpages = {1}
}

@article{10.1145/3263606,
author = {Kuehn, Jennifer},
title = {Session Details: Session 8: User Behavior},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263606},
doi = {10.1145/3263606},
journal = {SIGIR Forum},
month = jun,
numpages = {1}
}

@article{10.1145/1095454.1095458,
author = {Salton, Gerard},
title = {Abstracts of Selected Journal Articles},
year = {1982},
issue_date = {Winter 1982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095454.1095458},
doi = {10.1145/1095454.1095458},
journal = {SIGIR Forum},
month = jan,
pages = {23–28},
numpages = {6}
}

@article{10.1145/1095360.1095362,
author = {Ashworth, E. R.},
title = {Review of "Data Structures and Programming Techniques, by Herman H. Maurer", Prentice-Hall 1977.},
year = {1979},
issue_date = {Winter 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095360.1095362},
doi = {10.1145/1095360.1095362},
abstract = {Professor Maurer's book has been translated into English by C. C. Price from the original Dataenstrukturen und Programmierverfahren. The text is based on the author's revised and expanded lecture notes. The four major topics are: A Model for the Manipulation of Data Structures, Lists, Trees, and Complex Data Structures. It concludes with an Index of Symbols, a Bibliography of 67 references, of which 79 percent are in English, and a Subject Index. In Addition, the translator had each segment of a program tested on a computer using a subset of PL/I.},
journal = {SIGIR Forum},
month = jan,
pages = {8–11},
numpages = {4}
}

@article{10.1145/983026.983021,
author = {Chang, Hsu},
title = {Bubbles for Relational Database},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983021},
doi = {10.1145/983026.983021},
abstract = {The mechanical disk storage is limited by long initial delay, few inputs/outputs, and serial access, thus necessitating large complex programs in existing database systems in order to map the user's view into the physical storage and to provide different access paths in response to different queries. Bubble devices are capable of set-oriented processing and associative addressing architecture. This paper presents concepts on data structure, storage structure, and access methods for bubble implementation of relational database.},
journal = {SIGIR Forum},
month = aug,
pages = {110–116},
numpages = {7}
}

@article{10.1145/983026.983017,
author = {Hutchison, J. S. and Roman, W. G.},
title = {Madman Machine},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983017},
doi = {10.1145/983026.983017},
abstract = {A back-end data base machine is discussed in which the back-end is closely coupled to the host system as an intelligent I/O device. The design of the hardware and software is such that the data base disks can be on either the host or back-end computers. The design is motivated by memory size considerations on mini-computer systems and also by cost considerations of large disks. The implementations of such a system on PDP-11s is discussed.},
journal = {SIGIR Forum},
month = aug,
pages = {85–90},
numpages = {6}
}

@article{10.1145/983026.983005,
author = {Lipovski, G. Jack},
title = {Semantic Paging on Intelligent Discs},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983005},
doi = {10.1145/983026.983005},
abstract = {In order to apply Artificial Intelligence techniques like inferencing to large (109-1012 bit) data bases, an intelligent secondary memory is proposed that is capable of extracting a subgraph from a graph stored in it for further processing in a conventional or special purpose computer. The "pointer transfer" technique developed for CASSM is used to efficiently mark and output a subgraph stored in one file, and a simple technique is proposed to link parts of the subgraph stored on different files. Besides proposing a useful secondary memory system for applying Artificial Intelligence techniques to large data bases, this paper attacks one of the most difficult problems in distributed data base systems, which is the generation of "homomorphic query fragments" that automatically carry the query from one file to other files needed to resolve the query.},
journal = {SIGIR Forum},
month = aug,
pages = {30–34},
numpages = {5}
}

@article{10.1145/3263594,
author = {Reimann, Oskar},
title = {Session Details: Session 3},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263594},
doi = {10.1145/3263594},
journal = {SIGIR Forum},
month = aug,
numpages = {1}
}

@article{10.1145/1095515.1095518,
author = {Groman, Robert C.},
title = {Review of "Computer Data-Base Organization by James Martin", Prentice-Hall, Incorporated, Englewood Cliffs, New Jersey, 1975, 558 Pp., $26.50},
year = {1977},
issue_date = {Fall 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095515.1095518},
doi = {10.1145/1095515.1095518},
abstract = {James Martin's book strives to satisfy the need for an advanced textbook on data-base technology. He has organized his book into two major sections. Part I covers what he labels 'logical organization' and Part II covers 'physical organization'. While the book addresses all the major areas in data-base technology, it lacks the technical detail necessary for advanced courses in computer science.},
journal = {SIGIR Forum},
month = sep,
pages = {7–9},
numpages = {3}
}

@article{10.1145/1095286.1095300,
author = {McGill, Michael J. and Smith, Linda C. and Davidson, Stuart and Noreault, Terry},
title = {Syracuse Information Retrieval Experiment (SIRE): Design of an on-Line Bibliographic Retrieval System},
year = {1976},
issue_date = {Spring 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095286.1095300},
doi = {10.1145/1095286.1095300},
abstract = {Proponents of interactive online bibliographic retrieval systems frequently stress the potential of such systems to take advantage of both human and computer capabilities in the document retrieval process. Yet systems implemented to date have to a great extent placed constraints on both human and machine performance by decisions made at the design stage. To increase the flexibility of online systems, alternative modes of document representation, storage utilization, and query formulation should be considered.},
journal = {SIGIR Forum},
month = apr,
pages = {37–44},
numpages = {8}
}

@article{10.1145/1095286.1095295,
author = {Lang, Tomas},
title = {A Two-Level Architecture for a Large Data Base},
year = {1976},
issue_date = {Spring 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095286.1095295},
doi = {10.1145/1095286.1095295},
abstract = {A two-level architecture is being proposed for extending third generation computer systems such as the S/370. By attaching a DASD processor to each DASD, performance in large data base applications can be improved. This improvement is achievable without modifying existing data base organization. The DASD processor is very simple and can be implemented using commercially available microprocessors.},
journal = {SIGIR Forum},
month = apr,
pages = {23},
numpages = {1}
}

@article{10.1145/1095277.1095284,
author = {Stemple, David W.},
title = {A Data Base Management Facility for Automatic Generation of Data Base Managers},
year = {1975},
issue_date = {Winter 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095277.1095284},
doi = {10.1145/1095277.1095284},
abstract = {This paper presents a facility for the implementation of data base management systems having high degrees of <u>horizontal</u> data independence, i.e. independence from chosen logical properties of a data base as opposed to <u>vertical</u> independence from storage structures. The facility consists of a high level language for the specification of virtual data base managers, a compiler from this language to a pseudo-machine language, and an interpreter for the pseudo-machine language.It is shown how this facility can be used to produce efficient data base management systems with any degree of both horizontal and vertical data independence. Two key features of this tool are the compilation of tailored data base managers from individual schemas and multiple levels of optional binding.},
journal = {SIGIR Forum},
month = dec,
pages = {14},
numpages = {1},
keywords = {data base management systems, data independence}
}

@article{10.1145/1095277.1095282,
author = {Lin, C. S. and Smith, Diane C. P.},
title = {The Design of a Rotating Associative Array Memory for a Relational Data Base Management Application},
year = {1975},
issue_date = {Winter 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095277.1095282},
doi = {10.1145/1095277.1095282},
abstract = {There are significant advantages to tailoring hardware storage devices to support high level data models in very large data bases. A storage device that can assume some of the data selection functions traditionally performed by the CPU can substantially reduce the amount of data to be transferred to the CPU. This reduction together with increased concurrency of CPU and device operation result in increased data rates and lower response times. By designing the device to support one specific data model, greater efficiency can be achieved than in devices designed to be a compromise in their support of several different models. The number and complexity of the functions performed by the device can be drastically reduced, along with its development and production costs. In this paper we describe the design and usage of an associative array memory using a rotating storage device which is tailored to support the relational model of E.F. Codd.},
journal = {SIGIR Forum},
month = dec,
pages = {12},
numpages = {1}
}

@article{10.1145/1095277.1095279,
author = {Chen, Peter Pin-Shan},
title = {The Entity-Relationship Model: Toward a Unified View of Data},
year = {1975},
issue_date = {Winter 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095277.1095279},
doi = {10.1145/1095277.1095279},
abstract = {A data model, called the entity-relationship model, is proposed. This model incorporates some of the important semantic information in the real world. A special diagramatic technique is introduced as a tool for data base design. An example of data base design and description using the model and the diagramatic technique is given. Some implications on data integrity, information retrieval, and data manipulation are discussed.The entity-relationship model can be used as a basis for unification of different views of data: the network model, the relational model, and the entity set model. Semantic ambiguities in these models are analyzed. Possible ways to derive their views of data from the entity-relationship model are presented.},
journal = {SIGIR Forum},
month = dec,
pages = {9},
numpages = {1},
keywords = {entity set model, semantics of data, data models, data base design, network model, data base task group, relational model, data integrity and consistency, data definition and manipulation, logical view of data, entity-relationship model}
}

@article{10.1145/1095271.1095273,
author = {Morrison, D. R.},
title = {On the Language of Information Science},
year = {1975},
issue_date = {Summer 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095271.1095273},
doi = {10.1145/1095271.1095273},
abstract = {1. <u>Lavoisier and The Nomenclature of Chemistry.</u> As a science matures, the language used by its practitioners evolves. Hogben (1) describes the evolution of the language of several sciences. Of particular interest is his description of the evolution of the language of chemistry. The clarity of thinking in chemistry, and the progress in the field took a sharp upturn after Lavoisier introduced revolutionary changes in the system of chemical nomenclature. Before Lavoisier, substances were generally known by names that might be called recipes or histories; somebody's notion or recollection of how they first encountered the substance. Methane was known as marsh gas, because it was first found bubbling up through the mud of marshes, as a result of the decay of organic materials under the mud. Hydrochloric acid was known as muriatic acid, from muria, the Latin name for brine, a common source of hydrochloric acid. Muria, in turn, comes from mare, Latin for sea. Chlorine was known to sixteenth century chemists and alchemists as dephlogisticated muriatic acid. The original process by which chlorine was manufactured, and still a common process, is by oxidation of the hydrogen in hydrochloric acid. Since oxidation was not yet understood at that time, it was called dephlogistication -- removal of the phlogiston. Lavoisier's new nomenclature describes substances not by their surmised origin, but by their present content, structure and condition.},
journal = {SIGIR Forum},
month = jul,
pages = {21–32},
numpages = {12}
}

@article{10.1145/1095495.1095496,
title = {Data Structures for Information Retrieval},
year = {1972},
issue_date = {Winter 1972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095495.1095496},
doi = {10.1145/1095495.1095496},
abstract = {During the last decade the most outstanding advances in the computer field have been increased speeds of operation, larger auxiliary random access to these memories. Since these advances obviously are in the hardware domain, i.e., they are technological advances, similar progress had to be made in the software arena to take advantage of this added new power.},
journal = {SIGIR Forum},
month = dec,
pages = {3–11},
numpages = {9}
}

@article{10.1145/1095489.1095490,
author = {Doyle, Lauren B.},
title = {I Think, Therefore I.R.},
year = {1971},
issue_date = {Summer 1971},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095489.1095490},
doi = {10.1145/1095489.1095490},
abstract = {I first heard the words "information retrieval" in 1957, in a meeting of programmers and other assorted "types". We were all working on the SAGE air defense system, an ugly, unwitting precursor of time-sharing---people, display consoles, keyboards, tapes, etc, etc, hooked into a central computer.},
journal = {SIGIR Forum},
month = jul,
pages = {12–15},
numpages = {4}
}

@article{10.1145/75335.75360,
author = {Amsler, R. A.},
title = {Research toward the Development of a Lexical Knowledge Base for Natural Language Processing},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75360},
doi = {10.1145/75335.75360},
abstract = {This paper documents research toward building a complete lexicon containing all the words found in general newspaper text. It is intended to provide the reader with an understanding of the inherent limitations of existing vocabulary collection methods and the need for greater attention to multi-word phrases as the building blocks of text. Additionally, while traditional reference books define many proper nouns, they appear to be very limited in their coverage of the new proper nouns appearing daily in newspapers. Proper nouns appear to require a grammar and lexicon of components much the way general parsing of text requires syntactic rules and a lexicon of common nouns.},
journal = {SIGIR Forum},
month = may,
pages = {242–249},
numpages = {8}
}

@inproceedings{10.1145/75334.75360,
author = {Amsler, R. A.},
title = {Research toward the Development of a Lexical Knowledge Base for Natural Language Processing},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75360},
doi = {10.1145/75334.75360},
abstract = {This paper documents research toward building a complete lexicon containing all the words found in general newspaper text. It is intended to provide the reader with an understanding of the inherent limitations of existing vocabulary collection methods and the need for greater attention to multi-word phrases as the building blocks of text. Additionally, while traditional reference books define many proper nouns, they appear to be very limited in their coverage of the new proper nouns appearing daily in newspapers. Proper nouns appear to require a grammar and lexicon of components much the way general parsing of text requires syntactic rules and a lexicon of common nouns.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {242–249},
numpages = {8},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/75335.75340,
author = {Pejtersen, A. M.},
title = {A Library System for Information Retrieval Based on a Cognitive Task Analysis and Supported by an Icon-Based Interface},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75340},
doi = {10.1145/75335.75340},
journal = {SIGIR Forum},
month = may,
pages = {40–47},
numpages = {8}
}

@inproceedings{10.1145/75334.75340,
author = {Pejtersen, A. M.},
title = {A Library System for Information Retrieval Based on a Cognitive Task Analysis and Supported by an Icon-Based Interface},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75340},
doi = {10.1145/75334.75340},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {40–47},
numpages = {8},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/1013230.511832,
author = {Maron, M. E.},
title = {Open Problems in Information Retrieval},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511832},
doi = {10.1145/1013230.511832},
journal = {SIGIR Forum},
month = jun,
pages = {266–267},
numpages = {2}
}

@inproceedings{10.1145/511793.511832,
author = {Maron, M. E.},
title = {Open Problems in Information Retrieval},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511832},
doi = {10.1145/511793.511832},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {266–267},
numpages = {2},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511828,
author = {Kukich, Karen},
title = {Knowledge-Based Report Generation: A Technique for Automatically Generating Natural Language Reports from Databases},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511828},
doi = {10.1145/1013230.511828},
abstract = {Knowledge-Based Report Generation is a technique for automatically generating natural language summaries from databases. It is so named because it applies the tools of knowledge-based expert systems design to the problem of text generation. The technique is currently being applied to the design of an automatic natural language stock report generator. Examples drawn from the implementation of the stock report generator are used to describe the components of a knowledge-based report generator.},
journal = {SIGIR Forum},
month = jun,
pages = {246–250},
numpages = {5},
keywords = {natural language processing, knowledge-based expert systems, databases, text generation}
}

@inproceedings{10.1145/511793.511828,
author = {Kukich, Karen},
title = {Knowledge-Based Report Generation: A Technique for Automatically Generating Natural Language Reports from Databases},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511828},
doi = {10.1145/511793.511828},
abstract = {Knowledge-Based Report Generation is a technique for automatically generating natural language summaries from databases. It is so named because it applies the tools of knowledge-based expert systems design to the problem of text generation. The technique is currently being applied to the design of an automatic natural language stock report generator. Examples drawn from the implementation of the stock report generator are used to describe the components of a knowledge-based report generator.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {246–250},
numpages = {5},
keywords = {text generation, databases, natural language processing, knowledge-based expert systems},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511823,
author = {Eastman, C. M.},
title = {Current Practice in the Evaluation of Multikey Search Algorithms},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511823},
doi = {10.1145/1013230.511823},
abstract = {File structures and algorithms for multikey searching allow more than a single key to be used in locating a record for use in retrieval or update. Such algorithms are of use in many different kinds of information systems, including database systems, information retrieval systems, and pattern recognition and image processing systems. Such algorithms have received increased attention in recent years. However, they are not as well understood as those which handle single keys.Multikey algorithms are more difficult to evaluate than those based on the use of single keys. There are simply more factors to be considered. The evaluations performed for such algorithms should allow comparisons in order to be useful to a community of researchers and users. Theoretical analyses should be based on reasonable and clearly stated assumptions. Experiments should be repeatable and statistically valid whether they are based on "real" data or on randomly generated data.},
journal = {SIGIR Forum},
month = jun,
pages = {197–204},
numpages = {8}
}

@inproceedings{10.1145/511793.511823,
author = {Eastman, C. M.},
title = {Current Practice in the Evaluation of Multikey Search Algorithms},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511823},
doi = {10.1145/511793.511823},
abstract = {File structures and algorithms for multikey searching allow more than a single key to be used in locating a record for use in retrieval or update. Such algorithms are of use in many different kinds of information systems, including database systems, information retrieval systems, and pattern recognition and image processing systems. Such algorithms have received increased attention in recent years. However, they are not as well understood as those which handle single keys.Multikey algorithms are more difficult to evaluate than those based on the use of single keys. There are simply more factors to be considered. The evaluations performed for such algorithms should allow comparisons in order to be useful to a community of researchers and users. Theoretical analyses should be based on reasonable and clearly stated assumptions. Experiments should be repeatable and statistically valid whether they are based on "real" data or on randomly generated data.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {197–204},
numpages = {8},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511816,
author = {Tolle, John E.},
title = {Transaction Log Analysis Online Catalogs},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511816},
doi = {10.1145/1013230.511816},
abstract = {From November 1981 to April 1983, OCLC's Office of Research has been conducting research into online public access catalogs (OPACs). This project has been funded in part by the Council on Library Resources, Inc. as an attempt to provide new insight into the use of online catalogs by obtaining information which may serve as input for better system design of OPACs, utilizing not only desired user features but also more effective searching.The overall study is concerned with the patron and the system and consists of three major parts. The first is the study of current use of online catalogs, i.e., the actual use - what is really happening. The second element is concerned with the perceived patron use of the catalogs and involves the use of questionnaires and focus group interviews at the participating institutions. The third part is an application of the findings from the first two parts.This paper focuses on the current utilization of OPACs. The methodology chosen to employ is to obtain machine-readable transaction logs, via tapes, from the online catalogs and subsequently analyzing these transactions by stochastic search pattern development and mathematical models utilizing Markov chain analysis and the development of transition probability matrices.},
journal = {SIGIR Forum},
month = jun,
pages = {147–160},
numpages = {14}
}

@inproceedings{10.1145/511793.511816,
author = {Tolle, John E.},
title = {Transaction Log Analysis Online Catalogs},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511816},
doi = {10.1145/511793.511816},
abstract = {From November 1981 to April 1983, OCLC's Office of Research has been conducting research into online public access catalogs (OPACs). This project has been funded in part by the Council on Library Resources, Inc. as an attempt to provide new insight into the use of online catalogs by obtaining information which may serve as input for better system design of OPACs, utilizing not only desired user features but also more effective searching.The overall study is concerned with the patron and the system and consists of three major parts. The first is the study of current use of online catalogs, i.e., the actual use - what is really happening. The second element is concerned with the perceived patron use of the catalogs and involves the use of questionnaires and focus group interviews at the participating institutions. The third part is an application of the findings from the first two parts.This paper focuses on the current utilization of OPACs. The methodology chosen to employ is to obtain machine-readable transaction logs, via tapes, from the online catalogs and subsequently analyzing these transactions by stochastic search pattern development and mathematical models utilizing Markov chain analysis and the development of transition probability matrices.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {147–160},
numpages = {14},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013228.511769,
author = {Kambayashi, Yahiko and Hayashi, Takaki and Yajima, Shuzo},
title = {Dynamic Clustering Procedures for Bibliographic Data},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511769},
doi = {10.1145/1013228.511769},
abstract = {Clustering is an important tool for efficient retrieval of documents in bibliographic database systems. It can be also used to find research trend from a set of research papers. This paper discusses new clustering procedures called dynamic ones which seem to be suitable for bibliographic data handling. These procedures are developed to solve the following problems.(1) Depending on the characteristics of data, several different clustering procedures are required to obtain good results.(2) Large clusters are tend to be generated.Dynamic clustering procedures are difined to be procedures which change parameter values according to the characteristics of data. Similarity values and threshold values are dynamically modified to handle the above problems. Furthermore, to treat the latter problem data duplication is considered.},
journal = {SIGIR Forum},
month = may,
pages = {90–99},
numpages = {10}
}

@inproceedings{10.1145/511754.511769,
author = {Kambayashi, Yahiko and Hayashi, Takaki and Yajima, Shuzo},
title = {Dynamic Clustering Procedures for Bibliographic Data},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511769},
doi = {10.1145/511754.511769},
abstract = {Clustering is an important tool for efficient retrieval of documents in bibliographic database systems. It can be also used to find research trend from a set of research papers. This paper discusses new clustering procedures called dynamic ones which seem to be suitable for bibliographic data handling. These procedures are developed to solve the following problems.(1) Depending on the characteristics of data, several different clustering procedures are required to obtain good results.(2) Large clusters are tend to be generated.Dynamic clustering procedures are difined to be procedures which change parameter values according to the characteristics of data. Similarity values and threshold values are dynamically modified to handle the above problems. Furthermore, to treat the latter problem data duplication is considered.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {90–99},
numpages = {10},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013881.802704,
author = {Ozso, Tamer M. and Ozkarahan, Esen A.},
title = {SYNGLISH - a High Level Query Language for the RAP Database Machine},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802704},
doi = {10.1145/1013881.802704},
abstract = {This paper describes a high-level query language developed and implemented for the RAP database machine. The language, called SYNGLISH, is based on the semantic structure of the English sentences. The software system developed accepts SYNGLISH queries and produces RAP assembler code which is then executed by the RAP software emulator.},
journal = {SIGIR Forum},
month = mar,
pages = {139–150},
numpages = {12},
keywords = {Database machines, Semantic predication analysis, Relational model, Synthetic english, Very-high-level query language}
}

@inproceedings{10.1145/800083.802704,
author = {Ozso, Tamer M. and Ozkarahan, Esen A.},
title = {SYNGLISH - a High Level Query Language for the RAP Database Machine},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802704},
doi = {10.1145/800083.802704},
abstract = {This paper describes a high-level query language developed and implemented for the RAP database machine. The language, called SYNGLISH, is based on the semantic structure of the English sentences. The software system developed accepts SYNGLISH queries and produces RAP assembler code which is then executed by the RAP software emulator.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {139–150},
numpages = {12},
keywords = {Synthetic english, Very-high-level query language, Semantic predication analysis, Database machines, Relational model},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013881.802702,
author = {Bisiani, R.},
title = {The Harpy Machine: A Data Structure-Oriented Architecture},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802702},
doi = {10.1145/1013881.802702},
abstract = {Efficiently storing and retrieving data has always been one of the major problems in computer technology. Until recently there has been more interest for the technology of storing and retrieving data in mass memory than for the problem of accessing data in main memory. Semiconductor technology improvements have lowered main memory cost and increased speed, therefore opening new application areas (e.g. image and speech understanding, graphics) to low cost systems. Some of the tasks in these areas are data intensive and require complex data structures. In these cases, most of the computing power is used to access data rather than to perform operations on them. The performance of such applications can be improved if the memories are tailored to the data structures they contain and to the access operations that can be performed on those data structures. The paper describes an architecture designed to explore the advantages offered by tailored, intelligent memories. The architecture has been implemented and tested on the Harpy speech understanding system. The implementation has been measured and the results are reported in the paper.},
journal = {SIGIR Forum},
month = mar,
pages = {128–136},
numpages = {9}
}

@inproceedings{10.1145/800083.802702,
author = {Bisiani, R.},
title = {The Harpy Machine: A Data Structure-Oriented Architecture},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802702},
doi = {10.1145/800083.802702},
abstract = {Efficiently storing and retrieving data has always been one of the major problems in computer technology. Until recently there has been more interest for the technology of storing and retrieving data in mass memory than for the problem of accessing data in main memory. Semiconductor technology improvements have lowered main memory cost and increased speed, therefore opening new application areas (e.g. image and speech understanding, graphics) to low cost systems. Some of the tasks in these areas are data intensive and require complex data structures. In these cases, most of the computing power is used to access data rather than to perform operations on them. The performance of such applications can be improved if the memories are tailored to the data structures they contain and to the access operations that can be performed on those data structures. The paper describes an architecture designed to explore the advantages offered by tailored, intelligent memories. The architecture has been implemented and tested on the Harpy speech understanding system. The implementation has been measured and the results are reported in the paper.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {128–136},
numpages = {9},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013881.802698,
author = {Oliver, Ellen J. and Berra, P. Bruce},
title = {RELACS a Relational Associative Computer System},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802698},
doi = {10.1145/1013881.802698},
abstract = {Recent advances in LSI, VLSI and memory technology have led to a reduction in hardware cost and an increase in mass storage capacity such that an associative array memory can be produced and supported. Toward this end, in this paper such an associative array computer called RELational Associative Computer System (RELACS) is proposed.},
journal = {SIGIR Forum},
month = mar,
pages = {106–114},
numpages = {9}
}

@inproceedings{10.1145/800083.802698,
author = {Oliver, Ellen J. and Berra, P. Bruce},
title = {RELACS a Relational Associative Computer System},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802698},
doi = {10.1145/800083.802698},
abstract = {Recent advances in LSI, VLSI and memory technology have led to a reduction in hardware cost and an increase in mass storage capacity such that an associative array memory can be produced and supported. Toward this end, in this paper such an associative array computer called RELational Associative Computer System (RELACS) is proposed.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {106–114},
numpages = {9},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013881.802690,
author = {Burkowski, F. J.},
title = {A Microprogrammed Search Controller for a Text Scanning Processor},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802690},
doi = {10.1145/1013881.802690},
abstract = {The objective of the research in this paper is the design of a non-numeric processor to be used in the scanning of textual information brought in from serial storage. Source text progresses through a linear array of 32 cells each cell capable of holding one character. With all cells operating in parallel, character subsequences in the source stream can be compared with character strings in any one of 16 registers associated with the cellular array. Various modules associated with the array are used to aid the query resolution process. The overall design emphasizes speed of execution and versatility of operation.},
journal = {SIGIR Forum},
month = mar,
pages = {39–48},
numpages = {10}
}

@inproceedings{10.1145/800083.802690,
author = {Burkowski, F. J.},
title = {A Microprogrammed Search Controller for a Text Scanning Processor},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802690},
doi = {10.1145/800083.802690},
abstract = {The objective of the research in this paper is the design of a non-numeric processor to be used in the scanning of textual information brought in from serial storage. Source text progresses through a linear array of 32 cells each cell capable of holding one character. With all cells operating in parallel, character subsequences in the source stream can be compared with character strings in any one of 16 registers associated with the cellular array. Various modules associated with the array are used to aid the query resolution process. The overall design emphasizes speed of execution and versatility of operation.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {39–48},
numpages = {10},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013881.802688,
author = {Menon, M. Jaishankar and Hsiao, David K.},
title = {The Access Control Mechanism of a Database Computer (DBC)},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802688},
doi = {10.1145/1013881.802688},
abstract = {The database computer (DBC) is a specialized back-end computer which is capable of managing data 1010 bytes in size and supporting known data models such as relational, network, hierarchical and attribute-based models. It is also perhaps the first database machine to have a built-in security mechanism for access control.At the outset, the security mechanism was made an integral part of the DBC design. This design philosophy not only allowed us to construct a system that has no “backdoors”, but also ensured that all access requests are, in fact, controlled by DBC's security mechanism. The DBC security mechanism is based on the concept of security atoms, aggregates of data units being definable by the user in terms of conjunctions of query predicates. The fundamental gain in utilizing query conjunctions for the purpose of access control is that any data that is accessible or updateable is also protectable.It is believed that the DBC security mechanism is less cumbersome than the view mechanism of some database systems and more efficient than the query modification mechanism used by some other systems. This is demonstrated at three levels of access control, namely the subfile, record and field (attribute) levels.},
journal = {SIGIR Forum},
month = mar,
pages = {17–28},
numpages = {12}
}

@inproceedings{10.1145/800083.802688,
author = {Menon, M. Jaishankar and Hsiao, David K.},
title = {The Access Control Mechanism of a Database Computer (DBC)},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802688},
doi = {10.1145/800083.802688},
abstract = {The database computer (DBC) is a specialized back-end computer which is capable of managing data 1010 bytes in size and supporting known data models such as relational, network, hierarchical and attribute-based models. It is also perhaps the first database machine to have a built-in security mechanism for access control.At the outset, the security mechanism was made an integral part of the DBC design. This design philosophy not only allowed us to construct a system that has no “backdoors”, but also ensured that all access requests are, in fact, controlled by DBC's security mechanism. The DBC security mechanism is based on the concept of security atoms, aggregates of data units being definable by the user in terms of conjunctions of query predicates. The fundamental gain in utilizing query conjunctions for the purpose of access control is that any data that is accessible or updateable is also protectable.It is believed that the DBC security mechanism is less cumbersome than the view mechanism of some database systems and more efficient than the query modification mechanism used by some other systems. This is demonstrated at three levels of access control, namely the subfile, record and field (attribute) levels.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {17–28},
numpages = {12},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013232.511711,
author = {Mazlack, Lawrence J.},
title = {An Empirical Comparison: Tree and Lattice Structures for Symbolic Data Bases},
year = {1979},
issue_date = {September 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013232.511711},
doi = {10.1145/1013232.511711},
abstract = {Unidirectional trees and lattices may both be used to hold a symbolic data base consisting of lexes, lexemes or other symbol strings. This paper empirically compares placing symbolic information into both trees and lattices (a lattice may be thought of as a unidirectional network with single and initiating and terminating nodes).},
journal = {SIGIR Forum},
month = sep,
pages = {33–40},
numpages = {8}
}

@inproceedings{10.1145/511706.511711,
author = {Mazlack, Lawrence J.},
title = {An Empirical Comparison: Tree and Lattice Structures for Symbolic Data Bases},
year = {1979},
isbn = {9781450373456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511706.511711},
doi = {10.1145/511706.511711},
abstract = {Unidirectional trees and lattices may both be used to hold a symbolic data base consisting of lexes, lexemes or other symbol strings. This paper empirically compares placing symbolic information into both trees and lattices (a lattice may be thought of as a unidirectional network with single and initiating and terminating nodes).},
booktitle = {Proceedings of the 2nd Annual International ACM SIGIR Conference on Information Storage and Retrieval: Information Implications into the Eighties},
pages = {33–40},
numpages = {8},
location = {Dallas, Texas},
series = {SIGIR '79}
}

@article{10.1145/1013232.511707,
author = {Salton, Gerard},
title = {Progress Report on Automatic Information Retrieval},
year = {1979},
issue_date = {September 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013232.511707},
doi = {10.1145/1013232.511707},
journal = {SIGIR Forum},
month = sep,
pages = {1},
numpages = {1}
}

@inproceedings{10.1145/511706.511707,
author = {Salton, Gerard},
title = {Progress Report on Automatic Information Retrieval},
year = {1979},
isbn = {9781450373456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511706.511707},
doi = {10.1145/511706.511707},
booktitle = {Proceedings of the 2nd Annual International ACM SIGIR Conference on Information Storage and Retrieval: Information Implications into the Eighties},
pages = {1},
numpages = {1},
location = {Dallas, Texas},
series = {SIGIR '79}
}

@article{10.1145/965643.810251,
author = {Rosenthal, Robert S.},
title = {The Data Management Machine, a Classification},
year = {1977},
issue_date = {May 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/965643.810251},
doi = {10.1145/965643.810251},
abstract = {There has been much interest in the use of special purpose processors as the data base management component of data processing systems. The generic terms “backend” and “data management machine” have been applied to such devices. Examination of the literature reveals a broad cross section of host to backend functional distribution and interconnection methodology. This discussion represents an attempt to examine and classify several of these backend data base management machine configurations in terms of their operational parameters and application constraints. A formal taxonomy of such systems remains yet to be performed.At least three distinct classes of data management machine (DMM) are evidenced in the literature; they are the large host backend, distributed network data node and smart peripheral. The intended classes of problem that the various authors envision amenable to solution by the DMM approach exhibit overlap while the performance envelope in which each DMM architecture would provide a technically acceptable, economically sound solution to a given user requirement set varies. Some of the papers used as source for this work contained no explicit mention of either the problem classes or performance constraints that the described configuration was to address; thus liberty has been taken in interpreting the implicit application goals of these authors.},
journal = {SIGIR Forum},
month = jan,
pages = {35–39},
numpages = {5}
}

@inproceedings{10.1145/800180.810251,
author = {Rosenthal, Robert S.},
title = {The Data Management Machine, a Classification},
year = {1977},
isbn = {9781450374804},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800180.810251},
doi = {10.1145/800180.810251},
abstract = {There has been much interest in the use of special purpose processors as the data base management component of data processing systems. The generic terms “backend” and “data management machine” have been applied to such devices. Examination of the literature reveals a broad cross section of host to backend functional distribution and interconnection methodology. This discussion represents an attempt to examine and classify several of these backend data base management machine configurations in terms of their operational parameters and application constraints. A formal taxonomy of such systems remains yet to be performed.At least three distinct classes of data management machine (DMM) are evidenced in the literature; they are the large host backend, distributed network data node and smart peripheral. The intended classes of problem that the various authors envision amenable to solution by the DMM approach exhibit overlap while the performance envelope in which each DMM architecture would provide a technically acceptable, economically sound solution to a given user requirement set varies. Some of the papers used as source for this work contained no explicit mention of either the problem classes or performance constraints that the described configuration was to address; thus liberty has been taken in interpreting the implicit application goals of these authors.},
booktitle = {Proceedings of the 3rd Workshop on Computer Architecture : Non-Numeric Processing},
pages = {35–39},
numpages = {5},
series = {CAW '77}
}

@article{10.1145/1842890.1842893,
author = {Hanbury, Allan and Zenz, Veronika and Berger, Helmut},
title = {1st International Workshop on Advances in Patent Information Retrieval (AsPIRe'10)},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1842890.1842893},
doi = {10.1145/1842890.1842893},
journal = {SIGIR Forum},
month = aug,
pages = {19–22},
numpages = {4}
}

@article{10.1145/948716.948723,
author = {Wacholder, Nina},
title = {The Technology of Phrase Browsing Applications: Workshop Held in Conjunction with the First ACM-IEEE Joint Conference on Digital Libraries},
year = {2001},
issue_date = {Spring 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/948716.948723},
doi = {10.1145/948716.948723},
journal = {SIGIR Forum},
month = apr,
pages = {16–20},
numpages = {5}
}

@article{10.1145/948716.948722,
author = {B\"{o}rner, Katy and Chen, Chaomei},
title = {Visual Interfaces to Digital Libraries: The First International Workshop at the First ACM+IEEE Joint Conference on Digital Libraries},
year = {2001},
issue_date = {Spring 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/948716.948722},
doi = {10.1145/948716.948722},
journal = {SIGIR Forum},
month = apr,
pages = {12–15},
numpages = {4}
}

@article{10.1145/948716.948718,
author = {Oard, Douglas W.},
title = {Interactive Cross-Language Information Retrieval},
year = {2001},
issue_date = {Spring 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/948716.948718},
doi = {10.1145/948716.948718},
journal = {SIGIR Forum},
month = apr,
pages = {1–3},
numpages = {3}
}

@article{10.1145/344250.344254,
author = {Hawking, David},
title = {Plans for the TREC-9 Web Track},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/344250.344254},
doi = {10.1145/344250.344254},
abstract = {In recent years, TREC has broadened its scope to include many more facets of the Web searching process. In TREC-8 (1999), the Web special interest track evaluated link-based retrieval methods investigated differences between Web and traditional TREC ad hoc documents, and studied efficiency and effectiveness tradeoffs on large data sets. In addition, although neither used Web data, both the Cross-Lingual track and the Question &amp; Answer track studied issues of considerable importance to everyday Web search.In TREC-9, the main Web track task will use a larger set of Web documents than last year and will use search topics derived from search engine logs. This task will be the closest approximation in TREC-9 to the traditional TREC Ad Hoc retrieval task.},
journal = {SIGIR Forum},
month = dec,
pages = {17–18},
numpages = {2}
}

@article{10.1145/344250.344252,
author = {Voorhees, Ellen M. and Harman, Donna},
title = {The Text REtrieval Conference (TREC): History and Plans for TREC-9},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/344250.344252},
doi = {10.1145/344250.344252},
abstract = {Text retrieval systems have historically been refined through experimentation on test collections. In 1990 NIST was asked to build a very large test collection for use in evaluation of text retrieval technology in the DARPA TIPSTER project. This collection was to be on the order of 1 million full-text documents: a magnitude about 100 times larger than any existing non-proprietary test collection. The following year NIST proposed that this collection be made available to the full research community by the formation of the Text REtrieval Conference (TREC). The first conference took place in September, 1992 with 25 participating groups including most of the leading text retrieval research groups. Although scaling their research algorithms to handle this near-operational amount of text (for 1992) was a Herculean task, groups joined TREC to get the test data and to take part in the first major cross-system search engine evaluation. Participation in TREC has since increased each year. The most recent TREC (TREC-8 held in November, 1999) had 66 participating groups representing 16 different countries.This paper serves as a general introduction to TREC. Detailed information about TREC including the complete Proceedings for each workshop, instructions for obtaining test collections, and the Call for Participation for TREC-9 can be found on the TREC web site at http://trec.nist.gov. Task descriptions for some of the tasks to be done in TREC-9 follow in this issue. To participate in TREC-9, follow the instructions given in the Call for Participation.},
journal = {SIGIR Forum},
month = dec,
pages = {12–15},
numpages = {4}
}

@article{10.1145/331403.331411,
author = {Hill, Linda},
title = {Networked Knowledge Organization Systems (NKOS) Workshop},
year = {1999},
issue_date = {Fall 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/331403.331411},
doi = {10.1145/331403.331411},
journal = {SIGIR Forum},
month = sep,
pages = {32–33},
numpages = {2}
}

@article{10.1145/207556.207559,
author = {Pejtersen, Annelise Mark},
title = {Supporting Semantic Information Retrieval in Communication Networks by Multimedia Techniques},
year = {1995},
issue_date = {Spring 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/207556.207559},
doi = {10.1145/207556.207559},
abstract = {The aim of the project is to understand and describe the information needs and search behavior of a professional design team as a basis for formulation of specifications of an information system that effectively supports the access to a wide network of heterogeneous databases. This project will supplement a similar project focused on the needs of casual users in public libraries and thus serve to generalize from previous research. To limit the scope of the study to a realistic project, it will be focused on the activities of an industrial design team. Below follows a resume of the original project proposal.},
journal = {SIGIR Forum},
month = mar,
pages = {9–19},
numpages = {11}
}

@article{10.1145/207556.207557,
author = {Croft, W. Bruce},
title = {Lab Report Special Section: The University of Massachusetts Center for Intelligent Information Retrieval},
year = {1995},
issue_date = {Spring 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/207556.207557},
doi = {10.1145/207556.207557},
journal = {SIGIR Forum},
month = mar,
pages = {1–7},
numpages = {7}
}

@article{10.1145/182119.1096164,
author = {Can, Fazli},
title = {Book Review: Information Retrieval Data Structures &amp; Algorithms by William B. Frakes (Software Engineering Guild), Ricardo Baeza-Yates (University of Chile). Prentice Hall, Englewood Cliffs, New Jersey, 1992, 504 Pp., $50.00 (Retail Price), ISBN 0-13-463837-9.},
year = {1993},
issue_date = {Fall 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/182119.1096164},
doi = {10.1145/182119.1096164},
abstract = {This is an extremely welcome addition to the Information Retrieval (IR) literature. Because of its technical approach it is much different from most of the available books on IR. The book consists of five sections containing eighteen chapters. The chapters are written by different authors.},
journal = {SIGIR Forum},
month = sep,
pages = {24–25},
numpages = {2}
}

@article{10.1145/378881.378888,
author = {Fox, Christopher},
title = {A Stop List for General Text},
year = {1989},
issue_date = {Fall 89/Winter 90},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/378881.378888},
doi = {10.1145/378881.378888},
abstract = {A stop list, or negative dictionary is a device used in automatic indexing to filter out words that would make poor index terms. Traditionally stop lists are supposed to have included only the most frequently occurring words. In practice, however, stop lists have tended to include infrequently occurring words, and have not included many frequently occurring words. Infrequently occurring words seem to have been included because stop list compilers have not, for whatever reason, consulted empirical studies of word frequencies. Frequently occurring words seem to have been left out for the same reason, and also because many of them might still be important as index terms.This paper reports an exercise in generating a stop list for general text based on the Brown corpus of 1,014,000 words drawn from a broad range of literature in English. We start with a list of tokens occurring more than 300 times in the Brown corpus. From this list of 278 words, 32 are culled on the grounds that they are too important as potential index terms. Twenty-six words are then added to the list in the belief that they may occur very frequently in certain kinds of literature. Finally, 149 words are added to the list because the finite state machine based filter in which this list is intended to be used is able to filter them at almost no cost. The final product is a list of 421 stop words that should be maximally efficient and effective in filtering the most frequently occurring and semantically neutral words in general literature in English.},
journal = {SIGIR Forum},
month = sep,
pages = {19–21},
numpages = {3}
}

@article{10.1145/1095483.1095486,
author = {Humphrey, Susanne M.},
title = {Selected IR-Related Dissertation Abstracts},
year = {1988},
issue_date = {Fall 1988/Winter 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095483.1095486},
doi = {10.1145/1095483.1095486},
abstract = {The following are citations selected by title and abstract as being related to Information Retrieval (IR), resulting from a computer search, using the BRS Information Technologies retrieval service, of the Dissertation Abstracts International (DAI) database produced by University Microfilms International.},
journal = {SIGIR Forum},
month = sep,
pages = {26–35},
numpages = {10}
}

@article{10.1145/24634.24636,
author = {Frakes, W B and Nejmeh, B A},
title = {Software Reuse through Information Retrieval},
year = {1986},
issue_date = {Sept.-March 1986-1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/24634.24636},
doi = {10.1145/24634.24636},
abstract = {There is widespread need for safe, verifiable, efficient, and reliable software that can be delivered in a timely manner. Software reuse can make a valuable contrbution toward this goal by increasing programmer productivity and software quality. Unfortunately, the amount of software reuse currently done is quite small. DeMarco [1] estimates that in the average software development environment only about five percent of code is reused.},
journal = {SIGIR Forum},
month = sep,
pages = {30–36},
numpages = {7}
}

@article{10.1145/15497.15501,
author = {Wong, S K and Ziarko, Wojciech},
title = {A Concept-Learning Information Retrieval System-Basic Ideas},
year = {1986},
issue_date = {Spring-Summer 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/15497.15501},
doi = {10.1145/15497.15501},
journal = {SIGIR Forum},
month = may,
pages = {16–17},
numpages = {2}
}

@article{10.1145/1095398.1095401,
author = {Krishnayya, J. G.},
title = {Review of "The Implementation of Complex Information Systems, 1979, by Andrew E. Wessel", John Wiley &amp; Sons, New York},
year = {1981},
issue_date = {Spring 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095398.1095401},
doi = {10.1145/1095398.1095401},
abstract = {This book is one of the Information Sciences series published by John Wiley and is meant for "Users, Managers, and Technologists." The objective is to give a set of guidelines for implementing "complex" information systems. Complex information systems are defined as those "functioning within a multipurpose, multiuser environment - whether they are relatively simple data banks, more involved accounting or banking/credit systems, documentation systems, or middle or higher level management decision systems." Though the definition includes "management decision systems," the book focuses upon information storage and retrieval systems. Four of the five case studies presented are on the computerization of documentation systems. No mention has been made of simulation, modelling, optimization packages, etc., which are essential components of any information support system for managerial decision making, nor is the general problem of management information system design covered.},
journal = {SIGIR Forum},
month = apr,
pages = {10–12},
numpages = {3}
}

@article{10.1145/1095398.1095399,
author = {Salton, G.},
title = {Abstracts: Chosen by G. Salton from Current Issues of Journals in the Retrieval Area},
year = {1981},
issue_date = {Spring 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095398.1095399},
doi = {10.1145/1095398.1095399},
journal = {SIGIR Forum},
month = apr,
pages = {13–18},
numpages = {6}
}

@article{10.1145/1095394.1095396,
author = {Salton, G.},
title = {Abstracts: Chosen by G. Salton from Current Issues of Journals in the Retrieval Area},
year = {1980},
issue_date = {Summer 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095394.1095396},
doi = {10.1145/1095394.1095396},
journal = {SIGIR Forum},
month = aug,
pages = {22–27},
numpages = {6}
}

@article{10.1145/1095377.1095379,
author = {Murphy, Rochester},
title = {Review of "Data Base Management Systems, by Alfonso F. Cardenas", Allyn and Bacon, Inc., 1979.},
year = {1979},
issue_date = {Summer 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095377.1095379},
doi = {10.1145/1095377.1095379},
abstract = {The author has been unquestionably successful in accomplishing his objectives, the most outstanding of which is an "illustrative...critical, and quantative" presentation of representative samples (chapters 5 through 9) of the network, hierarchic, inverted tree, and relational approaches to generalized data base management system (GDBMS). The common example carried through these chapters was a well chosen and effective vehicle for showing the commonalities, differences, strengths, and weaknesses of the approaches. The fundamentals of file organization and data base concepts (chapters 2 and 3), built upon some of the author's previously published work, preceed a short economic and architectual tabulation of marketed systems (chapter 4). The presentation of the last generalized data base management approach, IBM's experimental System R, is followed by a one chapter treatment of supporting concepts, functional dependencies, and normalization.},
journal = {SIGIR Forum},
month = jul,
pages = {2–3},
numpages = {2}
}

@article{10.1145/983026.983008,
author = {Bird, R. M. and Newsbaum, J. B. and Trefftzs, J. L.},
title = {Text File Inversion: An Evaluation},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983008},
doi = {10.1145/983026.983008},
abstract = {This paper compares inversion of text files with inversion of more structured records. The unique characteristics of textual data which restrict the utility of inversion are identified and discussed. Inversion is shown to be useful only for small, static data bases, and when full text search is not required.},
journal = {SIGIR Forum},
month = aug,
pages = {42–50},
numpages = {9}
}

@article{10.1145/3263593,
author = {Lipovski, G. Jack},
title = {Session Details: Session 2},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263593},
doi = {10.1145/3263593},
journal = {SIGIR Forum},
month = aug,
numpages = {1}
}

@article{10.1145/1095317.1095320,
author = {Berztiss, A. T.},
title = {Review of "Data Structures: Theory and Practice by A. T. Berztiss", Second Edition, 1975},
year = {1977},
issue_date = {Winter 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095317.1095320},
doi = {10.1145/1095317.1095320},
journal = {SIGIR Forum},
month = dec,
pages = {2},
numpages = {1}
}

@article{10.1145/1095325.1095328,
author = {Smith, Linda C.},
title = {Review of "Computer-Aided Information Retrieval by Andrew E. Wessel"; Los Angeles, Melville Publishing Company, 1975},
year = {1976},
issue_date = {Winter 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095325.1095328},
doi = {10.1145/1095325.1095328},
abstract = {The author defines the scope of his discussion in his statement: "The core notion in this book is that an inter-locked triad of user organization, thesauri builder and computer technologist is capable of achieving computer-aided information retrieval systems which make actual a great deal of the potential of automated search" (p. 169). Wessel offers theoretical and practical grounds for choosing a methodology centered on people supported by computers rather than a fully automated approach. In particular he advocates development and use of well structured thesauri stored in computers to assist in both indexing and search of documents.},
journal = {SIGIR Forum},
month = dec,
pages = {12–13},
numpages = {2}
}

@article{10.1145/1095286.1095293,
author = {Hollaar, Lee A.},
title = {An Architecture for the Efficient Combining of Linearly Ordered Lists},
year = {1976},
issue_date = {Spring 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095286.1095293},
doi = {10.1145/1095286.1095293},
abstract = {Many applications require the combining of two or more linearly ordered lists according to a given set of rules. Probably the best example of this is the combining of index lists in an inverted file information retrieval system according to a Boolean expression specified by the system user. If the user specifies the AND of two terms, the intersection of the two lists associated with the terms if formed; if OR, the union is formed; and if he specifies A AND NOT B the result will be those entries in list A which are not also in list B.},
journal = {SIGIR Forum},
month = apr,
pages = {16–21},
numpages = {6}
}

@article{10.1145/1095495.1095500,
title = {A Set Theoretic Data Structure and Retrieval Language},
year = {1972},
issue_date = {Winter 1972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095495.1095500},
doi = {10.1145/1095495.1095500},
abstract = {This paper describes a data structure and retrieval program for general large scale information systems. Retrieval operations are done by means of set theoretic operations. The general structure of the data structure and retrieval program are outlined here, and the retrieval language is briefly explained with accompanying examples. The major components of the data structure are discussed in detail: The directory, the dictionary, and the data itself. Limitations of the system and plans for improvement are mentioned.},
journal = {SIGIR Forum},
month = dec,
pages = {45–55},
numpages = {11}
}

@article{10.1145/1095495.1095498,
title = {Data Base Organization and Retrieval Techniques for Steam Turbine Engineering},
year = {1972},
issue_date = {Winter 1972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095495.1095498},
doi = {10.1145/1095495.1095498},
abstract = {The data base organization and information retrieval techniques described in this paper are used by the Westinghouse Electric Corporation's Large Turbine Division at Lester, Pa. to store and retrieve engineering and descriptive information pertaining to the entire life of a steam turbine from the original design of the unit through the latest overhaul.The large volume of data generated during the design, manufacture and subsequent operation of a steam turbine requires the use of a computer for effective data management. Manual record keeping has become increasingly inadequate to cope with the task of relating this ever growing data to sound management and engineering decisions.An operational computer oriented data bank system has been installed to fulfill the following data storage and retrieval needs:1. Quicker and more comprehensive retrieval of failure data to assist in service work.2. Organized and efficient feedback of failure information to the Engineering Department.3. An integrated data reference source for turbine history.4. Greater insight into reliability problems to provide statistics for design guidance and manpower allocation.5. Greater insight into proper turbine operating techniques and maintenance schedules.The system is built upon a master "Generic Profile" data base; all other files and reports are derived from it. Indexed sequential data sets are used throughout providing complete random access to any information in the data base. A substantial number of types of retrieval are available, and within each type the user is able to request any combination of data he may require. In some instances, retrieval requests of the same type are processed simultaneously, thereby reducing file access and overall execution time.Topics covered in the paper include:Data Base content.Data base organization and access methods.Types of retrieval available.Retrieval techniques.The system employs an IBM 360 Model 50 computer operating under MVT and OS. The largest program requires approximately 150 K of core storage for execution. All programs are written in ANS Cobol.},
journal = {SIGIR Forum},
month = dec,
pages = {17–35},
numpages = {19}
}

@article{10.1145/75335.75359,
author = {Parkes, A.},
title = {Settings and the Setting Structure: The Description and Automated Propagation of Networks for Perusing Videodisk Image States},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75359},
doi = {10.1145/75335.75359},
abstract = {This paper describes a system for formally representing spatial relationships between videodisc image states called settings. A number of setting relations are defined, these being based on the manipulations of the camera typically used in the production of the moving film: zooming in or out, panning etc.. An algorithm is presented which, given a limited level of initial specification by a describer, will constrain, where possible, the setting relations holding between all pairs of settings. The resulting network is called the settings structure. The paper begins by placing the settings structure into the context of its being one part of the CLORIS system.},
journal = {SIGIR Forum},
month = may,
pages = {229–238},
numpages = {10}
}

@inproceedings{10.1145/75334.75359,
author = {Parkes, A.},
title = {Settings and the Setting Structure: The Description and Automated Propagation of Networks for Perusing Videodisk Image States},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75359},
doi = {10.1145/75334.75359},
abstract = {This paper describes a system for formally representing spatial relationships between videodisc image states called settings. A number of setting relations are defined, these being based on the manipulations of the camera typically used in the production of the moving film: zooming in or out, panning etc.. An algorithm is presented which, given a limited level of initial specification by a describer, will constrain, where possible, the setting relations holding between all pairs of settings. The resulting network is called the settings structure. The paper begins by placing the settings structure into the context of its being one part of the CLORIS system.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {229–238},
numpages = {10},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/75335.75351,
author = {Klein, S. T. and Bookstein, A. and Deerwester, S.},
title = {Storing Text Retrieval Systems on CD-ROM: Compression and Encryption Considerations},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75351},
doi = {10.1145/75335.75351},
journal = {SIGIR Forum},
month = may,
pages = {160–167},
numpages = {8}
}

@inproceedings{10.1145/75334.75351,
author = {Klein, S. T. and Bookstein, A. and Deerwester, S.},
title = {Storing Text Retrieval Systems on CD-ROM: Compression and Encryption Considerations},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75351},
doi = {10.1145/75334.75351},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {160–167},
numpages = {8},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/1013230.511827,
author = {Griffiths, Jose-Marie and King, Donald W.},
title = {An Approach to Enhancement of Statistical Survey Databases},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511827},
doi = {10.1145/1013230.511827},
abstract = {This paper deals with statistical databases that are generated from statistical surveys and that reside in organizations which perform a large number of surveys--some of which are repetitive. Examples of such organizations are Federal statistical agencies such as the Energy Information Administration, Bureau of Labor Statistics, National Center for Educational Statistics, National Center for Health Statistics, etc; state governments that have bureaus or departments that collect such data; and marketing research departments of most large consumer-oriented companies. Computer processing has provided a powerful tool for storing, manipulating, and analyzing statistical survey data. However, in addition to these advantages, computing has created a major problem in that most data analysts and users have lost touch with the data and their generation. They no longer have the feel and sense for the data that once was possible. In this paper we present an approach to database design that will directly attack this problem and enhance the usefulness of such databases as well.},
journal = {SIGIR Forum},
month = jun,
pages = {239–245},
numpages = {7}
}

@inproceedings{10.1145/511793.511827,
author = {Griffiths, Jose-Marie and King, Donald W.},
title = {An Approach to Enhancement of Statistical Survey Databases},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511827},
doi = {10.1145/511793.511827},
abstract = {This paper deals with statistical databases that are generated from statistical surveys and that reside in organizations which perform a large number of surveys--some of which are repetitive. Examples of such organizations are Federal statistical agencies such as the Energy Information Administration, Bureau of Labor Statistics, National Center for Educational Statistics, National Center for Health Statistics, etc; state governments that have bureaus or departments that collect such data; and marketing research departments of most large consumer-oriented companies. Computer processing has provided a powerful tool for storing, manipulating, and analyzing statistical survey data. However, in addition to these advantages, computing has created a major problem in that most data analysts and users have lost touch with the data and their generation. They no longer have the feel and sense for the data that once was possible. In this paper we present an approach to database design that will directly attack this problem and enhance the usefulness of such databases as well.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {239–245},
numpages = {7},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511821,
author = {Zarri, Gian Piero},
title = {RESEDA, an Information Retrieval System Using Artificial Intelligence and Knowledge Representation Techniques},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511821},
doi = {10.1145/1013230.511821},
abstract = {The RESEDA project is concerned with the construction of AI Information Retrieval systems working on databases containing biographical data. There exist in RESEDA two fundamental ways of retrieving information requested by a user. In the first case, the information we wish to obtain is data which already exists in the base. This data can be obtained by direct match with the "search model" corresponding to the user's question. If this is not possible, we can still try to get an answer by using the inference procedures of the "transformation" type. The second method retrieves information which, in contrast, is created ex nihilo by the search procedure itself. It expresses, in fact, the possibility of a new causal relationship, within the base, between an "episode" provided explicitly by the user and one or more "episodes" that the system retrieves by applying an inference procedure of the type "hypothesis".},
journal = {SIGIR Forum},
month = jun,
pages = {189–195},
numpages = {7}
}

@inproceedings{10.1145/511793.511821,
author = {Zarri, Gian Piero},
title = {RESEDA, an Information Retrieval System Using Artificial Intelligence and Knowledge Representation Techniques},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511821},
doi = {10.1145/511793.511821},
abstract = {The RESEDA project is concerned with the construction of AI Information Retrieval systems working on databases containing biographical data. There exist in RESEDA two fundamental ways of retrieving information requested by a user. In the first case, the information we wish to obtain is data which already exists in the base. This data can be obtained by direct match with the "search model" corresponding to the user's question. If this is not possible, we can still try to get an answer by using the inference procedures of the "transformation" type. The second method retrieves information which, in contrast, is created ex nihilo by the search procedure itself. It expresses, in fact, the possibility of a new causal relationship, within the base, between an "episode" provided explicitly by the user and one or more "episodes" that the system retrieves by applying an inference procedure of the type "hypothesis".},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {189–195},
numpages = {7},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511803,
author = {de Sope\~{n}a, Luis},
title = {Natural Language Grammars for an Information System},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511803},
doi = {10.1145/1013230.511803},
abstract = {The User Specialty Languages (USL) System is an applications independent natural language interface to a Relational Database System. It provides non DP-trained people with a tool to introduce, query, manipulate and analyse the data stored in a Relational Database via natural language. USL interfaces with different languages; in the present paper the grammar developed for Spanish is presented, and compared with the German grammar which was previously implemented and upon which it is based. Their main differences are pointed out, and the generality of the system to deal with other natural languages shown.},
journal = {SIGIR Forum},
month = jun,
pages = {75–80},
numpages = {6}
}

@inproceedings{10.1145/511793.511803,
author = {de Sope\~{n}a, Luis},
title = {Natural Language Grammars for an Information System},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511803},
doi = {10.1145/511793.511803},
abstract = {The User Specialty Languages (USL) System is an applications independent natural language interface to a Relational Database System. It provides non DP-trained people with a tool to introduce, query, manipulate and analyse the data stored in a Relational Database via natural language. USL interfaces with different languages; in the present paper the grammar developed for Spanish is presented, and compared with the German grammar which was previously implemented and upon which it is based. Their main differences are pointed out, and the generality of the system to deal with other natural languages shown.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {75–80},
numpages = {6},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013228.511774,
author = {Hausen, Hans-Ludwig},
title = {Outline of a Dynamic Self-Tuning and Adaptive Information Retrieval System},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511774},
doi = {10.1145/1013228.511774},
abstract = {A self-tuning adaptive information retrieval system as an extension of the concept of a "classical" document retrieval system, is outlined. This system accepts documents and search requests in natural language, as well as the system-proposals previously produced by the system itself or prepared by the system operator. It produces a system-proposal that consists of a list of documents ranked according to their relevance to the query.Incorporated into the system is a system valuation subsystem that uses weighted relevance judgements. This subsystem gives as output an effectiveness value and an efficiency value: both together measure the quality of an information retrieval system.The computation of the quality values and the values themselves are independent of a specific implementation. The retrieval process in this system consists of two parts, namely a query-document match and a query-query match.},
journal = {SIGIR Forum},
month = may,
pages = {132–144},
numpages = {13},
keywords = {document retrieval, document query correlation, sytem valuation, query query correlation}
}

@inproceedings{10.1145/511754.511774,
author = {Hausen, Hans-Ludwig},
title = {Outline of a Dynamic Self-Tuning and Adaptive Information Retrieval System},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511774},
doi = {10.1145/511754.511774},
abstract = {A self-tuning adaptive information retrieval system as an extension of the concept of a "classical" document retrieval system, is outlined. This system accepts documents and search requests in natural language, as well as the system-proposals previously produced by the system itself or prepared by the system operator. It produces a system-proposal that consists of a list of documents ranked according to their relevance to the query.Incorporated into the system is a system valuation subsystem that uses weighted relevance judgements. This subsystem gives as output an effectiveness value and an efficiency value: both together measure the quality of an information retrieval system.The computation of the quality values and the values themselves are independent of a specific implementation. The retrieval process in this system consists of two parts, namely a query-document match and a query-query match.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {132–144},
numpages = {13},
keywords = {document retrieval, document query correlation, sytem valuation, query query correlation},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013228.511765,
author = {Landauer, Christopher},
title = {Statistical Models for Unformatted Text},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511765},
doi = {10.1145/1013228.511765},
abstract = {In this note, we will describe some of the outstanding problems concerning statistical information retrieval models, and the underlying stochastic language production models they assume. The problems can be separated into classes according to the underlying language model, which can be either a sequence model or a grammar model. Both kinds of model are based on a stochastic process, but there is a different filter for the realization. The grammar models use a stochastic context sensitive grammar, and the sequence models use a high order Markov chain.Most of these problems cannot be solved without experimentation with information retrieval concepts and systems. Most information retrieval systems that currently exist have had to make operational assumptions about the answers to these questions. It is expected that more precise knowledge of solutions for these problems will simplify the design and improve the effectiveness of statistical information retrieval systems.},
journal = {SIGIR Forum},
month = may,
pages = {72–76},
numpages = {5},
keywords = {stochastic language description models, discrete probability structures, statistical information retrieval}
}

@inproceedings{10.1145/511754.511765,
author = {Landauer, Christopher},
title = {Statistical Models for Unformatted Text},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511765},
doi = {10.1145/511754.511765},
abstract = {In this note, we will describe some of the outstanding problems concerning statistical information retrieval models, and the underlying stochastic language production models they assume. The problems can be separated into classes according to the underlying language model, which can be either a sequence model or a grammar model. Both kinds of model are based on a stochastic process, but there is a different filter for the realization. The grammar models use a stochastic context sensitive grammar, and the sequence models use a high order Markov chain.Most of these problems cannot be solved without experimentation with information retrieval concepts and systems. Most information retrieval systems that currently exist have had to make operational assumptions about the answers to these questions. It is expected that more precise knowledge of solutions for these problems will simplify the design and improve the effectiveness of statistical information retrieval systems.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {72–76},
numpages = {5},
keywords = {stochastic language description models, statistical information retrieval, discrete probability structures},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013881.802703,
author = {Greenblatt, Richard D. and Knight, Thomas F. and Holloway, John T. and Moon, David A.},
title = {A LISP Machine},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802703},
doi = {10.1145/1013881.802703},
abstract = {LISP is the second oldest computer-programming language still in active use. Our implementation is based on a powerful microprogrammed processor designed specifically for LISP. This processor supports a tagged macro-architecture; it manipulates items which have a built-in data-type field.The system supports several important new storage-management features, including a real-time garbage collector with hardware assist (using the basic algorithm of Baker).The software itself is written in LISP to a much larger extent than in previous systems. In fact, there are only two levels in which code is written: LISP and microcode. Among other things this improves the consistancy of system interfaces.The system design incorporates the personal computer philosophy. We believe the personal computer will predominate in the future since it is preferable to time-sharing in most cases and technological trends are greatly reducing its cost penality. In the case of very large programs, the personal computer can be cost-effective today, due to the phenomenon of thrashing encountered in time-sharing systems.},
journal = {SIGIR Forum},
month = mar,
pages = {137–138},
numpages = {2}
}

@inproceedings{10.1145/800083.802703,
author = {Greenblatt, Richard D. and Knight, Thomas F. and Holloway, John T. and Moon, David A.},
title = {A LISP Machine},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802703},
doi = {10.1145/800083.802703},
abstract = {LISP is the second oldest computer-programming language still in active use. Our implementation is based on a powerful microprogrammed processor designed specifically for LISP. This processor supports a tagged macro-architecture; it manipulates items which have a built-in data-type field.The system supports several important new storage-management features, including a real-time garbage collector with hardware assist (using the basic algorithm of Baker).The software itself is written in LISP to a much larger extent than in previous systems. In fact, there are only two levels in which code is written: LISP and microcode. Among other things this improves the consistancy of system interfaces.The system design incorporates the personal computer philosophy. We believe the personal computer will predominate in the future since it is preferable to time-sharing in most cases and technological trends are greatly reducing its cost penality. In the case of very large programs, the personal computer can be cost-effective today, due to the phenomenon of thrashing encountered in time-sharing systems.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {137–138},
numpages = {2},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013881.802689,
author = {Vemuri, V. and Liuzzi, R. A. and Cavano, J. P. and Berra, P. B.},
title = {Evaluation of Alternate Data Base Machine Designs},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802689},
doi = {10.1145/1013881.802689},
abstract = {The purpose of this paper is to point out the need for performance evaluation measures and techniques suitable for the evaluation of specialized architectural features in nonnumeric applications. Toward this end, problems associated with the use of data base machines are examined at three levels of detail: the user level, the system level and the device level.},
journal = {SIGIR Forum},
month = mar,
pages = {29–38},
numpages = {10}
}

@inproceedings{10.1145/800083.802689,
author = {Vemuri, V. and Liuzzi, R. A. and Cavano, J. P. and Berra, P. B.},
title = {Evaluation of Alternate Data Base Machine Designs},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802689},
doi = {10.1145/800083.802689},
abstract = {The purpose of this paper is to point out the need for performance evaluation measures and techniques suitable for the evaluation of specialized architectural features in nonnumeric applications. Toward this end, problems associated with the use of data base machines are examined at three levels of detail: the user level, the system level and the device level.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {29–38},
numpages = {10},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013234.803143,
title = {INSPECTOR},
year = {1978},
issue_date = {May 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013234.803143},
doi = {10.1145/1013234.803143},
abstract = {INSPECTOR is a proprietary software system that is designed to be used in an information retrieval environment. Specifically, it is oriented toward the on-line retrieval of microfilmed documents through the indexing of certain key terms relating to the document itself. Items such as date, account number, name, customer name or number, purchase order number, etc. might be considered as key descriptive terms. Thus by indexing these elements on a randomly accessible disk drive, the location of the filmed image of all original documents pertaining to a particular descriptive term may be quickly located by the computer and the location displayed to the operator. Alternatively, if used in conjunction with the Eastman Kodak IC-5/PR-1 microfilm retrieval unit, the computer system will cause the film display unit to automatically advance to the correct frame(s), keeping operator intervention to an absolute minimum.},
journal = {SIGIR Forum},
month = may,
pages = {175–176},
numpages = {2}
}

@inproceedings{10.1145/800096.803143,
title = {INSPECTOR},
year = {1978},
isbn = {9781450374026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800096.803143},
doi = {10.1145/800096.803143},
abstract = {INSPECTOR is a proprietary software system that is designed to be used in an information retrieval environment. Specifically, it is oriented toward the on-line retrieval of microfilmed documents through the indexing of certain key terms relating to the document itself. Items such as date, account number, name, customer name or number, purchase order number, etc. might be considered as key descriptive terms. Thus by indexing these elements on a randomly accessible disk drive, the location of the filmed image of all original documents pertaining to a particular descriptive term may be quickly located by the computer and the location displayed to the operator. Alternatively, if used in conjunction with the Eastman Kodak IC-5/PR-1 microfilm retrieval unit, the computer system will cause the film display unit to automatically advance to the correct frame(s), keeping operator intervention to an absolute minimum.},
booktitle = {Proceedings of the 1st Annual International ACM SIGIR Conference on Information Storage and Retrieval},
pages = {175–176},
numpages = {2},
series = {SIGIR '78}
}

@article{10.1145/1013234.803141,
author = {Williamson, Robert E.},
title = {Does Relevance Feedback Improve Document Retrieval Performance?},
year = {1978},
issue_date = {May 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013234.803141},
doi = {10.1145/1013234.803141},
abstract = {Many authors (1, 2, 3, 5, 6, 7) have suggested that overall performance of a document retrieval system is improved by relevance feedback. Relevance feedback denotes the last three steps in the following process: 1) the searcher enters a query, 2) the system prepares a ranked list of suggested documents, 3) the searcher judges some of the documents for relevancy, 4) the searcher informs the system of these documents judged and of the judgement, 5) the system constructs a new query based on the descriptors used in the original query and the descriptors used in the documents judged, 6) the system prepares a second ranked list of suggested documents.The presumption is that the second list is better than the first. By all performance measures (e.g. “fluid ranking” and “frozen ranking”), the second list is better than the first. However, if one reranks documents in the original list so as to reflect the searcher's efforts (step 3), the corresponding performance measures are comparable to those for the second list. The marginal difference between the performance measures for the ”reranked original” list (searcher's efforts alone) and the second list (which includes computer efforts) makes it unclear if the cost of steps 4 through 6 above can be justified. It is hoped that advocates of relevance feedback will present “reranked original” performance measures as a basis for any performance improvement claims.This paper also presents three reasonable, easily understood retrieval procedures for which the frozen ranking, the fluid ranking, and the reranked original evaluations are “obviously” the pertinent way to evaluate. Relevance feedback techniques as implemented in Salton's SMART DRS appear to show that it is worthwhile for user's to read abstracts prior to evaluation of full texts. The last indication presented in this paper is that the relevance feedback performance improvements noted using SMART are due mostly to the user making assessments; subsequent computer efforts appear to be most likely to result in no further change. For a query for which there is a subsequent change, the change is as likely to be harmful as helpful.},
journal = {SIGIR Forum},
month = may,
pages = {151–170},
numpages = {20}
}

@inproceedings{10.1145/800096.803141,
author = {Williamson, Robert E.},
title = {Does Relevance Feedback Improve Document Retrieval Performance?},
year = {1978},
isbn = {9781450374026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800096.803141},
doi = {10.1145/800096.803141},
abstract = {Many authors (1, 2, 3, 5, 6, 7) have suggested that overall performance of a document retrieval system is improved by relevance feedback. Relevance feedback denotes the last three steps in the following process: 1) the searcher enters a query, 2) the system prepares a ranked list of suggested documents, 3) the searcher judges some of the documents for relevancy, 4) the searcher informs the system of these documents judged and of the judgement, 5) the system constructs a new query based on the descriptors used in the original query and the descriptors used in the documents judged, 6) the system prepares a second ranked list of suggested documents.The presumption is that the second list is better than the first. By all performance measures (e.g. “fluid ranking” and “frozen ranking”), the second list is better than the first. However, if one reranks documents in the original list so as to reflect the searcher's efforts (step 3), the corresponding performance measures are comparable to those for the second list. The marginal difference between the performance measures for the ”reranked original” list (searcher's efforts alone) and the second list (which includes computer efforts) makes it unclear if the cost of steps 4 through 6 above can be justified. It is hoped that advocates of relevance feedback will present “reranked original” performance measures as a basis for any performance improvement claims.This paper also presents three reasonable, easily understood retrieval procedures for which the frozen ranking, the fluid ranking, and the reranked original evaluations are “obviously” the pertinent way to evaluate. Relevance feedback techniques as implemented in Salton's SMART DRS appear to show that it is worthwhile for user's to read abstracts prior to evaluation of full texts. The last indication presented in this paper is that the relevance feedback performance improvements noted using SMART are due mostly to the user making assessments; subsequent computer efforts appear to be most likely to result in no further change. For a query for which there is a subsequent change, the change is as likely to be harmful as helpful.},
booktitle = {Proceedings of the 1st Annual International ACM SIGIR Conference on Information Storage and Retrieval},
pages = {151–170},
numpages = {20},
series = {SIGIR '78}
}

@article{10.1145/1013234.803137,
author = {Yang, Chung-Shu},
title = {Record Block Allocation for Retrieval on Secondary Keys},
year = {1978},
issue_date = {May 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013234.803137},
doi = {10.1145/1013234.803137},
abstract = {Query retrieval based on secondary keys is an important operation in retrieval systems. Such a query generally retrieves more than one data record which satisfies the query criterion. This paper studies the problem of record address allocation in disk-like devices so as to facilitate the fast retrieval of a set of records which are jointly accessed by a query. A heuristic scheme, using the proposed minimal access retrieval property, is designed to assign records to blocks. Some experimental results are also presented.},
journal = {SIGIR Forum},
month = may,
pages = {83–108},
numpages = {26}
}

@inproceedings{10.1145/800096.803137,
author = {Yang, Chung-Shu},
title = {Record Block Allocation for Retrieval on Secondary Keys},
year = {1978},
isbn = {9781450374026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800096.803137},
doi = {10.1145/800096.803137},
abstract = {Query retrieval based on secondary keys is an important operation in retrieval systems. Such a query generally retrieves more than one data record which satisfies the query criterion. This paper studies the problem of record address allocation in disk-like devices so as to facilitate the fast retrieval of a set of records which are jointly accessed by a query. A heuristic scheme, using the proposed minimal access retrieval property, is designed to assign records to blocks. Some experimental results are also presented.},
booktitle = {Proceedings of the 1st Annual International ACM SIGIR Conference on Information Storage and Retrieval},
pages = {83–108},
numpages = {26},
series = {SIGIR '78}
}

@article{10.1145/1013234.803136,
author = {Croft, W. Bruce},
title = {A File Organization for Cluster-Based Retrieval},
year = {1978},
issue_date = {May 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013234.803136},
doi = {10.1145/1013234.803136},
abstract = {A file organization for cluster-based retrieval is presented and tested. This file organization is based on the bottom-up search which, in contrast to the more usual top-down search, starts at the lowest level of a cluster hierarchy (the documents) and looks at progressively larger clusters. This approach enables most of the efficiency problems previously associated with clustered file organizations to be avoided. There are two parts to this file organization - a compact cluster hierarchy representation which does not store cluster representatives and a compact inverted file which is used to provide a starting point for the bottom-up search.Retrieval experiments show that the bottom-up search using this file organization can be more effective than a serial search, especially if high precision results are required.},
journal = {SIGIR Forum},
month = may,
pages = {65–82},
numpages = {18}
}

@inproceedings{10.1145/800096.803136,
author = {Croft, W. Bruce},
title = {A File Organization for Cluster-Based Retrieval},
year = {1978},
isbn = {9781450374026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800096.803136},
doi = {10.1145/800096.803136},
abstract = {A file organization for cluster-based retrieval is presented and tested. This file organization is based on the bottom-up search which, in contrast to the more usual top-down search, starts at the lowest level of a cluster hierarchy (the documents) and looks at progressively larger clusters. This approach enables most of the efficiency problems previously associated with clustered file organizations to be avoided. There are two parts to this file organization - a compact cluster hierarchy representation which does not store cluster representatives and a compact inverted file which is used to provide a starting point for the bottom-up search.Retrieval experiments show that the bottom-up search using this file organization can be more effective than a serial search, especially if high precision results are required.},
booktitle = {Proceedings of the 1st Annual International ACM SIGIR Conference on Information Storage and Retrieval},
pages = {65–82},
numpages = {18},
series = {SIGIR '78}
}

@article{10.1145/965643.810250,
author = {Hsiao, David K. and Kannan, Krishnamurthi},
title = {The Architecture of a Database Computer - a Summary},
year = {1977},
issue_date = {May 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/965643.810250},
doi = {10.1145/965643.810250},
abstract = {The motivation for seeking hardware solutions to database management functions traditionally carried out by software has been apparent to data-base designers for sometime now. Firstly, database management software has grown in complexity and size over the years. This growth is prompted by the increase in user requirements, by the formulation of sophisticated models and by the change in data processing mode from an off-line, batched, single user environment to an on-line, concurrent and multi-user environment. Large and complex software systems tend to be failure-prone. Further-more, practical verification methods for software systems are still not in sight. On the other hand, methods for verifying hardware functionality, design and production have long been available. Advanced technology has also overcome some of the problems of the logic complexity and capacity requirements, making the construction of relatively large and complex computers viable. By incorporating basic database management functions into hardware, not only can we provide more reliable basic functions, but we can also improve the software reliability since the software requirements will be less complex and the system software will be smaller in size.},
journal = {SIGIR Forum},
month = jan,
pages = {31–33},
numpages = {3}
}

@inproceedings{10.1145/800180.810250,
author = {Hsiao, David K. and Kannan, Krishnamurthi},
title = {The Architecture of a Database Computer - a Summary},
year = {1977},
isbn = {9781450374804},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800180.810250},
doi = {10.1145/800180.810250},
abstract = {The motivation for seeking hardware solutions to database management functions traditionally carried out by software has been apparent to data-base designers for sometime now. Firstly, database management software has grown in complexity and size over the years. This growth is prompted by the increase in user requirements, by the formulation of sophisticated models and by the change in data processing mode from an off-line, batched, single user environment to an on-line, concurrent and multi-user environment. Large and complex software systems tend to be failure-prone. Further-more, practical verification methods for software systems are still not in sight. On the other hand, methods for verifying hardware functionality, design and production have long been available. Advanced technology has also overcome some of the problems of the logic complexity and capacity requirements, making the construction of relatively large and complex computers viable. By incorporating basic database management functions into hardware, not only can we provide more reliable basic functions, but we can also improve the software reliability since the software requirements will be less complex and the system software will be smaller in size.},
booktitle = {Proceedings of the 3rd Workshop on Computer Architecture : Non-Numeric Processing},
pages = {31–33},
numpages = {3},
series = {CAW '77}
}

@article{10.1145/1842890.1842897,
author = {Beckers, T. and Bellot, P. and Demartini, G. and Denoyer, L. and De Vries, C. M. and Doucet, A. and Fachry, K. N. and Fuhr, N. and Gallinari, P. and Geva, S. and Huang, W.-C. and Iofciu, T. and Kamps, J. and Kazai, G. and Koolen, M. and Kutty, S. and Landoni, M. and Lehtonen, M. and Moriceau, V. and Nayak, R. and Nordlie, R. and Pharo, N. and SanJuan, E. and Schenkel, R. and Tannier, X. and Theobald, M. and Thom, J. A. and Trotman, A. and de Vries, A. P.},
title = {Report on INEX 2009},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1842890.1842897},
doi = {10.1145/1842890.1842897},
abstract = {INEX investigates focused retrieval from structured documents by providing large test collections of structured documents, uniform evaluation measures, and a forum for organizations to compare their results. This paper reports on the INEX 2009 evaluation campaign, which consisted of a wide range of tracks: Ad hoc, Book, Efficiency, Entity Ranking, Interactive, QA, Link the Wiki, and XML Mining. INEX in running entirely on volunteer effort by the IR research community: anyone with an idea and some time to spend, can have a major impact.},
journal = {SIGIR Forum},
month = aug,
pages = {38–57},
numpages = {20}
}

@article{10.1145/511144.511149,
author = {Chen, Kuang-hua and Chen, Hsin-Hsi},
title = {Cross-Language Chinese Text Retrieval in NTCIR Workshop: Towards Cross-Language Multilingual Text Retrieval},
year = {2001},
issue_date = {Fall 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/511144.511149},
doi = {10.1145/511144.511149},
abstract = {This article reports the results of Chinese Text Retrieval (CHTR) tasks in NTCIR Workshop 2 and the future plan of NTCIR workshop. CHTR tasks fall into two categories: Chinese-Chinese IR (CHIR) and English-Chinese IR (ECIR). The definitions, schedules, test collection (CIRB010), search results, evaluation, and initial analyses of search results of CHIR and ECIR are discussed in this article. The new plan of NTCIR towards multilingual Cross-Language Information Retrieval (CLIR) is also described.},
journal = {SIGIR Forum},
month = sep,
pages = {12–19},
numpages = {8}
}

@article{10.1145/948716.948720,
author = {Smeaton, Alan and Callan, Jamie},
title = {Joint DELOS-NSF Workshop on Personalisation and Recommender Systems in Digital Libraries},
year = {2001},
issue_date = {Spring 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/948716.948720},
doi = {10.1145/948716.948720},
journal = {SIGIR Forum},
month = apr,
pages = {7–11},
numpages = {5}
}

@article{10.1145/181886.181887,
author = {Donaldson, Cameron},
title = {InQuisiX—an Electronic Catalog for Software Reuse},
year = {1994},
issue_date = {Spring 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/181886.181887},
doi = {10.1145/181886.181887},
abstract = {InQuisiX is an interactive system supporting the development and use of an electronic catalog. Features are provided for organizing the catalog, classifying and describing items, and searching and browsing catalog descriptions. Items described in the catalog are stored elsewhere and are accessed for display or retrieval through end-user tools integrated with InQuisiX. InQuisiX provides public interfaces for loading data, exchanging catalog data with other tools, invoking end-user tools, and making searchable any information stored outside the catalog, such as documents or graphics.Although InQuisiX is being marketed for use in cataloguing reusable software assets, there is nothing inherent in the design or functionality which restricts its use to this domain. Certain features, particularly the ability to invoke and work cooperatively with other automated tools in the development environment, are particularly useful to software developers. Hexible classification and description features are also important for the emerging software reuse market because best practices in classifying and describing software are still a research topic.InQuisiX runs on UNIX/X Window based environments and is currently hosted on both Sun SPARCstations and IBM RISC 6000 workstations. The system has been developed entirely in Classic-Ada, an object-oriented preprocessor for Ada, and uses a custom, automatically generated persistent object base for storing all information, including both the organization and the contents of the catalog, inverted indexes used to support searching, saved queries, and interfaces to end-user tools. The object base is implemented as a single binary file.},
journal = {SIGIR Forum},
month = mar,
pages = {8–12},
numpages = {5}
}

@article{10.1145/174263.174265,
author = {Mukhopadhyay, Debajyoti},
title = {A Generic Information Retrieval System to Support Interoperability},
year = {1993},
issue_date = {Spring 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/174263.174265},
doi = {10.1145/174263.174265},
abstract = {Retrieval of information from a database is a basic and vital function that any system is expected to provide. With the growing complexity of information, and with the advent of distributed systems, it has become necessary to process any retrieval request coming from any system which is a part of the distributed environment. This calls for a generic retrieval system supporting interoperability which can formulate the request on the fly. Interoperability is the ability to interconnect software products irrespective of their suppliers and vintages, to provide access to corporate data by any authorized user, and to maintain that interconnection and access over changes in suppliers and vintages. This paper describes such a system which is generic in nature, and at the same time provides a mechanism which supports the mapping of the logical view to physical database implementation supporting interoperability.},
journal = {SIGIR Forum},
month = mar,
pages = {14–21},
numpages = {8},
keywords = {physical view, distributed system, database accessor, logical view, contracts, building blocks, layer, output formatter, interoperability, SQL constructor, SQL parser and translator, OSCA architecture, view manager, release independence, interface}
}

@article{10.1145/122665.122669,
author = {Korfhage, Robert R. and Yang, Jing-Jye},
title = {A Cautionary Tale},
year = {1991},
issue_date = {Fall 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/122665.122669},
doi = {10.1145/122665.122669},
abstract = {Recently we have been investigating various methods for improving the retrieval of documents. One frequently used context for such studies is to work with a known database and set of queries, where sufficient work has previously been done to establish an "official" set of relevant documents for each query. Working within such a context, we have discovered at least one instance wherein the combination of the document descriptions in the database, the query, and the set of documents deemed relevant foredooms our attempts at retrieval improvement to failure. This note is to caution other researchers against such possibilities, and to recommend that the database in question, that of the National Physical Laboratory (NPL), as represented on Virginia Disk 1, be retired from use.},
journal = {SIGIR Forum},
month = sep,
pages = {104–105},
numpages = {2}
}

@article{10.1145/101306.1096783,
author = {Humphrey, Susanne M.},
title = {Selected IR-Related Dissertation Abstracts},
year = {1990},
issue_date = {Fall 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/101306.1096783},
doi = {10.1145/101306.1096783},
abstract = {The following are citations selected by title and abstract as being related to Information Retrieval (IR), resulting from a computer search, using Dialog Information Services, of the Dissertation Abstracts Online database produced by University Microfilms International (UMI). Included are UMI order number, title, author, degree, year, institution; number of pages, one or more Dissertation Abstracts International (DAI) subject descriptors chosen by the author, and abstract. Unless otherwise specified, paper or microform copies of dissertations may be ordered from University Microfilms International, Dissertation Copies, Post Office Box 1764, Ann Arbor, MI 48106; telephone for U.S. (except Michigan, Hawaii, Alaska): 1-800-521-3042, for Canada: 1-800-268-6090. Price lists and other ordering and shipping information are in the introduction to the published DAI. An alternate source for copies is sometimes provided. Dissertation titles and abstracts contained here are published with permission of University Microfilms International, publishers of Dissertation Abstracts International (copyright by University Microfilms International), and may not be reproduced without their prior permission.},
journal = {SIGIR Forum},
month = nov,
pages = {85–111},
numpages = {27}
}

@article{10.1145/101306.1096780,
author = {Can, Fazli},
title = {Book Review: An Introduction to Text Processing by Peter D. Smith. The MIT Press, Cambridge, Massachusetts, 1990, 300 Pp., $32.50, ISBN 0-262-19299-3},
year = {1990},
issue_date = {Fall 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/101306.1096780},
doi = {10.1145/101306.1096780},
abstract = {There are very few books on text processing, Recently I performed a search on the CD version of the Books in Print Plus, which is the master reference to currently available books, authors, and publishers in the US. I found just fifty books that contain the words "text" and "processing," and fourteen books that contain "document" and "processing" in their titles. (As a side light and for comparison: there are 644 books containing "information" and "retrieval" in their titles.) This book is a survey of text processing applications, and algorithms; a welcome addition to the literature.},
journal = {SIGIR Forum},
month = nov,
pages = {72–73},
numpages = {2}
}

@article{10.1145/101306.101309,
author = {Frakes, W. B. and Pole, T. P.},
title = {Proteus: A Software Reuse Library System},
year = {1990},
issue_date = {Fall 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/101306.101309},
doi = {10.1145/101306.101309},
abstract = {Many methods for representing software components for reuse have been proposed. These include traditional library and information science methods, knowledge based methods, and hypertext. There has been no empirical evaluation of these methods, and consequently there is no data about their relative costs and effectiveness. Proteus is an experimental reuse library system that will be used to help gather such data. Reuse library systems are usually tied to one method---Proteus supports multiple methods.},
journal = {SIGIR Forum},
month = nov,
pages = {43–55},
numpages = {13}
}

@article{10.1145/378881.378889,
author = {Salton, G.},
title = {IR-Related Abstracts},
year = {1989},
issue_date = {Fall 89/Winter 90},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/378881.378889},
doi = {10.1145/378881.378889},
journal = {SIGIR Forum},
month = sep,
pages = {36–39},
numpages = {4}
}

@article{10.1145/378881.378885,
author = {Nielsen, Jakob},
title = {Three Medium-Sized Hypertexts on CD-ROM},
year = {1989},
issue_date = {Fall 89/Winter 90},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/378881.378885},
doi = {10.1145/378881.378885},
abstract = {A review of the Macintosh CD-ROM versions of The Manhole, the Time Table of History, and the Electronic Whole Earth Catalog with emphasis on their usability and their support of hypertext navigation. Based on the discussion of these hypertexts the following general principles are found to be useful for analyzing hypertext user interfaces: Navigational dimensions and their explicitness, directionality and literalness, landmarks, locational orientation, history lists, and backtrack mechanisms.},
journal = {SIGIR Forum},
month = sep,
pages = {2–10},
numpages = {9},
keywords = {interactive fiction, navigation, usability, Macintosh, animated visual effects, CD-ROM, electronic encyclopedias, hypertext}
}

@article{10.1145/74697.1096799,
author = {Humphrey, Susanne M.},
title = {Selected IR-Related Dissertation Abstracts},
year = {1989},
issue_date = {Spring 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/74697.1096799},
doi = {10.1145/74697.1096799},
abstract = {The following are citations selected by title and abstract as being related to Information Retrieval (IR), resulting from a computer search, using the BRS Information Technologies retrieval service, of the Dissertation Abstracts International (DAI) database produced by University Microfilms International. Included are the UM order number and year-month of entry into the database; author, university, degree, and, if available, number of pages; title; DAI subject category chosen by the author of the dissertation; and abstract. References are sorted first by DAI subject category and second by author. Citations denoted by an MAI reference do not yet have abstracts in the database and refer to abstracts in the published Masters Abstracts International. Unless otherwise specified, paper or microform copies of dissertations may be ordered from University Microfilms International, Dissertation Copies, Post Office Box 1764, Ann Arbor, MI 48106; telephone for U.S. (except Michigan, Hawaii, Alaska): 1-800-521-3042, for Canada: 1-800-268-6090. Price lists and other ordering and shipping information are in the introduction to the published DAI. An alternate source for copies is sometimes provided at the end of the abstract. The dissertation titles and abstracts contained here are published with permission of University Microfilms International, publishers of Dissertation Abstracts International (copyright by University Microfilms International), and may not be reproduced without their prior permission.},
journal = {SIGIR Forum},
month = apr,
pages = {114–122},
numpages = {9}
}

@article{10.1145/1095483.1095487,
author = {Groman, R. C.},
title = {Dissertation Abstract},
year = {1988},
issue_date = {Fall 1988/Winter 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095483.1095487},
doi = {10.1145/1095483.1095487},
abstract = {Information retrieval can be defined as the extraction of specific information out of a great number of stored information items. Information retrieval systems, used for the retrieval of documents, try to answer more or less precise questions about interesting topics with a number of suitable documents or references to documents. Such systems should contain 'knowledge' about the meaning of questions, about the content of the stored information and the particular user's needs for information.Knowledge-bases systems claim to be able to store knowledge an draw conclusions from it. The goal of this thesis is to investigate the use of knowledge-based methods and technologies for information retrieval. A knowledge-based information retrieval system should represent its Information Structures, as well as knowledge in a common knowledge representation formalism. The retrieval process of the system should employ the inferential methods of the used knowledge representation formalism.A subset of first order logic is chosen for this thesis to represent knowledge. Specially designed retrieval rules represent knowledge for the purpose of retrieval. Retrieval rules capture knowledge about the user's vocabulary, his working domain and his way to perform the retrieval of documents. The problem of recall and precision of the answers of an information retrieval system is approached by an explicit representation of control knowledge.A theoretical model of a knowledge-based information retrieval system developed in this thesis specifies the requirements and properties, of such a system. In particular a novel term-similarity function could be defined. Properties like completeness and termination could be derived and boundaries for the amount of overhead of false control strategies could be investigated.The proposed model is implemented in a prototype of a knowledge-based information retrieval system, called KIR. KIR is a single-user system for personal document- and knowledge retrieval running on computer workstations. It is implemented using Prolog and Modula-2.},
journal = {SIGIR Forum},
month = sep,
pages = {35},
numpages = {1}
}

@article{10.1145/43936.43938,
author = {Hanson, Robin},
title = {Toward Hypertext Publishing},
year = {1988},
issue_date = {Fall 1987/Winter 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/43936.43938},
doi = {10.1145/43936.43938},
abstract = {Hypertext publishing, the integration of a very large body of public writings into a unified hypertext environment, will require the simultaneous solution of problems involving very wide database distribution, copyright, freedom of speech, privacy, and information overload. This paper describes these problems and presents, for criticism and discussion, an abstract design called LinkText which seems to solve many of them. LinkText is presented both as a specification and as design approaches grouped around various levels of electronic publishing.},
journal = {SIGIR Forum},
month = jan,
pages = {9–26},
numpages = {18}
}

@article{10.1145/15497.15502,
author = {Lesk, Michael},
title = {Information in Data: Using the Oxford English Dictionary on a Computer},
year = {1986},
issue_date = {Spring-Summer 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/15497.15502},
doi = {10.1145/15497.15502},
journal = {SIGIR Forum},
month = may,
pages = {18–21},
numpages = {4}
}

@article{10.1145/15497.15500,
author = {Wong, S K and Ziarko, W},
title = {A Unified Approach for Artificial Intelligence and Information Retrieval},
year = {1986},
issue_date = {Spring-Summer 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/15497.15500},
doi = {10.1145/15497.15500},
abstract = {In the past, several mathematical models for document retrieval systems have been developed [C82, S83, S83a, T76, WO84]. These models are used to formally represent the basic characteristics, functional components, and the retrieval processes of document retrieval systems. Two basic categories of models that have been employed in information retrieval are the vector processing models and the Boolean retrieval models.In the conventional vector space model (VSM), proposed by Salton [S71, S83] index terms are basic vectors in a vector space. Each document or query is represented as a linear combination of these basic term vectors. The retrieval operation consists of computing the cosine similarity function between a given query vector and the set of document vectors and then ranking documents accordingly. In this approach, the interpretation that the occurrence frequency of a term in a document represents the component of the document vector along the corresponding basic term vectors is made.The advantages of this model are that it is simple and yet powerful. The vector operations can be performed efficiently enough to handle very large collections. Furthermore, it has been shown that the retrieval effectiveness is significantly higher compared to that of the Boolean retrieval models. However, this vector model has been incorporated into very few commercial systems.In the strict Boolean retrieval systems [BU81, P84] the user query normally consists of index terms that are connected by Boolean operators AND, OR and NOT. The advantage of using Boolean connectives is to provide a better structure to formulate the user query. The major problem in such a system is that there is no provision for associating weights of importance to the terms which are assigned either to the documents or to the queries. In other words, the representation is binary, indicating either the presence or the absence of the various index terms. The output obtained in response to a query is not ranked in any order of presumed importance to the user. In most cases, the AND connectives tend to be too restrictive [BU81]. Mose commercially available retrieval systems essentially conform to this model.One of the challenges for researchers in information retrieval has been to achieve greater acceptance of the vector processing models in commercial systems. The main difficulty in this connection is due to the inability of the vector processing systems to handle Boolean queries. In recent years some progress has been made in expressing Boolean queries as vectors [S83a, S83b]. If attractive ways to achieve this are advanced, it would then be possible to modify existing systems to use vector processing techniques without a great deal of cost and effort.Another problem in the conventional vector space model is that it assumes that term vectors are orthogonal. It is generally agreed that terms are correlated and it is necessary to generalize the model to incorporate term correlations. A vector processing model termed the GVSM [WO84a, WO85] was proposed in response to this need. In the GVSM, the queries are assumed to be presented as a list of terms and corresponding weights. Thus, no provision is made for processing Boolean queries. However, the premises of the model naturally lead to a scheme for handling Boolean queries. In this paper we present the details of this scheme. This result will help achieve the aim of integrating vector processing capabilities into existing systems which use Boolean retrieval models.},
journal = {SIGIR Forum},
month = may,
pages = {14–15},
numpages = {2}
}

@article{10.1145/15497.1096833,
author = {Yu, Clement},
title = {Abstracts},
year = {1986},
issue_date = {Spring-Summer 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/15497.1096833},
doi = {10.1145/15497.1096833},
abstract = {The first part of this paper reports a comparative study of the document classifications produced by the use of the single linkage, complete linkage, group average, and Ward clustering methods. Studies of cluster membership and of the effectiveness of cluster searches support previous findings that suggest that the single linkage classifications are rather different from those produced by the other three methods. These latter methods all produce large numbers of small clusters containing just pairs of documents. This finding motivates the work reported in the second part of the paper, which considers the use of clusters consisting of a document together with that document with which it is most similar. A comparison of the use of such clusters with conventional best match searches using seven documents test collections suggest that the two types of search are of comparable effectiveness, but they retrieve noticeably different sets of relevant documents.},
journal = {SIGIR Forum},
month = may,
pages = {23–29},
numpages = {7}
}

@article{10.1145/3263600,
author = {Doszkocs, Tamas},
title = {Session Details: Session 2: State-of-the-Art Tutorials},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263600},
doi = {10.1145/3263600},
journal = {SIGIR Forum},
month = jun,
numpages = {1}
}

@article{10.1145/1095464.1095465,
author = {Mah, Clinton P. and D'Amore, Raymond J.},
title = {Complete Statistical Indexing of Text by Overlapping Word Fragments},
year = {1983},
issue_date = {Winter-Spring 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095464.1095465},
doi = {10.1145/1095464.1095465},
abstract = {By using overlapping word fragments to index text, we can combine the best features of the keyword and the full text approaches to document retrieval so as to facilitate searches on any content word. The characteristics of a retrieval system based on word fragment indexing can be precisely predicted from a multinomial model of text. Controlled experiments with two different text collections indicate that such a system can be highly effective under quite general conditions.},
journal = {SIGIR Forum},
month = jan,
pages = {6–16},
numpages = {11}
}

@article{10.1145/1095312.1095315,
author = {Noreault, Terry},
title = {Review of "Data Base Processing Fundamentals, Modeling, Applications by David Kroenke"; Science Research Associates, 1977},
year = {1977},
issue_date = {Spring 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095312.1095315},
doi = {10.1145/1095312.1095315},
abstract = {This book is an introductory text for data base management systems. The author's presentation starts with descriptions of the physical characteristics of secondary storage devices and ends with a discussion of the design and administration of data base systems. The book would probably be useful to those with some prior knowledge of data structures.},
journal = {SIGIR Forum},
month = apr,
pages = {23},
numpages = {1}
}

@article{10.1145/1095325.1095329,
author = {Wood, Daniel K.},
title = {Review of "Applied Data Management by Charles T. Meadow"; 1976, John Wiley and Sons},
year = {1976},
issue_date = {Winter 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095325.1095329},
doi = {10.1145/1095325.1095329},
abstract = {This book belongs to the Information Sciences Series published by John Wiley and Sons which is designed to cover the various aspects of communicating, utilizing, and storing digital and graphic information. The book deals with concepts of managing the data, rather than techniques for application in data management.},
journal = {SIGIR Forum},
month = dec,
pages = {13},
numpages = {1}
}

@article{10.1145/1095307.1095310,
author = {Smith, Linda C.},
title = {Review of "Information Retrieval by C. J. van Rijsbergen"; London, Butterworths, 1975},
year = {1976},
issue_date = {Fall 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095307.1095310},
doi = {10.1145/1095307.1095310},
journal = {SIGIR Forum},
month = sep,
pages = {7–9},
numpages = {3}
}

@article{10.1145/1095302.1095305,
author = {Mazlack, Lawrence J.},
title = {Review of "Shockwave Rider by John Brunner"; Harper and Row 1975},
year = {1976},
issue_date = {Summer 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095302.1095305},
doi = {10.1145/1095302.1095305},
journal = {SIGIR Forum},
month = jul,
pages = {8},
numpages = {1}
}

@article{10.1145/1095302.1095303,
author = {Tars, Arvo},
title = {Stemming as a System Design Consideration},
year = {1976},
issue_date = {Summer 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095302.1095303},
doi = {10.1145/1095302.1095303},
abstract = {A good deal of work has been done over the years trying to demonstrate the feasibility or superiority of automatic indexing techniques. (1--8) Most of these techniques are designed for natural language systems, i. e., systems which have an uncontrolled vocabulary. While they incorporate many desirable features, they also have some disadvantages.},
journal = {SIGIR Forum},
month = jul,
pages = {9–16},
numpages = {8}
}

@article{10.1145/1095286.1095294,
author = {Berra, P. Bruce and Singhania, Ashok K.},
title = {A Multiple Associative Memory Organization for Pipelining a Directory to a Very Large Data Base},
year = {1976},
issue_date = {Spring 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095286.1095294},
doi = {10.1145/1095286.1095294},
abstract = {The limitation of the existing class of sequential computers in the management of large data bases is well known. This has led to investigations of Associative/Parallel devices, working alone or in conjunction with sequential devices, as possible tools for Data Base Management (DBM). Associative Memories have been shown to be an attractive tool for DBM when the data base is sufficiently small; however, their usefulness in the management of large data bases has not yet been established.The research that we are presently undertaking addresses itself to data retrieval and update in an environment of a large, general data base with substantial activity. A hierarchical directory to the data base is utilized that permits both single and multiple-attribute retrievals. A series of Associative Memories is used to pipeline the searches at various levels of the directory. The performance of this system is being compared with both sequential and other organizations utilizing Associative Memories. The criteria for comparison are retrieval and update performance, storage utilization and flexibility.},
journal = {SIGIR Forum},
month = apr,
pages = {22},
numpages = {1}
}

@article{10.1145/1095286.1095290,
author = {Reszka, A. and Gonzalez, M. J.},
title = {A General Approach to Functionally Distributed Computer Architecture},
year = {1976},
issue_date = {Spring 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095286.1095290},
doi = {10.1145/1095286.1095290},
abstract = {It is shown in this paper that in a computer organization which is based on partitioning functionally interrelated hardware and software components together into functionally independent nodes, the interfunctional overhead activity can be reduced to a minimum. The reduction of the interfunctional overhead activity, which is the main contributor to poor system performance, results in a corresponding increase in system performance. In addition it is shown that in a functionally distributed system organization there exists a sequential job-shop or pipeline like flow of information (data and supervisory overhead) within the computer system which is essentially application independent. It is this type of flow that introduces a basic structure into the system which is practically non-existent in a centralized system architecture.In summary, the functionally distributed computer architecture proposed in this paper is based on a structured flow of blocks of information with a minimum of supervisory overhead through functionally independent but sequentially cooperating nodes. It is shown that this type of organization produces optimal system performance, i.e., response time, throughput and system availability.},
journal = {SIGIR Forum},
month = apr,
pages = {9},
numpages = {1}
}

@article{10.1145/1095277.1095280,
author = {Bayer, R. and Metzger, J. K. and Germany, M\"{u}nchen W.},
title = {On the Encipherment of Search Trees and Random Access Files},
year = {1975},
issue_date = {Winter 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095277.1095280},
doi = {10.1145/1095277.1095280},
abstract = {The securing of information in indexed, random access files by means of privacy transformations must be considered as a problem distinct from that for sequential files. Not only must processing overhead due to encrypting be considered, but also must threats to encipherment arising from updating and the file structure itself be countered. A general encipherment scheme is proposed for files maintained in a paged structure on secondary storage. This is then applied to the encipherment of indexes organized as B-trees, a particular type of multiway search tree. Threats to the encipherment of B-trees, especially relating to updating, are examined, and counter-measures proposed for each. In addition, the effect of encipherment on file access and update, on paging mechanisms, and on files related to the enciphered index are discussed. Many of the concepts presented here may be readily transferred to other forms of multiway index trees and to binary search trees.},
journal = {SIGIR Forum},
month = dec,
pages = {10},
numpages = {1},
keywords = {B-trees, paging, search trees, indexes, random access files, indexed sequential files, encipherment, protection, cryptography, security, privacy transformation, privacy}
}

@article{10.1145/1095271.1095272,
author = {Lipovski, G. Jack and Su, Stanley Y. W.},
title = {On Non-Numeric Architecture},
year = {1975},
issue_date = {Summer 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095271.1095272},
doi = {10.1145/1095271.1095272},
abstract = {In this informal paper, we present what we believe is one of the major problems in computer science of the 70's and several approaches to the solution of this problem that are being studied by our group and by others. (A formal paper that includes a detailed bibliography on this topic is in preparation. Therefore, we are writing this paper in an informal style without references). A very large part of the computational load throughout the world is essentially business computation. Perhaps it is the majority of computation. Business computation is heavily oriented to data base management and information retrieval. We will refer to this type of computation as non-numeric processing. The main primitive operation here is the search. However, we are using standard von Neumann computers whose main primitive operation is addition. What is good for numeric problems like inverting large matrices is not necessarily good for non-numeric problems like searching large data bases. The hardware limitations of conventional von Neumann computers tend to straightjacket our approach to non-numeric processing.},
journal = {SIGIR Forum},
month = jul,
pages = {5–20},
numpages = {16}
}

@article{10.1145/1095495.1095502,
title = {A System Structure and Data Structure for an Interactive On-Line Thesaurus},
year = {1972},
issue_date = {Winter 1972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095495.1095502},
doi = {10.1145/1095495.1095502},
abstract = {The data structure for a thesaurus is conceptually presented as a continuous string of characters. Hashing into the string permits access to terms and their related terms. A prefix hashing scheme is described which permits thesaurus access with partial spellings and defines file blocking to improve sequential (alphabetic) scans. A general system structure is proposed with display formats and a user command language.},
journal = {SIGIR Forum},
month = dec,
pages = {65–70},
numpages = {6}
}

@article{10.1145/75335.75349,
author = {Krovetz, R. and Croft, W. B.},
title = {Word Sense Disambiguation Using Machine-Readable Dictionaries},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75349},
doi = {10.1145/75335.75349},
journal = {SIGIR Forum},
month = may,
pages = {127–136},
numpages = {10}
}

@inproceedings{10.1145/75334.75349,
author = {Krovetz, R. and Croft, W. B.},
title = {Word Sense Disambiguation Using Machine-Readable Dictionaries},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75349},
doi = {10.1145/75334.75349},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {127–136},
numpages = {10},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/75335.75344,
author = {van Rijsbergen, C. J.},
title = {Towards an Information Logic},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75344},
doi = {10.1145/75335.75344},
abstract = { 'Probability is expectation founded upon partial knowledge.' (Boole, 1854)Information retrieval based on stored program electronic computers has been an active area of research since the time these machines were invented. It is therefore somewhat surprising that even now no formal computational model for IR exists. There is no well-defined logic to describe information retrieval, and there is no proof or model theory to talk about the truths of IR.This paper argues that much of the research work in the past has been steps in the direction of a logic for IR. These steps have been taken by developing formal models for information retrieval, but to date none of these are complete nor could any claim to be a computational model for IR. To appreciate this development I shall present a picture of IR, describing bits of a puzzle which may fit together to point to a new framework within which a computational model or logic could be described.},
journal = {SIGIR Forum},
month = may,
pages = {77–86},
numpages = {10}
}

@inproceedings{10.1145/75334.75344,
author = {van Rijsbergen, C. J.},
title = {Towards an Information Logic},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75344},
doi = {10.1145/75334.75344},
abstract = { 'Probability is expectation founded upon partial knowledge.' (Boole, 1854)Information retrieval based on stored program electronic computers has been an active area of research since the time these machines were invented. It is therefore somewhat surprising that even now no formal computational model for IR exists. There is no well-defined logic to describe information retrieval, and there is no proof or model theory to talk about the truths of IR.This paper argues that much of the research work in the past has been steps in the direction of a logic for IR. These steps have been taken by developing formal models for information retrieval, but to date none of these are complete nor could any claim to be a computational model for IR. To appreciate this development I shall present a picture of IR, describing bits of a puzzle which may fit together to point to a new framework within which a computational model or logic could be described.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {77–86},
numpages = {10},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/1013230.511817,
author = {Somers, Patricia},
title = {The User View of File Management: Recommendations for a User Interface Based on Analysis of UNIX File System Use},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511817},
doi = {10.1145/1013230.511817},
abstract = {The structures in which users store their files facilitate retrieval by enabling users to deduce a file's contents from its place in the organization. This study examined structures created by UNIX users to organize their files within a hierarchical directory scheme, and examined the relation between structure and command usage. Users' difficulties in managing the complexity of a hierarchical structure limited the amount of information about files that these structures contained. Tree complexity increased in a negatively accelerating function with the number of files. Users who grouped their files into few directories arranged in shallow trees could navigate through the tree easily, but they sacrificed information: directory names were less specific, and users made more command errors. More sophisticated users created deeper trees. They were able to manage more files but also made extensive use of navigation aids.},
journal = {SIGIR Forum},
month = jun,
pages = {161},
numpages = {1}
}

@inproceedings{10.1145/511793.511817,
author = {Somers, Patricia},
title = {The User View of File Management: Recommendations for a User Interface Based on Analysis of UNIX File System Use},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511817},
doi = {10.1145/511793.511817},
abstract = {The structures in which users store their files facilitate retrieval by enabling users to deduce a file's contents from its place in the organization. This study examined structures created by UNIX users to organize their files within a hierarchical directory scheme, and examined the relation between structure and command usage. Users' difficulties in managing the complexity of a hierarchical structure limited the amount of information about files that these structures contained. Tree complexity increased in a negatively accelerating function with the number of files. Users who grouped their files into few directories arranged in shallow trees could navigate through the tree easily, but they sacrificed information: directory names were less specific, and users made more command errors. More sophisticated users created deeper trees. They were able to manage more files but also made extensive use of navigation aids.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {161},
numpages = {1},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511814,
author = {Pollitt, A. S.},
title = {End User Touch Searching for Cancer Therapy Literature: A Rule Based Approach},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511814},
doi = {10.1145/1013230.511814},
abstract = {This paper reviews work towards building an expert system for searching the cancer therapy literature on MEDLINE. A modified subset of the Medical Subject Headings (MeSH) has been stored on a micro-computer and accessed via a touch terminal. Searches, previously requested of the Oncology Information Service at the University of Leeds, have been used to test out the principle of end user searching and the results compared with the searching expertise of a MEDLARS indexer. Original program development was in PASCAL, but a rule-based approach, which is independent of a particular programming language, has been developed for search term and frame selection adopting a 'blackboard' philosophy in tracing the process of selection. Work is progressing on an implementation using the expert systems programming language PROLOG, which has been found a very suitable language for representing rules and provides a ready made rule interpreter. It is suggested that this approach is superior in terms of retrieval performance compared with alternative approaches to end-user searching which fail to exhibit detailed knowledge regarding the subject matter of the search.},
journal = {SIGIR Forum},
month = jun,
pages = {136–145},
numpages = {10}
}

@inproceedings{10.1145/511793.511814,
author = {Pollitt, A. S.},
title = {End User Touch Searching for Cancer Therapy Literature: A Rule Based Approach},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511814},
doi = {10.1145/511793.511814},
abstract = {This paper reviews work towards building an expert system for searching the cancer therapy literature on MEDLINE. A modified subset of the Medical Subject Headings (MeSH) has been stored on a micro-computer and accessed via a touch terminal. Searches, previously requested of the Oncology Information Service at the University of Leeds, have been used to test out the principle of end user searching and the results compared with the searching expertise of a MEDLARS indexer. Original program development was in PASCAL, but a rule-based approach, which is independent of a particular programming language, has been developed for search term and frame selection adopting a 'blackboard' philosophy in tracing the process of selection. Work is progressing on an implementation using the expert systems programming language PROLOG, which has been found a very suitable language for representing rules and provides a ready made rule interpreter. It is suggested that this approach is superior in terms of retrieval performance compared with alternative approaches to end-user searching which fail to exhibit detailed knowledge regarding the subject matter of the search.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {136–145},
numpages = {10},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013881.802694,
author = {Wolf, G.},
title = {Associative Mass Storage for Database},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802694},
doi = {10.1145/1013881.802694},
abstract = {Two types of associative mass storage for use in database systems, have been introduced in this paper, they areI Hybrid associative storage For use as an associative primary storage, it comprise a storing “basement” and an associative surface matrix. The suggested configuration has a capacity of up to 64 megabytes and a search rate of the order of 2 to 8 gigabytes per second. As well as associative operation, it is also suitable for extremely fast sorting.II Hardware hash coding system A hardware structure provides associative access to conventional, numerically addressed storage media. The prefered application is for quasi-associative access to data in secondary storages.Associative mass storages systems differ in their characteristics and complement each other. Together they form the hardware building blocks of a database system.},
journal = {SIGIR Forum},
month = mar,
pages = {70–81},
numpages = {12}
}

@inproceedings{10.1145/800083.802694,
author = {Wolf, G.},
title = {Associative Mass Storage for Database},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802694},
doi = {10.1145/800083.802694},
abstract = {Two types of associative mass storage for use in database systems, have been introduced in this paper, they areI Hybrid associative storage For use as an associative primary storage, it comprise a storing “basement” and an associative surface matrix. The suggested configuration has a capacity of up to 64 megabytes and a search rate of the order of 2 to 8 gigabytes per second. As well as associative operation, it is also suitable for extremely fast sorting.II Hardware hash coding system A hardware structure provides associative access to conventional, numerically addressed storage media. The prefered application is for quasi-associative access to data in secondary storages.Associative mass storages systems differ in their characteristics and complement each other. Together they form the hardware building blocks of a database system.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {70–81},
numpages = {12},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013232.511718,
author = {Khairy, Salah A. and Miller, George C.},
title = {Document Storage and Retrieval},
year = {1979},
issue_date = {September 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013232.511718},
doi = {10.1145/1013232.511718},
journal = {SIGIR Forum},
month = sep,
pages = {78–82},
numpages = {5}
}

@inproceedings{10.1145/511706.511718,
author = {Khairy, Salah A. and Miller, George C.},
title = {Document Storage and Retrieval},
year = {1979},
isbn = {9781450373456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511706.511718},
doi = {10.1145/511706.511718},
booktitle = {Proceedings of the 2nd Annual International ACM SIGIR Conference on Information Storage and Retrieval: Information Implications into the Eighties},
pages = {78–82},
numpages = {5},
location = {Dallas, Texas},
series = {SIGIR '79}
}

@article{10.1145/1013232.511713,
author = {Jamieson, S. H.},
title = {The Economic Implementation of Experimental Retrieval Techniques on a Very Large Scale Using an Intelligent Terminal},
year = {1979},
issue_date = {September 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013232.511713},
doi = {10.1145/1013232.511713},
abstract = {The results and achievements of research in information retrieval have had little influence on the types of retrieval mechanism implemented in the large commercial on-line retrieval systems. Commercial systems still use simple Boolean techniques while experiments have shown that other techniques, such as those making use of relevance information, perform better. Reasons for this are suggested. A strategy is described for the implementation of high-powered techniques which overcomes this problem - an intelligent terminal is used in conjunction with an existing commercial I. R. system. The added processing capability permits the implementation of more sophisticated retrieval techniques very cheaply. Retrieval methods that can be implemented on such a terminal used in this way are described.Particular emphasis is placed upon the practical implementation of a term weighting scheme based on relevance feedback information which generates a ranked list of documents in answer to a query.},
journal = {SIGIR Forum},
month = sep,
pages = {45–51},
numpages = {7}
}

@inproceedings{10.1145/511706.511713,
author = {Jamieson, S. H.},
title = {The Economic Implementation of Experimental Retrieval Techniques on a Very Large Scale Using an Intelligent Terminal},
year = {1979},
isbn = {9781450373456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511706.511713},
doi = {10.1145/511706.511713},
abstract = {The results and achievements of research in information retrieval have had little influence on the types of retrieval mechanism implemented in the large commercial on-line retrieval systems. Commercial systems still use simple Boolean techniques while experiments have shown that other techniques, such as those making use of relevance information, perform better. Reasons for this are suggested. A strategy is described for the implementation of high-powered techniques which overcomes this problem - an intelligent terminal is used in conjunction with an existing commercial I. R. system. The added processing capability permits the implementation of more sophisticated retrieval techniques very cheaply. Retrieval methods that can be implemented on such a terminal used in this way are described.Particular emphasis is placed upon the practical implementation of a term weighting scheme based on relevance feedback information which generates a ranked list of documents in answer to a query.},
booktitle = {Proceedings of the 2nd Annual International ACM SIGIR Conference on Information Storage and Retrieval: Information Implications into the Eighties},
pages = {45–51},
numpages = {7},
location = {Dallas, Texas},
series = {SIGIR '79}
}

@article{10.1145/1013232.511708,
author = {Dominick, W. D. and Penniman, W. D.},
title = {Automated Monitoring to Support the Analysis and Evaluation of Information Systems},
year = {1979},
issue_date = {September 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013232.511708},
doi = {10.1145/1013232.511708},
abstract = {This paper is based on, and extracted in part from, a much more expanded and detailed manuscript entitled "Monitoring and Evaluation of On-Line Information System Usage", accepted for publication in Information Processing and Management.},
journal = {SIGIR Forum},
month = sep,
pages = {2–9},
numpages = {8}
}

@inproceedings{10.1145/511706.511708,
author = {Dominick, W. D. and Penniman, W. D.},
title = {Automated Monitoring to Support the Analysis and Evaluation of Information Systems},
year = {1979},
isbn = {9781450373456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511706.511708},
doi = {10.1145/511706.511708},
abstract = {This paper is based on, and extracted in part from, a much more expanded and detailed manuscript entitled "Monitoring and Evaluation of On-Line Information System Usage", accepted for publication in Information Processing and Management.},
booktitle = {Proceedings of the 2nd Annual International ACM SIGIR Conference on Information Storage and Retrieval: Information Implications into the Eighties},
pages = {2–9},
numpages = {8},
location = {Dallas, Texas},
series = {SIGIR '79}
}

@article{10.1145/965643.810252,
author = {McDonell, Ken J.},
title = {Trends in Non-Software Support for Input-Output Functions},
year = {1977},
issue_date = {May 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/965643.810252},
doi = {10.1145/965643.810252},
abstract = {Input-output subsystem architectures have evolved over the past 20-odd years to the point where two divergent approaches have found acceptance in current computer systems; the 'IBM channel' is the archetype of the lower level alternative, while the functionally more complex techniques involve a wide spectrum of distributed processor architectures supporting database and/or storage management functions independently with respect to the central processor. The paper traces the historical development of support (outside central processor based software) for input-output functions and concludes with a preliminary comparison of the relative merits of the software interfaces provided by the alternative input-output subsystem architectures.},
journal = {SIGIR Forum},
month = jan,
pages = {40–47},
numpages = {8}
}

@inproceedings{10.1145/800180.810252,
author = {McDonell, Ken J.},
title = {Trends in Non-Software Support for Input-Output Functions},
year = {1977},
isbn = {9781450374804},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800180.810252},
doi = {10.1145/800180.810252},
abstract = {Input-output subsystem architectures have evolved over the past 20-odd years to the point where two divergent approaches have found acceptance in current computer systems; the 'IBM channel' is the archetype of the lower level alternative, while the functionally more complex techniques involve a wide spectrum of distributed processor architectures supporting database and/or storage management functions independently with respect to the central processor. The paper traces the historical development of support (outside central processor based software) for input-output functions and concludes with a preliminary comparison of the relative merits of the software interfaces provided by the alternative input-output subsystem architectures.},
booktitle = {Proceedings of the 3rd Workshop on Computer Architecture : Non-Numeric Processing},
pages = {40–47},
numpages = {8},
series = {CAW '77}
}

@article{10.1145/945546.945549,
author = {Allan, James and Aslam, Jay and Belkin, Nicholas and Buckley, Chris and Callan, Jamie and Croft, Bruce and Dumais, Sue and Fuhr, Norbert and Harman, Donna and Harper, David J. and Hiemstra, Djoerd and Hofmann, Thomas and Hovy, Eduard and Kraaij, Wessel and Lafferty, John and Lavrenko, Victor and Lewis, David and Liddy, Liz and Manmatha, R. and McCallum, Andrew and Ponte, Jay and Prager, John and Radev, Dragomir and Resnik, Philip and Robertson, Stephen and Rosenfeld, Roni and Roukos, Salim and Sanderson, Mark and Schwartz, Rich and Singhal, Amit and Smeaton, Alan and Turtle, Howard and Voorhees, Ellen and Weischedel, Ralph and Xu, Jinxi and Zhai, ChengXiang},
title = {Challenges in Information Retrieval and Language Modeling: Report of a Workshop Held at the Center for Intelligent Information Retrieval, University of Massachusetts Amherst, September 2002},
year = {2003},
issue_date = {Spring 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/945546.945549},
doi = {10.1145/945546.945549},
journal = {SIGIR Forum},
month = apr,
pages = {31–47},
numpages = {17}
}

@article{10.1145/281250.281256,
author = {Zobel, Justin and Moffat, Alistair},
title = {Exploring the Similarity Space},
year = {1998},
issue_date = {Spring 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/281250.281256},
doi = {10.1145/281250.281256},
abstract = {Ranked queries are used to locate relevant documents in text databases. In a ranked query a list of terms is specified, then the documents that most closely match the query are returned---in decreasing order of similarity---as answers. Crucial to the efficacy of ranked querying is the use of a similarity heuristic, a mechanism that assigns a numeric score indicating how closely a document and the query match. In this note we explore and categorise a range of similarity heuristics described in the literature. We have implemented all of these measures in a structured way, and have carried out retrieval experiments with a substantial subset of these measures.Our purpose with this work is threefold: first, in enumerating the various measures in an orthogonal framework we make it straightforward for other researchers to describe and discuss similarity measures; second, by experimenting with a wide range of the measures, we hope to observe which features yield good retrieval behaviour in a variety of retrieval environments; and third, by describing our results so far, to gather feedback on the issues we have uncovered. We demonstrate that it is surprisingly difficult to identify which techniques work best, and comment on the experimental methodology required to support any claims as to the superiority of one method over another.},
journal = {SIGIR Forum},
month = apr,
pages = {18–34},
numpages = {17}
}

@article{10.1145/270886.270887,
author = {Willett, Peter},
title = {Lab Report Special Section: Information Retrieval Research in the University of Sheffield},
year = {1997},
issue_date = {Fall 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/270886.270887},
doi = {10.1145/270886.270887},
journal = {SIGIR Forum},
month = dec,
pages = {7–13},
numpages = {7}
}

@article{10.1145/181886.181888,
author = {Park, Ki-hong and Aoe, Jun-ichi and Shishibori, Masami and Arita, Hisatoshi},
title = {An Automatic Selection Method of Key Search Algorithms Based on Expert Knowledge Bases},
year = {1994},
issue_date = {Spring 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/181886.181888},
doi = {10.1145/181886.181888},
abstract = {This paper proposes an automatic selection method for key search algorithms. The methodology has been implemented in a system called KEALASE (KEy-search Algorithm SElection). Key search algorithms are selected according to the user's requirements through interaction with KEALSE which bases its inferences on an evaluation table. The evaluation table contains values rating the performance of each key search algorithm for the different searching properties. The proposed selection algorithm is based on a step by step reduction of key search algorithms and searching properties. The paper also proposes assistance facilities that consist of both a support function and a program synthesis function. Experimental results show that the appropriate key search algorithms are effectively selected, and that the necessary number of questions asked, to select the appropriate algorithm, is reduced to less than half of the total number of possible questions. The support function is useful for the user during the selection process, and the program synthesis function fully translates a selected key search algorithm into high level language in an average of less than 1 hour.},
journal = {SIGIR Forum},
month = mar,
pages = {13–26},
numpages = {14}
}

@article{10.1145/146565.146570,
author = {Liddy, Elizabeth D. and Myaeng, Sung H.},
title = {DR-LINK: Document Retrieval Using Linguistic Knowledge Project Description},
year = {1992},
issue_date = {Fall 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/146565.146570},
doi = {10.1145/146565.146570},
abstract = {DR-LINK is a multi-stage document detection system (see Figure 1) being developed under the auspices of DARPA's TIPSTER Project. DR-LINK's overall goal is to simultaneously focus the flow of texts through the system by selecting a sub-set of texts on the basis of subject content and then high-lighting those sub-parts of a document which are likely spots of relevant text while enriching the semantic representation of text content by: 1) delineating each text's discourse-level structure; 2) detecting relations among concepts; 3) expanding lexical representation with semantically-related terms, and; 4) representing concepts and relations in Conceptual Graphs.},
journal = {SIGIR Forum},
month = oct,
pages = {39–43},
numpages = {5}
}

@article{10.1145/15497.15499,
author = {Kraft, Donald H},
title = {Research into Fuzzy Extensions of Information Retrieval},
year = {1986},
issue_date = {Spring-Summer 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/15497.15499},
doi = {10.1145/15497.15499},
abstract = {Modern computerized information retrieval systems consist of mechanisms to acquire, describe (e.g., index), and store "documents", and to receive, analyze, and respond to queries for information for users. A key element is the index language, by which the users (or user intermediaries) and indexers can communicate. Modern technology allows natural language processing mechanisms to begin to be incorporated in the sense of matching terms found in the free text specification of the query and the free text within the document.},
journal = {SIGIR Forum},
month = may,
pages = {12–13},
numpages = {2}
}

@article{10.1145/15497.1096832,
author = {Frakes, William B.},
title = {Book Review: Information and Misinformation: An Investigation of the Notions of Information, Misinformation, Informing, and Misinforming by Christopher Fox (Greenwood Press, 1983)},
year = {1986},
issue_date = {Spring-Summer 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/15497.1096832},
doi = {10.1145/15497.1096832},
abstract = {Information and Misinformation: An Investigation of the Notions of Information, Misinformation, Informing, and Misinforming. Fox, Christopher John. Westport Conn.: Greenwood Press; 1983: 223 pp.},
journal = {SIGIR Forum},
month = may,
pages = {22},
numpages = {1}
}

@article{10.1145/16287.1096838,
author = {Salton, Gerard and Raghavan, V.},
title = {ABSTRACTS (Chosen by G. Salton or V. Raghavan from 1983 Issues of Journals in the Retrieval Area)},
year = {1986},
issue_date = {Winter 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/16287.1096838},
doi = {10.1145/16287.1096838},
abstract = {This article outlines basic videodisc and optical disk technology. Both optical and capacitance videodisc technology are described. Optical disk technology as a mass digital image and data storage device is defined and briefly compared with other established information storage media including magnetic tape and microforms. The article includes a look into the future of videodisc and optical disk.},
journal = {SIGIR Forum},
month = jan,
pages = {36–48},
numpages = {13}
}

@article{10.1145/1095464.1095467,
author = {Salton, G.},
title = {Abstracts: Chosen by G. Salton from Current Issues of Journals in the Retrieval Area},
year = {1983},
issue_date = {Winter-Spring 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095464.1095467},
doi = {10.1145/1095464.1095467},
journal = {SIGIR Forum},
month = jan,
pages = {30–36},
numpages = {7}
}

@article{10.1145/1095479.1095481,
author = {Salton, Gerard},
title = {Abstracts of Selected Journal Articles},
year = {1982},
issue_date = {Fall 1982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095479.1095481},
doi = {10.1145/1095479.1095481},
journal = {SIGIR Forum},
month = sep,
pages = {25–31},
numpages = {7}
}

@article{10.1145/1095450.1095452,
author = {Salton, G.},
title = {Abstracts: Chosen by G. Salton from Current Issues of Journals in the Retrieval Area},
year = {1982},
issue_date = {Spring 1982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095450.1095452},
doi = {10.1145/1095450.1095452},
journal = {SIGIR Forum},
month = apr,
pages = {10–16},
numpages = {7}
}

@article{10.1145/1095450.1095451,
author = {Croft, W. Bruce},
title = {Experiments with Automatic Text Filing and Retrieval in the Office Environment},
year = {1982},
issue_date = {Spring 1982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095450.1095451},
doi = {10.1145/1095450.1095451},
abstract = {A series of experiments using statistical techniques for the filing and retrieval of business text are described. The text documents used in the experiments are a combination of memos, letters, reports and informal messages. The results show that these techniques are effective in the office environment and, using this as a basis, recommendations are made for the design of the text filing and retrieval component of an office information system.},
journal = {SIGIR Forum},
month = apr,
pages = {2–9},
numpages = {8}
}

@article{10.1145/1095425.1095427,
author = {Salton, G.},
title = {A Blueprint for Automatic Indexing},
year = {1981},
issue_date = {Fall 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095425.1095427},
doi = {10.1145/1095425.1095427},
abstract = {This note summarizes some of the currently available insights in automatic indexing. The emphasis is on aspects that are expected to be useful in a practical automatic indexing applications. The discussion is necessarily cursory, but the references will lead interested readers to a deeper treatment of the indexing problem.},
journal = {SIGIR Forum},
month = sep,
pages = {22–38},
numpages = {17}
}

@article{10.1145/1095403.1095405,
author = {Salton, G.},
title = {Abstracts: Chosen by G. Salton from Current Issues of Journals in the Retrieval Area},
year = {1980},
issue_date = {Winter 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095403.1095405},
doi = {10.1145/1095403.1095405},
journal = {SIGIR Forum},
month = dec,
pages = {47–54},
numpages = {8}
}

@article{10.1145/983026.983018,
author = {Banerjee, Jayanta and Hsiao, David K.},
title = {The Use of a Database Machine for Supporting Relational Databases},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983018},
doi = {10.1145/983026.983018},
abstract = {One of the goals in the design of database machines of the future is their generality. In addition to being capable of carrying out the common database management functions with high reliability and performance, some of these machines are intended to support more than one data model. A specific database machine, known as the DBC, is intended to support several existing data models. Although the DBC supports many data models, we single out the relational data model for this discussion. In particular, we have tried to concentrate mainly on the subject of database representation and query translation of System R-like database management systems. Some estimates of the storage requirements and performance gains are given in this paper. However, due to limited space, the detailed analysis is shown elsewhere in [22].},
journal = {SIGIR Forum},
month = aug,
pages = {91–98},
numpages = {8}
}

@article{10.1145/1095317.1095322,
author = {Hardine, D. A.},
title = {Review of "The ANSI/SPARC DBMS Model Proceedings of the 2nd SHARE Working Conference on Data Base Management Systems Edited by D. A. Hardine", Montreal, Canada, 1976},
year = {1977},
issue_date = {Winter 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095317.1095322},
doi = {10.1145/1095317.1095322},
journal = {SIGIR Forum},
month = dec,
pages = {2–3},
numpages = {2}
}

@article{10.1145/1095317.1095318,
author = {Berra, P. Bruce},
title = {Data Base Machines},
year = {1977},
issue_date = {Winter 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095317.1095318},
doi = {10.1145/1095317.1095318},
abstract = {In the past few years there has been increased emphasis in the use of new and different hardware in the data base management field. This has given rise to an interesting area of research called data base machines. The objectives are to implement many of the traditional software data base management functions in hardware in order to increase performance and capability.The reasons for increased research activity in data base machines are many fold. The modern digital computer with all its power still executes only a single instruction at a time al beit with a few exceptions. Since the digital computer was primarily designed for numeric applications, the ratio of useful instructions to overhead instructions tends to be very low in non-numeric applications such as data base management. There is an increasing body of knowledge that indicates that parallelism and addressing by content can be used to advantage in such data base management functions as retrieval and update. The above reasons coupled with the fact that software and personnel costs continued to rise while hardware costs continue to decrease makes it imperative that researchers find new solutions to the data base management problem that take maximum advantage of hardware architecture and technology.In this paper a brief review of current efforts in data base machines is presented. A review of the more important functions performed in data base management is given first. This is followed by a brief discussion of mini computer implementations. Then a review of some of the current efforts in data base machines is given. Finally, a few thoughts are presented on future trends.},
journal = {SIGIR Forum},
month = dec,
pages = {4–23},
numpages = {20}
}

@article{10.1145/1095312.1095313,
author = {McGill, Michael J.},
title = {Abstracts},
year = {1977},
issue_date = {Spring 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095312.1095313},
doi = {10.1145/1095312.1095313},
journal = {SIGIR Forum},
month = apr,
pages = {20–22},
numpages = {3}
}

@article{10.1145/1095307.1095309,
author = {Smith, Linda C.},
title = {Review of "Information Retrieval and Processing by Lauren B. Doyle"; Los Angeles, Melville Publishing Company, 1975},
year = {1976},
issue_date = {Fall 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095307.1095309},
doi = {10.1145/1095307.1095309},
journal = {SIGIR Forum},
month = sep,
pages = {7–9},
numpages = {3}
}

@article{10.1145/1095286.1095298,
author = {Ackerman, S. J. and Eman, A. and Lipovski, G. J. and Su, S. W.},
title = {Implementation of a Context-Addressed Pipeline<sup>3</sup> SIMD Architecture},
year = {1976},
issue_date = {Spring 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095286.1095298},
doi = {10.1145/1095286.1095298},
abstract = {The context-addressed SIMD architecture is being examined as a means to provide suitable processing capabilities for non-numeric applications. This paper considers techniques which are being applied to realize this architecture in a segment sequential fashion.A fixed head disc provides a large amount of sequential storage already segmented into tracks. Economical bit-serial microprocessors are employed one per track to process the instructions and data sequentially as the disc rotates. A microprocessor and its track are here called a cell. A chain of cells can search a file consisting of fixed length words organized into variable length records in one revolution or cycle of the disc. Intercell communication in the chain as a pipeline allows files and records which overlap segment boundaries to be processed as an intact file or record, with all segments processed in parallel. Transfers of words and bits in pipeline fashion between cells allows the file to change size dynamically without regard for its cellular segmentation, as words may be either inserted or deleted within a record.Instruction execution in this architecture is also pipelined. The next instruction is preprocessed in one cycle along with its operand while the current instruction is executing, and the previous one is finishing up its operation or post-processing. This instruction pipelining is performed in order to minimize the execution time for a sequential instruction by overlapping the instruction fetch and execute of two consecutive cycles. The segment sequential organization also demands that the instruction execution continue into the next cycle in order to process the elements of a record that may overlap segments. Again by overlapping this instruction clean-up with the next instruction's execution, we may minimize the instruction execution time.A hardware realization of this pipeline of cells which pipelines its instruction execution becomes another pipeline. Each bit serial microprocessor is in fact a pipeline of modules each performing some phase of instruction execution or segment support such as garbage word deletion or new data insertion. The segment sequential architecture lends itself very nicely to this pipeline3 approach.Although they provide a powerful architecture, these three pipeline constructs also develope new problems in their control and timing. Such problems include that the words which are pipelined between cells are not processed twice, missed entirely, or only partially processed by the instruction pipeline. A solution to these and to other problems related to this architecture are presented in this paper.},
journal = {SIGIR Forum},
month = apr,
pages = {27–28},
numpages = {2}
}

@article{10.1145/75335.75357,
author = {Campagnoni, F. R. and Erlich, K.},
title = {Information Retrieval Using a Hypertext-Based Help System},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75357},
doi = {10.1145/75335.75357},
abstract = {Hypertext offers users a simple, flexible way to navigate through electronic information systems but at the potential risk of becoming lost in the network of interconnected pieces of information. A study was conducted on information retrieval using a commercial hypertext based help system. It was found that the predominant search strategy was “browsing” (characterized by scanning tables of contents and paging through topics), rather than employing the indexes (“analytical search”). Although subjects did not become lost, individuals with better spatial visualization ability, as measured by a standardized test, were faster at retrieving information and returned to the top of the information hierarchy less often than those with poorer spatial visualization ability. These results support previous studies that have found a strong preference by users to browse in hypertext systems and extend those findings to a new domain (help), a different type of user interface, and a different information architecture. In addition, the results demonstrate the importance of spatial visualization ability for efficient navigation and information retrieval in a hierarchical hypertext system.},
journal = {SIGIR Forum},
month = may,
pages = {212–220},
numpages = {9}
}

@inproceedings{10.1145/75334.75357,
author = {Campagnoni, F. R. and Erlich, K.},
title = {Information Retrieval Using a Hypertext-Based Help System},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75357},
doi = {10.1145/75334.75357},
abstract = {Hypertext offers users a simple, flexible way to navigate through electronic information systems but at the potential risk of becoming lost in the network of interconnected pieces of information. A study was conducted on information retrieval using a commercial hypertext based help system. It was found that the predominant search strategy was “browsing” (characterized by scanning tables of contents and paging through topics), rather than employing the indexes (“analytical search”). Although subjects did not become lost, individuals with better spatial visualization ability, as measured by a standardized test, were faster at retrieving information and returned to the top of the information hierarchy less often than those with poorer spatial visualization ability. These results support previous studies that have found a strong preference by users to browse in hypertext systems and extend those findings to a new domain (help), a different type of user interface, and a different information architecture. In addition, the results demonstrate the importance of spatial visualization ability for efficient navigation and information retrieval in a hierarchical hypertext system.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {212–220},
numpages = {9},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/75335.75355,
author = {Maarek, Y. S. and Smadja, F. Z.},
title = {Full Text Indexing Based on Lexical Relations an Application: Software Libraries},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75355},
doi = {10.1145/75335.75355},
abstract = {In contrast to other kinds of libraries, software libraries need to be conceptually organized. When looking for a component, the main concern of users is the functionality of the desired component; implementation details are secondary. Software reuse would be enhanced with conceptually organized large libraries of software components. In this paper, we present GURU, a tool that allows automatical building of such large software libraries from documented software components. We focus here on GURU's indexing component which extracts conceptual attributes from natural language documentation. This indexing method is based on words' co-occurrences. It first uses EXTRACT, a co-occurrence knowledge compiler for extracting potential attributes from textual documents. Conceptually relevant collocations are then selected according to their resolving power, which scales down the noise due to context words. This fully automated indexing tool thus goes further than keyword-based tools in the understanding of a document without the brittleness of knowledge based tools. The indexing component of GURU is fully implemented, and some results are given in the paper.},
journal = {SIGIR Forum},
month = may,
pages = {198–206},
numpages = {9}
}

@inproceedings{10.1145/75334.75355,
author = {Maarek, Y. S. and Smadja, F. Z.},
title = {Full Text Indexing Based on Lexical Relations an Application: Software Libraries},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75355},
doi = {10.1145/75334.75355},
abstract = {In contrast to other kinds of libraries, software libraries need to be conceptually organized. When looking for a component, the main concern of users is the functionality of the desired component; implementation details are secondary. Software reuse would be enhanced with conceptually organized large libraries of software components. In this paper, we present GURU, a tool that allows automatical building of such large software libraries from documented software components. We focus here on GURU's indexing component which extracts conceptual attributes from natural language documentation. This indexing method is based on words' co-occurrences. It first uses EXTRACT, a co-occurrence knowledge compiler for extracting potential attributes from textual documents. Conceptually relevant collocations are then selected according to their resolving power, which scales down the noise due to context words. This fully automated indexing tool thus goes further than keyword-based tools in the understanding of a document without the brittleness of knowledge based tools. The indexing component of GURU is fully implemented, and some results are given in the paper.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {198–206},
numpages = {9},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/75335.75350,
author = {Christodoulakis, S. and Ford, D. A.},
title = {File Organizations and Access Methods for CLV Disks},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75350},
doi = {10.1145/75335.75350},
abstract = {A large and important class of optical disc technology are CLV format discs such as CD ROM and WORM. In this paper, we examine the issues related to the implementation and performance of several different file organizations on CLV format optical discs such as CD ROM and WORM. The organizations examined are based on hashing and trees.The CLV recording scheme is shown to be a good environment for efficiently implementing hashing. Single seek access and storage utilization levels approaching 100% can be achieved for CD ROM's. It is shown that a B-tree organization is not a good choice for WORM discs (both CAV and CLV), but a modified ISAM approach can be appropriate for WORM discs. We describe clustered BIM's, a class of tree organizations appropriate for CD ROMS. Expressions for the expected retrieval performance of both hashing and trees are also given.The paper concludes by outlining recent results and future directions on buffered implementations of access methods for WORM discs, as well as advantages of signature based access methods for text retrieval in WORM disc architectures.},
journal = {SIGIR Forum},
month = may,
pages = {152–159},
numpages = {8}
}

@inproceedings{10.1145/75334.75350,
author = {Christodoulakis, S. and Ford, D. A.},
title = {File Organizations and Access Methods for CLV Disks},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75350},
doi = {10.1145/75334.75350},
abstract = {A large and important class of optical disc technology are CLV format discs such as CD ROM and WORM. In this paper, we examine the issues related to the implementation and performance of several different file organizations on CLV format optical discs such as CD ROM and WORM. The organizations examined are based on hashing and trees.The CLV recording scheme is shown to be a good environment for efficiently implementing hashing. Single seek access and storage utilization levels approaching 100% can be achieved for CD ROM's. It is shown that a B-tree organization is not a good choice for WORM discs (both CAV and CLV), but a modified ISAM approach can be appropriate for WORM discs. We describe clustered BIM's, a class of tree organizations appropriate for CD ROMS. Expressions for the expected retrieval performance of both hashing and trees are also given.The paper concludes by outlining recent results and future directions on buffered implementations of access methods for WORM discs, as well as advantages of signature based access methods for text retrieval in WORM disc architectures.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {152–159},
numpages = {8},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/75335.75348,
author = {Metzler, D. P. and Haas, S. W.},
title = {The Constituent Object Parser: Syntactic Structure Matching for Information Retrieval},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75348},
doi = {10.1145/75335.75348},
journal = {SIGIR Forum},
month = may,
pages = {117–126},
numpages = {10}
}

@inproceedings{10.1145/75334.75348,
author = {Metzler, D. P. and Haas, S. W.},
title = {The Constituent Object Parser: Syntactic Structure Matching for Information Retrieval},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75348},
doi = {10.1145/75334.75348},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {117–126},
numpages = {10},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/75335.75343,
author = {Fuhr, N.},
title = {Optimum Polynomial Retrieval Functions},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75343},
doi = {10.1145/75335.75343},
abstract = {We show that any approach to develop optimum retrieval functions is based on two kinds of assumptions: first, a certain form of representation for documents and requests, and second, additional simplifying assumptions that predefine the type of the retrieval function. Then we describe an approach for the development of optimum polynomial retrieval functions: request-document pairs (undefinedl, dm) are mapped onto description vectors @@@@(undefinedl, dm), and a polynomial function of the form @@@@T · @@@@(@@@@) is developed such that it yields estimates of the probability of relevance P(R|@@@@(undefinedl, dm)) with minimum square errors. We give experimental results for the application of this approach to documents with weighted indexing as well as to documents with complex representations. In contrast to other probabilistic models, our approach yields estimates of the actual probabilities, it can handle very complex representations of documents and requests, and it can be easily applied to multi-valued relevance scales. On the other hand, this approach is not suited to log-linear probabilistic models, and it needs large samples of relevance feedback data for its application.},
journal = {SIGIR Forum},
month = may,
pages = {69–76},
numpages = {8}
}

@inproceedings{10.1145/75334.75343,
author = {Fuhr, N.},
title = {Optimum Polynomial Retrieval Functions},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75343},
doi = {10.1145/75334.75343},
abstract = {We show that any approach to develop optimum retrieval functions is based on two kinds of assumptions: first, a certain form of representation for documents and requests, and second, additional simplifying assumptions that predefine the type of the retrieval function. Then we describe an approach for the development of optimum polynomial retrieval functions: request-document pairs (undefinedl, dm) are mapped onto description vectors @@@@(undefinedl, dm), and a polynomial function of the form @@@@T · @@@@(@@@@) is developed such that it yields estimates of the probability of relevance P(R|@@@@(undefinedl, dm)) with minimum square errors. We give experimental results for the application of this approach to documents with weighted indexing as well as to documents with complex representations. In contrast to other probabilistic models, our approach yields estimates of the actual probabilities, it can handle very complex representations of documents and requests, and it can be easily applied to multi-valued relevance scales. On the other hand, this approach is not suited to log-linear probabilistic models, and it needs large samples of relevance feedback data for its application.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {69–76},
numpages = {8},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/75335.75341,
author = {McAlpine, G. and Ingwersen, P.},
title = {Integrated Information Retrieval in a Knowledge Worker Support System},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75341},
doi = {10.1145/75335.75341},
abstract = {This paper describes the design of the information retrieval facilities of an integrated information system called EUROMATH. EUROMATH is an example of a Knowledge Worker Support System: it has been designed specifically to support mathematicians in their research work. EUROMATH is required to provide uniform retrieval facilities for searching in a user's personal data, in a shared database of structured documents and in public, bibliographic databases. The design of information retrieval facilities that satisfy these and other requirements posed several interesting design issues regarding the integration of various retrieval techniques. As well as a uniform query language, designed to be highly usable by the target user group, the retrieval facilities provide expert intermediary functions, i.e. sophisticated support for the retrieval of bibliographic data. This support is achieved using a model of the user, a model of the user's information need and a set of search strategies based on those used by human intermediaries. The expert intermediary facilities include extensive help facilities, automatic query reformulation and browsing of a variety of sources of query terms.},
journal = {SIGIR Forum},
month = may,
pages = {48–57},
numpages = {10}
}

@inproceedings{10.1145/75334.75341,
author = {McAlpine, G. and Ingwersen, P.},
title = {Integrated Information Retrieval in a Knowledge Worker Support System},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75341},
doi = {10.1145/75334.75341},
abstract = {This paper describes the design of the information retrieval facilities of an integrated information system called EUROMATH. EUROMATH is an example of a Knowledge Worker Support System: it has been designed specifically to support mathematicians in their research work. EUROMATH is required to provide uniform retrieval facilities for searching in a user's personal data, in a shared database of structured documents and in public, bibliographic databases. The design of information retrieval facilities that satisfy these and other requirements posed several interesting design issues regarding the integration of various retrieval techniques. As well as a uniform query language, designed to be highly usable by the target user group, the retrieval facilities provide expert intermediary functions, i.e. sophisticated support for the retrieval of bibliographic data. This support is achieved using a model of the user, a model of the user's information need and a set of search strategies based on those used by human intermediaries. The expert intermediary facilities include extensive help facilities, automatic query reformulation and browsing of a variety of sources of query terms.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {48–57},
numpages = {10},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/1013230.511824,
author = {Fraenkel, Aviezri S. and Mor, Moshe},
title = {Combinatorial Compression and Partitioning of Large Dictionaries: Theory and Experiments},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511824},
doi = {10.1145/1013230.511824},
abstract = {A method for compressing large dictionaries is proposed, based on transforming words into lexicographically ordered strings of distinct letters, together with permutation indexes. Algorithms to generate such strings are described. Results of applying the method to the dictionaries of two databases, in Hebrew and English, are presented in detail. The main message is a method of partitioning the dictionary such that the "information bearing fraction" is stored in fast memory, and the bulk in auxiliary memory.},
journal = {SIGIR Forum},
month = jun,
pages = {205–219},
numpages = {15}
}

@inproceedings{10.1145/511793.511824,
author = {Fraenkel, Aviezri S. and Mor, Moshe},
title = {Combinatorial Compression and Partitioning of Large Dictionaries: Theory and Experiments},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511824},
doi = {10.1145/511793.511824},
abstract = {A method for compressing large dictionaries is proposed, based on transforming words into lexicographically ordered strings of distinct letters, together with permutation indexes. Algorithms to generate such strings are described. Results of applying the method to the dictionaries of two databases, in Hebrew and English, are presented in detail. The main message is a method of partitioning the dictionary such that the "information bearing fraction" is stored in fast memory, and the bulk in auxiliary memory.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {205–219},
numpages = {15},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013228.511771,
author = {Nikkuni, Michiyo and Tanaka, Hajime},
title = {Document Contents Representation Model of Sentence Retrieval System SCAT-IR},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511771},
doi = {10.1145/1013228.511771},
abstract = {A "Document Contents Representation" (DCR) model is introduced from a formal viewpoint to deal with the entire contents of a document such as individual sentences of a text, bibliography, references, etc. in a scientific information system. A "Mapping Definition Language" (MDL) is proposed to map directly and naturally the document contents into the DCR model. An application of the DCR model and MDL to scientific documents is shown. Some examples of advanced retrieval by SCAT-IR system implemented on the basis of the DCR model and MDL are illustrated.},
journal = {SIGIR Forum},
month = may,
pages = {106–112},
numpages = {7}
}

@inproceedings{10.1145/511754.511771,
author = {Nikkuni, Michiyo and Tanaka, Hajime},
title = {Document Contents Representation Model of Sentence Retrieval System SCAT-IR},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511771},
doi = {10.1145/511754.511771},
abstract = {A "Document Contents Representation" (DCR) model is introduced from a formal viewpoint to deal with the entire contents of a document such as individual sentences of a text, bibliography, references, etc. in a scientific information system. A "Mapping Definition Language" (MDL) is proposed to map directly and naturally the document contents into the DCR model. An application of the DCR model and MDL to scientific documents is shown. Some examples of advanced retrieval by SCAT-IR system implemented on the basis of the DCR model and MDL are illustrated.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {106–112},
numpages = {7},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013228.511764,
author = {Tague, Jean M. and Nelson, Michael J.},
title = {Simulation of User Judgments in Bibliographic Retrieval Systems},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511764},
doi = {10.1145/1013228.511764},
abstract = {The general model and simulation algorithms for bibliographic retrieval systems presented in an earlier paper are expanded. The new model integrates the physical as well as the logical and semantic elements of these systems. A modified algorithm is developed for the simulation of user relevance judgments, and is validated, by means of recall-precision curves and a Kolmogorov-Smirnov test of recall, for two test collections. Other approaches to goodness-of-fit testing are suggested.},
journal = {SIGIR Forum},
month = may,
pages = {66–71},
numpages = {6}
}

@inproceedings{10.1145/511754.511764,
author = {Tague, Jean M. and Nelson, Michael J.},
title = {Simulation of User Judgments in Bibliographic Retrieval Systems},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511764},
doi = {10.1145/511754.511764},
abstract = {The general model and simulation algorithms for bibliographic retrieval systems presented in an earlier paper are expanded. The new model integrates the physical as well as the logical and semantic elements of these systems. A modified algorithm is developed for the simulation of user relevance judgments, and is validated, by means of recall-precision curves and a Kolmogorov-Smirnov test of recall, for two test collections. Other approaches to goodness-of-fit testing are suggested.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {66–71},
numpages = {6},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013228.511763,
author = {Stirling, Keith H.},
title = {On the Limitations of Document Ranking Algorithms in Information Retrieval},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511763},
doi = {10.1145/1013228.511763},
abstract = {A document retrieval system should rank documents in order of their usefulness or satisfaction to the users. This principle was first explicated in the classic paper by Maron and Kuhns (1). Additional considerations concerning document ranking have been suggested by other researchers (2,3). Particular attention will be given here to the ranking algorithm appropriate for those presenting the same request, but having different information needs. The research on which this report is based identifies limitations associated with sequencing rules that use a probability ranking technique (4). Three basic and somewhat interdependent limitations will be discussed.},
journal = {SIGIR Forum},
month = may,
pages = {63–65},
numpages = {3}
}

@inproceedings{10.1145/511754.511763,
author = {Stirling, Keith H.},
title = {On the Limitations of Document Ranking Algorithms in Information Retrieval},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511763},
doi = {10.1145/511754.511763},
abstract = {A document retrieval system should rank documents in order of their usefulness or satisfaction to the users. This principle was first explicated in the classic paper by Maron and Kuhns (1). Additional considerations concerning document ranking have been suggested by other researchers (2,3). Particular attention will be given here to the ranking algorithm appropriate for those presenting the same request, but having different information needs. The research on which this report is based identifies limitations associated with sequencing rules that use a probability ranking technique (4). Three basic and somewhat interdependent limitations will be discussed.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {63–65},
numpages = {3},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013881.802691,
author = {Haskin, Roger},
title = {Hardware for Searching Very Large Text Databases},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802691},
doi = {10.1145/1013881.802691},
abstract = {This paper discusses the problem of searching very large text databases. It is shown that conventional techniques for searching current databases cannot be scaled up to larger ones, and that it is necessary to build hardware to search the database in parallel if reasonable search times are expected. The part of the search process requiring the highest bandwidth is scanning the database to detect instances of search terms. Methods of doing this in hardware that have been mentioned in the literature are examined, and design criteria for term matchers are discussed. A new design that uses a nondeterministic finite state automaton to control matching, is introduced, its operation is explained, and the practicality of using it in a real system is discussed.},
journal = {SIGIR Forum},
month = mar,
pages = {49–56},
numpages = {8}
}

@inproceedings{10.1145/800083.802691,
author = {Haskin, Roger},
title = {Hardware for Searching Very Large Text Databases},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802691},
doi = {10.1145/800083.802691},
abstract = {This paper discusses the problem of searching very large text databases. It is shown that conventional techniques for searching current databases cannot be scaled up to larger ones, and that it is necessary to build hardware to search the database in parallel if reasonable search times are expected. The part of the search process requiring the highest bandwidth is scanning the database to detect instances of search terms. Methods of doing this in hardware that have been mentioned in the literature are examined, and design criteria for term matchers are discussed. A new design that uses a nondeterministic finite state automaton to control matching, is introduced, its operation is explained, and the practicality of using it in a real system is discussed.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {49–56},
numpages = {8},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013232.511715,
author = {Landau, Robert M.},
title = {Productivity, Information Technology and the Office},
year = {1979},
issue_date = {September 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013232.511715},
doi = {10.1145/1013232.511715},
abstract = {It is well known that American productivity has advanced very little in the last ten years in contrast to many other countries' rapidly rising productivity. It is becoming evident that major productivity gains can be made, particularly in the office workforce, which constitutes the majority of the American workforce today. Rapidly developing information technologies are making it possible to achieve radically increased productivity in the office. This paper will discuss the specific technologies; the specific major office functions; how they interrelate; and how they are making such radical productivity increases possible. "The Paperless Office", created by Micronet, Inc. in Washington, D.C., will be described. The current project to automate the office activities of the American Productivity Center in Houston, Texas, will be described. Some projections of the significance of these projects will be given.},
journal = {SIGIR Forum},
month = sep,
pages = {59–63},
numpages = {5}
}

@inproceedings{10.1145/511706.511715,
author = {Landau, Robert M.},
title = {Productivity, Information Technology and the Office},
year = {1979},
isbn = {9781450373456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511706.511715},
doi = {10.1145/511706.511715},
abstract = {It is well known that American productivity has advanced very little in the last ten years in contrast to many other countries' rapidly rising productivity. It is becoming evident that major productivity gains can be made, particularly in the office workforce, which constitutes the majority of the American workforce today. Rapidly developing information technologies are making it possible to achieve radically increased productivity in the office. This paper will discuss the specific technologies; the specific major office functions; how they interrelate; and how they are making such radical productivity increases possible. "The Paperless Office", created by Micronet, Inc. in Washington, D.C., will be described. The current project to automate the office activities of the American Productivity Center in Houston, Texas, will be described. Some projections of the significance of these projects will be given.},
booktitle = {Proceedings of the 2nd Annual International ACM SIGIR Conference on Information Storage and Retrieval: Information Implications into the Eighties},
pages = {59–63},
numpages = {5},
location = {Dallas, Texas},
series = {SIGIR '79}
}

@article{10.1145/1013232.511710,
author = {Dattola, Robert T.},
title = {Use of Dynamic Discrimination Values in a Document Retrieval System},
year = {1979},
issue_date = {September 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013232.511710},
doi = {10.1145/1013232.511710},
abstract = {The use of discrimination values as a term weighting function in document retrieval systems is examined. It is shown that regular discrimination values are too costly to compute after every update to the data base. Dynamic discrimination values that are easy to update are defined for use as approximations to regular values. Experiments are performed comparing regular vs. dynamic discrimination values. Actual user queries from an operational data base are used to evaluate dynamic discrimination values in a production environment. Generalized forms of normalized recall and precision are used as evaluation measures. Retrieval results indicate statistically significant improvements using dynamic discrimination weighting.},
journal = {SIGIR Forum},
month = sep,
pages = {23–32},
numpages = {10}
}

@inproceedings{10.1145/511706.511710,
author = {Dattola, Robert T.},
title = {Use of Dynamic Discrimination Values in a Document Retrieval System},
year = {1979},
isbn = {9781450373456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511706.511710},
doi = {10.1145/511706.511710},
abstract = {The use of discrimination values as a term weighting function in document retrieval systems is examined. It is shown that regular discrimination values are too costly to compute after every update to the data base. Dynamic discrimination values that are easy to update are defined for use as approximations to regular values. Experiments are performed comparing regular vs. dynamic discrimination values. Actual user queries from an operational data base are used to evaluate dynamic discrimination values in a production environment. Generalized forms of normalized recall and precision are used as evaluation measures. Retrieval results indicate statistically significant improvements using dynamic discrimination weighting.},
booktitle = {Proceedings of the 2nd Annual International ACM SIGIR Conference on Information Storage and Retrieval: Information Implications into the Eighties},
pages = {23–32},
numpages = {10},
location = {Dallas, Texas},
series = {SIGIR '79}
}

@article{10.1145/1013234.803142,
title = {INQUIRE System Overview},
year = {1978},
issue_date = {May 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013234.803142},
doi = {10.1145/1013234.803142},
abstract = {INQUIRE is a versatile database management system with integrated information retrieval and full-text processing capabilities. Designed primarily for the end-user of information, INQUIRE features rapid start-up of applications and has a broad range of facilities for both technical and non-technical users.INQUIRE is operational on IBM System 360 or 370, Amdahl 470, or equivalent, under OS, VS, MVS, or CMS.},
journal = {SIGIR Forum},
month = may,
pages = {171–174},
numpages = {4}
}

@inproceedings{10.1145/800096.803142,
title = {INQUIRE System Overview},
year = {1978},
isbn = {9781450374026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800096.803142},
doi = {10.1145/800096.803142},
abstract = {INQUIRE is a versatile database management system with integrated information retrieval and full-text processing capabilities. Designed primarily for the end-user of information, INQUIRE features rapid start-up of applications and has a broad range of facilities for both technical and non-technical users.INQUIRE is operational on IBM System 360 or 370, Amdahl 470, or equivalent, under OS, VS, MVS, or CMS.},
booktitle = {Proceedings of the 1st Annual International ACM SIGIR Conference on Information Storage and Retrieval},
pages = {171–174},
numpages = {4},
series = {SIGIR '78}
}

@article{10.1145/965643.810255,
author = {Landson, Barry M. and Sargent, Robert G.},
title = {A Comparison of Sequential and Associate Computing of Priority Queues},
year = {1977},
issue_date = {May 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/965643.810255},
doi = {10.1145/965643.810255},
abstract = {A comparison of priority queues on four different types of computer memories are made by ring a model to determine the total time to do comparable tasks. The four types of memories compared are random access (RAM), associate (AM), hybrid consisting of an associate memory and a random access memory (AM/RAM), and the hybrid memory with an auxiliary memory having the @@@@pability to perform Lewin's Associate algorithm @@@@], (AM/RAM/AML).The model used for the comparisons is an extension of the MIX model developed by Knuth [1]. The MIX model was extended to include the four types of memories and the instruction set expanded include @@@@ instructions for the memories added. This @@del allows direct comparisons to be made of the different architectures and different software algorithms in performing the same tasks.},
journal = {SIGIR Forum},
month = jan,
pages = {77–78},
numpages = {2}
}

@inproceedings{10.1145/800180.810255,
author = {Landson, Barry M. and Sargent, Robert G.},
title = {A Comparison of Sequential and Associate Computing of Priority Queues},
year = {1977},
isbn = {9781450374804},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800180.810255},
doi = {10.1145/800180.810255},
abstract = {A comparison of priority queues on four different types of computer memories are made by ring a model to determine the total time to do comparable tasks. The four types of memories compared are random access (RAM), associate (AM), hybrid consisting of an associate memory and a random access memory (AM/RAM), and the hybrid memory with an auxiliary memory having the @@@@pability to perform Lewin's Associate algorithm @@@@], (AM/RAM/AML).The model used for the comparisons is an extension of the MIX model developed by Knuth [1]. The MIX model was extended to include the four types of memories and the instruction set expanded include @@@@ instructions for the memories added. This @@del allows direct comparisons to be made of the different architectures and different software algorithms in performing the same tasks.},
booktitle = {Proceedings of the 3rd Workshop on Computer Architecture : Non-Numeric Processing},
pages = {77–78},
numpages = {2},
series = {CAW '77}
}

@article{10.1145/1842890.1842906,
author = {Hauff, Claudia},
title = {Predicting the Effectiveness of Queries and Retrieval Systems},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1842890.1842906},
doi = {10.1145/1842890.1842906},
abstract = {We consider users' attempts to express their information needs through queries, or search requests and try to predict whether those requests will be of high or low quality. The second type of methods under investigation are those which attempt to estimate the quality of search systems themselves. Given a number of search systems to consider, these methods estimate how well or how poorly the systems will perform in comparison to each other.First, pre-retrieval predictors are investigated, which predict a query's effectiveness before the retrieval step and are thus independent of the ranked list of results. Such predictors base their predictions solely on query terms, collection statistics and possibly external sources. Twenty-two prediction algorithms are categorized and their quality is assessed on three different TREC test collections. A number of newly applied methods for combining various predictors are examined to obtain a better prediction of a query's effectiveness.Building on the analysis of pre-retrieval predictors, post-retrieval approaches are then investigated, which estimate a query's effectiveness on the basis of the retrieved results. The thesis focuses in particular on the Clarity Score approach and provides an analysis of its sensitivity towards different variables such as the collection, the query set and the retrieval approach. Adaptations to Clarity Score are introduced which improve the estimation accuracy of the original algorithm.The utility of query effectiveness prediction methods is commonly evaluated by reporting correlation coefficients, such as Kendall's Tau. Largely unexplored though is the question of the relationship between the current evaluation methodology for query effectiveness prediction and the change in effectiveness of retrieval systems that employ a predictor. We investigate this question by examining how the observed quality of predictors (with respect to Kendall's Tau) affects the retrieval effectiveness in two adaptive system settings: selective query expansion and meta-search.The last part of the thesis is concerned with the task of estimating the ranking of retrieval systems according to their retrieval effectiveness without relying on costly relevance judgments. Five different system ranking estimation approaches are evaluated on a wide range of data sets which cover a variety of retrieval tasks and test collections. It is shown that under certain conditions, automatic methods yield a highly accurate ranking of systems.Available online at http://www.cs.utwente.nl/~hauffc/phd/thesis.pdf.},
journal = {SIGIR Forum},
month = aug,
pages = {88},
numpages = {1}
}

@article{10.1145/1041394.1041398,
author = {Jones, Karen Sparck},
title = {What's New about the Semantic Web? Some Questions},
year = {2004},
issue_date = {December 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1041394.1041398},
doi = {10.1145/1041394.1041398},
abstract = {It is not completely clear what the Semantic Web (SW) is meant to be. Statements about it differ or, rather, the interpretations of statements about it differ. The grand view is that the SW is the core model of the way the world is, expressed in a manner that supports reasoning about this world. The modest view is that the SW is the minimal apparatus of shared generic terminology that can be used to send some carrier pigeon messages from one universe of discourse to another. The 'authorised' view presented in Berners-Lee, Hendler and Lassila (2001) might be regarded as intermediate. It treats the key notion of ontology as a structure of well-defined, i.e. unambiguous, concepts standing for objects, properties, relations etc, which has an accompanying logic allowing inference about the concepts. This is much like the terminological and assertional components familiar from AI knowledge representation. There is indeed no claim that everything that users may want to talk about (or all information) can be captured in this way, either descriptively or inferentially, But the belief is that, even with restricted conceptual coverage and limited inference, it will be possible to throw a large semantic net over the Web, that does far more to catch the information fish than purely syntactic hooks and with much less effort for the human fisherman. This large net can, conveniently, be made by combining many little nets with a few well-made loops. The whole rests upon a proper formal language syntactic apparatus (XML, RDF).},
journal = {SIGIR Forum},
month = dec,
pages = {18–23},
numpages = {6}
}

@article{10.1145/1041394.1041397,
author = {O'Hara, Kieron},
title = {Ontologies and Technologies: Knowledge Representation or Misrepresentation},
year = {2004},
issue_date = {December 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1041394.1041397},
doi = {10.1145/1041394.1041397},
abstract = {The development of the Semantic Web (SW) raises a number of difficult and interesting technical issues. Less often remarked, however, are the social and political debates that it will engender, if and when the technologies become widely accepted. As the SW is a technology for transferring information and knowledge efficiently and effectively, then many of these questions have an epistemological base. In this paper I want to focus especially on the epistemological underpinnings of these social issues, to think about the interaction between the epistemological and the political. How does technology affect the social networks in which it is embedded? How can technology be successfully transplanted into a new context? And, perhaps most importantly for us, how is technology affected by its context? In particular, I want to look at how our decisions about how we treat knowledge can impact quite dramatically on the technologies we produce.},
journal = {SIGIR Forum},
month = dec,
pages = {11–17},
numpages = {7}
}

@article{10.1145/344250.344251,
author = {Hersh, William and Over, Paul},
title = {TREC-8 Interactive Track},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/344250.344251},
doi = {10.1145/344250.344251},
journal = {SIGIR Forum},
month = dec,
pages = {8–11},
numpages = {4}
}

@article{10.1145/270886.606663,
author = {Groman, Robert C.},
title = {Book Review: Searching Multimedia Databases by Content, Christos Faloutsos, Kluwer Academic Publishers, 1996.},
year = {1997},
issue_date = {Fall 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/270886.606663},
doi = {10.1145/270886.606663},
journal = {SIGIR Forum},
month = dec,
pages = {34},
numpages = {1}
}

@article{10.1145/122665.1096777,
author = {Humphrey, Susanne M.},
title = {Selected IR-Related Dissertation Abstracts},
year = {1991},
issue_date = {Fall 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/122665.1096777},
doi = {10.1145/122665.1096777},
abstract = {The following are citations selected by title and abstract as being related to Information Retrieval (IR), resulting from a computer search, using BRS Information Technologies, of the Dissertation Abstracts Online database produced by University Microfilms International (UMI). Included are UMI order number, title, author, degree, year, institution; number of pages, one or more Dissertation Abstracts International (DAI) subject descriptors chosen by the author, and abstract. Unless otherwise specified, paper or microform copies of dissertations may be ordered from University Microfilms International, Dissertation Copies, Post Office Box 1764, Ann Arbor, MI 48106; telephone for U.S. (except Michigan, Hawaii, Alaska): 1-800-521-3042, for Canada: 1-800-268-6090. Price lists and other ordering and shipping information are in the introduction to the published DAI. An alternate source for copies is sometimes provided. Dissertation titles and abstracts contained here are published with permission of University Microfilms International, publishers of Dissertation Abstracts International (copyright by University Microfilms International), and may not be reproduced without their prior permission.},
journal = {SIGIR Forum},
month = sep,
pages = {106–136},
numpages = {31}
}

@article{10.1145/122642.122643,
author = {Aoki, Paul M.},
title = {Implementation of Extended Indexes in POSTGRES},
year = {1991},
issue_date = {Spring 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/122642.122643},
doi = {10.1145/122642.122643},
abstract = {The vaunted "Spartan simplicity" of the relational model can limit the usefulness of the relational database management system (RDBMS) for non-traditional applications. For example, there is no natural way to model a keyword index for bibliographic informational retrieval (IR), or any other index whose key values are computed from column values, in a standard RDBMS. The extended indexing proposed in [LYNC88a] is intended to support applications that require indexes on computed values. This paper reports on an implementation of this type of indexing using the POSTGRES extensible database management system [STON86a], focusing on two issues: general problems, and the features in POSTGRES that proved helpful in the solution of these problems.},
journal = {SIGIR Forum},
month = may,
pages = {2–9},
numpages = {8}
}

@article{10.1145/101306.101311,
author = {Savoy, Jacques},
title = {Statistical Behavior of Fast Hashing of Variable Length Test Strings},
year = {1990},
issue_date = {Fall 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/101306.101311},
doi = {10.1145/101306.101311},
abstract = {In information retrieval, we often have to store and search for a particular record into a large amount of information. For example, during a document indexing process or when a program is trying to spell a text, a dictionary has to be used in an efficient way. A solution to that problem resides in using a hash table. However, if we known many algorithms for manipulating or accessing hash tables [Knuth 73], [Standish 80], [Wiederhold 87], the main problem is to define a "good" hash function for a variable-length string. In order to answer that question our main goals are to present some concrete algorithms and to study their statistical behavior.},
journal = {SIGIR Forum},
month = nov,
pages = {62–71},
numpages = {10}
}

@article{10.1145/101306.101308,
author = {Aoe, Jun-ichi},
title = {A Compendium of Key Search References},
year = {1990},
issue_date = {Fall 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/101306.101308},
doi = {10.1145/101306.101308},
abstract = {How to store and to search, or retrieve, information efficiently is an important problem in computer science because searching is the most time-consuming part of many programs, and the substitution of a good search method for a bad one often leads to a substantial increase in speed. Particularly, a key search technique of finding which record has a special field as its key has been widely used in database management, compiler construction, natural language processing, and many other applications. The aim of this article is to provide a great deal of references, classified by consideration of their problems.},
journal = {SIGIR Forum},
month = nov,
pages = {26–42},
numpages = {17}
}

@article{10.1145/74697.74699,
author = {Aoe, J. I.},
title = {An Efficient Implemenatation of String Pattern Matching Machines for a Finite Number of Keywords},
year = {1989},
issue_date = {Spring 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/74697.74699},
doi = {10.1145/74697.74699},
abstract = {This paper describes a method of implementing a static transition table of a string pattern matching machine to locate all occurrences of a finite number of keywords in a text string. The scheme combines the fast access of an array representation with the compactness of a list structure. Each transition can be computed from the present data structure in O(1) time and the storage is as small as the list structure. The construction and pattern matching programs associated with the present data structure are provided and the efficiency is evaluated by a empirical results.},
journal = {SIGIR Forum},
month = apr,
pages = {22–33},
numpages = {12}
}

@article{10.1145/54347.1096814,
author = {Humphrey, Susanne},
title = {Disertation Abstracts},
year = {1988},
issue_date = {Spring/Summer 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/54347.1096814},
doi = {10.1145/54347.1096814},
journal = {SIGIR Forum},
month = may,
pages = {29–51},
numpages = {23}
}

@article{10.1145/30075.1096828,
author = {Yeung, Grace C. N.},
title = {Book Review: Database System Concepts by Henry F. Korth and Abraham Silberschatz (McGraw-Hill, New York, 1986, 546 Pp., $37.95)},
year = {1987},
issue_date = {March 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/30075.1096828},
doi = {10.1145/30075.1096828},
abstract = {This book is an excellent introduction to database system concepts. In its fifteen chapters it covers data abstraction; data models, instances, and schemes; data independence; data definition language; data manipulation language; the database manager, administrator, and users; and overall database system structure. There are individual chapters on the four major data models: entity-relationship, relational, network, and hierarchical. There is also a chapter on the theory of relational database design, with normalization and data independence covered in detail.},
journal = {SIGIR Forum},
month = mar,
pages = {21},
numpages = {1}
}

@article{10.1145/15497.1096834,
author = {Salton, Gerard},
title = {ABSTRACTS (Chosen by G. Salton or V. Raghavan from 1984 Issues of Journals in the Retrieval Area)},
year = {1986},
issue_date = {Spring-Summer 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/15497.1096834},
doi = {10.1145/15497.1096834},
abstract = {Examined in this article is the hypothesis that it is now technologically and economically feasible to move the content of documents electronically among nodes of a library network rather than the documents themselves or photocopies thereof. Comparisons are made on the basis of response-to-request time, quality of reproduced copy and cost factors. The conclusion is reached that electronic interlibrary resource-sharing networks are ideally suited to situations where there are high frequency occurrences of internode requests for information contained in serials, where nodal separation distances do not exceed a few tens of miles and where copy is in six-point type or larger. A three-node network is examined in detail. Specifications for each element of the network are given, with emphasis placed on a highly critical element, the bound-document scanner. The results of an economic study of interlibrary electronic networks are also presented.},
journal = {SIGIR Forum},
month = may,
pages = {30–42},
numpages = {13}
}

@article{10.1145/16287.16289,
author = {Williamson, Donna},
title = {Information Retrieval Research at the National Library of Medicine},
year = {1986},
issue_date = {Winter 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/16287.16289},
doi = {10.1145/16287.16289},
journal = {SIGIR Forum},
month = jan,
pages = {15–20},
numpages = {6}
}

@article{10.1145/16287.1096835,
author = {Martin, Ann},
title = {BOOK REVIEW: Database: A Primer by C. J. Date (Addison-Wesley Publishing Company, 1983)},
year = {1986},
issue_date = {Winter 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/16287.1096835},
doi = {10.1145/16287.1096835},
abstract = {A giant in the field of database management systems, C. J. Date, has proved that databases can be explained in conversational English without falling back on the technical sublanguage usually employed. Time was when the very term "database" implied a vast amount of data, multiple users, and arcane language. But times change. It is significant that this database primer is issued in paperback for the publisher's microcomputer popular series, at a modest price ($12.95). And it is a book that appeals to the reading public -- the issue used for this review is from the third printing, April 1984.},
journal = {SIGIR Forum},
month = jan,
pages = {23–24},
numpages = {2}
}

@article{10.1145/1095469.1095471,
title = {Abstracts: Chosen by G. Salton from Current Issues of Journals in the Retrieval Area},
year = {1983},
issue_date = {Fall-Winter 1983-84},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095469.1095471},
doi = {10.1145/1095469.1095471},
journal = {SIGIR Forum},
month = sep,
pages = {44–51},
numpages = {8}
}

@article{10.1145/3263610,
author = {Noreault, Terry},
title = {Session Details: Session 12: Panel on Key Issues in Information Retrieval},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263610},
doi = {10.1145/3263610},
journal = {SIGIR Forum},
month = jun,
numpages = {1}
}

@article{10.1145/3263607,
author = {Kameen, Karen},
title = {Session Details: Session 9: System Design},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263607},
doi = {10.1145/3263607},
journal = {SIGIR Forum},
month = jun,
numpages = {1}
}

@article{10.1145/1095366.1095368,
author = {Koll, Matthew B.},
title = {WEIRD: An Approach to Concept-Based Information Retrieval},
year = {1979},
issue_date = {Spring 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095366.1095368},
doi = {10.1145/1095366.1095368},
abstract = {WEIRD is an automatic document retrieval system designed and implemented at Syracuse University, which attempts to advance the art of computerized retrieval from word-matching to judging conceptual similarity. WEIRD uses a vector space model to represent the relations among terms and documents. Items in the space are located according to their "meaning", which is their proximity to all other items in the data base as measured by co-occurrence frequencies. This is done without manipulating large matrices. The dimensions of the space are not used to define relations; items are defined solely by their position relative to the other items. Retrieval is determined by Euclidean distance from the plotted query. In the first section of the paper the basic characteristics of WEIRD are described. Second, the results of a preliminary evaluation are reported. Alternatives for further development of WEIRD are then considered.},
journal = {SIGIR Forum},
month = apr,
pages = {32–50},
numpages = {19}
}

@article{10.1145/983026.983024,
author = {Matteucci, Dante R.},
title = {A Distributed Structure for the Automization of the Catalog of the National Cultural Heritage: Experiencies and Proposals},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983024},
doi = {10.1145/983026.983024},
abstract = {Efforts to automate the handling of information concerning the Catalog of the Italian cultural and artistic heritage have been made in the past by the Institute for the Catalog and Documentation (ICCD) of the Ministry of Cultural and Environmental Heritage.A feasibility study for the realization of a data base of the national cultural heritage has been conducted by CNUCE, the scientific computing center of the Italian National Research Council and ICCD. This study led to the determination of the caracteristics of data contained on the record cards, to the location of some samples areas, sufficiently representative of the Italian situation, for the setting up of a model of information system and to the implementation of a data bank on CNUCE computers using the IBM STAIRS information retrieval system.Following this study, a project is presently conducted by the two institutions, with the aim of setting up a distributed structure for the preparation, acquisition, access to and dissemination of the information concerning the Italian cultural and artistic heritage.This paper describes the functions of this proposed structure, with reference to the results of the first experiences and implementations.},
journal = {SIGIR Forum},
month = aug,
pages = {121–133},
numpages = {13}
}

@article{10.1145/3263596,
author = {Schuster, Stewart},
title = {Session Details: Session 6},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263596},
doi = {10.1145/3263596},
journal = {SIGIR Forum},
month = aug,
numpages = {1}
}

@article{10.1145/3263592,
author = {Hollaar, Lee A.},
title = {Session Details: Session 1},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263592},
doi = {10.1145/3263592},
journal = {SIGIR Forum},
month = aug,
numpages = {1}
}

@article{10.1145/1095286.1095292,
author = {Roberts, David C.},
title = {A Specialized Computer Architecture for High-Speed Text Searching},
year = {1976},
issue_date = {Spring 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095286.1095292},
doi = {10.1145/1095286.1095292},
abstract = {This paper describes a specialized parallel computer architecture that is proposed for high-speed searching of large text data bases. The proposed machine architecture is a parallel array of independent processors connected to a common bus. Each processor consists of a microprocessor, a high-speed block-access memory for storage of a part of the data base, read-only memory for control software, and random-access memory for storage of programs and working storage. The processors are connected by a common high-speed bus that is used for communication of data, programs, commands and results. The benefits claimed for this architecture are design simplicity, high speed for suitable applications, ease of software development, reliability and reasonable cost. This machine architecture is under consideration as a means for providing high-speed text searching capabilities.},
journal = {SIGIR Forum},
month = apr,
pages = {12–15},
numpages = {4}
}

@article{10.1145/1095495.1095497,
title = {PATRICIA - II: Two Level Overlayed Indexes for Large Libraries},
year = {1972},
issue_date = {Winter 1972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095495.1095497},
doi = {10.1145/1095495.1095497},
abstract = {This paper is a discussion of extending PATRICIA [3] which was developed by Donald R. Morrison. The ideas and notation of [3] are used and extended here. The reader is advised, therefore, to familiarize himself with the notation and terminology of [3].},
journal = {SIGIR Forum},
month = dec,
pages = {12–16},
numpages = {5}
}

@article{10.1145/1013230.511831,
author = {van Rijsbergen, C. J.},
title = {Information Retrieval: New Directions: Old Solutions},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511831},
doi = {10.1145/1013230.511831},
journal = {SIGIR Forum},
month = jun,
pages = {264–265},
numpages = {2}
}

@inproceedings{10.1145/511793.511831,
author = {van Rijsbergen, C. J.},
title = {Information Retrieval: New Directions: Old Solutions},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511831},
doi = {10.1145/511793.511831},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {264–265},
numpages = {2},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511825,
author = {Yannakoudakis, E J},
title = {Derived Search Keys for Bibliographic Retrieval},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511825},
doi = {10.1145/1013230.511825},
abstract = {A principle of information science states that the entropy of a set of symbols is maximised when the probability of occurrence of each becomes the same. This paper presents the results of a number of experiments which utilise this principle to construct fixed length keys from pertinent fields in order to locate and retrieve unique records as well as clusters with lexically homogeneous information. Each key incorporates codes derived by various positional selection methods and their discriminating strength proves to be well over 95%.},
journal = {SIGIR Forum},
month = jun,
pages = {220–237},
numpages = {18}
}

@inproceedings{10.1145/511793.511825,
author = {Yannakoudakis, E J},
title = {Derived Search Keys for Bibliographic Retrieval},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511825},
doi = {10.1145/511793.511825},
abstract = {A principle of information science states that the entropy of a set of symbols is maximised when the probability of occurrence of each becomes the same. This paper presents the results of a number of experiments which utilise this principle to construct fixed length keys from pertinent fields in order to locate and retrieve unique records as well as clusters with lexically homogeneous information. Each key incorporates codes derived by various positional selection methods and their discriminating strength proves to be well over 95%.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {220–237},
numpages = {18},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511809,
author = {Katzer, Jeffrey and Tessier, Judith and Frakes, William and Das-Gupta, Padmini},
title = {A Study of the Overlap among Document Representations},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511809},
doi = {10.1145/1013230.511809},
abstract = {Most previous investigations comparing the performance of different representations have used recall and precision as performance measures. However, there is evidence to show that these measures are insensitive to an important difference between representations. To explain, two representations may perform similarly on these measures, while retrieving very different sets of documents. Equivalence of representations should be decided on the basis of similarity in performance and similarity in the documents retrieved. This study compared the performance of four representations in the PsycAbs database. In addition, overlap between retrieved sets was also computed where overlap is the proportion of retrieved documents that are the same for pairs of document representations. Results indicate that for any two representations considered, performance values differed slightly while overlap scores were also low, thus supporting the evidence that recall and precision as performance measures mask differences between the sets of retrieved documents. Results are interpreted to propose an optimal ordering of the representations and to examine the contribution of each representation given this combination.},
journal = {SIGIR Forum},
month = jun,
pages = {106–114},
numpages = {9}
}

@inproceedings{10.1145/511793.511809,
author = {Katzer, Jeffrey and Tessier, Judith and Frakes, William and Das-Gupta, Padmini},
title = {A Study of the Overlap among Document Representations},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511809},
doi = {10.1145/511793.511809},
abstract = {Most previous investigations comparing the performance of different representations have used recall and precision as performance measures. However, there is evidence to show that these measures are insensitive to an important difference between representations. To explain, two representations may perform similarly on these measures, while retrieving very different sets of documents. Equivalence of representations should be decided on the basis of similarity in performance and similarity in the documents retrieved. This study compared the performance of four representations in the PsycAbs database. In addition, overlap between retrieved sets was also computed where overlap is the proportion of retrieved documents that are the same for pairs of document representations. Results indicate that for any two representations considered, performance values differed slightly while overlap scores were also low, thus supporting the evidence that recall and precision as performance measures mask differences between the sets of retrieved documents. Results are interpreted to propose an optimal ordering of the representations and to examine the contribution of each representation given this combination.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {106–114},
numpages = {9},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511804,
author = {Bates, Madeleine and Bobrow, Robert J.},
title = {Information Retrieval Using a Transportable Natural Language Interface},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511804},
doi = {10.1145/1013230.511804},
abstract = {This paper describes work in progress to develop a facility for natural language access to a variety of computer databases and database systems. This facility, called IRUS for Information Retrieval using the RUS parsing system, allows users who are unfamiliar with the technical characteristics of the underlying database system to query databases using typed English input. This system can be thought of as a stand-alone query system or as part of a management information system (MIS) or a decision support system (DSS).Many systems boast of having a "user-friendly" or "English-like" or even "English" interface so that users require a minimum of special training to use the system, but most such systems use shallow, relatively ad hoc techniques that are not robust or linguistically sound. We are using a large, well-tested, theoretically-based, general parser of English that has been developed and extended in a variety of research projects for over a decade.One of the primary emphases of IRUS is transportability, which includes three types of changes: (1) changing the domain, (2) changing data bases within the same domain, and (3) changing data base systems. The use of a general parser for English is an important part of the solution to the transportability problem, but there are other parts as well, since portions of the system beyond the parser must know the conceptual content of the domain, the way in which this is reflected in a collection of datasets, and the operating characteristics of the dbms being used to access these datasets.Other researchers have investigated similar issues [8, 5, 6, 12]. We have attacked this problem by building a knowledge-based system, with procedural components independent of domain and data base structure, directed by domain and database dependent knowledge structures. We are also building tools for conveniently creating and maintaining these knowledge structures, with an eventual goal of allowing end-users to extend and modify these knowledge structures to suit their own needs. Given this set of goals, and these tools, we consider the current implementation, which uses the System 1022 dbms on the DEC KL-2060, to be only one of a set of possible implementations, and are not constraining IRUS on the basis of 1022's strengths and weaknesses.This paper presents an overview of the IRUS system, emphasizing those aspects of the design that are critical to transportability. We describe the parsing system, which is a completely independent module that has been interfaced to a variety of different applications, and then discuss the other modules which bridge the gap between the parser and the dbms.},
journal = {SIGIR Forum},
month = jun,
pages = {81–86},
numpages = {6}
}

@inproceedings{10.1145/511793.511804,
author = {Bates, Madeleine and Bobrow, Robert J.},
title = {Information Retrieval Using a Transportable Natural Language Interface},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511804},
doi = {10.1145/511793.511804},
abstract = {This paper describes work in progress to develop a facility for natural language access to a variety of computer databases and database systems. This facility, called IRUS for Information Retrieval using the RUS parsing system, allows users who are unfamiliar with the technical characteristics of the underlying database system to query databases using typed English input. This system can be thought of as a stand-alone query system or as part of a management information system (MIS) or a decision support system (DSS).Many systems boast of having a "user-friendly" or "English-like" or even "English" interface so that users require a minimum of special training to use the system, but most such systems use shallow, relatively ad hoc techniques that are not robust or linguistically sound. We are using a large, well-tested, theoretically-based, general parser of English that has been developed and extended in a variety of research projects for over a decade.One of the primary emphases of IRUS is transportability, which includes three types of changes: (1) changing the domain, (2) changing data bases within the same domain, and (3) changing data base systems. The use of a general parser for English is an important part of the solution to the transportability problem, but there are other parts as well, since portions of the system beyond the parser must know the conceptual content of the domain, the way in which this is reflected in a collection of datasets, and the operating characteristics of the dbms being used to access these datasets.Other researchers have investigated similar issues [8, 5, 6, 12]. We have attacked this problem by building a knowledge-based system, with procedural components independent of domain and data base structure, directed by domain and database dependent knowledge structures. We are also building tools for conveniently creating and maintaining these knowledge structures, with an eventual goal of allowing end-users to extend and modify these knowledge structures to suit their own needs. Given this set of goals, and these tools, we consider the current implementation, which uses the System 1022 dbms on the DEC KL-2060, to be only one of a set of possible implementations, and are not constraining IRUS on the basis of 1022's strengths and weaknesses.This paper presents an overview of the IRUS system, emphasizing those aspects of the design that are critical to transportability. We describe the parsing system, which is a completely independent module that has been interfaced to a variety of different applications, and then discuss the other modules which bridge the gap between the parser and the dbms.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {81–86},
numpages = {6},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511800,
author = {Brooks, H. M. and Belkin, N. J.},
title = {Using Discourse Analysis for the Design of Information Retrieval Interaction Mechanisms},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511800},
doi = {10.1145/1013230.511800},
journal = {SIGIR Forum},
month = jun,
pages = {31–47},
numpages = {17}
}

@inproceedings{10.1145/511793.511800,
author = {Brooks, H. M. and Belkin, N. J.},
title = {Using Discourse Analysis for the Design of Information Retrieval Interaction Mechanisms},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511800},
doi = {10.1145/511793.511800},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {31–47},
numpages = {17},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511799,
author = {Lebowitz, Michael},
title = {Intelligent Information Systems},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511799},
doi = {10.1145/1013230.511799},
abstract = {Natural language processing techniques developed for Artificial Intelligence programs can aid in constructing powerful information retrieval systems in at least two areas. Automatic construction of new concepts allows a large body of information to be organized compactly and in a manner that allows a wide range of queries to be answered. Also, using natural language processing techniques to conceptually analyze the documents being stored in a system greatly expands the effectiveness of queries about given pieces of text. However, only robust conceptual analysis methods are adequate for such systems. This paper will discuss approaches to both concept learning, in the form of Generalization-Based Memory, and powerful, robust text processing achieved by Memory-Based Understanding. These techniques have been implemented in the computer systems IPP, a program that reads, remembers and generalizes from news stories about terrorism, and RESEARCHER, currently in the prototype stage, that operates in a very different domain (technical texts, patent abstracts in particular).},
journal = {SIGIR Forum},
month = jun,
pages = {25–30},
numpages = {6}
}

@inproceedings{10.1145/511793.511799,
author = {Lebowitz, Michael},
title = {Intelligent Information Systems},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511799},
doi = {10.1145/511793.511799},
abstract = {Natural language processing techniques developed for Artificial Intelligence programs can aid in constructing powerful information retrieval systems in at least two areas. Automatic construction of new concepts allows a large body of information to be organized compactly and in a manner that allows a wide range of queries to be answered. Also, using natural language processing techniques to conceptually analyze the documents being stored in a system greatly expands the effectiveness of queries about given pieces of text. However, only robust conceptual analysis methods are adequate for such systems. This paper will discuss approaches to both concept learning, in the form of Generalization-Based Memory, and powerful, robust text processing achieved by Memory-Based Understanding. These techniques have been implemented in the computer systems IPP, a program that reads, remembers and generalizes from news stories about terrorism, and RESEARCHER, currently in the prototype stage, that operates in a very different domain (technical texts, patent abstracts in particular).},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {25–30},
numpages = {6},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511796,
author = {DeJong, Gerald},
title = {Artificial Intelligence Implications for Information Retrieval},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511796},
doi = {10.1145/1013230.511796},
abstract = {Overall, the field of information retrieval is already more aware than many other fields of the relevance of artificial intelligence (AI) [1-6]. Nonetheless there remain exciting applications of artificial intelligence that have been so far overlooked. In this paper we will point out some of the ways artificial intelligence might influence the field of information retrieval. We will then examine one application in more detail to discover the kind of technical problems involved in its fruitful exploitation.Before proceeding, it is important to interject a note of caution. While the promise of artificial intelligence is indeed bright, the time of complete fulfillment of its promise is a long way off. Of course, some of the expected contributions are shorter term than others. However, the more difficult problems will fall only after a good deal of basic research is accomplished. Artificial intelligence researchers have, in the past, been culpable of what can most charitably be described as over-optimism [7,8]. This naivete on the part of even the most respected of researchers stemmed from the profound subtleties underlying intelligent behavior. The problem is compounded by the fact that some of the most difficult of intelligent behavior (i.e. common sense) seems intuitively easy.},
journal = {SIGIR Forum},
month = jun,
pages = {10–17},
numpages = {8}
}

@inproceedings{10.1145/511793.511796,
author = {DeJong, Gerald},
title = {Artificial Intelligence Implications for Information Retrieval},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511796},
doi = {10.1145/511793.511796},
abstract = {Overall, the field of information retrieval is already more aware than many other fields of the relevance of artificial intelligence (AI) [1-6]. Nonetheless there remain exciting applications of artificial intelligence that have been so far overlooked. In this paper we will point out some of the ways artificial intelligence might influence the field of information retrieval. We will then examine one application in more detail to discover the kind of technical problems involved in its fruitful exploitation.Before proceeding, it is important to interject a note of caution. While the promise of artificial intelligence is indeed bright, the time of complete fulfillment of its promise is a long way off. Of course, some of the expected contributions are shorter term than others. However, the more difficult problems will fall only after a good deal of basic research is accomplished. Artificial intelligence researchers have, in the past, been culpable of what can most charitably be described as over-optimism [7,8]. This naivete on the part of even the most respected of researchers stemmed from the profound subtleties underlying intelligent behavior. The problem is compounded by the fact that some of the most difficult of intelligent behavior (i.e. common sense) seems intuitively easy.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {10–17},
numpages = {8},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511795,
author = {Hollaar, Lee A.},
title = {Hardware Systems for Text Information Retrieval},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511795},
doi = {10.1145/1013230.511795},
abstract = {As databases become very large, conventional digital computers cannot provide satisfactory response time. This is particularly true for text databases, which must often be several orders of magnitude larger than formatted databases to store a useful amount of information. Even the standard techniques for improving system performance (such as inverted files) may not be sufficient to give the desired performance, and the use of an unconventional hardware organization may become necessary.A variety of different organizations has been proposed to enhance processing of text retrieval operations. Most of these have concentrated on the design of fast, efficient search engines. These can be divided into three classes: associative memories, cellular pattern matchers, and finite state automata. The advantages and disadvantages inherent in each of these approaches are discussed, along with a number of proposed implementations. Finally, the text retrieval system under development at the University of Utah is discussed in more detail.},
journal = {SIGIR Forum},
month = jun,
pages = {3–9},
numpages = {7}
}

@inproceedings{10.1145/511793.511795,
author = {Hollaar, Lee A.},
title = {Hardware Systems for Text Information Retrieval},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511795},
doi = {10.1145/511793.511795},
abstract = {As databases become very large, conventional digital computers cannot provide satisfactory response time. This is particularly true for text databases, which must often be several orders of magnitude larger than formatted databases to store a useful amount of information. Even the standard techniques for improving system performance (such as inverted files) may not be sufficient to give the desired performance, and the use of an unconventional hardware organization may become necessary.A variety of different organizations has been proposed to enhance processing of text retrieval operations. Most of these have concentrated on the design of fast, efficient search engines. These can be divided into three classes: associative memories, cellular pattern matchers, and finite state automata. The advantages and disadvantages inherent in each of these approaches are discussed, along with a number of proposed implementations. Finally, the text retrieval system under development at the University of Utah is discussed in more detail.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3–9},
numpages = {7},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013228.511775,
author = {Shoval, Peretz},
title = {Expert/Consultation System for a Retrieval Data-Base with Semantic Network of Concepts},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511775},
doi = {10.1145/1013228.511775},
abstract = {This paper describes a development and implementation of an expert/consultation system for a retrieval data-base, that interfaces between the user and a retrieval system. The system's objective is to perform the information consultant's job in assisting a user to select the right vocabulary terms for his query. It is particularly useful for a novice user of a controlled-vocabulary, index-based retrieval system, who is not familiar with the vocabulary and the system Thesaurus. The user will enter his terms/keywords, that represent his information need, and the system will apply search procedures on its knowledge-base, and will find relevant concepts to be used as query-terms. The system is interactive; it can explain to the user why/how a concept was discovered/suggested, and it can back-track and try to find alternatives in case the user rejects a suggested concept. Two versions of the system were developed, utilizing two search and interaction strategies. Experiments will be conducted with the two alternatives in order to find out user preference and to compare performance. Performance will also be compard with an alternative "conventional" approach, which is an On-Line-Thesarus - developed as part of this study.},
journal = {SIGIR Forum},
month = may,
pages = {145–149},
numpages = {5}
}

@inproceedings{10.1145/511754.511775,
author = {Shoval, Peretz},
title = {Expert/Consultation System for a Retrieval Data-Base with Semantic Network of Concepts},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511775},
doi = {10.1145/511754.511775},
abstract = {This paper describes a development and implementation of an expert/consultation system for a retrieval data-base, that interfaces between the user and a retrieval system. The system's objective is to perform the information consultant's job in assisting a user to select the right vocabulary terms for his query. It is particularly useful for a novice user of a controlled-vocabulary, index-based retrieval system, who is not familiar with the vocabulary and the system Thesaurus. The user will enter his terms/keywords, that represent his information need, and the system will apply search procedures on its knowledge-base, and will find relevant concepts to be used as query-terms. The system is interactive; it can explain to the user why/how a concept was discovered/suggested, and it can back-track and try to find alternatives in case the user rejects a suggested concept. Two versions of the system were developed, utilizing two search and interaction strategies. Experiments will be conducted with the two alternatives in order to find out user preference and to compare performance. Performance will also be compard with an alternative "conventional" approach, which is an On-Line-Thesarus - developed as part of this study.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {145–149},
numpages = {5},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013228.511772,
author = {Noreault, Terry and Dovidio, John F.},
title = {Spatial Representations of Knowledge: Validity and Applications to Information Science},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511772},
doi = {10.1145/1013228.511772},
abstract = {This research examined the relationship between subjects' knowledge of an area and their similarity ratings of pairs of concepts. Knowledge was operationalized as (1) test score performance, and (2) correspondence with an expert's similarity judgments. Subjects (n=55) were exposed to a three-week module on social psychology as part of their introductory psychology course. At the end of this course segment they were administered an examination and, later, a term similarity questionnaire. Students' similarity ratings related to both exam score and similarity ratings of the expert. Furthermore, as expected, test performance was strongly related (r=+.55) to the correlation with the expert's similarity judgments. A model based on term similarity judgments was proposed as a theoretical explanation of how term dependence models influence information retrieval system performance.},
journal = {SIGIR Forum},
month = may,
pages = {113–125},
numpages = {13}
}

@inproceedings{10.1145/511754.511772,
author = {Noreault, Terry and Dovidio, John F.},
title = {Spatial Representations of Knowledge: Validity and Applications to Information Science},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511772},
doi = {10.1145/511754.511772},
abstract = {This research examined the relationship between subjects' knowledge of an area and their similarity ratings of pairs of concepts. Knowledge was operationalized as (1) test score performance, and (2) correspondence with an expert's similarity judgments. Subjects (n=55) were exposed to a three-week module on social psychology as part of their introductory psychology course. At the end of this course segment they were administered an examination and, later, a term similarity questionnaire. Students' similarity ratings related to both exam score and similarity ratings of the expert. Furthermore, as expected, test performance was strongly related (r=+.55) to the correlation with the expert's similarity judgments. A model based on term similarity judgments was proposed as a theoretical explanation of how term dependence models influence information retrieval system performance.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {113–125},
numpages = {13},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013228.511761,
author = {Yu, C. T. and Lam, K.},
title = {An Approach to Probabilistic Retrieval},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511761},
doi = {10.1145/1013228.511761},
abstract = {The objective is to relate the effectiveness of retrieval, the fuzzy set concept and the processing of Boolean query. The use of a probabilistic retrieval scheme is motivated. It is found that there is a correspondence between probabilistic retrieval schmes and fuzzy sets. A fuzzy set corresponding to a potentially optimal probabilistic retrieval scheme is obtained. Then the retrieval scheme for the fuzzy set is constructed.},
journal = {SIGIR Forum},
month = may,
pages = {46–55},
numpages = {10}
}

@inproceedings{10.1145/511754.511761,
author = {Yu, C. T. and Lam, K.},
title = {An Approach to Probabilistic Retrieval},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511761},
doi = {10.1145/511754.511761},
abstract = {The objective is to relate the effectiveness of retrieval, the fuzzy set concept and the processing of Boolean query. The use of a probabilistic retrieval scheme is motivated. It is found that there is a correspondence between probabilistic retrieval schmes and fuzzy sets. A fuzzy set corresponding to a potentially optimal probabilistic retrieval scheme is obtained. Then the retrieval scheme for the fuzzy set is constructed.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {46–55},
numpages = {10},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013881.802696,
author = {Shaw, David Elliot},
title = {A Relational Database Machine Architecture},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802696},
doi = {10.1145/1013881.802696},
abstract = {Algorithms are described and analyzed for the efficient evaluation of the project and join operators of a relational algebra on a proposed non-von Neumann machine based on a hierarchy of associative storage devices. This architecture permits an O(log n) decrease in time complexity over the best known evaluation methods on a conventional computer system, without the use of redundant storage, and using currently available and potentially competitive technology. In many cases of practical import, the proposed architecture may also permit a significant improvement (by a factor roughly proportional to the capacity of the primary associative storage device) over the performance of previously implemented or proposed database machine architectures based on associative secondary storage devices.},
journal = {SIGIR Forum},
month = mar,
pages = {84–95},
numpages = {12}
}

@inproceedings{10.1145/800083.802696,
author = {Shaw, David Elliot},
title = {A Relational Database Machine Architecture},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802696},
doi = {10.1145/800083.802696},
abstract = {Algorithms are described and analyzed for the efficient evaluation of the project and join operators of a relational algebra on a proposed non-von Neumann machine based on a hierarchy of associative storage devices. This architecture permits an O(log n) decrease in time complexity over the best known evaluation methods on a conventional computer system, without the use of redundant storage, and using currently available and potentially competitive technology. In many cases of practical import, the proposed architecture may also permit a significant improvement (by a factor roughly proportional to the capacity of the primary associative storage device) over the performance of previously implemented or proposed database machine architectures based on associative secondary storage devices.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {84–95},
numpages = {12},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013881.802687,
author = {Banerjee, Jayanta},
title = {Data Structuring and Indexing for Data Base Machines},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802687},
doi = {10.1145/1013881.802687},
abstract = {Our focus in this paper is not the design of new and improved hardware for data base management. Instead, our main interest is to document the results of our investigation on the data structuring and indexing requirements of the class of data base machines that contain partitioned content-addressable memory (PCAM).},
journal = {SIGIR Forum},
month = mar,
pages = {11–16},
numpages = {6}
}

@inproceedings{10.1145/800083.802687,
author = {Banerjee, Jayanta},
title = {Data Structuring and Indexing for Data Base Machines},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802687},
doi = {10.1145/800083.802687},
abstract = {Our focus in this paper is not the design of new and improved hardware for data base management. Instead, our main interest is to document the results of our investigation on the data structuring and indexing requirements of the class of data base machines that contain partitioned content-addressable memory (PCAM).},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {11–16},
numpages = {6},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013232.511717,
author = {Croft, W. Bruce},
title = {On the Implementation of Some Models of Document Retrieval},
year = {1979},
issue_date = {September 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013232.511717},
doi = {10.1145/1013232.511717},
abstract = {Recently several models of the search process in a document retrieval system have been proposed and retrieval experiments have shown that they will improve system performance. These include models which use relevance judgements to rank documents in order of probability of relevance and models of retrieval from clusters of documents. In this paper various models are compared in terms of the ease with which they could be implemented. An important consideration is how this implementation would be affected by the introduction of new hardware such as content-addressable memories. The main conclusion is that models which concentrate on improving the effectiveness of the search process are not rendered redundant by the availability of new hardware. However, the efficiency of their implementation would be improved.},
journal = {SIGIR Forum},
month = sep,
pages = {71–77},
numpages = {7}
}

@inproceedings{10.1145/511706.511717,
author = {Croft, W. Bruce},
title = {On the Implementation of Some Models of Document Retrieval},
year = {1979},
isbn = {9781450373456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511706.511717},
doi = {10.1145/511706.511717},
abstract = {Recently several models of the search process in a document retrieval system have been proposed and retrieval experiments have shown that they will improve system performance. These include models which use relevance judgements to rank documents in order of probability of relevance and models of retrieval from clusters of documents. In this paper various models are compared in terms of the ease with which they could be implemented. An important consideration is how this implementation would be affected by the introduction of new hardware such as content-addressable memories. The main conclusion is that models which concentrate on improving the effectiveness of the search process are not rendered redundant by the availability of new hardware. However, the efficiency of their implementation would be improved.},
booktitle = {Proceedings of the 2nd Annual International ACM SIGIR Conference on Information Storage and Retrieval: Information Implications into the Eighties},
pages = {71–77},
numpages = {7},
location = {Dallas, Texas},
series = {SIGIR '79}
}

@article{10.1145/1013234.803146,
author = {Koll, Matthew B.},
title = {WEIRD: An Approach to Concept-Based Information Retrieval},
year = {1978},
issue_date = {May 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013234.803146},
doi = {10.1145/1013234.803146},
abstract = {WEIRD is an automatic document retrieval system designed and implemented at Syracuse University, which attempts to advance the art of computerized retrieval from word-matching to judging conceptual similarity. WEIRD uses a vector space model to represent the relations among terms and documents. Items in the space are located according to their “meaning”, which is their proximity to all other items in the data base as measured by co-occurrence frequencies. This is done without manipulating large matrices. The dimensions of the space are not used to define relations; items are defined solely by their position relative to the other items. Retrieval is determined by Euclidean distance from the plotted query. In the first section of the paper the basic characteristics of WEIRD are described. Second, the results of a preliminary evaluation are reported. Alternatives for further development of WEIRD are then considered.},
journal = {SIGIR Forum},
month = may,
pages = {180},
numpages = {1}
}

@inproceedings{10.1145/800096.803146,
author = {Koll, Matthew B.},
title = {WEIRD: An Approach to Concept-Based Information Retrieval},
year = {1978},
isbn = {9781450374026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800096.803146},
doi = {10.1145/800096.803146},
abstract = {WEIRD is an automatic document retrieval system designed and implemented at Syracuse University, which attempts to advance the art of computerized retrieval from word-matching to judging conceptual similarity. WEIRD uses a vector space model to represent the relations among terms and documents. Items in the space are located according to their “meaning”, which is their proximity to all other items in the data base as measured by co-occurrence frequencies. This is done without manipulating large matrices. The dimensions of the space are not used to define relations; items are defined solely by their position relative to the other items. Retrieval is determined by Euclidean distance from the plotted query. In the first section of the paper the basic characteristics of WEIRD are described. Second, the results of a preliminary evaluation are reported. Alternatives for further development of WEIRD are then considered.},
booktitle = {Proceedings of the 1st Annual International ACM SIGIR Conference on Information Storage and Retrieval},
pages = {180},
numpages = {1},
series = {SIGIR '78}
}

@article{10.1145/965643.810254,
author = {Bray, Olin H.},
title = {Data Management Requirements: The Similarity of Memory Management, Database Systems, and Message Processing},
year = {1977},
issue_date = {May 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/965643.810254},
doi = {10.1145/965643.810254},
abstract = {Memory management, database management, and message processing have in the past been defined in a relatively narrow way. With memory management the problem was to obtain cost effective use of real memory. Given a multiprogrammed environment, virtual memory systems allowed more effective use of expensive real memory. Memory management has become even more important with the development of very large and complex memory hierarchies. Database management systems were developed to allow the more effective use, sharing, and control of data resources - objectives which operating systems had previously provided for hardware resources. The driving force behind message processing has been the increased use of data communications and computer networks. This paper will consider the basis of the overlap in these areas, their common data management functions. Data management, as defined in this paper, includes the locating, routing, moving, and translating of data resources and the locating, reserving, and releasing of physical resources, i.e., primary and secondary storage.The analysis performed in this paper is essential because of trends in computer architecture discussed below. Early hardware was designed for general purpose environments with software used to tailor it to specific applications. However, according to Gagliardi9 future systems will consist of a set of subsystems, including a storage subsystem at the core surrounded by computational, spooling, and communications subsystems. The computational subsystem is the traditional “number cruncher” part of the system. The spooling subsystem provides the I/O interface between the system and the outside world. The communications subsystem links the various subsystems together and provides an interface to the rest of the network if the system is part of a larger distributed system. The storage subsystem consists of all the system's storage resources and their control processes. It controls all levels of the system memory and storage hierarchy. The storage subsystem controls the allocation of the physical storage resources and the movement of the data resources through the system. Depending on how these resources are used, they may be non-conserved or conserved, and if conserved, either serially reusable or sharable. Physical and data resources may be located, and if necessary reserved, independently or jointly.},
journal = {SIGIR Forum},
month = jan,
pages = {68–76},
numpages = {9}
}

@inproceedings{10.1145/800180.810254,
author = {Bray, Olin H.},
title = {Data Management Requirements: The Similarity of Memory Management, Database Systems, and Message Processing},
year = {1977},
isbn = {9781450374804},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800180.810254},
doi = {10.1145/800180.810254},
abstract = {Memory management, database management, and message processing have in the past been defined in a relatively narrow way. With memory management the problem was to obtain cost effective use of real memory. Given a multiprogrammed environment, virtual memory systems allowed more effective use of expensive real memory. Memory management has become even more important with the development of very large and complex memory hierarchies. Database management systems were developed to allow the more effective use, sharing, and control of data resources - objectives which operating systems had previously provided for hardware resources. The driving force behind message processing has been the increased use of data communications and computer networks. This paper will consider the basis of the overlap in these areas, their common data management functions. Data management, as defined in this paper, includes the locating, routing, moving, and translating of data resources and the locating, reserving, and releasing of physical resources, i.e., primary and secondary storage.The analysis performed in this paper is essential because of trends in computer architecture discussed below. Early hardware was designed for general purpose environments with software used to tailor it to specific applications. However, according to Gagliardi9 future systems will consist of a set of subsystems, including a storage subsystem at the core surrounded by computational, spooling, and communications subsystems. The computational subsystem is the traditional “number cruncher” part of the system. The spooling subsystem provides the I/O interface between the system and the outside world. The communications subsystem links the various subsystems together and provides an interface to the rest of the network if the system is part of a larger distributed system. The storage subsystem consists of all the system's storage resources and their control processes. It controls all levels of the system memory and storage hierarchy. The storage subsystem controls the allocation of the physical storage resources and the movement of the data resources through the system. Depending on how these resources are used, they may be non-conserved or conserved, and if conserved, either serially reusable or sharable. Physical and data resources may be located, and if necessary reserved, independently or jointly.},
booktitle = {Proceedings of the 3rd Workshop on Computer Architecture : Non-Numeric Processing},
pages = {68–76},
numpages = {9},
series = {CAW '77}
}

@article{10.1145/1842890.1842905,
author = {Bierig, Ralf},
title = {Event and Map Content Personalisation in a Mobile and Context-Aware-Environment},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1842890.1842905},
doi = {10.1145/1842890.1842905},
abstract = {Effective methods for information access are of the greatest importance for our modern lives -- particularly with respect to handheld devices. Personalisation is one such method which models a user's characteristics to deliver content more focused to the user's needs. The emerging area of sophisticated mobile computing devices has started to inspire new forms of personalised systems that include aspects of the person's contextual environment. This thesis seeks to understand the role of personalisation and context, to evaluate the effectiveness of context for content personalisation and to investigate the event and map content domain for mobile usage. The work presented in this thesis has three parts.The first part is a user experiment on context that investigated the contextual attributes of time, location and interest, with respect to participants' perception of their usefulness. Results show highly dynamic and interconnected effects of context on participants' usefulness ratings.In the second part, these results were applied to create a predictive model of context that was related to attribution theory and then combined with an information retrieval score to create a weighted personalisation model.In the third part of this work, the personalisation model was applied in a mobile experiment. Participants solved situational search tasks using a (i) non-personalized and a (ii) personalized mobile information system, and rating entertainment events based on usefulness. Results showed that the personalised system delivered about 20% more useful content to the mobile user than the non-personalised system, with some indication for reduced search effort in terms of time and the amount of queries per task.The work presented provides evidence for the promising potential of context to facilitate personalised information delivery to users of mobile devices. Overall, it serves as an example of an investigation into the effectiveness of context from multiple angles and provides a potential link to some of the aspects of psychology as a potential source for a deeper understanding of contextual processes in humans.},
journal = {SIGIR Forum},
month = aug,
pages = {87},
numpages = {1}
}

@article{10.1145/1842890.1842892,
author = {Gurrin, Cathal and He, Yulan and Kruschwitz, Udo and Little, Suzanne and R\"{u}ger, Stefan},
title = {ECIR 2010: 32nd European Conference on Information Retrieval Research},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1842890.1842892},
doi = {10.1145/1842890.1842892},
journal = {SIGIR Forum},
month = aug,
pages = {2–18},
numpages = {17}
}

@article{10.1145/959258.959272,
author = {Warner, Simeon and Nelson, Michael},
title = {Report on the Metadata Harvesting Workshop at JCDL 2003},
year = {2003},
issue_date = {Fall 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/959258.959272},
doi = {10.1145/959258.959272},
journal = {SIGIR Forum},
month = sep,
pages = {73–78},
numpages = {6}
}

@article{10.1145/959258.959271,
author = {Soergel, Dagobert},
title = {Building a More Meaningful Web: From Traditional Knowledge Organization Systems to New Semantic Tools},
year = {2003},
issue_date = {Fall 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/959258.959271},
doi = {10.1145/959258.959271},
journal = {SIGIR Forum},
month = sep,
pages = {65–72},
numpages = {8}
}

@article{10.1145/959258.959269,
author = {Mostafa, Javed and B\"{o}rner, Katy},
title = {Information Visualization Interfaces for Retrieval and Analysis (IVIRA) Workshop Summary},
year = {2003},
issue_date = {Fall 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/959258.959269},
doi = {10.1145/959258.959269},
journal = {SIGIR Forum},
month = sep,
pages = {59–61},
numpages = {3}
}

@article{10.1145/959258.959259,
author = {Bauer, Travis L. and Leake, David B.},
title = {Detecting Context-Differentiating Terms Using Competitive Learning},
year = {2003},
issue_date = {Fall 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/959258.959259},
doi = {10.1145/959258.959259},
abstract = {Personal information agents monitor ongoing user information accesses in order to provide users with context-relevant information. Providing the needed information requires effective methods for identifying the user's task context, based on available information. For user browsing tasks, one approach to context identification is to extract context-determining terms from the documents that the user consults. The thesis of this article is (1) that term extraction for personal information agents can be done by learning terms whose occurrence frequencies have a large variance over time, (2) that indexing and retrieval based on these terms can be at least as effective as standard information retrieval techniques, and (3) that this information can be learned without comprehensive corpus analysis, making it suitable for use in personal information retrieval.We have developed an unsupervised term extraction algorithm, WordSieve, that learns individualized context-differentiating terms for document indexing and retrieval. This article presents a new version of WordSieve, compares its design and performance to our initial approach, and assesses its effectiveness for a controlled personal information retrieval task, compared to three common indexing techniques requiring statistics about the global corpus. In the experiments, the new version of WordSieve generates task-relevant indices of comparable or better quality to common indexing techniques, using only local information.},
journal = {SIGIR Forum},
month = sep,
pages = {4–17},
numpages = {14}
}

@article{10.1145/511144.511146,
author = {Bergmark, Donna and Phempoonpanich, Paradee and Zhao, Shumin},
title = {Scraping the ACM Digital Library},
year = {2001},
issue_date = {Fall 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/511144.511146},
doi = {10.1145/511144.511146},
abstract = {As part of a larger project to automatically reference link the online scholarly literature, an attempt to analyze PDF documents was undertaken. The ACM Digital Library was used as the corpus for these experiments. With the current PDF and HTML analysis tools, roughly 80% accuracy was obtained in the automatic extraction of reference linking information.},
journal = {SIGIR Forum},
month = sep,
pages = {1–7},
numpages = {7}
}

@article{10.1145/344250.344253,
author = {Hull, David and Robertson, Stephen},
title = {The TREC-9 Filtering Track},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/344250.344253},
doi = {10.1145/344250.344253},
journal = {SIGIR Forum},
month = dec,
pages = {16},
numpages = {1}
}

@article{10.1145/219587.219590,
author = {Harman, Donna},
title = {Natural Language Processing and Information Retrieval Group Information Access and User Interfaces Division National Institute of Standards and Technology},
year = {1995},
issue_date = {Fall 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/219587.219590},
doi = {10.1145/219587.219590},
journal = {SIGIR Forum},
month = sep,
pages = {6–12},
numpages = {7}
}

@article{10.1145/195498.195500,
author = {Marcus, Richard S.},
title = {The RIAO 94 Conference and the Status of Information Retrieval: A Personal View},
year = {1994},
issue_date = {Fall 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/195498.195500},
doi = {10.1145/195498.195500},
abstract = {The RIAO 94 Conference provided a strong collection of presentations giving an excellent panorama of the best in current IR R&amp;D. This review briefly summarizes most of those presentations as a basis for characterizing the current state of research and development in information retrieval. The theme of this characterization is that a great number of exciting developments are bubbling just below (and even into) the operational system status but that these developments could be accelerated by an attention to a number of verities. For example, there are multiple paradigms for improving current operational systems and these need to be carefully evaluated through objective scientific experimentation and analysis so that the best techniques from each can be properly integrated into new, improved systems which will go beyond any one paradigm. Not only must current researchers be aware of competing new paradigms but they need to be aware of the work of past generations in Information Science. In particular, the standard structured, contextual, interactive Boolean techniques of modern retrieval systems do work well under intelligent human control and new attempts to add intelligent computer techniques and aides to this paradigm possibly serve as a better basis for optimized information retrieval than the competing paradigms based on statistics, advanced linguistics, or thesaural/classification development and browsing.},
journal = {SIGIR Forum},
month = sep,
pages = {7–16},
numpages = {10}
}

@article{10.1145/174263.1096175,
author = {Humphrey, Susanne M.},
title = {Selected IR-Related Dissertation Abstracts},
year = {1993},
issue_date = {Spring 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/174263.1096175},
doi = {10.1145/174263.1096175},
abstract = {The following are citations selected by title and abstract as being related to Information Retrieval (IR), resulting from a computer search, using BRS Information Technologies, of the Dissertation Abstracts Online database produced by University Microfilms International (UMI). Included are UMI order number, title, author, degree, year, institution; number of pages, and abstract. Unless otherwise specified, paper or microform copies of dissertations may be ordered from University Microfilms International, Dissertation Copies, Post Office Box 1764, Ann Arbor, MI 48106; telephone for U.S. (except Michigan, Hawaii, Alaska): 1-800-521-3042, for Canada: 1-800-343-5299; fax: 313-973-1540. Price lists and other ordering and shipping information are in the introduction to the published DAI. An alternate source for copies is sometimes provided. Dissertation titles and abstracts contained here are published with permission of University Microfilms International, publishers of Dissertation Abstracts International (copyright by University Microfilms International), and may not be reproduced without their prior permission.},
journal = {SIGIR Forum},
month = mar,
pages = {22–47},
numpages = {26}
}

@article{10.1145/122642.1096778,
author = {Can, Fazli},
title = {Hypertext and Hyperrnedia by Jakob Nielsen. Academic Press, Inc, San Diego, California, 1990, Xii + 263 Pp., $29.95, ISBN 0-12-518410-7},
year = {1991},
issue_date = {Spring 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/122642.1096778},
doi = {10.1145/122642.1096778},
abstract = {The term hypertext has recently become a known word in computer science. It finally appeared in "Index to the CR Classification System" of ACM Computing Reviews [1]. A hypertext document is distinguished by its nonsequential reading environment. This is because information is divided into sections and each section is stored in a node; the nodes are connected by links. Nodes may have more than one incoming and outgoing link. Using links, the readers have the freedom of reading a hypertext in any way that they want to read. By definition, hypertext is a network of nodes and links. In hypermedia, nodes may contain text, images, animation, video, sound, graphics, programs, etc. In general, the term hypertext is used to indicate nonlinear organization of information.},
journal = {SIGIR Forum},
month = may,
pages = {24–25},
numpages = {2}
}

@article{10.1145/101306.1096782,
author = {Salton, Gerry},
title = {Selected Information Retrieval Abstracts},
year = {1990},
issue_date = {Fall 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/101306.1096782},
doi = {10.1145/101306.1096782},
journal = {SIGIR Forum},
month = nov,
pages = {76–85},
numpages = {10}
}

@article{10.1145/101306.1096781,
author = {Bruza, P. D.},
title = {Book Review: Language and Representation in Information Retrieval by D.C. Blair. Elsevier Science Publishers 1990},
year = {1990},
issue_date = {Fall 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/101306.1096781},
doi = {10.1145/101306.1096781},
abstract = {One of the remarkable things about the book Language and Representation in Information Retrieval is the large number of references to philosophers. Wittgenstein is quoted at the beginning of each chapter and there are also references to Hegel, Heiddegger and even to Nietsche. This naturally raises the question as to what these philosophers have to do with Information Retrieval. The answer is that the author considers several issues through the premises of a particular philosophy.},
journal = {SIGIR Forum},
month = nov,
pages = {74–76},
numpages = {3}
}

@article{10.1145/378881.378890,
author = {Humphrey, Susanne M.},
title = {Selected IR-Related Dissertation Abstracts},
year = {1989},
issue_date = {Fall 89/Winter 90},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/378881.378890},
doi = {10.1145/378881.378890},
journal = {SIGIR Forum},
month = sep,
pages = {40–83},
numpages = {44}
}

@article{10.1145/74697.74702,
author = {Kuo, S. and Cross, G. R.},
title = {An Improved Algorithm to Find the Length of the Longest Common Subsequence of Two Strings},
year = {1989},
issue_date = {Spring 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/74697.74702},
doi = {10.1145/74697.74702},
abstract = {Let A and B be strings of common length n. Define LLCS(A, B) to be the length of the longest common subsequence of A and B. Hunt and Szymanski presented an algorithm for finding LLCS(A, B) with time complexity O((r + n)logn), where r is the number of elements in the set {(i, j)|A[i] = B[j]}. In the worst case the algorithm has running time of O(n2logn). We present an improvement to this algorithm which changes the time complexity to O(r + n(LLCS(A, B) + logn)). Some experimental results show dramatic improvements for large n.},
journal = {SIGIR Forum},
month = apr,
pages = {89–99},
numpages = {11}
}

@article{10.1145/30075.30077,
author = {Tague, J.},
title = {Informativeness as an Ordinal Utility Function for Information Retrieval},
year = {1987},
issue_date = {March 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/30075.30077},
doi = {10.1145/30075.30077},
abstract = {Information retrieval has all the elements of a classical decision problem: a set of possible actions, a set of potential states, and a reward or utility attached to each combination of action and state. How the actions, states, and utilities are described, however, is variable, and depends very much on the describer's point of view.},
journal = {SIGIR Forum},
month = mar,
pages = {10–17},
numpages = {8}
}

@article{10.1145/30075.1096829,
author = {Salton, Gerald},
title = {ABSTRACTS (Chosen by G. Salton from Recent Issues of Journals in the Retrieval Area).},
year = {1987},
issue_date = {March 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/30075.1096829},
doi = {10.1145/30075.1096829},
journal = {SIGIR Forum},
month = mar,
pages = {22–37},
numpages = {16}
}

@article{10.1145/1095475.1095476,
author = {Girill, T. R.},
title = {Online Access AIDS for Documentation: A Bibliographic Outline},
year = {1985},
issue_date = {Fall 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095475.1095476},
doi = {10.1145/1095475.1095476},
abstract = {Computer documentation poses three information management problems, access problems that readers face when they try to find answers to questions using the documentation. All three problems arise from a mismatch between what readers want or expect and what document authors provide in (1) vocabulary, (2) text structure, and (3) text scope.},
journal = {SIGIR Forum},
month = sep,
pages = {24–27},
numpages = {4}
}

@article{10.1145/3263609,
author = {Vasta, Bruno},
title = {Session Details: Session 11: Numerical Databases},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263609},
doi = {10.1145/3263609},
journal = {SIGIR Forum},
month = jun,
numpages = {1}
}

@article{10.1145/3263603,
author = {Yu, Clement},
title = {Session Details: Session 5: Statistical Techniques 1},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263603},
doi = {10.1145/3263603},
journal = {SIGIR Forum},
month = jun,
numpages = {1}
}

@article{10.1145/1095460.1095462,
author = {Salton, Gerard},
title = {Abstracts of Slected Journal Articles},
year = {1982},
issue_date = {Summer 1982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095460.1095462},
doi = {10.1145/1095460.1095462},
journal = {SIGIR Forum},
month = jul,
pages = {23–33},
numpages = {11}
}

@article{10.1145/1095425.1095428,
author = {Salton, G.},
title = {Abstracts: Chosen by G. Salton from Current Issues of Journals in the Retrieval Area},
year = {1981},
issue_date = {Fall 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095425.1095428},
doi = {10.1145/1095425.1095428},
journal = {SIGIR Forum},
month = sep,
pages = {39–45},
numpages = {7}
}

@article{10.1145/1095425.1095426,
title = {Summaries of Papers: British Computer Society Information Retrieval Specialist Group Third Research Colloquium},
year = {1981},
issue_date = {Fall 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095425.1095426},
doi = {10.1145/1095425.1095426},
abstract = {At the heart of much research in information systems lies the problem of matching the query terms supplied by a searcher with the terms under which information has previously been indexed, particularly where a controlled standard thesaurus cannot be used.},
journal = {SIGIR Forum},
month = sep,
pages = {12–21},
numpages = {10}
}

@article{10.1145/1095383.1095385,
author = {Wiersba, Richard K.},
title = {Review of "Information Retrieval: Computational and Theoretical Aspects, by H. S. Heaps", Academic Press Inc.},
year = {1980},
issue_date = {Winter 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095383.1095385},
doi = {10.1145/1095383.1095385},
abstract = {The author of this book has done an excellent job of achieving at least one portion of his two-fold purpose: "...to introduce the computer science student to some of the basic problems of information retrieval and to describe the techniques required to develop suitable computer programs, ... (and) ... to describe the general structure of the relevant computer programs so that basic design considerations may be understood by information officers and librarians will find this text palatable."},
journal = {SIGIR Forum},
month = jan,
pages = {10–16},
numpages = {7}
}

@article{10.1145/983026.983023,
author = {El Masri, A. and Rohmer, J. and Tusera, D.},
title = {A Machine for Information Retrieval},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983023},
doi = {10.1145/983026.983023},
journal = {SIGIR Forum},
month = aug,
pages = {117–120},
numpages = {4}
}

@article{10.1145/983026.983015,
author = {Harvill, J. B.},
title = {Functional Parallelism in an Operand State Saving Computer},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983015},
doi = {10.1145/983026.983015},
abstract = {Multiple, high-level operators are assigned to a general operand. The operators are implemented with individual micro-processors and are "attached" dynamically to the memory location representing the "current" value of the operand. The operators then asynchronously use each new operand value as it is stored and perform their operations in parallel. The proposed architecture represents a true M I S D (Multiple Instruction Stream - Single Data Stream) computer. Its architecture can provide effective parallelism and reduced programming complexity for a large class of both numeric and non-numeric computer problems.},
journal = {SIGIR Forum},
month = aug,
pages = {77–84},
numpages = {8}
}

@article{10.1145/983026.983012,
author = {Gouda, Mohamed G.},
title = {A Hierarchical Controller for Concurrent Accessing of Distributed Databases},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983012},
doi = {10.1145/983026.983012},
abstract = {An access controller for a distributed database is a (central or distributed) structure which routes access requests to the different components of the database. Such a controller is also supposed to resolve the conflicts between concurrent requests, if any, such that deadlock situations never arise.In this paper, some architectures for distributed access controllers of distributed databases are investigated. In particular, three controllers with hierarchical architectures are considered. The controllers are evaluated based on three criteria: (i) freedom of deadlocks, (ii) robustness, and (iii) parallelism. The third criterion implies that the added redundancy to increase the controller robustness against failure conditions should also contribute to the amount of achieved parallelism during the no-failure periods. We then define a controller architecture which satisfies all the three criteria.},
journal = {SIGIR Forum},
month = aug,
pages = {65–70},
numpages = {6}
}

@article{10.1145/983026.983011,
author = {Stucki, M. J. and Cox, J. R. and Roman, G. C. and Turcu, P. N.},
title = {Coordinating Concurrent Access in a Distributed Database Architecture},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983011},
doi = {10.1145/983026.983011},
abstract = {A distributed architecture for an interactive information system is described, and a scheme for coordinating concurrent access to its data is presented. The scheme is deadlock free and is carried out without the need for centralized control. Conflicts are detected as they occur, and competing processes are given exclusive access to the data they need.},
journal = {SIGIR Forum},
month = aug,
pages = {60–64},
numpages = {5}
}

@article{10.1145/983026.983009,
author = {Roberts, David C.},
title = {A Specialized Computer Architecture for Text Retrieval},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983009},
doi = {10.1145/983026.983009},
abstract = {This paper describes a specialized computer architecture for text retrieval that provides a wide range of query capabilities, without the use of indexes of the material retrieved. A distributed approach is employed, with direct search processors. Each search processor is closely associated with one or more disk drives that store the data to be searched and each consists of a comparator for matching query terms, logic elements to combine query terms, a disk controller and a control minicomputer.The key element of the architecture is the comparator, which can store over 64,000 characters of query terms and compare all of these terms simultaneously with data arriving from a disk continuously at more than one million bytes per second. Exact match, partical match, numeric comparison and context limitation are among the capabilities provided. The comparator is implemented as three similar universal finite-state automata, with special features to facilitate text retrieval and reduce hardware costs.A breadboard version of the system with one searcher is operational and has undergone detailed evaluation. A prototype system with two searchers is being implemented and will be placed into regularly scheduled use.},
journal = {SIGIR Forum},
month = aug,
pages = {51–59},
numpages = {9}
}

@article{10.1145/983026.983006,
author = {Williams, Rhon},
title = {A Multiprocessing System for the Direct Execution of LISP},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983006},
doi = {10.1145/983026.983006},
abstract = {Current implementations were found to be impractical for airborne use due to LISP's incompatability with conventional computer architectures. Direct execution of LISP with tasks distributed between three processors, seemed to be a workable solution. The language was analyzed, and a special token was devised, using a descriptor with a single pointer. Through careful distribution of responsibilities, control and data flow between the processors was minimized. Significant memory savings resulted from ASCII storage and real time garbage collection. A simulation was used to help estimate execution times and showed a factor of 50 to 100 increase in speed. Thus, through the direct execution of LISP by a multiprocessing system, Computer-Aided Decision-Making could be implimented to enhance the safety of flight operations.},
journal = {SIGIR Forum},
month = aug,
pages = {35–41},
numpages = {7}
}

@article{10.1145/3263599,
author = {Hsiao, David K.},
title = {Session Details: Session 10},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263599},
doi = {10.1145/3263599},
journal = {SIGIR Forum},
month = aug,
numpages = {1}
}

@article{10.1145/3263597,
author = {Korfhage, Robert},
title = {Session Details: Session 7},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263597},
doi = {10.1145/3263597},
journal = {SIGIR Forum},
month = aug,
numpages = {1}
}

@article{10.1145/1095286.1095299,
author = {Emam, Ahmed and Su, Stanley Y. W. and Lipovski, G. J.},
title = {Software Aspect of the CASSM System},
year = {1976},
issue_date = {Spring 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095286.1095299},
doi = {10.1145/1095286.1095299},
abstract = {This paper deals with the software aspect of the CASSM system. A high level language for large data base management, CASDAL, a compiler for that language, and a cross assembler, CASSMBLR, designed and implemented for the CASSM system are described.},
journal = {SIGIR Forum},
month = apr,
pages = {29–31},
numpages = {3}
}

@article{10.1145/1095286.1095297,
author = {Schuster, S. A. and Ozkarahan, E. A. and Smith, K. C.},
title = {A Virtual Memory System for a Relational Associative Processor},
year = {1976},
issue_date = {Spring 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095286.1095297},
doi = {10.1145/1095286.1095297},
abstract = {The Relational Associative Processor (RAP) is an experimental "backend" cellular processor for implementing a data base management system which supports Codd's relational model of data. The capacity of a RAP device implemented with current IC and memory technology can be estimated to contain 108 to 109 bits of associatively processable data. Because of this limitation, a virtual memory environment for RAP has been proposed and its performance simulated. The environment incorporates conventional memories for bulk storage and a single RAP processor both controlled by a front-end computer. An entire relational data base is divided into pages of size equal to one RAP cell memory. A buffer memory is added to RAP to permit the overlap of paging with processing. It has been found that environments which process user queries that exhibit long processing times relative to paging time or some "locality", that is, a better than random probability of referencing the same relations over some interval of time, can efficiently page data from large data bases without significant losses in performance.},
journal = {SIGIR Forum},
month = apr,
pages = {25–26},
numpages = {2},
keywords = {simulation, relational data bases, data base machines, virtual memory, associative processors}
}

@article{10.1145/1095286.1095287,
author = {Jordan, B. W. and King, K. J. and Miller, G. D.},
title = {File Operations in a Streaming Processor},
year = {1976},
issue_date = {Spring 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095286.1095287},
doi = {10.1145/1095286.1095287},
abstract = {There are several operations in non-numeric processing which can be classified as file operations. These operations include such things as sorting, searching, and table lookup. They are characterized by their repetitious, homogeneous treatment of fields within records within files. Present computer organizations generally require several instructions imbedded in a loop to process each source-operand pair. This paper outlines a computer organization (called a streaming processor) which operates on long data streams with considerably less instruction processing overhead: fetching and decoding. Thus a greater percentage of the storage bandwidth is used for data and consequently the streaming processor is more efficient for such file operations.},
journal = {SIGIR Forum},
month = apr,
pages = {6},
numpages = {1}
}

@article{10.1145/1095277.1095283,
author = {Navathe, Shamkant B. and Fry, James P.},
title = {Restructuring for Large Data Bases: Three Levels of Abstraction},
year = {1975},
issue_date = {Winter 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095277.1095283},
doi = {10.1145/1095277.1095283},
abstract = {The development of a powerful restructuring function involves two important components - the unambiguous specification of the restructuring operations and the realization of these operations in a software system. We direct our efforts to the first component in the belief that a precise specification will provide a firm foundation for restructuring algorithms and implementations. This paper defines completely the semantics of the restructuring of tree structured data bases.The delineation of the restructuring function is accomplished by formulating three different levels of abstraction, with each level of abstraction representing successively more detailed semantics of the function.At the first level of abstraction, the schema modification, three types are identified: naming, combining and relating, and are further divided into eight schema operations. The second level of abstraction, the instance operations, constitutes the transformations on the data instances. They are divided into group operations such as replication, factoring, union and group relation operations such as collapsing, refinement, fusion etc. The final level, the item values operations, includes the actual item operations such as copy value, delete value, or create a null value.},
journal = {SIGIR Forum},
month = dec,
pages = {13},
numpages = {1},
keywords = {data definition, data translation, data base, data restructuring}
}

@article{10.1145/75335.75353,
author = {Chang, J. W. and Lee, J. H. and Lee, Y. J.},
title = {Multikey Access Methods Based on Term Discrimination and Signature Clustering},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75353},
doi = {10.1145/75335.75353},
abstract = {In order to improve the two-level signature file method designed by Sacks-Davis et al. [20], we propose new multikey access methods based on term discrimination and signature clustering. By term discrimination, we create separate, efficient access methods for the terms frequently used in user queries. We in addition cluster similar signatures by means of these terms so that we may achieve good performance on retrieval. Meanwhile we provide the space-time analysis of the proposed methods and compare them with the two-level signature file method. We show that the proposed methods achieve 15-30% savings in retrieval time and require 3-9 % more storage overhead.},
journal = {SIGIR Forum},
month = may,
pages = {176–185},
numpages = {10}
}

@inproceedings{10.1145/75334.75353,
author = {Chang, J. W. and Lee, J. H. and Lee, Y. J.},
title = {Multikey Access Methods Based on Term Discrimination and Signature Clustering},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75353},
doi = {10.1145/75334.75353},
abstract = {In order to improve the two-level signature file method designed by Sacks-Davis et al. [20], we propose new multikey access methods based on term discrimination and signature clustering. By term discrimination, we create separate, efficient access methods for the terms frequently used in user queries. We in addition cluster similar signatures by means of these terms so that we may achieve good performance on retrieval. Meanwhile we provide the space-time analysis of the proposed methods and compare them with the two-level signature file method. We show that the proposed methods achieve 15-30% savings in retrieval time and require 3-9 % more storage overhead.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {176–185},
numpages = {10},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/75335.75345,
author = {Stanfill, C. and Thau, R. and Waltz, D.},
title = {A Parallel Indexed Algorithm for Information Retrieval},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75345},
doi = {10.1145/75335.75345},
abstract = {In this paper we present a parallel document ranking algorithm suitable for use on databases of 1-1000 GB, resident on primary or secondary storage. The algorithm is based on inverted indexes, and has two advantages over a previously published parallel algorithm for retrieval based on signature files. First, it permits the employment of ranking strategies which cannot be easily implemented using signature files, specifically methods which depend on document-term weighting. Second, it permits the interactive searching of databases resident on secondary storage. The algorithm is evaluated via a mixture of analytic and simulation techniques, with a particular focus on how cost-effectiveness and efficiency change as the size of the database, number of processors, and cost of memory are altered. In particular, we find that if the ratio of the number of processors and/or disks to the size of the database is held constant, then the cost-effectiveness of the resulting system remains constant. Furthermore, for a given size of database, there is a number of processors which optimizes cost-effectiveness. Estimated response times are also presented. Using these methods, it appears that cost-effective interactive access to databases in the 100-1000 GB range can be achieved using current technology.},
journal = {SIGIR Forum},
month = may,
pages = {88–97},
numpages = {10}
}

@inproceedings{10.1145/75334.75345,
author = {Stanfill, C. and Thau, R. and Waltz, D.},
title = {A Parallel Indexed Algorithm for Information Retrieval},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75345},
doi = {10.1145/75334.75345},
abstract = {In this paper we present a parallel document ranking algorithm suitable for use on databases of 1-1000 GB, resident on primary or secondary storage. The algorithm is based on inverted indexes, and has two advantages over a previously published parallel algorithm for retrieval based on signature files. First, it permits the employment of ranking strategies which cannot be easily implemented using signature files, specifically methods which depend on document-term weighting. Second, it permits the interactive searching of databases resident on secondary storage. The algorithm is evaluated via a mixture of analytic and simulation techniques, with a particular focus on how cost-effectiveness and efficiency change as the size of the database, number of processors, and cost of memory are altered. In particular, we find that if the ratio of the number of processors and/or disks to the size of the database is held constant, then the cost-effectiveness of the resulting system remains constant. Furthermore, for a given size of database, there is a number of processors which optimizes cost-effectiveness. Estimated response times are also presented. Using these methods, it appears that cost-effective interactive access to databases in the 100-1000 GB range can be achieved using current technology.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {88–97},
numpages = {10},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/75335.75342,
author = {Raghavan, V. V. and Bollmann, P. and Jung, G. S.},
title = {Retrieval System Evaluation Using Recall and Precision: Problems and Answers},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75342},
doi = {10.1145/75335.75342},
journal = {SIGIR Forum},
month = may,
pages = {59–68},
numpages = {10}
}

@inproceedings{10.1145/75334.75342,
author = {Raghavan, V. V. and Bollmann, P. and Jung, G. S.},
title = {Retrieval System Evaluation Using Recall and Precision: Problems and Answers},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75342},
doi = {10.1145/75334.75342},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {59–68},
numpages = {10},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/75335.75339,
author = {Godin, R. and Pichet, C. and Gecsei, J.},
title = {Design of a Browsing Interface for Information Retrieval},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75339},
doi = {10.1145/75335.75339},
abstract = {In conventional Boolean retrieval systems, users have difficulty controlling the amount of output obtained from a given query. This paper describes the design of a user interface which permits gradual enlargement or refinement of the user's query by browsing through a graph of term and document subsets. This graph is obtained from a lattice automatically generated from the usual document-term relation. The major design features of the proposed interface are the integration of menu, fill-in the blank and direct manipulation modes of interaction within the “fisheye view” [Furnas, 1986] paradigm. A prototype user interface incorporating some of these ideas has been implemented on a microcomputer.The resulting interface is well adapted to various kinds of users and needs. More experienced users with a particular subject in mind can directly specify a query which results into a jump to a particular vertex in the graph. From there, the user can refine his initial query by browsing through the graph from that point on. On the other hand, casual users without any prior knowledge of the contents of the system or users without any particular subject in mind can freely navigate through the graph without ever specifying any query.},
journal = {SIGIR Forum},
month = may,
pages = {32–39},
numpages = {8}
}

@inproceedings{10.1145/75334.75339,
author = {Godin, R. and Pichet, C. and Gecsei, J.},
title = {Design of a Browsing Interface for Information Retrieval},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75339},
doi = {10.1145/75334.75339},
abstract = {In conventional Boolean retrieval systems, users have difficulty controlling the amount of output obtained from a given query. This paper describes the design of a user interface which permits gradual enlargement or refinement of the user's query by browsing through a graph of term and document subsets. This graph is obtained from a lattice automatically generated from the usual document-term relation. The major design features of the proposed interface are the integration of menu, fill-in the blank and direct manipulation modes of interaction within the “fisheye view” [Furnas, 1986] paradigm. A prototype user interface incorporating some of these ideas has been implemented on a microcomputer.The resulting interface is well adapted to various kinds of users and needs. More experienced users with a particular subject in mind can directly specify a query which results into a jump to a particular vertex in the graph. From there, the user can refine his initial query by browsing through the graph from that point on. On the other hand, casual users without any prior knowledge of the contents of the system or users without any particular subject in mind can freely navigate through the graph without ever specifying any query.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {32–39},
numpages = {8},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/75335.75337,
author = {Belew, R. K.},
title = {Adaptive Information Retrieval: Using a Connectionist Representation to Retrieve and Learn about Documents},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75337},
doi = {10.1145/75335.75337},
abstract = {AIR represents a connectionist approach to the task of information retrieval. The system uses relevance feedback from its users to change its representation of authors, index terms and documents so that, over time, AIR improves at its task. The result is a representation of the consensual meaning of keywords and documents shared by some group of users. The central focus goal of this paper is to use our experience with AIR to highlight those characteristics of connectionist representations that make them particularly appropriate for IR applications. We argue that this associative representation is a natural generalization of traditional IR techniques, and that connectionist learning techniques are effective in this setting.},
journal = {SIGIR Forum},
month = may,
pages = {11–20},
numpages = {10}
}

@inproceedings{10.1145/75334.75337,
author = {Belew, R. K.},
title = {Adaptive Information Retrieval: Using a Connectionist Representation to Retrieve and Learn about Documents},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75337},
doi = {10.1145/75334.75337},
abstract = {AIR represents a connectionist approach to the task of information retrieval. The system uses relevance feedback from its users to change its representation of authors, index terms and documents so that, over time, AIR improves at its task. The result is a representation of the consensual meaning of keywords and documents shared by some group of users. The central focus goal of this paper is to use our experience with AIR to highlight those characteristics of connectionist representations that make them particularly appropriate for IR applications. We argue that this associative representation is a natural generalization of traditional IR techniques, and that connectionist learning techniques are effective in this setting.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {11–20},
numpages = {10},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/1013230.511818,
author = {Borgman, Christine L.},
title = {End User Behavior on an Online Information Retrieval System: A Computer Monitoring Study},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511818},
doi = {10.1145/1013230.511818},
abstract = {We report on a computer monitoring study of users of the Ohio State University Libraries' online catalog, an established and heavily used information retrieval system. To our knowledge, this is the first monitoring study of an online catalog performed without system-defined user sessions. Online catalogs represent a class of retrieval systems which are designed for end users, require little or no formal training, and replace an existing manual system. The study characterizes user behavior in terms of types of searches done, patterns of use, time spent on searching, errors, and system problems. Preliminary results suggest that users have much shorter sessions than on other types of retrieval systems. Patterns of use vary between campus libraries, academic quarters, and between short and long sessions. Results of the study will be applied to improving the user interface and other system features.},
journal = {SIGIR Forum},
month = jun,
pages = {162–176},
numpages = {15}
}

@inproceedings{10.1145/511793.511818,
author = {Borgman, Christine L.},
title = {End User Behavior on an Online Information Retrieval System: A Computer Monitoring Study},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511818},
doi = {10.1145/511793.511818},
abstract = {We report on a computer monitoring study of users of the Ohio State University Libraries' online catalog, an established and heavily used information retrieval system. To our knowledge, this is the first monitoring study of an online catalog performed without system-defined user sessions. Online catalogs represent a class of retrieval systems which are designed for end users, require little or no formal training, and replace an existing manual system. The study characterizes user behavior in terms of types of searches done, patterns of use, time spent on searching, errors, and system problems. Preliminary results suggest that users have much shorter sessions than on other types of retrieval systems. Patterns of use vary between campus libraries, academic quarters, and between short and long sessions. Results of the study will be applied to improving the user interface and other system features.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {162–176},
numpages = {15},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013228.511773,
author = {Carroll, John M.},
title = {Content Analysis as a Word-Processing Option},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511773},
doi = {10.1145/1013228.511773},
abstract = {A simple content-analysis program incorporated in a word-processing system can display the most significant sentence of a page of text and give a short list of the more important words. This could help authors write titles, summaries, and descriptor lists. The content-analysis program relies on word frequency, precedence, and co-occurrence as indicators of content significance. Test show it performs at least as well as some trained indexers.},
journal = {SIGIR Forum},
month = may,
pages = {126–131},
numpages = {6}
}

@inproceedings{10.1145/511754.511773,
author = {Carroll, John M.},
title = {Content Analysis as a Word-Processing Option},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511773},
doi = {10.1145/511754.511773},
abstract = {A simple content-analysis program incorporated in a word-processing system can display the most significant sentence of a page of text and give a short list of the more important words. This could help authors write titles, summaries, and descriptor lists. The content-analysis program relies on word frequency, precedence, and co-occurrence as indicators of content significance. Test show it performs at least as well as some trained indexers.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {126–131},
numpages = {6},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013228.511759,
author = {Wu, Harry and Salton, Gerard},
title = {A Comparison of Search Term Weighting: Term Relevance vs. Inverse Document Frequency},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511759},
doi = {10.1145/1013228.511759},
abstract = {The term relevance weighting method has been shown to produce optimal information retrieval queries under well-defined conditions. The parameters needed to generate the term relevance factors cannot unfortunately be estimated accurately in practice; futhermore, in realistic test situations, it appears difficult to obtain improved retrieval results using the term relevance weights over much simpler term weighting systems such as, for example, the inverse document frequency weights.It is shown in this study that the inverse document frequency weights and the term relevance weights are closely related over a wide range of the frequency spectrum. Methods are introduced for estimating the term relevance weights, and experimental results are given comparing the inverse document frequency with the estimated term relevance weights.},
journal = {SIGIR Forum},
month = may,
pages = {30–39},
numpages = {10}
}

@inproceedings{10.1145/511754.511759,
author = {Wu, Harry and Salton, Gerard},
title = {A Comparison of Search Term Weighting: Term Relevance vs. Inverse Document Frequency},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511759},
doi = {10.1145/511754.511759},
abstract = {The term relevance weighting method has been shown to produce optimal information retrieval queries under well-defined conditions. The parameters needed to generate the term relevance factors cannot unfortunately be estimated accurately in practice; futhermore, in realistic test situations, it appears difficult to obtain improved retrieval results using the term relevance weights over much simpler term weighting systems such as, for example, the inverse document frequency weights.It is shown in this study that the inverse document frequency weights and the term relevance weights are closely related over a wide range of the frequency spectrum. Methods are introduced for estimating the term relevance weights, and experimental results are given comparing the inverse document frequency with the estimated term relevance weights.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {30–39},
numpages = {10},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013228.511757,
author = {Bollmann, P. and Cherniavsky, V. S.},
title = {Restricted Evaluation in Information Retrieval},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511757},
doi = {10.1145/1013228.511757},
journal = {SIGIR Forum},
month = may,
pages = {15–21},
numpages = {7}
}

@inproceedings{10.1145/511754.511757,
author = {Bollmann, P. and Cherniavsky, V. S.},
title = {Restricted Evaluation in Information Retrieval},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511757},
doi = {10.1145/511754.511757},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {15–21},
numpages = {7},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013881.802701,
author = {Creutz, G. and Kiel, F.},
title = {An Approach towards Information Systems with Very Large Numbers of Subscribers},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802701},
doi = {10.1145/1013881.802701},
abstract = {The Federal Ministry of Research and Technology (BMFT) took the initiative in starting a project concerning two-way cable television in 1976 at the Heinrich-Hertz-Institute. The two-way cable television provided a model for investigating the possibilities of new screen-orientated, interactive systems for large numbers of subscribers using alpha-numerics, graphics, motion-pictures, and sound.One of the most important research aspects proved to be the construction of a computer control centre which would cater for this type of hybrid information system.At present a laboratory model of such a control centre is being developed by the Heinrich-Hertz-Institute in collaboration with the Computer Industry. This model is based on a mini-computer multi-processor system.},
journal = {SIGIR Forum},
month = mar,
pages = {126–127},
numpages = {2}
}

@inproceedings{10.1145/800083.802701,
author = {Creutz, G. and Kiel, F.},
title = {An Approach towards Information Systems with Very Large Numbers of Subscribers},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802701},
doi = {10.1145/800083.802701},
abstract = {The Federal Ministry of Research and Technology (BMFT) took the initiative in starting a project concerning two-way cable television in 1976 at the Heinrich-Hertz-Institute. The two-way cable television provided a model for investigating the possibilities of new screen-orientated, interactive systems for large numbers of subscribers using alpha-numerics, graphics, motion-pictures, and sound.One of the most important research aspects proved to be the construction of a computer control centre which would cater for this type of hybrid information system.At present a laboratory model of such a control centre is being developed by the Heinrich-Hertz-Institute in collaboration with the Computer Industry. This model is based on a mini-computer multi-processor system.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {126–127},
numpages = {2},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013881.802699,
author = {Toong, Hoo-min D. and Strommen, Svein O. and Goodrich, Earl R.},
title = {A General Multi-Microprocessor Interconnection Mechanism for Non-Numeric Processing},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802699},
doi = {10.1145/1013881.802699},
abstract = {MMPS interconnection problems are discussed in terms of a single time-shared bus. The performance drawbacks usually associated with the single bus alternative are attributed to the high bus utilization at the basic building block level. The Pended Transaction Bus protocol is presented as a general solution to such utilizations. Such a bus is developed to support more than 50 processors without severe contention. The basic protocol of the MC68000 as a current generation microprocessor is investigated, and shown ineffective for true multi-microprocessor systems.},
journal = {SIGIR Forum},
month = mar,
pages = {115–123},
numpages = {9}
}

@inproceedings{10.1145/800083.802699,
author = {Toong, Hoo-min D. and Strommen, Svein O. and Goodrich, Earl R.},
title = {A General Multi-Microprocessor Interconnection Mechanism for Non-Numeric Processing},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802699},
doi = {10.1145/800083.802699},
abstract = {MMPS interconnection problems are discussed in terms of a single time-shared bus. The performance drawbacks usually associated with the single bus alternative are attributed to the high bus utilization at the basic building block level. The Pended Transaction Bus protocol is presented as a general solution to such utilizations. Such a bus is developed to support more than 50 processors without severe contention. The basic protocol of the MC68000 as a current generation microprocessor is investigated, and shown ineffective for true multi-microprocessor systems.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {115–123},
numpages = {9},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013232.511719,
author = {Fayen, Emily G. and Baird, Susan B.},
title = {On-Line Personal Bibliographic Retrieval System},
year = {1979},
issue_date = {September 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013232.511719},
doi = {10.1145/1013232.511719},
abstract = {The Norris Cotton Cancer Center (NCCC) On-Line Personal Bibliographic Retrieval System was developed to assist researchers at the Center in managing personal or project-related collections of reference materials. The system supports on-line entry, storage, and retrieval of bibliographic citations for collections of books, journal articles, reprints, reports, manuscripts, other documents, and audio-visual materials.The NCCC system is intended for relatively small collections of materials (under 10,000 items) and is not intended to duplicate or compete in any way with MEDLARS, CANCERLINE, or any of the other on-line bibliographic retrieval services. It is similar in concept to Mitre's SHOEBOX (1), but is much less complex and requires far less computer resources. The major advantage of the NCCC system is that it is simple, small, and easy to use.None of the techniques used in developing the NCCC system is particularly new or innovative. Rather, several well-known approaches to bibliographic retrieval were combined to produce a system that was easy and inexpensive to develop and is easy and inexpensive to use. The system is now running on the Dartmouth College Computing system's equivalent of a Honeywell 66/DPS-3. The programs are all written in BASIC.},
journal = {SIGIR Forum},
month = sep,
pages = {83–86},
numpages = {4}
}

@inproceedings{10.1145/511706.511719,
author = {Fayen, Emily G. and Baird, Susan B.},
title = {On-Line Personal Bibliographic Retrieval System},
year = {1979},
isbn = {9781450373456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511706.511719},
doi = {10.1145/511706.511719},
abstract = {The Norris Cotton Cancer Center (NCCC) On-Line Personal Bibliographic Retrieval System was developed to assist researchers at the Center in managing personal or project-related collections of reference materials. The system supports on-line entry, storage, and retrieval of bibliographic citations for collections of books, journal articles, reprints, reports, manuscripts, other documents, and audio-visual materials.The NCCC system is intended for relatively small collections of materials (under 10,000 items) and is not intended to duplicate or compete in any way with MEDLARS, CANCERLINE, or any of the other on-line bibliographic retrieval services. It is similar in concept to Mitre's SHOEBOX (1), but is much less complex and requires far less computer resources. The major advantage of the NCCC system is that it is simple, small, and easy to use.None of the techniques used in developing the NCCC system is particularly new or innovative. Rather, several well-known approaches to bibliographic retrieval were combined to produce a system that was easy and inexpensive to develop and is easy and inexpensive to use. The system is now running on the Dartmouth College Computing system's equivalent of a Honeywell 66/DPS-3. The programs are all written in BASIC.},
booktitle = {Proceedings of the 2nd Annual International ACM SIGIR Conference on Information Storage and Retrieval: Information Implications into the Eighties},
pages = {83–86},
numpages = {4},
location = {Dallas, Texas},
series = {SIGIR '79}
}

@article{10.1145/1013234.803144,
title = {MAGIC},
year = {1978},
issue_date = {May 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013234.803144},
doi = {10.1145/1013234.803144},
abstract = {MAGIC is a simple, elegant, and time-saving system for retrieving, manipulating, and displaying time series data. The user of MAGIC is not required to know anything about file structures or computer programming. Finished reports and graphs suitable for reproduction are attainable after minimal experience with the MAGIC system.},
journal = {SIGIR Forum},
month = may,
pages = {177},
numpages = {1}
}

@inproceedings{10.1145/800096.803144,
title = {MAGIC},
year = {1978},
isbn = {9781450374026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800096.803144},
doi = {10.1145/800096.803144},
abstract = {MAGIC is a simple, elegant, and time-saving system for retrieving, manipulating, and displaying time series data. The user of MAGIC is not required to know anything about file structures or computer programming. Finished reports and graphs suitable for reproduction are attainable after minimal experience with the MAGIC system.},
booktitle = {Proceedings of the 1st Annual International ACM SIGIR Conference on Information Storage and Retrieval},
pages = {177},
numpages = {1},
series = {SIGIR '78}
}

@article{10.1145/1013234.803140,
author = {Raghavan, Vijay V. and Yu, C. T.},
title = {Experiments on the Determination of the Relationships between Terms},
year = {1978},
issue_date = {May 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013234.803140},
doi = {10.1145/1013234.803140},
abstract = {The retrieval effectiveness of an automatic method that uses relevance judgements for the determination of positive as well as negative relationships between terms is evaluated. The term relationships are incorporated into the retrieval process by using a generalized similarity function that has a term match component, a positive term relationship component, and a negative term relationship component. Two strategies, query partitioning and query clustering, for the evaluation of the effectiveness of the term relationships are investigated. The latter appears to be more attractive from linguistic as well as economic points of view. The positive and the negative relationships are verified to be effective both when used individually, and in combination. The importance attached to the term relationship components relative to that of term match component is found to have a substantial effect on the retrieval performance. The usefulness of discriminant analysis as a technique for determining the relative importance of these components is investigated.},
journal = {SIGIR Forum},
month = may,
pages = {150},
numpages = {1}
}

@inproceedings{10.1145/800096.803140,
author = {Raghavan, Vijay V. and Yu, C. T.},
title = {Experiments on the Determination of the Relationships between Terms},
year = {1978},
isbn = {9781450374026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800096.803140},
doi = {10.1145/800096.803140},
abstract = {The retrieval effectiveness of an automatic method that uses relevance judgements for the determination of positive as well as negative relationships between terms is evaluated. The term relationships are incorporated into the retrieval process by using a generalized similarity function that has a term match component, a positive term relationship component, and a negative term relationship component. Two strategies, query partitioning and query clustering, for the evaluation of the effectiveness of the term relationships are investigated. The latter appears to be more attractive from linguistic as well as economic points of view. The positive and the negative relationships are verified to be effective both when used individually, and in combination. The importance attached to the term relationship components relative to that of term match component is found to have a substantial effect on the retrieval performance. The usefulness of discriminant analysis as a technique for determining the relative importance of these components is investigated.},
booktitle = {Proceedings of the 1st Annual International ACM SIGIR Conference on Information Storage and Retrieval},
pages = {150},
numpages = {1},
series = {SIGIR '78}
}

@article{10.1145/1013234.803139,
author = {Eastman, Caroline M. and Weiss, Stephen F.},
title = {A Tree Algorithm for Nearest Neighbor Searching in Document Retrieval Systems},
year = {1978},
issue_date = {May 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013234.803139},
doi = {10.1145/1013234.803139},
abstract = {The problem of finding nearest neighbors to a query in a document collection is a special case of associative retrieval, in which searches are performed using more than one key. A nearest neighbors associative retrieval algorithm, suitable for document retrieval using similarity matching, is described. The basic structure used is a binary tree, at each node a set of keys (concepts) is tested to select the most promising branch. Backtracking to initially rejected branches is allowed and often necessary.Under certain conditions, the search time required by this algorithm is 0(log2N)k. N is the number of documents, and k is a system-dependent parameter. A series of experiments with a small collection confirm the predictions made using the analytic model; k is approximately 4 in this situation.This algorithm is compared with two other searching algorithms; sequential search and clustered search. For large collections, the average search time for this algorithm is less than that for a sequential search and greater than that for a clustered search. However, the clustered search, unlike the sequential search and this algorithm, does not guarantee that the near neighbors found are actually the nearest neighbors.},
journal = {SIGIR Forum},
month = may,
pages = {131–149},
numpages = {19}
}

@inproceedings{10.1145/800096.803139,
author = {Eastman, Caroline M. and Weiss, Stephen F.},
title = {A Tree Algorithm for Nearest Neighbor Searching in Document Retrieval Systems},
year = {1978},
isbn = {9781450374026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800096.803139},
doi = {10.1145/800096.803139},
abstract = {The problem of finding nearest neighbors to a query in a document collection is a special case of associative retrieval, in which searches are performed using more than one key. A nearest neighbors associative retrieval algorithm, suitable for document retrieval using similarity matching, is described. The basic structure used is a binary tree, at each node a set of keys (concepts) is tested to select the most promising branch. Backtracking to initially rejected branches is allowed and often necessary.Under certain conditions, the search time required by this algorithm is 0(log2N)k. N is the number of documents, and k is a system-dependent parameter. A series of experiments with a small collection confirm the predictions made using the analytic model; k is approximately 4 in this situation.This algorithm is compared with two other searching algorithms; sequential search and clustered search. For large collections, the average search time for this algorithm is less than that for a sequential search and greater than that for a clustered search. However, the clustered search, unlike the sequential search and this algorithm, does not guarantee that the near neighbors found are actually the nearest neighbors.},
booktitle = {Proceedings of the 1st Annual International ACM SIGIR Conference on Information Storage and Retrieval},
pages = {131–149},
numpages = {19},
series = {SIGIR '78}
}

@article{10.1145/1013234.803138,
author = {Baxter, Anthony Q. and Johnson, Rowland R.},
title = {A Block Structured Query Language for Accessing a Relational Data Base},
year = {1978},
issue_date = {May 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013234.803138},
doi = {10.1145/1013234.803138},
abstract = {This paper describes a Block Structured Query Language (BSQL) to be used with relational data bases. The syntax of the language is presented and discussed. Facilities of the language are illustrated by examples of actual queries. In particular we demonstrate the ability of BSQL to obtain useful information from a relational data base that is incomplete. A relational calculus is then presented which forms a basis for a formalism which precisely describes the semantics of BSQL. Finally, comparative examples with other query languages are given.},
journal = {SIGIR Forum},
month = may,
pages = {109–130},
numpages = {22},
keywords = {Query languages, Data base languages}
}

@inproceedings{10.1145/800096.803138,
author = {Baxter, Anthony Q. and Johnson, Rowland R.},
title = {A Block Structured Query Language for Accessing a Relational Data Base},
year = {1978},
isbn = {9781450374026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800096.803138},
doi = {10.1145/800096.803138},
abstract = {This paper describes a Block Structured Query Language (BSQL) to be used with relational data bases. The syntax of the language is presented and discussed. Facilities of the language are illustrated by examples of actual queries. In particular we demonstrate the ability of BSQL to obtain useful information from a relational data base that is incomplete. A relational calculus is then presented which forms a basis for a formalism which precisely describes the semantics of BSQL. Finally, comparative examples with other query languages are given.},
booktitle = {Proceedings of the 1st Annual International ACM SIGIR Conference on Information Storage and Retrieval},
pages = {109–130},
numpages = {22},
keywords = {Data base languages, Query languages},
series = {SIGIR '78}
}

@article{10.1145/1147197.1147205,
author = {Voorhees, Ellen M.},
title = {The TREC 2005 Robust Track},
year = {2006},
issue_date = {June 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1147197.1147205},
doi = {10.1145/1147197.1147205},
abstract = {The TREC robust retrieval track explores methods for improving the consistency of retrieval technology by focusing on poorly performing topics. The retrieval task in the track is a traditional ad hoc retrieval task where the evaluation methodology emphasizes a system's least effective topics. The 2005 edition of the track used 50 topics that had been demonstrated to be difficult on one document collection, and ran those topics on a different document collection. Relevance information from the first collection could be exploited in producing a query for the second collection, if desired. As in previous years, the most effective retrieval strategy was to expand queries using terms derived from additional corpora. The relative difficulty of topics differed across the two document sets.},
journal = {SIGIR Forum},
month = jun,
pages = {41–48},
numpages = {8}
}

@article{10.1145/207556.207558,
author = {Korfhage, Robert},
title = {Some Thoughts on Similarity Measures},
year = {1995},
issue_date = {Spring 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/207556.207558},
doi = {10.1145/207556.207558},
journal = {SIGIR Forum},
month = mar,
pages = {8},
numpages = {1}
}

@article{10.1145/146565.146569,
author = {Gallant, Stephen I. and Caid, William R. and Carleton, Joel and Hecht-Nielsen, Robert and Qing, Kent Pu and Sudbeck, David},
title = {HNC's <i>MatchPlus</i> System},
year = {1992},
issue_date = {Fall 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/146565.146569},
doi = {10.1145/146565.146569},
abstract = {HNC is developing a neural network related approach to document retrieval called MatchPlus. Goals of this approach include high precision/recall performance, ease of use, incorporation of machine learning algorithms, and sensitivity to similarity of use.},
journal = {SIGIR Forum},
month = oct,
pages = {34–38},
numpages = {5}
}

@article{10.1145/146565.146567,
author = {Harman, Donna},
title = {The DARPA TIPSTER Project},
year = {1992},
issue_date = {Fall 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/146565.146567},
doi = {10.1145/146565.146567},
abstract = {This note is the first of four papers in this issue describing the ongoing work connected with the DARPA TIPSTER Project. The note provides an overview of the project, and the next papers by three of the contractors involved in the project provide some details on the systems involved, and some of the initial results.The TIPSTER project is sponsored by the Software and Intelligent Systems Technology Office of the Defense Advanced Research Projects Agency (DARPA/SISTO) in an effort to significantly advance the state of the art in effective document detection (information retrieval) and data extraction from large, real-world data collections. The first two-year phase of the program is concerned with the development of algorithms for document retrieval, document routing, and data extraction that are both domain and language independent. A call for proposals was made in June of 1990, and contracts for the six participating groups were let in the fall of 1991. Three meetings have been held so far, with the first results presented in September of 1992.There are two separate, but connected parts of TIPSTER. The first part of the project, document detection, is concerned with retrieving relevant documents" from very large (3 gigabyte) collections of documents, both in a routing environment, and in an adhoc retrieval environment. The routing environment is similar to the document filtering or profile searches currently done in libraries, where a query topic is constant, and the documents are viewed as the incoming stream of publications. The adhoc part of the project is similar to the standard search done against static collections.The second part of the TIPSTER project is concerned with data extraction. Here it is assumed that there is a much smaller set of documents, presumed to be mostly relevant to a topic, and the goal is to extract information to fill a database. This database could then be used for many applications, such as question-answering systems, report writing, or data analysis. The data extraction part of TIPSTER is being done by groups using natural language understanding techniques, and this part will not be described in this issue.},
journal = {SIGIR Forum},
month = oct,
pages = {26–28},
numpages = {3}
}

@article{10.1145/134374.134375,
author = {Li, Tong and Chiu, Victoria and Gey, Fredric},
title = {X-Window Interface to SMART, an Advanced Text Retrieval System},
year = {1992},
issue_date = {Spring 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/134374.134375},
doi = {10.1145/134374.134375},
abstract = {In a research environment for text and document retreival, the experimental functionality is and must be paramount. However, for long-term durability of a software product, the user-interface is seen as a critical component to successful development. In order to explore the effort involved in developing a modern user interface to a text retrieval system, the authors chose to implement a limited X-Window interface to the Cornell University SMART system.The first section of this paper will briefly introduce the history of the SMART system, its command line interface, and the goal of this project; the second will discuss the scope of the project; the development and integration strategies will be covered in sections three and four; then some ideas on the desired enchancements  in section five.},
journal = {SIGIR Forum},
month = feb,
pages = {5–16},
numpages = {12}
}

@article{10.1145/101306.101310,
author = {Paice, Chris D.},
title = {Another Stemmer},
year = {1990},
issue_date = {Fall 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/101306.101310},
doi = {10.1145/101306.101310},
abstract = {In natural language processing, conflation is the process of merging or lumping together nonidentical words which refer to the same principal concept. This can relate both to words which are entirely different in form (e.g., "group" and "collection"), and to words which share some common root (e.g., "group", "grouping", "subgroups"). In the former case the words can only be mapped by referring to a dictionary or thesaurus, but in the latter case use can be made of the orthographic similarities between the forms. One popular approach is to remove affixes from the input words, thus reducing them to a stem; if this could be done correctly, all the variant forms of a word would be converted to the same standard form. Since the process is aimed at mapping for retrieval purposes, the stem need not be a linguistically correct lemma or root (see also Frakes 1982).},
journal = {SIGIR Forum},
month = nov,
pages = {56–61},
numpages = {6}
}

@article{10.1145/378881.378887,
author = {Aoe, Jun-ichi},
title = {A Method for Building Knowledge Bases with Morphological Semantics},
year = {1989},
issue_date = {Fall 89/Winter 90},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/378881.378887},
doi = {10.1145/378881.378887},
abstract = {This paper presents a strategy for building a morphological machine dictionary of English efficiently to infer meanings of derivatives from a simple word (hereafter a semantic stem) by considering morphological affixes and their semantic classifications. The basic concept is to group the derivatives into one frame and to restrict the derivatives, accessible to a knowledge base, to the semantic stem. This approach enables us to simplify the structures of a morphological dictionary and the representation of the knowledge base.},
journal = {SIGIR Forum},
month = sep,
pages = {11–18},
numpages = {8}
}

@article{10.1145/1095469.1095470,
author = {Brown, George},
title = {"Do We Need an Information Policy?"},
year = {1983},
issue_date = {Fall-Winter 1983-84},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095469.1095470},
doi = {10.1145/1095469.1095470},
abstract = {It's a real pleasure to have the opportunity to speak at this important conference. The research and the ideas you are discussing this week will have a profound influence on our society during the coming decades. The societal and economic changes, both now and in the future, brought about by information systems and computers are attracting the attention of the media, the general public, and even the Congress. As you may know, "High Technology" is one of the most frequently heard buzzwords around Washington these days. If you could retrieve, from a data base of this year's congressional speeches, those speeches containing the key words "High Tech," I'd bet you'd find at least one speech by each member of Congress. In my own case, you'd probably get a list of every speech I made.},
journal = {SIGIR Forum},
month = sep,
pages = {7–12},
numpages = {6}
}

@article{10.1145/3263604,
author = {Kraft, Don},
title = {Session Details: Session 6: Statistical Techniques 2},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263604},
doi = {10.1145/3263604},
journal = {SIGIR Forum},
month = jun,
numpages = {1}
}

@article{10.1145/3263602,
author = {Borgman, Christine},
title = {Session Details: Session 4: User Interface 1},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263602},
doi = {10.1145/3263602},
journal = {SIGIR Forum},
month = jun,
numpages = {1}
}

@article{10.1145/3263601,
author = {Brown, Gerry E.},
title = {Session Details: Session 3: Intelligent Systems},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263601},
doi = {10.1145/3263601},
journal = {SIGIR Forum},
month = jun,
numpages = {1}
}

@article{10.1145/1095403.1095406,
author = {King, Chester and Goldstein, Larry and Stocker, Gail},
title = {MEDUS/A: A User-Oriented Database Management System for Medical Research},
year = {1980},
issue_date = {Winter 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095403.1095406},
doi = {10.1145/1095403.1095406},
abstract = {MEDUS/A was designed by members of the Health Systems Project at the Harvard School of Public Health. As a general-purpose DBMS, it enables clinical and public health researchers and their staff to define a database and enter, query, and retrieve their data for analysis without a programmer. The system has simultaneously supported a variety of projects in the Harvard Medical Area since 1976 and is ready for release outside of Harvard in a new version written in Standard MUMPS. Though designed for medicine, the system is sufficiently general for other fields.},
journal = {SIGIR Forum},
month = dec,
pages = {55–60},
numpages = {6}
}

@article{10.1145/1095394.1095395,
author = {Dattola, Robert T.},
title = {Some Ideas for Estimating the Number of Relevant Documents},
year = {1980},
issue_date = {Summer 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095394.1095395},
doi = {10.1145/1095394.1095395},
abstract = {A model is proposed for estimating the total number of relevant documents in a collection for a given query. The total number of relevant documents is needed in order to compute recall values for use in evaluating document retrieval systems. If x represents document rank and y represents precision, then one of the following functions is fit to the points obtained by plotting precision vs. document rank after each retrieved document:1. y = AeBx exponential2. y = AxB power3. y = A - B/x hyperbolic4. y = 1/(A + Bx) hyperbolic5. y = x/(A + Bx) hyperbolicThat equation with the best fit satisfying certain constraints is used to estimate the total number of relevant documents for any given query. Experimental comparisons of this best fit are made with random sampling methods.},
journal = {SIGIR Forum},
month = aug,
pages = {13–21},
numpages = {9}
}

@article{10.1145/1095387.1095392,
author = {Krishnayya, J. G.},
title = {Review of "Industrial Information Systems: A Manual for Higher Managements and Their Information Officer/Librarian Associates by E. B. &amp; R. L. Jackson"; Academic Press for Dowden, Hutchison &amp; Ross, 1978, Stroudsburg, PA},
year = {1980},
issue_date = {Spring 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095387.1095392},
doi = {10.1145/1095387.1095392},
abstract = {This book is written primarily as a guide to industrial higher management and to Information Officers in large industrial corporations. It is also intended to be used as a graduate text in courses in Information Systems/Services and in industrial special librarianship. It largely succeeds in these objectives but may not be of much utility to persons working in a library or below the corporate level or in a smaller corporation.},
journal = {SIGIR Forum},
month = apr,
pages = {11–12},
numpages = {2}
}

@article{10.1145/1095387.1095389,
author = {Salton, Gerard},
title = {Abstracts of Selected Journal Articles},
year = {1980},
issue_date = {Spring 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095387.1095389},
doi = {10.1145/1095387.1095389},
journal = {SIGIR Forum},
month = apr,
pages = {17–21},
numpages = {5}
}

@article{10.1145/983026.983014,
author = {Gavish, Bezalel and Koch, Harvey},
title = {An Extensible Architecture for Data Flow Processing},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/983026.983014},
doi = {10.1145/983026.983014},
abstract = {In this research, we propose a general model for computer architectures. This model allows us to integrate some of the existing system architecture approaches for increasing computer capacity and indicates new possibilites for improving the cost/performance ratio of future computer systems. The model leads to the development of general purpose data flow machines and to different degrees of sophistication within these machines. Our fundamental approach is to separate the CPU into elementary components. This allows us to make a distinction between components for control and components for performing various processing functions, thus yielding a high degree of resource sharing.},
journal = {SIGIR Forum},
month = aug,
pages = {71–76},
numpages = {6}
}

@article{10.1145/3263598,
author = {Krygiel, Annette J.},
title = {Session Details: Session 8},
year = {1978},
issue_date = {August 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3263598},
doi = {10.1145/3263598},
journal = {SIGIR Forum},
month = aug,
numpages = {1}
}

@article{10.1145/1095334.1095337,
author = {Korfhage, R. R.},
title = {The Impact of Personal Computers on Library-Based Information Systems},
year = {1978},
issue_date = {Spring 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095334.1095337},
doi = {10.1145/1095334.1095337},
abstract = {With the size and price of computer hardware shrinking so rapidly, it is clear that we will shortly enter an era when computers are common both in the home and as portable personal tools. This wide availability of an information processing tool will impact the informational needs of each individual, and hence will impact any information service, including the news media, bookstores, and libraries.},
journal = {SIGIR Forum},
month = apr,
pages = {10–13},
numpages = {4}
}

@article{10.1145/1095334.1095336,
title = {Book Clubs for Computer Professionals},
year = {1978},
issue_date = {Spring 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095334.1095336},
doi = {10.1145/1095334.1095336},
abstract = {The average price of twelve recently published, computer-related, books is $18.98. The standard deviation is close to five dollars. Unless your employer routinely adds to your personal library of computer-related books, you will probably not buy many new texts in a year. Therefore, a book club for computer professionals that stretches a finite book budget is of interest.},
journal = {SIGIR Forum},
month = apr,
pages = {7–9},
numpages = {3}
}

@article{10.1145/1095334.1095335,
title = {Book Review Editor's Note},
year = {1978},
issue_date = {Spring 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095334.1095335},
doi = {10.1145/1095334.1095335},
abstract = {I am implementing a suggestion made by Professor R.E. Nance (Virginia Polytechnic Institute and State University) to seek out "systems sketches" from commercial sources of computer software and hardware (see <u>FORUM</u>, Winter 1976). Letters are being mailed to computer manufacturing companies, software houses and consulting firms. If your company is interested in submitting a technical description of a new (or recently improved) database management system, operating system, or other major software or hardware project, please forward your material to Robert C. Groman, DESC Building, Woods Hole Oceanographic Institution, Woods Hole, Massachusetts 02543.},
journal = {SIGIR Forum},
month = apr,
pages = {6},
numpages = {1}
}

@article{10.1145/1095317.1095323,
author = {Samuelson, K. and Amey, G. X. and Borko, H.},
title = {Review of "Information Systems and Networks by K. Samuelson, G. X. Amey and H. Borko", 1977},
year = {1977},
issue_date = {Winter 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095317.1095323},
doi = {10.1145/1095317.1095323},
journal = {SIGIR Forum},
month = dec,
pages = {3},
numpages = {1}
}

@article{10.1145/1095286.1095296,
author = {Czkarahan, E. A. and Schuster, S. A. and Sevcik, K. C.},
title = {Performance Evaluation of a Relational Associative Processor},
year = {1976},
issue_date = {Spring 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095286.1095296},
doi = {10.1145/1095286.1095296},
abstract = {A relational associative processor called RAP has been designed to provide hardware support for the use and manipulation of a relational data base. In this paper, we describe the relational operations provided by the RAP hardware, and devise a representative approach to providing the same relational operations with conventional software and hardware. Analytic models are constructed for both RAP and the conventional system. All simplifying assumptions are made to favor the conventional system. The execution times of several of the operations are shown to be improved with RAP by several orders of magnitude.},
journal = {SIGIR Forum},
month = apr,
pages = {24},
numpages = {1},
keywords = {performance evaluation, reiational data bases, associative processors, data base machines}
}

@article{10.1145/1095505.1095507,
title = {An Inverted File with an Uncontrolled Vocabulary},
year = {1973},
issue_date = {Spring 1973},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095505.1095507},
doi = {10.1145/1095505.1095507},
abstract = {A technique based upon hash coding is proposed to invert a file with an unpredictable and large vocabulary, such as natural language or computer-generated fragments of chemical structures. Each record consists of two linked lists, descriptors and references. Suggestions for refinements and a prototype program are also given.},
journal = {SIGIR Forum},
month = apr,
pages = {18–19},
numpages = {2}
}

@article{10.1145/1095495.1095503,
title = {User-Accessible Data Structures in Information Retrieval},
year = {1972},
issue_date = {Winter 1972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095495.1095503},
doi = {10.1145/1095495.1095503},
abstract = {This paper discusses briefly, certain aspects of user languages and data structures in information retrieval. ZUCCHINI, a system currently under development to permit the user increased control over his data base, is then described.},
journal = {SIGIR Forum},
month = dec,
pages = {71–76},
numpages = {6}
}

@article{10.1145/1095495.1095501,
title = {An Approach for a Working Relational Data System},
year = {1972},
issue_date = {Winter 1972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095495.1095501},
doi = {10.1145/1095495.1095501},
abstract = {Users of large data bases and applications programs which access them must be prevented from having to know how the information they access is organized internally. On the other hand, systems programmers must be allowed to arrange the data base in some way which is both natural and convenient to them.This paper proposes a system which acts as an interface between a user or an applications program, and a data base which consists of multiple files of differing types. The system handles all requests for data, and returns the results in a standard way. The most important feature of this system is that it presents a standard view of data that is highly independent of its machine representation.},
journal = {SIGIR Forum},
month = dec,
pages = {56–64},
numpages = {9}
}

@article{10.1145/75335.75356,
author = {Kwasnik, B.},
title = {How a Personal Document's Intended Use or Purpose Affects Its Classification in an Office},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75356},
doi = {10.1145/75335.75356},
abstract = {This paper reports on one of the findings of a larger case study that attempts to describe how people organize documents in their own offices. In that study, several dimensions along which people make classificatory decisions were identified. Of these, the use to which a document is put emerged as a strong determiner of that document's classification. The method of analysis is reviewed, and examples of different kinds of uses are presented, demonstrating that it is possible to describe a wide variety of specific instances using a closed set of descriptors. The suggestion is made that, in designing systems for organizing materials, it might be advantageous to incorporate information about contextual variables, such as use, since these seem to be particularly important in classification decisions made within personal environments.},
journal = {SIGIR Forum},
month = may,
pages = {207–210},
numpages = {4}
}

@inproceedings{10.1145/75334.75356,
author = {Kwasnik, B.},
title = {How a Personal Document's Intended Use or Purpose Affects Its Classification in an Office},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75356},
doi = {10.1145/75334.75356},
abstract = {This paper reports on one of the findings of a larger case study that attempts to describe how people organize documents in their own offices. In that study, several dimensions along which people make classificatory decisions were identified. Of these, the use to which a document is put emerged as a strong determiner of that document's classification. The method of analysis is reviewed, and examples of different kinds of uses are presented, demonstrating that it is possible to describe a wide variety of specific instances using a closed set of descriptors. The suggestion is made that, in designing systems for organizing materials, it might be advantageous to incorporate information about contextual variables, such as use, since these seem to be particularly important in classification decisions made within personal environments.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {207–210},
numpages = {4},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/75335.75346,
author = {Mitkas, P. A. and Guilfoyle, P. S.},
title = {An Optical System for Full Text Search},
year = {1989},
issue_date = {June 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {SI},
issn = {0163-5840},
url = {https://doi.org/10.1145/75335.75346},
doi = {10.1145/75335.75346},
abstract = {In this paper we propose a full text search system based on optics. The storage and processing of the textual data are performed by an optical back-end system to an electronic computer. In this way we can take advantage of the speed and parallelism of digital optical processing. Using the proposed configuration we show how one might implement a set of text processing operations using lasers, spatial light modulators and photodetectors.},
journal = {SIGIR Forum},
month = may,
pages = {98–107},
numpages = {10}
}

@inproceedings{10.1145/75334.75346,
author = {Mitkas, P. A. and Guilfoyle, P. S.},
title = {An Optical System for Full Text Search},
year = {1989},
isbn = {0897913213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75334.75346},
doi = {10.1145/75334.75346},
abstract = {In this paper we propose a full text search system based on optics. The storage and processing of the textual data are performed by an optical back-end system to an electronic computer. In this way we can take advantage of the speed and parallelism of digital optical processing. Using the proposed configuration we show how one might implement a set of text processing operations using lasers, spatial light modulators and photodetectors.},
booktitle = {Proceedings of the 12th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {98–107},
numpages = {10},
location = {Cambridge, Massachusetts, USA},
series = {SIGIR '89}
}

@article{10.1145/1013230.511811,
author = {Bollmann, Peter},
title = {The Normalized Recall and Related Measures},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511811},
doi = {10.1145/1013230.511811},
abstract = {The normalized recall is one of the most popular evaluation measures for information retrieval systems. In this paper an overview of its development is given. It is then shown that the normalized recall is closely related to other measures such as the CRE-measure and the expected search length. Some implications are analysed.},
journal = {SIGIR Forum},
month = jun,
pages = {122–128},
numpages = {7}
}

@inproceedings{10.1145/511793.511811,
author = {Bollmann, Peter},
title = {The Normalized Recall and Related Measures},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511811},
doi = {10.1145/511793.511811},
abstract = {The normalized recall is one of the most popular evaluation measures for information retrieval systems. In this paper an overview of its development is given. It is then shown that the normalized recall is closely related to other measures such as the CRE-measure and the expected search length. Some implications are analysed.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {122–128},
numpages = {7},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511802,
author = {Wessel, Andrew E.},
title = {Progress Report on Project Information Bridge},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511802},
doi = {10.1145/1013230.511802},
abstract = {Project Information Bridge is a West German Federal Ministry for Research and Technology supported project. It has been conducted in cooperation with the Gesellschaft f\"{u}r Information und Dokumentation (Society for Information and Documentation) (GID) and the various data base hosts in West Germany. Its goal was to develop and test a working prototype of an add-on package for existing IR systems.This report covers the time period from October 1981 through March 1983 during which the prototype was successfully developed and tested. The principal emphasis was to provide users with search formulation aids applicable to specific document files searchable using differing IR systems. Aids for thesaurus construction for natural language words and for file construction and indexing have not at this date been tested. Should tests be completed prior to the conference date, information concerning these topics will be presented at the conference.},
journal = {SIGIR Forum},
month = jun,
pages = {49–74},
numpages = {26}
}

@inproceedings{10.1145/511793.511802,
author = {Wessel, Andrew E.},
title = {Progress Report on Project Information Bridge},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511802},
doi = {10.1145/511793.511802},
abstract = {Project Information Bridge is a West German Federal Ministry for Research and Technology supported project. It has been conducted in cooperation with the Gesellschaft f\"{u}r Information und Dokumentation (Society for Information and Documentation) (GID) and the various data base hosts in West Germany. Its goal was to develop and test a working prototype of an add-on package for existing IR systems.This report covers the time period from October 1981 through March 1983 during which the prototype was successfully developed and tested. The principal emphasis was to provide users with search formulation aids applicable to specific document files searchable using differing IR systems. Aids for thesaurus construction for natural language words and for file construction and indexing have not at this date been tested. Should tests be completed prior to the conference date, information concerning these topics will be presented at the conference.},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {49–74},
numpages = {26},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013230.511797,
author = {Croft, W. Bruce},
title = {Applications for Information Retrieval Techniques in the Office},
year = {1983},
issue_date = {Summer 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013230.511797},
doi = {10.1145/1013230.511797},
journal = {SIGIR Forum},
month = jun,
pages = {18–23},
numpages = {6}
}

@inproceedings{10.1145/511793.511797,
author = {Croft, W. Bruce},
title = {Applications for Information Retrieval Techniques in the Office},
year = {1983},
isbn = {0897911075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511793.511797},
doi = {10.1145/511793.511797},
booktitle = {Proceedings of the 6th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {18–23},
numpages = {6},
location = {Bethesda, Maryland},
series = {SIGIR '83}
}

@article{10.1145/1013228.511766,
author = {Fraenkel, Aviezri S.},
title = {Document Classification, Indexing and Abstracting May Be Inherently Difficult Problems},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511766},
doi = {10.1145/1013228.511766},
abstract = {The main features of document indexing are abstracted. It is shown that the easy part of indexing, namely the question whether there is a bounded number of descriptors for indexing a document is NP-complete. Thus even the most efficient algorithm for exact indexing is not, at least at the present time, bounded by a polynomial-time function.},
journal = {SIGIR Forum},
month = may,
pages = {77–82},
numpages = {6}
}

@inproceedings{10.1145/511754.511766,
author = {Fraenkel, Aviezri S.},
title = {Document Classification, Indexing and Abstracting May Be Inherently Difficult Problems},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511766},
doi = {10.1145/511754.511766},
abstract = {The main features of document indexing are abstracted. It is shown that the easy part of indexing, namely the question whether there is a bounded number of descriptors for indexing a document is NP-complete. Thus even the most efficient algorithm for exact indexing is not, at least at the present time, bounded by a polynomial-time function.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {77–82},
numpages = {6},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013228.511762,
author = {Buell, Duncan A. and Kraft, Donald H.},
title = {Performance Measurement in a Fuzzy Retrieval Environment},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511762},
doi = {10.1145/1013228.511762},
abstract = {We shall consider retrieval performance measures for generalized (non-Boolean) queries and indexing functions. The meanings of recall and precision in such a generalized system will be discussed. Finally, we shall explore the meaning and difficulty of using such measures to compare Boolean and non-Boolean retrieval systems.},
journal = {SIGIR Forum},
month = may,
pages = {56–62},
numpages = {7}
}

@inproceedings{10.1145/511754.511762,
author = {Buell, Duncan A. and Kraft, Donald H.},
title = {Performance Measurement in a Fuzzy Retrieval Environment},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511762},
doi = {10.1145/511754.511762},
abstract = {We shall consider retrieval performance measures for generalized (non-Boolean) queries and indexing functions. The meanings of recall and precision in such a generalized system will be discussed. Finally, we shall explore the meaning and difficulty of using such measures to compare Boolean and non-Boolean retrieval systems.},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {56–62},
numpages = {7},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013228.511758,
author = {Robertson, S. E.},
title = {Term Frequency and Term Value},
year = {1981},
issue_date = {Summer 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013228.511758},
doi = {10.1145/1013228.511758},
journal = {SIGIR Forum},
month = may,
pages = {22–29},
numpages = {8}
}

@inproceedings{10.1145/511754.511758,
author = {Robertson, S. E.},
title = {Term Frequency and Term Value},
year = {1981},
isbn = {0897910524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511754.511758},
doi = {10.1145/511754.511758},
booktitle = {Proceedings of the 4th Annual International ACM SIGIR Conference on Information Storage and Retrieval: Theoretical Issues in Information Retrieval},
pages = {22–29},
numpages = {8},
location = {Oakland, California},
series = {SIGIR '81}
}

@article{10.1145/1013881.802700,
author = {Poon, Ronnie K. L. and Wong, Kwan Y.},
title = {Fifth Workshop on Computer Architecture for Non-Numeric Processing: A Flexible Image Processor Using Array Elements},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802700},
doi = {10.1145/1013881.802700},
abstract = {The purpose of this short paper is to describe some activities in our laboratory on designing a flexible image processor using array processing elements. In many document creation applications, it is desirable to include image handling capability in the system together with keystroke captured text processing function. However, this image handling creates two problems: one is the large amount of data needed for image storage, and the other is the large amount of processing required to produce an output image. Data compression reduces storage and transmission bandwidth requirements, but it also requires processing power to do compression and de-compression of images. The objective of the study is to provide low-cost hardware which has the flexibility to do a variety of image processing algorithms.},
journal = {SIGIR Forum},
month = mar,
pages = {124–125},
numpages = {2}
}

@inproceedings{10.1145/800083.802700,
author = {Poon, Ronnie K. L. and Wong, Kwan Y.},
title = {Fifth Workshop on Computer Architecture for Non-Numeric Processing: A Flexible Image Processor Using Array Elements},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802700},
doi = {10.1145/800083.802700},
abstract = {The purpose of this short paper is to describe some activities in our laboratory on designing a flexible image processor using array processing elements. In many document creation applications, it is desirable to include image handling capability in the system together with keystroke captured text processing function. However, this image handling creates two problems: one is the large amount of data needed for image storage, and the other is the large amount of processing required to produce an output image. Data compression reduces storage and transmission bandwidth requirements, but it also requires processing power to do compression and de-compression of images. The objective of the study is to provide low-cost hardware which has the flexibility to do a variety of image processing algorithms.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {124–125},
numpages = {2},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013881.802693,
author = {Sabbatel, G. Berger},
title = {Data Base Processor Mage},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802693},
doi = {10.1145/1013881.802693},
abstract = {In this paper, we present the design of data base processor MAGE. This DBP is based on a hierarchical DB access method. It is composed of two microprocessors, a disk processor and a moving head disk. The processor requirements, design decisions, and architecture are discussed.We start with an overview of DBP framework. The MAGE DB access method is then summarized. Finally, we present the design and implementation of the DBP, with a particular emphasis on the disk processor.},
journal = {SIGIR Forum},
month = mar,
pages = {62–69},
numpages = {8}
}

@inproceedings{10.1145/800083.802693,
author = {Sabbatel, G. Berger},
title = {Data Base Processor Mage},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802693},
doi = {10.1145/800083.802693},
abstract = {In this paper, we present the design of data base processor MAGE. This DBP is based on a hierarchical DB access method. It is composed of two microprocessors, a disk processor and a moving head disk. The processor requirements, design decisions, and architecture are discussed.We start with an overview of DBP framework. The MAGE DB access method is then summarized. Finally, we present the design and implementation of the DBP, with a particular emphasis on the disk processor.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {62–69},
numpages = {8},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013881.802686,
author = {Laub, Leonard J.},
title = {Optical Mass Storage Technology},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802686},
doi = {10.1145/1013881.802686},
abstract = {This paper describes some of the history, general principles and current embodiments of the technology of data storage and retrieval by optical means. It also discusses the utility of some of these embodiments in certain classes of application.},
journal = {SIGIR Forum},
month = mar,
pages = {8–10},
numpages = {3}
}

@inproceedings{10.1145/800083.802686,
author = {Laub, Leonard J.},
title = {Optical Mass Storage Technology},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802686},
doi = {10.1145/800083.802686},
abstract = {This paper describes some of the history, general principles and current embodiments of the technology of data storage and retrieval by optical means. It also discusses the utility of some of these embodiments in certain classes of application.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {8–10},
numpages = {3},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013881.802685,
author = {Copeland, George},
title = {What If Mass Storage Were Free?},
year = {1980},
issue_date = {March 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013881.802685},
doi = {10.1145/1013881.802685},
abstract = {This paper investigates how database systems would be designed and used under the limiting-case assumption that mass storage is free. It is argued that free mass storage would free database systems from the limitations and problems caused by conventional deletion techniques. A non-deletion strategy would significantly simplify database systems and their operation, as well as increase their functionality and availability. Consideration of this limiting case helps shed light on a more realistic argument: if the cost of mass storage were low enough, then deletion would become undesirable.It is also argued that the often labor-intensive costs and time delays involved in archival and retrieval of older data can be minimized if a single technology were available with low-cost on-line storage and a low-cost archival media with long shelf life.Optical discs promise to come one to two orders of magnitude closer to the limiting case of free mass storage than ever before. Other features of optical discs include improved reliability and a single technology for both on-line and archival storage with a long shelf life. Because of these features and because of (not in spite of) their non-deletion limitation, it is argued that optical discs fit the requirements of database systems better than magnetic discs and tapes.},
journal = {SIGIR Forum},
month = mar,
pages = {1–7},
numpages = {7}
}

@inproceedings{10.1145/800083.802685,
author = {Copeland, George},
title = {What If Mass Storage Were Free?},
year = {1980},
isbn = {9781450373951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800083.802685},
doi = {10.1145/800083.802685},
abstract = {This paper investigates how database systems would be designed and used under the limiting-case assumption that mass storage is free. It is argued that free mass storage would free database systems from the limitations and problems caused by conventional deletion techniques. A non-deletion strategy would significantly simplify database systems and their operation, as well as increase their functionality and availability. Consideration of this limiting case helps shed light on a more realistic argument: if the cost of mass storage were low enough, then deletion would become undesirable.It is also argued that the often labor-intensive costs and time delays involved in archival and retrieval of older data can be minimized if a single technology were available with low-cost on-line storage and a low-cost archival media with long shelf life.Optical discs promise to come one to two orders of magnitude closer to the limiting case of free mass storage than ever before. Other features of optical discs include improved reliability and a single technology for both on-line and archival storage with a long shelf life. Because of these features and because of (not in spite of) their non-deletion limitation, it is argued that optical discs fit the requirements of database systems better than magnetic discs and tapes.},
booktitle = {Proceedings of the Fifth Workshop on Computer Architecture for Non-Numeric Processing},
pages = {1–7},
numpages = {7},
location = {Pacific Grove, California, USA},
series = {CAW '80}
}

@article{10.1145/1013232.511716,
author = {Landauer, Christopher and Mah, Clinton},
title = {Message Extraction through Estimated Relevance},
year = {1979},
issue_date = {September 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013232.511716},
doi = {10.1145/1013232.511716},
abstract = {METER is a text analysis and retrieval system for non-expert computer users to exploit statistical associations between index terms of documents. It will run on a DEC PDP-11/45 minicomputer with continually changing collections of up to 20,000 documents at a time. A scaled version of METER with all major features of the full system has been implemented on a DEC PDP-11/70 as an experimental test bed for evaluation and comparison of associative retrieval algorithms. Although the basic structure of METER is similar to earlier statistical systems for retrospective document searches, the severe requirements of frequent updates of a document collection, of running on a small processor, and of meeting needs of users with little technical training have led to some novel developments. Among these are an update procedure that draws as much as possible on intermediate results from previous updates and a user interface that provides for control over the process of retrieval without calling for knowledge of how that process works.},
journal = {SIGIR Forum},
month = sep,
pages = {64–70},
numpages = {7}
}

@inproceedings{10.1145/511706.511716,
author = {Landauer, Christopher and Mah, Clinton},
title = {Message Extraction through Estimated Relevance},
year = {1979},
isbn = {9781450373456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511706.511716},
doi = {10.1145/511706.511716},
abstract = {METER is a text analysis and retrieval system for non-expert computer users to exploit statistical associations between index terms of documents. It will run on a DEC PDP-11/45 minicomputer with continually changing collections of up to 20,000 documents at a time. A scaled version of METER with all major features of the full system has been implemented on a DEC PDP-11/70 as an experimental test bed for evaluation and comparison of associative retrieval algorithms. Although the basic structure of METER is similar to earlier statistical systems for retrospective document searches, the severe requirements of frequent updates of a document collection, of running on a small processor, and of meeting needs of users with little technical training have led to some novel developments. Among these are an update procedure that draws as much as possible on intermediate results from previous updates and a user interface that provides for control over the process of retrieval without calling for knowledge of how that process works.},
booktitle = {Proceedings of the 2nd Annual International ACM SIGIR Conference on Information Storage and Retrieval: Information Implications into the Eighties},
pages = {64–70},
numpages = {7},
location = {Dallas, Texas},
series = {SIGIR '79}
}

@article{10.1145/1013232.511709,
author = {Raghavan, Vijay V. and Birchard, Kim},
title = {A Clustering Strategy Based on a Formalism of the Reproductive Process in Natural Systems},
year = {1979},
issue_date = {September 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1013232.511709},
doi = {10.1145/1013232.511709},
abstract = {Given a set of objects each of which is represented by a finite number of attributes or features and a clustering criterion that associates a value of utility to any classification, the objective of a clustering method is to identify that classification of the objects which optimizes the criterion. A new strategy to solve this problem is developed. The approach is, in essence, a modification of the reproductive plan, a type of adaptive procedure devised by Holland [2], which embodies many principles found in the adaptation of natural systems through evolution. The proposed approach differs from conventional methods in the sense that the search through the space of possible solutions proceeds in a parallel fashion.The adaptive clustering strategy requires the specification of methods for the generation of an initial population of classifications, the parent selection, the modifications and the replacement of current classifications with new ones. The effects of changing several of these features are investigated. Experimental results show that it is possible to devise clustering strategies based on the principles of adaptation in natural systems that are both effective and efficient.},
journal = {SIGIR Forum},
month = sep,
pages = {10–22},
numpages = {13}
}

@inproceedings{10.1145/511706.511709,
author = {Raghavan, Vijay V. and Birchard, Kim},
title = {A Clustering Strategy Based on a Formalism of the Reproductive Process in Natural Systems},
year = {1979},
isbn = {9781450373456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511706.511709},
doi = {10.1145/511706.511709},
abstract = {Given a set of objects each of which is represented by a finite number of attributes or features and a clustering criterion that associates a value of utility to any classification, the objective of a clustering method is to identify that classification of the objects which optimizes the criterion. A new strategy to solve this problem is developed. The approach is, in essence, a modification of the reproductive plan, a type of adaptive procedure devised by Holland [2], which embodies many principles found in the adaptation of natural systems through evolution. The proposed approach differs from conventional methods in the sense that the search through the space of possible solutions proceeds in a parallel fashion.The adaptive clustering strategy requires the specification of methods for the generation of an initial population of classifications, the parent selection, the modifications and the replacement of current classifications with new ones. The effects of changing several of these features are investigated. Experimental results show that it is possible to devise clustering strategies based on the principles of adaptation in natural systems that are both effective and efficient.},
booktitle = {Proceedings of the 2nd Annual International ACM SIGIR Conference on Information Storage and Retrieval: Information Implications into the Eighties},
pages = {10–22},
numpages = {13},
location = {Dallas, Texas},
series = {SIGIR '79}
}

@article{10.1145/965643.810253,
author = {Cerretti, R. and Jasilli, D. and Matteucci, D. R.},
title = {Ulisse: An Italian Project for a Multifunctional Terminal System},
year = {1977},
issue_date = {May 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/965643.810253},
doi = {10.1145/965643.810253},
abstract = {The paper describes a project conducted in collaboration between CNUCE, an Institute of the Italian National Research Council, and a private research center, concerning a multifunctional system (Ulisse) capable of operating both as a stand alone unit for office administration and automation (word processsing, file management and retrieval) and as an intelligent terminal with local facilities for text editing, text formatting and storage.The first results of the application of Ulisse in the environment of the scientific users of CNUCE are illustrated.},
journal = {SIGIR Forum},
month = jan,
pages = {48–50},
numpages = {3}
}

@inproceedings{10.1145/800180.810253,
author = {Cerretti, R. and Jasilli, D. and Matteucci, D. R.},
title = {Ulisse: An Italian Project for a Multifunctional Terminal System},
year = {1977},
isbn = {9781450374804},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800180.810253},
doi = {10.1145/800180.810253},
abstract = {The paper describes a project conducted in collaboration between CNUCE, an Institute of the Italian National Research Council, and a private research center, concerning a multifunctional system (Ulisse) capable of operating both as a stand alone unit for office administration and automation (word processsing, file management and retrieval) and as an intelligent terminal with local facilities for text editing, text formatting and storage.The first results of the application of Ulisse in the environment of the scientific users of CNUCE are illustrated.},
booktitle = {Proceedings of the 3rd Workshop on Computer Architecture : Non-Numeric Processing},
pages = {48–50},
numpages = {3},
series = {CAW '77}
}

@article{10.1145/965643.810249,
author = {Zaky, S. G.},
title = {Microprocessors for Non-Numeric Processing},
year = {1977},
issue_date = {May 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/965643.810249},
doi = {10.1145/965643.810249},
abstract = {The problem of processing of non-numeric data has received considerable attention in the last few years. This is primarily motivate by the pressing needs in the are a of data base management. It has long been recognized that the parallel processing capabilities of an associative processor are fundamentally well suited to this environment. However, the complexity and cost of truely associative memories make this approach impractical. In this paper, the demands that non-numeric processing place on memory and processor hardware are discussed. Some emerging trends are presented, and a suggestion is given regarding the development of a “general purpose” microprocessor that is suited to this environment.Basically, the microprocessor discussed here is capable of performing simple search and update functions on a high speed, serial data stream. Therefore, it is suited to any application where such a situation is encountered, such as in digital communications.},
journal = {SIGIR Forum},
month = jan,
pages = {23–30},
numpages = {8}
}

@inproceedings{10.1145/800180.810249,
author = {Zaky, S. G.},
title = {Microprocessors for Non-Numeric Processing},
year = {1977},
isbn = {9781450374804},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800180.810249},
doi = {10.1145/800180.810249},
abstract = {The problem of processing of non-numeric data has received considerable attention in the last few years. This is primarily motivate by the pressing needs in the are a of data base management. It has long been recognized that the parallel processing capabilities of an associative processor are fundamentally well suited to this environment. However, the complexity and cost of truely associative memories make this approach impractical. In this paper, the demands that non-numeric processing place on memory and processor hardware are discussed. Some emerging trends are presented, and a suggestion is given regarding the development of a “general purpose” microprocessor that is suited to this environment.Basically, the microprocessor discussed here is capable of performing simple search and update functions on a high speed, serial data stream. Therefore, it is suited to any application where such a situation is encountered, such as in digital communications.},
booktitle = {Proceedings of the 3rd Workshop on Computer Architecture : Non-Numeric Processing},
pages = {23–30},
numpages = {8},
series = {CAW '77}
}

@article{10.1145/1842890.1842907,
author = {Zhang, Yan},
title = {The Construction of Mental Models of Information-Rich Web Spaces: The Development Process and the Impact of Task Complexity},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1842890.1842907},
doi = {10.1145/1842890.1842907},
abstract = {This study investigated the dynamic process of people constructing mental models of an information-rich web space during their interactions with the system and the impact of task complexity on model construction. In the study, subjects' mental models of MedlinePlus were measured at three time points: after subjects freely explored the system for 5 minutes, after the first search session, and after the second search session. During the first search session, the 39 subjects were randomly divided into two groups; one group completed 12 simple search tasks and the other group completed 3 complex search tasks. During the second search session, all subjects completed a set of 4 simple tasks and 2 complex tasks. Measures of the subjects' mental models included a concept listing protocol, a semi-structured interview, and a drawing task.The analysis revealed that subjects' mental models were a rich representation of the cognitive and emotional processes involved in their interaction with information systems. The mental models consisted of three dimensions (structure, evaluation and emotion, and (expected) behaviors); the structure and evaluation/emotion dimensions consisted of four components each: system, content, information organization, and interface. The construction of mental models was a process coordinated by people's internal cognitive structure and the external sources (the system, system feedback, and tasks) and a process distributed through time, in the sense that earlier mental models impacted later ones. Task complexity also impacted the construction of mental models by influencing what objects in the system were perceived and represented by the user, the specificity of the representations, and the user's feelings about the objects.Based on the study results, recommendations for employing mental models as a tool to assist designers in constructing user models, eliciting user requirements, and performing usability evaluations are put forward.},
journal = {SIGIR Forum},
month = aug,
pages = {89},
numpages = {1}
}

@article{10.1145/1842890.1842903,
author = {Roda, Giovanna},
title = {Connecting the Dots},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1842890.1842903},
doi = {10.1145/1842890.1842903},
abstract = {Symbolic Computation is an area of computer science that after 20 years of initial research had its acme in the mid-1980s, when its many new algorithms were made available in "math systems for the masses" like Mathematica and Maple. Computational algebra and computational logic are the two main pillars on which this discipline is based.Currently, the field experiences a new blossom by the integration and combination of new numeric, algebraic, geometric and logic algorithms made available in new, interactive and easy-to-use versions of these systems combined with web services. Spectacular new applications are reported in areas so different as elementary particle physics, cryptography, and automated software generation. One of the most outstanding outcomes of Symbolic Computation is the recently born Wolfram Alpha system, fully programmed in Mathematical.The goal of this writing is to remind the Information Retrieval community of the chances and capabilities offered by Symbolic Computation.},
journal = {SIGIR Forum},
month = aug,
pages = {82–86},
numpages = {5}
}

@article{10.1145/1842890.1842899,
author = {Macdonald, Craig and Santos, Rodrygo L.T. and Ounis, Iadh and Soboroff, Ian},
title = {Blog Track Research at TREC},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1842890.1842899},
doi = {10.1145/1842890.1842899},
abstract = {The TREC Blog track aims to explore information seeking behaviour in the blogosphere, by building reusable test collections for blog-related search tasks. Since, its advent in TREC 2006, the Blog track has led to much research in this growing field, and encapsulated cross-pollination from natural language processing research. This paper recaps on the tasks addressed at the TREC Blog track thus far, covering the period 2006 - 2009. In particular, we describe the used corpora, the tasks addressed within the track, and the resulting published research.},
journal = {SIGIR Forum},
month = aug,
pages = {58–75},
numpages = {18}
}

@article{10.1145/1842890.1842894,
author = {Kosmopoulos, A. and Gaussier, E. and Paliouras, G. and Aseervatham, S.},
title = {The ECIR 2010 Large Scale Hierarchical Classification Workshop},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/1842890.1842894},
doi = {10.1145/1842890.1842894},
abstract = {This paper reports on the Large Scale Hierarchical Classification workshop (http://kmi.open.ac.uk/events/ecir2010/workshops-tutorials), held in conjunction with the European Conference on Information Retrieval (ECIR) 2010. The workshop was associated with the PASCAL 2 Large-Scale Hierarchical Text Classification Challenge (http://lshtc.iit.demokritos.gr), which took place in 2009. We first provide information about the challenge, presenting the data used, the tasks and the evaluation measures and then we provide an overview of the approaches proposed by the participants of the workshop, together with a summary of the results of the challenge.},
journal = {SIGIR Forum},
month = aug,
pages = {23–32},
numpages = {10}
}

@article{10.1145/1041394.1041408,
author = {Kruschwitz, Udo},
title = {Exploiting Markup Structure for Intelligent Search},
year = {2004},
issue_date = {December 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1041394.1041408},
doi = {10.1145/1041394.1041408},
abstract = {Collections of digital documents can nowadays be found everywhere in institutions, universities or companies. Examples are Web sites or intranets. But searching them for information can still be painful. Searches often return either large numbers of matches or no suitable matches at all.},
journal = {SIGIR Forum},
month = dec,
pages = {62},
numpages = {1}
}

@article{10.1145/1041394.1041395,
author = {Joho, Hideo and Sanderson, Mark},
title = {The SPIRIT Collection: An Overview of a Large Web Collection},
year = {2004},
issue_date = {December 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1041394.1041395},
doi = {10.1145/1041394.1041395},
abstract = {A large scale collection of web pages has been essential for research in information retrieval and related areas. This paper provides an overview of a large web collection used in the SPIRIT project for the design and testing of spatially-aware retrieval systems. Several statistics are derived and presented to show the characteristics of the collection.},
journal = {SIGIR Forum},
month = dec,
pages = {57–61},
numpages = {5}
}

@article{10.1145/959258.959274,
author = {Jin, Rong},
title = {Statistical Approaches toward Automatic Title Generation},
year = {2003},
issue_date = {Fall 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/959258.959274},
doi = {10.1145/959258.959274},
journal = {SIGIR Forum},
month = sep,
pages = {79},
numpages = {1}
}

@article{10.1145/959258.959270,
author = {Caidi, Nadia and Komlodi, Anita},
title = {Digital Libraries across Cultures: Design and Usability Issues Outcomes of the "Cross-Cultural Usability for Digital Libraries" Workshop at JCDL '03},
year = {2003},
issue_date = {Fall 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/959258.959270},
doi = {10.1145/959258.959270},
journal = {SIGIR Forum},
month = sep,
pages = {62–64},
numpages = {3}
}

@article{10.1145/373593.373615,
author = {Porter, Martin and Boulton, Richard},
title = {Object Muscat, an Open Source Search Engine},
year = {2000},
issue_date = {April 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/373593.373615},
doi = {10.1145/373593.373615},
journal = {SIGIR Forum},
month = apr,
pages = {16–17},
numpages = {2}
}

@article{10.1145/305110.305132,
author = {Schmidt-Wesche, Birgit and Golovchinsky, Gene},
title = {And Now for Something Completely Different: The User!},
year = {1998},
issue_date = {Sept. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/305110.305132},
doi = {10.1145/305110.305132},
journal = {SIGIR Forum},
month = sep,
pages = {31–34},
numpages = {4}
}

@article{10.1145/305110.305117,
author = {Clarke, Charles L. A. and Cormack, Gordon V. and Palmer, Christopher R.},
title = {An Overview of Multitext},
year = {1998},
issue_date = {Sept. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/305110.305117},
doi = {10.1145/305110.305117},
journal = {SIGIR Forum},
month = sep,
pages = {14–15},
numpages = {2}
}

@article{10.1145/182119.182121,
author = {TREC-2 Program Committee, CORPORATE},
title = {Report on TREC-2 (Text REtrieval Conference): 30 August–2 September, Gaithersburg, USA},
year = {1993},
issue_date = {Fall 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {3},
issn = {0163-5840},
url = {https://doi.org/10.1145/182119.182121},
doi = {10.1145/182119.182121},
journal = {SIGIR Forum},
month = sep,
pages = {14–18},
numpages = {5}
}

@article{10.1145/134374.1096744,
author = {Humphrey, Susanne M.},
title = {Selected IR-Related Dissertation Abstracts},
year = {1992},
issue_date = {Spring 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/134374.1096744},
doi = {10.1145/134374.1096744},
journal = {SIGIR Forum},
month = feb,
pages = {22–47},
numpages = {26}
}

@article{10.1145/74697.74701,
author = {Collin, C. and Levinson, R.},
title = {Partial Order Maintenance},
year = {1989},
issue_date = {Spring 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/74697.74701},
doi = {10.1145/74697.74701},
abstract = {In this paper we show how to maintain a partially-ordered hierarchy of patterns by subpattern-of for efficient associative retrieval. The techniques described here are most applicable for databases of complex data structures such as graphs or matrices as opposed to simple data structures such as relations, sets, lists or frames that are seen in most information retrieval systems. Any representation scheme for the patterns in the database may be used as long as the user provides the system with the function that compares two patterns in the representation scheme and determines if one pattern is a subpattern of the other, if the patterns are identical or the patterns are incomparable. The user also provides utilities for reading and writing the patterns.},
journal = {SIGIR Forum},
month = apr,
pages = {59–88},
numpages = {30}
}

@article{10.1145/74697.74698,
author = {Aoe, J. I.},
title = {Storing a Tree Structure by Using Decimal Notation},
year = {1989},
issue_date = {Spring 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3–4},
issn = {0163-5840},
url = {https://doi.org/10.1145/74697.74698},
doi = {10.1145/74697.74698},
abstract = {A decimal notation satisfies many simple mathematical properties, and it is a useful tool in the analysis of trees. A practical method is presented, that compresses the decimal codes while maintaining the fast determination of relations(e.g., ancestor, descendant, brother, etc.). A special node, called a kernel node, including many common subcodes of the other codes, is defined, and a compact data structure is presented using the kernel nodes. Let n(m) be the number of the total(kernel) nodes. It is theoretically proved that encoding a decimal code is a constant time, that the worst-case time complexity of compressing the decimal codes is O(n+ m2), and that the size of the data structure is proportional to m. From the experimental results of some hierarchical semantic primitives for natural language processing, it is shown that the ratio m/n becomes an extremely small value, ranging from 0.047 to 0.13.},
journal = {SIGIR Forum},
month = apr,
pages = {8–21},
numpages = {14}
}

@article{10.1145/1095483.1095485,
author = {Salton, G.},
title = {Abstracts: Selected Articles from Recent Issues of Journals},
year = {1988},
issue_date = {Fall 1988/Winter 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {1–2},
issn = {0163-5840},
url = {https://doi.org/10.1145/1095483.1095485},
doi = {10.1145/1095483.1095485},
abstract = {This selection of abstracts chosen by G. Salton from recent
issues of journals in the retrieval area.},
journal = {SIGIR Forum},
month = sep,
pages = {16–24},
numpages = {9}
}

