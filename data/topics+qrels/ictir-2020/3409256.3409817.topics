<top>
<num> Number: 340981701
<title> Analysing the Effect of Clarifying Questions on Document Ranking in Conversational Search

<desc> Description:
However, it is often the case that in such information-seeking conversations, users fail to express their information need adequately. This makes the ability of a conversational search system to support mixed-initiative interactions imperative [6, 8]. Such a system can assist users to refine their information need, i.e., by disclosing new information to them [8], or posing clarifying questions [1].

<narr> Narrative:

</top>

<top>
<num> Number: 340981702
<title> Analysing the Effect of Clarifying Questions on Document Ranking in Conversational Search

<desc> Description:
Clarifying questions trigger users’ explicit feedback in the form of an answer, and have been shown to improve user experience [1, 2, 6, 9].

<narr> Narrative:

</top>

<top>
<num> Number: 340981703
<title> Analysing the Effect of Clarifying Questions on Document Ranking in Conversational Search

<desc> Description:
In this paper, we study the effect of the user’s feedback in mixed-initiative conversations. We categorise answers w.r.t. their polarity and length. Answer polarity indicates whether the question points to a relevant direction or not, while answer length enables us to (noisily) identify the presence of additional information in the response. We conduct our analysis on the Qulac dataset [1], using a query likelihood model chosen because of its simplicity and transparency [7].

<narr> Narrative:

</top>
