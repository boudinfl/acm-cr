<top>
<num> Number: 337796001
<title> Relevance Prediction from Eye-movements Using Semi-interpretable Convolutional Neural Networks

<desc> Description:
Information relevance is one of the fundamental concepts in Information Science in general, and Information Retrieval (IR) in particular [46, 47]. The primary purpose of IR systems is to fetch content which is useful and relevant to people. Understanding the cognitive processes of even one individual is challenging enough, and IR systems have to cater to a variety of users, who may have wildly different mental models of what they consider to be useful and relevant. To add another layer of complexity, these mental models are not static. They evolve as users’ knowledge and information needs change. Researchers have investigated various forms of ‘signals’ generated by users interacting with IR systems, that can serve as proxies for their mental processes. Examples include search queries, mouse-clicks, logs of viewed documents, and other forms of interaction-data. These proxies have been studied to infer what kind of information is relevant to users’ needs. Efforts from a system-centred perspective have been towards minimizing the gap between the users’ query and the documents retrieved. The search query is considered to be an exact representation of the users’ information needs. Documents matching the query using a given algorithm are deemed to contain the information that users are searching for, and are therefore relevant. This notion of relevance is regarded as algorithmic-, or system-relevance [48]. The limitation of this perspective is that the query is seldom an exact representation of what the user is looking for. As a result, retrieved documents often do not satisfy the user’s information needs.

<narr> Narrative:

</top>

<top>
<num> Number: 337796002
<title> Relevance Prediction from Eye-movements Using Semi-interpretable Convolutional Neural Networks

<desc> Description:
In a human-centred perspective, relevance arises from interactions between a user’s information need and information objects [3]. This interaction results in several manifestations of relevance [48], and becomes meaningful “only ... in relation to goals and tasks” [29]. Our interest is in situational relevance, or utility. As introduced by [62], “situationally relevant items of information are those that answer, or logically help to answer, questions of concern”. In this paper, we refer to situational relevance as the users’ perceived-relevance of the documents they examine for answering a question.

<narr> Narrative:

</top>

<top>
<num> Number: 337796005
<title> Relevance Prediction from Eye-movements Using Semi-interpretable Convolutional Neural Networks

<desc> Description:
In a majority of these relevance assessment studies, a common theme is to collapse the stream of eye-movement data into a set of single-number features, at various levels of analysis (stimulus, trial, or participant level). These features are then used for statistical inferences, classification, and prediction. For instance, some variants of aggregated fixation-count and fixation-duration were used in studies reported in [14, 15, 19, 21, 39, 41, 59, 63]. Eye-dwell time and/or visit time was used by [14]. [43] identified a comprehensive list of 22 such features, which were later used by others (e.g., [25]).

<narr> Narrative:

</top>

<top>
<num> Number: 337796006
<title> Relevance Prediction from Eye-movements Using Semi-interpretable Convolutional Neural Networks

<desc> Description:
While fixation-count, fixation-duration, and dwell-time are generic eye-movement features applicable to any type of stimuli, several studies used specific features for reading text. These works first labelled each eye-fixations as either reading or scanning/skimming. Then they used derived measures from these two types of fixations. [6] used reading-to-skimming ratio to infer when participants were reading relevant text. Over a group of studies, [19–22] reported that reading speed, number of fixations on words, count and length of reading sequences, count and percentage of words fixated upon, durations of reading and scanning, and distance covered by scanning proved to be good indicators of perceived-relevance for textual documents.

<narr> Narrative:

</top>

<top>
<num> Number: 337796007
<title> Relevance Prediction from Eye-movements Using Semi-interpretable Convolutional Neural Networks

<desc> Description:
Research on non-textual relevance assessment have also used the approach of aggregated features. For instance, relevance of images have been studied in [5, 16, 17, 24, 26, 36, 67], while that of live webpages were studied in [23, 40, 64]. Though most studies used aggregate features for the whole stimuli duration, the authors of [22] report that features from two-second windows near the end of viewing had more discriminating power than those obtained near the beginning of viewing. Thus, collapsing eye-tracking data and thereby losing temporal information, results in our reduced understanding of human relevance assessment.

<narr> Narrative:

</top>

<top>
<num> Number: 337796008
<title> Relevance Prediction from Eye-movements Using Semi-interpretable Convolutional Neural Networks

<desc> Description:
In terms of models used, most studies employed popular classifiers like Random Forests (RF) and Support Vector Machines (SVM). Few studies employed Hidden Markov Models [50] and Neural Networks [7]. Performance was varied, based on the choice of features. For instance, [64] predicted user-satisfaction while examining search results. They used advanced mathematical features (e.g., max. and SD of integrated curvature of fixations, using Frenet frame and Bishop frame) which are usually difficult to conceive in information science research. They obtained F1 scores in the range of 0.5 - 0.7 using RF and SVM. [52] predicted web-surfer’s click-intention from eye-tracking features. They used a battery of classifiers, but the F1 scores were not promising. Thus, appropriate feature selection is crucial to obtain good prediction performance when aggregating eye-tracking data.

<narr> Narrative:

</top>

<top>
<num> Number: 337796009
<title> Relevance Prediction from Eye-movements Using Semi-interpretable Convolutional Neural Networks

<desc> Description:
Summarily, we see that use of aggregated eye-tracking features and traditional classification techniques resulted in unpromising performances for relevance prediction. While statistical tests were significant at the p < .01 level, the classification and prediction accuracies were rarely more than 70% [23, 50, 52, 59]. In our proposed method, we demonstrate that utilizing the entire eye-tracking data, and applying image classification technique, we can predict perceived-relevance with up to 80% accuracy.

<narr> Narrative:

</top>

<top>
<num> Number: 337797701
<title> Effects of Past Interactions on User Experience with Recommended Documents

<desc> Description:
Recommender systems have been well integrated into many aspects of our lives [6, 7, 25]. In many domains such as e-commerce, entertainment, news feeds, hiring platforms, and social networks, these systems are primarily used to help users discover new items that might be of interest to them [11, 16, 20, 23, 33]. Document recommendation however, is a unique domain in that its chief concern is to facilitate re-finding of user’s items [26].

<narr> Narrative:

</top>

<top>
<num> Number: 337797702
<title> Effects of Past Interactions on User Experience with Recommended Documents

<desc> Description:
In comparison with other recommendation domains, document recommendation has been less examined with only few studies in this area focusing on improving the accuracy of the recommender algorithm behind the scenes [15, 26]. While the algorithm is an important aspect of the system, knowing about the effects of other aspects, for instance, presentation, explanations, and users’ interaction with the recommended items on user experience helps with designing more effective recommender systems.

<narr> Narrative:

</top>

<top>
<num> Number: 337797703
<title> Effects of Past Interactions on User Experience with Recommended Documents

<desc> Description:
In this work, we focus on user’s experience with recommended documents. Because individuals and their collaborators are likely to have had previous interactions with the document, the extent to which they recognize the recommended documents or how useful they find the documents may depend on these past interactions. Inspired by previous work in personal information management and refinding [2, 13], our study seeks to investigate the effects of three important dimensions of users’ past interactions with documents recommended to them on their recognition of, prior intent to open, and interest in the documents. The three dimensions are: recency of access, richness of prior interaction, and the presentation of interactions in document summaries.

<narr> Narrative:

</top>

<top>
<num> Number: 337797705
<title> Effects of Past Interactions on User Experience with Recommended Documents

<desc> Description:
Several studies have looked into characterizing and supporting personal information management strategies. One line of research focuses on studying the role of search in personal information management. For example, [12] argue that search systems can alleviate the need to organize personal information by helping us find it no matter where we encountered it, what we remember about it, and even if we forget it exists. [4] study whether improvements in search have changed this fundamental aspect of PIM. They also offer theoretical explanations for differences between PIM and Internet retrieval, and suggest alternative design directions for PIM systems. A detailed survey of research on information seeking, information needs, and user behavior is presented in [22].

<narr> Narrative:

</top>

<top>
<num> Number: 337797706
<title> Effects of Past Interactions on User Experience with Recommended Documents

<desc> Description:
Another thread of work focuses on personal information management in more specific domains. One domain that has received significant attention is email. For example, [31] focus on understanding activities and workflows surrounding how people use email. [24] study email use in the context of everyday work practices. They examine how users interlace email with their day-to-day, ongoing work processes. Other studies focus on documents. Folder navigation to retrieve documents is studied in detail in [5]. They argue that people dedicate considerable time to creating systematic structures to facilitate such retrieval. They also use a predictive model to formulate the effect of folder depth and folder size on retrieval time. An empirical study to compare two methods of organizing documents – placing them into folders or tagging them with labels – is described in [5]. Study results point to the importance of designing tools that combine strengths of folders and labels while avoiding their weaknesses.

<narr> Narrative:

</top>

<top>
<num> Number: 337797707
<title> Effects of Past Interactions on User Experience with Recommended Documents

<desc> Description:
Another body of work investigates how people recall and refind previously seen information. Research has shown that a significant portion of an individual’s web accesses tends to be revisits [10, 27, 29]. [17] study how people retain web information they have found for future use. In a user study on search, [28] reports that what makes a search result memorable is the rank and whether it was clicked on.

<narr> Narrative:

</top>

<top>
<num> Number: 337797708
<title> Effects of Past Interactions on User Experience with Recommended Documents

<desc> Description:
In addition to studying refinding in the context of Web search, researchers have studied re-finding of personal information, especially with an emphasis on email. [14] show that, with the increase of email messages over time, users tend to rely on search for refinding emails as opposed to using human-generated folders and tags. [13] describe the design of a system that facilitates information re-use. The system provides a unified index of information that a person has seen, regardless of whether it was seen as email, web page, document, etc. and uses rich contextual cues in the search interface. They found that that email was the most commonly retrieved source of personal information (e.g. files, web history, emails, etc.). More recently, researchers have also studied re-visitation patterns [1] and refinding strategies [21] employed by users to go back to previously seen email messages.

<narr> Narrative:

</top>

<top>
<num> Number: 337797710
<title> Effects of Past Interactions on User Experience with Recommended Documents

<desc> Description:
Personalized recommendations are increasingly employed in a variety of areas, most commonly in entertainment to for instance recommend music or videos [11, 19, 32, 35], product recommendation in online shopping platforms [25, 34], and social media platforms [16, 23]. Document recommendation, on the other hand, has not received as much attention. [15] studied document recommendation in the context of social tagging. They argue that annotating documents with freely chosen keywords (tags) can provide meaningful collaborative semantic data which can potentially be exploited by recommender systems. In more recent work, a document recommendation system to provide quick access to documents on the Google Drive platform was described in [26]. The system aims to surface the most relevant documents when a user visits the home screen. The paper reports significant productivity gains, in terms of time to locate documents, compared to other approaches that rely on search or browsing.

<narr> Narrative:

</top>

<top>
<num> Number: 337797711
<title> Effects of Past Interactions on User Experience with Recommended Documents

<desc> Description:
Although document recommendation is not a heavily studied area, it can benefit from several insights in studying recommendations in other domains. For example, several papers have attempted to model repeated consumption behavior and its impact on recommender systems. Several important aspects such as item popularity, recency of access [2], user reconsumption patterns [8] and interconsumption frequency [3] were highlighted.

<narr> Narrative:

</top>

<top>
<num> Number: 337798802
<title> Update Delivery Mechanisms for Prospective Information Needs: A Reproducibility Study

<desc> Description:
Previous work has explored two mechanisms for delivering updates to users: In the so-called “push” approach, an update is delivered to a user’s mobile device as a push notification, designed to attract the user’s attention with an alert [14]. In the so-called “pull” approach, an update is deposited into an inbox without interrupting the user; the setup is very much like email, where the updates are examined on the user’s own initiative. [10] compared these two approaches with data drawn from a two-year study in the context of the TREC Real-Time Summarization (RTS) Tracks [11, 12]. The study involved over 50 users who evaluated live system updates on their mobile devices in situ, i.e., as they were going about their daily lives, using a mobile app that implemented either the push- or pull-based delivery mechanism described above. In their paper, [10] noted a number of interesting findings about user attention and information consumption behavior, providing concrete guidance to system designers. However, the study was marred by a few methodological shortcomings (see Section 2), which raises questions about the veracity of their conclusions.

<narr> Narrative:

</top>

<top>
<num> Number: 337798803
<title> Update Delivery Mechanisms for Prospective Information Needs: A Reproducibility Study

<desc> Description:
This paper describes a reproducibility study following the same basic design as [10], but correcting for the methodological shortcomings. Overall, our results largely confirm the findings of the original study, although we note some surprising differences as well. Although our evaluation provides evidence supporting the veracity of the original conclusions, we also observed that the magnitude of the effects are not as strong as in the original study.

<narr> Narrative:

</top>

<top>
<num> Number: 337798804
<title> Update Delivery Mechanisms for Prospective Information Needs: A Reproducibility Study

<desc> Description:
The context of experiments by [10] was the Real-Time Summarization (RTS) Tracks at TREC 2016 [12] and TREC 2017 [11] (RTS16 and RTS17, for short), whose setup is shown in Figure 1. Twitter was used as the source of the live document stream, which participating systems “listened” to during a live evaluation period, sending their updates (i.e., tweets identified as relevant) to an evaluation broker. After deduplicating, the evaluation broker then delivered the updates to a cohort of users who subscribed to interest profiles (i.e., topics), received the updates, and provided relevance judgments in situ on their mobile devices, i.e., they were going about their daily business and were free to ignore or engage with the updates as they wished. This “living labs” setup [7, 13, 15, 17] attempts to faithfully mimic the real-world deployment of real-time summarization systems. These evaluations were framed as user studies (with appropriate ethics approval), where university students were recruited as paid human subjects to assess the delivered notifications.

<narr> Narrative:

</top>

<top>
<num> Number: 337798805
<title> Update Delivery Mechanisms for Prospective Information Needs: A Reproducibility Study

<desc> Description:
Ideally, in order to examine the impact of the delivery mechanism on information consumption behavior, the delivery mechanism should be the only interface manipulation, with all other variables controlled for. However, due to the realities of organizing large-scale evaluations at TREC, this ideal was not achieved. In 2016, updates were delivered to the users’ mobile devices via a custom app, where each update was accompanied by a push notification [12]. In 2017, updates were delivered to the users’ mobile devices via a completely redesigned mobile web app, but each update was silently deposited into users’ inboxes and not accompanied by alerts [11]. Thus, [10] analyzed push vs. pull differences across two evaluations, where delivery differences were conflated with interface changes. There were other methodological flaws as well:

<narr> Narrative:

</top>

<top>
<num> Number: 337800401
<title> Estimating Error and Bias in Offline Evaluation Results

<desc> Description:
The existence of this problem (and related problems with missing data in recommender evaluation) is well-documented [3, 6, 7, 10]. However, we do not yet understand the impact of this missing data: how frequently, and by how much, does it lead recommender system evaluations astray?

<narr> Narrative:

</top>

<top>
<num> Number: 337800402
<title> Estimating Error and Bias in Offline Evaluation Results

<desc> Description:
Several existing techniques attempt to measure and/or correct problems with offline evaluation. One approach is to change the experimental protocol. [2] proposed data splitting and analysis strategies to address popularity bias; these methods affect absolute metric values, but not necessarily the relative performance of algorithms [3]. Using random subsets of the item space as candidates for recommendation may reduce the impact of unknown relevant items [7], but it relies on unrealistically strong assumptions and likely exacerbates popularity bias [10].

<narr> Narrative:

</top>

<top>
<num> Number: 337800403
<title> Estimating Error and Bias in Offline Evaluation Results

<desc> Description:
Another approach is to seek metrics that admit statistically unbiased estimators with observable data. If ratings for relevant items are missing at random, recall [19] and unnormalized DCG [17] are unbiased. But these results limit choice of metrics and depend on assumptions unlikely to hold in actual use, as relevance is not the only influence on users’ choice of items to consume or rate.

<narr> Narrative:

</top>

<top>
<num> Number: 337800404
<title> Estimating Error and Bias in Offline Evaluation Results

<desc> Description:
Counterfactual evaluation [5, 11, 20] uses causal inference techniques — often inverse propensity scoring — to estimate how users would have responded to a different recommender algorithm. However, it is difficult to apply to commonly-used data sets and does not yield insight into the reliability of existing evaluations. It also cannot address the fundamental problem that concerns us in this work: if the user was never exposed to an item under the logging policy, the historical log data contains no information on its relevance. Such items are precisely where a recommender system can produce the most benefit in many discovery-oriented applications.

<narr> Narrative:

</top>

<top>
<num> Number: 337800405
<title> Estimating Error and Bias in Offline Evaluation Results

<desc> Description:
Simulation is a promising technique for studying evaluation procedures. Simulations can produce complete ground truth and corresponding observations in a controlled manner, subject to assumptions about the structure of the data generation process. [6] used probabilistic models to better understand the impact of popularity bias, finding relationships between popularity bias and structural assumptions about the underlying data and inversions in the relative performance of collaborative filtering algorithms between complete and observable data in some cases.

<narr> Narrative:

</top>

<top>
<num> Number: 337801001
<title> The Role of Word-Eye-Fixations for Query Term Prediction

<desc> Description:
User’s gaze behavior throughout a search session has been used in Information Retrieval (IR) as a source of implicit user and relevance feedback. It has been applied to understand the user interest [1], knowledge level [5], a viewed document’s relevance [14] or the overall task type [13]. Resulting insights from gaze behavior has been used, for example, for re-ranking results or query expansion [4].

<narr> Narrative:

</top>

<top>
<num> Number: 337801002
<title> The Role of Word-Eye-Fixations for Query Term Prediction

<desc> Description:
However, the examination of users’ gaze behavior on the textual level has been a hard and costly task so far, as standard eye tracking software only captures x,y-coordinates. The mapping from eye coordinates to actual text has to be done for each experiment from scratch. With the open source software Reading Protocol [7] it is possible to automatically process all eye fixations on individual words of viewed web pages in a search session resulting in precise data about word-eye-fixations (duration, frequency, and timestamps).

<narr> Narrative:

</top>

<top>
<num> Number: 337801003
<title> The Role of Word-Eye-Fixations for Query Term Prediction

<desc> Description:
In the following, we report on some works in the field of IR, which analyze reading behavior at the levels of paragraph, text and queries. [14] studied the user’s gaze behavior while reading a list of titles from scientific articles. Gaze data in combination with trained Hidden Markov Model (HMM) could be used to predict the relevance for new document titles. [2] did a study on reading behavior on search engine result pages. They found that fixations were longer on relevant topically related surrogates of the SERP. On the paragraph level, [3] found that relevant passages in a text have a higher number of fixations and regressions. [4] used eye-gazed features, e.g. eye movements, fixations, and saccades to find relevant paragraphs. [1] trained a SVM classifier based on eye-gaze features on short topical documents from Wikipedia which the user has marked as relevant or not. They could then automatically construct queries from eye movements where no learning data is available. Lately, [9] introduce a model for predicting document relevance in literature search with signals from EEG and eye-tracking. These neurophysiological features were calibrated by showing topics form the corpus and let the users select relevant keywords to the topic.

<narr> Narrative:

</top>

<top>
<num> Number: 337801004
<title> The Role of Word-Eye-Fixations for Query Term Prediction

<desc> Description:
[8] found that for domain-specific search a large part of used query terms has been seen before in the search session. [6] found that terms acquired in web search queries are fixated longer than non-query terms. They also show that there is a semantic relationship between reformulation terms and eye-fixated terms. In this paper, we extend their work by predicting future query terms using features such as Session Topic, Lexical, Term Context, and Browsing in addition to eye-fixation and semantic proximity features.

<narr> Narrative:

</top>

<top>
<num> Number: 337801101
<title> Personalized Entity Search by Sparse and Scrutable User Profiles

<desc> Description:
Personalization to improve web search result ranking has been a long-standing theme in information retrieval [34, 36]. With the increasing availability of individual users’ online traces and derived traits, personalization is again gaining importance for chatbots, recommender systems, product search, and more. [5] has formulated a vision and research agenda for constructing and leveraging personal knowledge graphs (PKG’s) in such settings. In this paper, we investigate the role of PKG’s for topical entity search, with the challenging case that the only per-user knowledge is a sparse profile obtained from a short questionnaire. In contrast to the “data-hungry” approaches of prior works, we focus on this “minimal PKG” case to strengthen the user’s ability to understand and control her user profile, similar to what major search engines offer for controlling the personalization of ads (e.g., adssettings.google.com). Note that our case is more ambitious, though: minimal-PKG profiles aim to capture the bare necessities, whereas ads controls often comprise a hundred or more tags for the same user. The fewer traits the profile contains and the more explicit they are (as opposed to learned latent models), the more scrutable and actionable the personalization model becomes from a user perspective.

<narr> Narrative:

</top>

<top>
<num> Number: 337801102
<title> Personalized Entity Search by Sparse and Scrutable User Profiles

<desc> Description:
The most important line of exploiting user information for general web search is based on query-and-click logs (e.g., [30, 34]). This helps in interpreting user interests and intents for ambiguous queries as well as for identifying salient pages for popular queries, and for suggestions for query auto-completion (e.g., [29]). In all this, cues about the user’s location and daytime are a major asset, too (e.g., [8]).

<narr> Narrative:

</top>

<top>
<num> Number: 337801103
<title> Personalized Entity Search by Sparse and Scrutable User Profiles

<desc> Description:
Recommender systems have incorporated personalization as well, for ads, products and other contents (e.g., [17, 26, 31]). Here, structured data is leveraged, most notably, purchases or ratings of products, likes of news, YouYube videos, Instagram photos, etc. This field has recently paid attention to scrutable recommendations that are comprehensible by end-users and pinpoint the specific data that explains how the recommended item was computed [6, 25, 38]. However, these approaches are at least as “data-hungry” as the search engines, and require extensive user-specific data.

<narr> Narrative:

</top>

<top>
<num> Number: 337801104
<title> Personalized Entity Search by Sparse and Scrutable User Profiles

<desc> Description:
Entity search about people, products or events has received great attention and has been incorporated into major search engines (see, e.g., [4, 7] and further references there). This methodology leverages large knowledge graphs to infer the focus of the query and/or return crisp entities as answers. However, except for special cases such as music recommendation [13] and consumer product search [2], there is hardly any work on personalized entity search with individual user traits.

<narr> Narrative:

</top>

<top>
<num> Number: 337801105
<title> Personalized Entity Search by Sparse and Scrutable User Profiles

<desc> Description:
Prior works covered two major dimensions [16]: 1. Creating user models from explicit signals like queries, clicks, likes, social links, etc. [1] or/and rich contents like email histories or desktop data [14, 22]. 2. Leveraging this background knowledge for answer ranking, query expansion, and auto-completion suggestion [12, 24, 29].

<narr> Narrative:

</top>

<top>
<num> Number: 337801106
<title> Personalized Entity Search by Sparse and Scrutable User Profiles

<desc> Description:
On the first dimension, [34] pioneered the analysis of user interests and activities reflected in query, click and mail histories, and possibly even other online contents written or read by a user. [28] focused on short-term context, like browser sessions, to infer the user’s interest and personalize interactive search. Numerous followup works addressed the analysis and usage of query-and-click logs and browsing sessions. To learn from this kind of expressive but highly noisy data, [1] introduced predictive models with learning-to-rank features, whereas [15] and [33] explored the use of similarity signals from taxonomies and ontologies. [37] learned models of user interests for proactive “zero-query” search. [8] studied the important role of user location.

<narr> Narrative:

</top>

<top>
<num> Number: 337801107
<title> Personalized Entity Search by Sparse and Scrutable User Profiles

<desc> Description:
On the second dimension, prior works explored personalization for ranking as well as query expansion and query suggestions. For personalized ranking, [32] developed methods for incorporating user-specific priors into language models. The interplay of a user’s long-term behavior and short-term context for personalized ranking has been investigated in [8, 10]. [35] and [9] addressed the issue of selective personalization: when to incorporate user profiles.

<narr> Narrative:

</top>

<top>
<num> Number: 337801108
<title> Personalized Entity Search by Sparse and Scrutable User Profiles

<desc> Description:
Another line of research addresses query expansion for personalization. [11, 39] utilize folksonomy data, like user-provided tags in social bookmarking communities, as a source for expanding a user’s queries. [22] personalizes email search via word embeddings learned from email histories. [14] proposes methods for harnessing a user’s desktop files (incl. email). The viability of all these methods relies on the availability of large collections of user data.

<narr> Narrative:

</top>

<top>
<num> Number: 337801109
<title> Personalized Entity Search by Sparse and Scrutable User Profiles

<desc> Description:
The same assumption holds for prior work on query auto-completion [12, 29], perhaps the most successful line of personalization in major search engines. The underlying user data ranges from long-term query-and-click histories to browser histories to email contents, in addition to location and daytime as short-term context.

<narr> Narrative:

</top>

<top>
<num> Number: 337801110
<title> Personalized Entity Search by Sparse and Scrutable User Profiles

<desc> Description:
For entity search, to the best of our knowledge, prior work on personalization is scarce. CLEF had a series of competitions on book recommendations [21], but this relied on posts, tags, reviews and ratings by many users in the LibraryThing community and the Amazonshop. The closest to our work is [3] on personalized product search. It is based on learning embeddings for users and items in the same semantic space, by leveraging user-written reviews on item pages. However, such rich data about individual users is not easily available for general entity search.

<narr> Narrative:

</top>

<top>
<num> Number: 337800904
<title> Quantifying the Effects of Prosody Modulation on User Engagement and Satisfaction in Conversational Systems

<desc> Description:
As these systems became more sophisticated, many work proposed new ideas to automate the evaluation process by predicting conversational user satisfaction, as defined in [28–30]. For instance, there have been successful attempts to predict satisfaction once conversations (sessions) are completed, using traditional methods [17, 22] and neural-based models [13, 14]. Lastly, one recent work [5] proposed a unified neural framework to predict offline (session-level) and online (turn-level) satisfaction simultaneously.

<narr> Narrative:

</top>

<top>
<num> Number: 337800907
<title> Quantifying the Effects of Prosody Modulation on User Engagement and Satisfaction in Conversational Systems

<desc> Description:
Thus, our work extends the ideas here by first train a state of the art immediate- and offline- satisfaction prediction model [5] and quantify both immediate and longer-term effects on user satisfaction and engagement using our proposed metrics, which are described later.

<narr> Narrative:

</top>

<top>
<num> Number: 337798502
<title> A Tool for Conducting User Studies on Mobile Devices

<desc> Description:
Research on mobile IR started as early as 2006 when [11] studied query logs of Google mobile search. Since then, there has been growing interest in studying this area both in industry and academia. Early studies mainly focused on understanding users information needs on mobile devices [12] and exploring conventional Web-based IR approaches on these devices [6]. More recently, along with advances in technology, researchers have explored various aspects of mobile IR. For instance, [15] studied and found significant differences in search patterns done using iPhone, iPad, and desktop. [7] conducted a comparative study on mobile spoken and written queries showing that spoken queries are longer and closer to natural language. [14] conducted a diary study in which they found that contextual features such as activity and time influence 72% of mobile information needs. [5] studied user interactions concerning mobile apps and mobile search, finding that users’ interactions with apps have an impact on search. [9] found that fragmented attention of users while searching on-the-go, affects their search objective and performance perception. Also, [1] confirmed the findings of this study by studying people’s behavior while searching in different contexts through a field study. More recently, researchers indicated the need for a universal mobile search framework and found that commercial mobile search engines such as Google and Bing are not the preferred means of information access for the majority of users’ information needs [3]. As it is obvious, above-mentioned studies either had access to commercial search logs or developed a specific app for their study.

<narr> Narrative:

</top>

<top>
<num> Number: 337796801
<title> Harnessing Evolution of Multi-Turn Conversations for Effective Answer Retrieval

<desc> Description:
Recent emergence of intelligent assistants, such as Google Assistant and Microsoft Cortana have led to an increasing interest in research on conversational systems. Conversational assistants can help users complete various types of tasks. The tasks can range from as simple as setting an alarm to more complex cases like health advice. Conversational assistants have been employed for information seeking [35] and recommendation [34] among other information systems applications. Moreover, such systems can be used as home assistants, e.g., Alexa and Google Home; or be integrated in a smartphone [1, 2] or wearable devices, e.g., Apple Siri. Several Information Retrieval (IR) tasks have been investigated in a conversational setting. Some examples include response ranking [40], item recommendation [11], evaluation [19, 21], and asking clarifying questions for users intent disambiguation [3].

<narr> Narrative:

</top>

<top>
<num> Number: 337796802
<title> Harnessing Evolution of Multi-Turn Conversations for Effective Answer Retrieval

<desc> Description:
Although much work has been devoted towards studying single-turn conversations, several new challenges, that a multi-turn dialogue based conversational system poses, remain to be explored. Multiple turns in a conversation can be used to understand the user information need more effectively [30]. For instance, while searching for a new smartphone, user and machine could discuss various features and options in multiple turns. In order to facilitate research on multi-turn information seeking conversations, TREC introduced the Conversational Assistance Track (CAsT) in 2019. The track contains 80 conversations on different topics, each of which consists of 8-12 turns (or utterances). Much work has been done on multi-turn conversational question answering [10, 16]. However, not much is known about how users interact with a machine in a multi-turn conversation and how their utterances can help the system to understand their information needs. Moreover, various aspects of multi-turn conversations are yet to be investigated, such as the way a user’s information need and intent evolves as the conversation develops.

<narr> Narrative:

</top>

<top>
<num> Number: 337796803
<title> Harnessing Evolution of Multi-Turn Conversations for Effective Answer Retrieval

<desc> Description:
Conversational search has been a long standing research problem in the IR community. However, with the recent advances in automatic voice recognition and the proliferation of Intelligent Personal Assistants such as Siri, Alexa, Google Assitant, and Cortana on personal devices, the area of Conversational search has received renewed attention in the past few years. One of the earliest attempts towards conversational mode in IR can be traced back to the work of [27] who proposed the introduction of dialogue for searching documents. [23] later proposed a system for retrieving airline information and ticket reservation using speech. Another IR system directed towards medical health professionals within a conversational setting was put forward by [9] in 1985 for searching documents related to Gastroenterology. However, it was the work by [12] on I3R, an expert interface communicating with the user in a search session, which laid the foundation for conversational IR. A few years later [7] characterized information-seeking strategies for conversational IR, offering users choices in a search session based on case-based reasoning. Since then, the problem of conversational systems has been studied by researchers from both the fields of IR and Natural Language Processing (NLP) with varied interests. Conversational Agents have forayed their applications in various domains ranging from conversational recommender systems [11, 34], human memory augmentation [6], e-Health systems [25], personality recognition [31] to museum tour guidance [22]. [17] provides a systematic review on neural approaches to conversational AI developed in the last few years. Recently, rule-based conversational IR system [24, 38, 39] have given way to learning based approaches [20] and even more recent methods based on deep learning [41]. Among the several facets of conversational IR systems, one research direction is focused on analyzing user-behavior and interaction with voice-only systems [33]. Along the same line, [30] proposed a theoretical framework for conversational search highlighting the need for multi-turn interactions with users for narrowing down their specific information needs. [35] studied conversations of real users to determine the frequently-used interactions and inform a conversational search system design. A close line of research deals with identifying user-intent while searching for information. Much work has been done in this direction, some of which include query suggestion to clarify users’ intent in a traditional IR setting [30], asking clarifying questions from users to understand users’ intent and redirect the search [3], clarifying user-intent by eliminating non-relevant items through negative user feedback in a conversational search [8]. On the other end of the spectrum, [5] posited that while understanding user intent and actions is important, little work has been addressed towards understanding the action taken by a conversational agent in the same context. They thus provided a framework for understanding the human-computer interaction from an agent’s point of view. [37] listed the important factors to consider while designing a conversational assistant. One of their key findings was that it is essential to maintain the conversational context which is one of the focal points of our paper.

<narr> Narrative:

</top>

<top>
<num> Number: 337795701
<title> Enabling Predictive Number Entry and Editing on Touchscreen-Based Mobile Devices

<desc> Description:
Although the acquirement, input, and editing of numeric values (represented either by digits or text) are important parts of mobile text entry [3], these have not been well explored in the literature. This negligence is evident in the suggestion bars of virtual keyboards. Nowadays, almost all virtual keyboards come with suggestion bars that present the most probable next words and seldom phrases using linguistic models [7, 21, 25]. However, none of these models provide the support for numeric values, thus the suggestion bars remain “blank” when these values are being entered or edited.

<narr> Narrative:

</top>

<top>
<num> Number: 337795702
<title> Enabling Predictive Number Entry and Editing on Touchscreen-Based Mobile Devices

<desc> Description:
The findings of an informal survey and user feedback from our previous studies revealed that mobile users desire an effective and user friendly method for interacting with numbers since they often work with numeric values on mobile devices. This includes entering an entirely new value (e.g., the date and time of a meeting), editing or converting an existing value (e.g., changing an amount from Euro to US Dollar), and performing arithmetic operations to a value (e.g., figuring out how to split a bill with friends before using a mobile payment app). Most users resolve to third-party apps for editing and conversion, such as calculators, unit converters, and Web browsers. For instance, users tend to use a native or a Web app to find a time for a virtual meeting that is appropriate for all international attendees. Incriminating and decrementing numeric values also require the assistance of third-party apps since increasing and decreasing different units, such as time, currency, or length and weight, are fundamentally different from one another. This process is not only time-consuming and tedious but also distracts the user from the task at hand by forcing her to switch between different apps [1]. To mitigate this, we developed a simple predictive system that uses text-based querying and regular expression to identify numeric values to suggest the most likely next actions in the suggestion bar (Figure 1). However, the main contribution of this work is not the predictive system, but the demonstration that providing support for numeric values in the suggestion bar can radically simplify the task of entering and editing numbers on mobile devices. Figure 2 illustrates the architecture of the proposed system.

<narr> Narrative:

</top>

<top>
<num> Number: 337795704
<title> Enabling Predictive Number Entry and Editing on Touchscreen-Based Mobile Devices

<desc> Description:
Some have proposed novel keypad layouts to facilitate number entry on various devices. [11] designed a gesture-based method for number entry on touchscreens. In a user study, this approach yielded a promising entry speed and accuracy. [8] proposed a method for automatically adjusting the layout and position of a virtual keypad based on how the user is holding a mobile device. A study revealed that this approach increases entry speed by 42% compared to a manually adjustable keypad. [22] investigated the effects of different key sizes and spacing on touch characteristics in number entry tasks. They found out that touch force, impulse, and dwell time are significantly affected by key size. In a similar study, [23] found out that both key size and layout affect input performance in terms of speed, accuracy, and task completion rate. [9], in contrast, studied the effects of age on the usability of number entry with both virtual and physical keypads. They recruited adults aged 23–33 years and older adults aged 65–76 years. Results revealed that tactile feedback increases input accuracy of the virtual keypad, and both adults and older adults prefer the virtual keypad than the physical one.

<narr> Narrative:

</top>

<top>
<num> Number: 337795705
<title> Enabling Predictive Number Entry and Editing on Touchscreen-Based Mobile Devices

<desc> Description:
Some have proposed novel keypad interactions to increase the security of conventional mobile user authentication approaches. [4] designed a keypad that enables the user to actively select digits and directional gestures as her passwords. [19] designed a force-based keypad that uses pressure as a binary input with two variances of the pattern-lock approach. [2] developed a different force-based keypad that uses three levels of pressure input as an extra security measure to the popular digit-lock approach.

<narr> Narrative:

</top>

<top>
<num> Number: 337795706
<title> Enabling Predictive Number Entry and Editing on Touchscreen-Based Mobile Devices

<desc> Description:
Several recent works have focused on number entry on medical equipment since the existing approaches are not optimized for common data entry tasks in hospitals [28]. However, [18] pointed out that these works explore only keypads and do not account for factors such as the range of values and the real-estate available on the equipment for keypads. Most of these works tend to show that input method significantly affects number entry speed and accuracy. In another work, [17] reported that typically there are two types of number entry methods available for medical devices: serial (such as a keypad) and incremental (which uses knobs or keys to increment/decrement numeric values). They reported that incremental methods lead to more accurate input than serial methods. In a follow-up work, [27] proposed thirteen different codes for classifying errors, and using checksums to detect these errors [29]. In a separate work, [26] designed a novel layout to make the entry of the most frequently entered numbers easier on infusion pumps. For this, they collected data from infusion pumps programmed on the ward. They evaluated the method with three existing interfaces. Results revealed that it reduces the total number of keystrokes needed to complete a task.

<narr> Narrative:

</top>

<top>
<num> Number: 340122402
<title> Local Self-Attention over Long Text for Efficient Document Retrieval

<desc> Description:
Neural models have shown successful results in a number of IR tasks [9, 10, 17]. [23] proposed a kernel pooling approach (KNRM) based on a bag-of-words representation of words. This was further extended by [5] to incorporate n-gram representations using convolutional architecture. Several others [8, 14] have highlighted important considerations for designing neural ranking models for documents that are distinct from dealing with passages and other short text. [26] have emphasized on efficiency in neural ranking models and introduced neural models for retrieving documents from a large corpus. More recently, Transformer [7] based architectures have been employed to learn contextual representations which have led to bigger improvements [11, 18, 19, 24]. [24] apply passage-level BERT-based relevance estimators to rank documents. [16] use pretrained contextual embeddings, without fine-tuning, in downstream ranking models.

<narr> Narrative:

</top>

<top>
<num> Number: 340122403
<title> Local Self-Attention over Long Text for Efficient Document Retrieval

<desc> Description:
Classically, assessing relevance of documents based on relevant parts has been studied in many forms [3, 21] and this study continues that exploration in the context of neural models. Unlike [16, 24], our proposed model is trained in a fully-supervised setting and only requires query-document relevance labels for training.

<narr> Narrative:

</top>

<top>
<num> Number: 340103201
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
Recommendations are part of everyday life. Be they made by a person, or by an automated system, the recommendations are often accompanied with an explanation, or reason, underlying the suggestions provided. Explanations are known to strongly impact how the recipient of a recommendation responds [13, 14, 23, 28], yet the effect is still not well understood.

<narr> Narrative:

</top>

<top>
<num> Number: 340103202
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
At the same time, automated recommender systems have recently proliferated. This has increased attention on explainable and transparent AI, both from technical and ethical perspectives [1, 18]. While explainable system design is not new (dating back to rule-based expert systems of the 1980s [5]), the role of explanations has gained more attention in the past decade [29].

<narr> Narrative:

</top>

<top>
<num> Number: 340103203
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
Our work starts with seven main goals of explanations, proposed by [26]: transparency, intended to explain how the system works; scrutability, allowing users to tell the system if it is wrong; trust, increasing users’ confidence in the system; effectiveness, helping users to make good decisions; efficiency, helping users to make decisions faster; persuasiveness, trying to convince users to select the given item; and satisfaction, increasing the ease of use of a system. They argued that these goals should be identified as distinct, even if they may interact [26]. Most previous studies on generating explanations optimize a single goal [20], and only a handful consider multiple goals [8, 13, 26]. Yet, depending on the perspective of the explanation generator, different goals may be appropriate, and may need to be traded off.

<narr> Narrative:

</top>

<top>
<num> Number: 340103204
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
The ability for an artificially intelligent system to explain recommendations has been shown to be an important factor for user acceptance and satisfaction [13, 14, 23, 28]. Explanations can be characterized along a number of dimensions, including their content, form of presentation, and system’s intended purpose [20]. Our interest is in the latter category, where we use the term goal to refer to the objective or purpose of the explanation. Specifically, our focus is on natural language explanations, the most commonly used way of presentation both historically [20] and recently [2, 6, 19].

<narr> Narrative:

</top>

<top>
<num> Number: 340103205
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
We use the seven explanation goals identified in [26] as a basis; these are listed in Table 1. We note that there are possible refinements to these goals. For example, in [20] satisfaction is not considered as a single objective, but is split into ease to use, enjoyment, and usefulness. Nonetheless, these seven goals are regarded as the canonical categorization within explainability research for recommender systems, accurately reflecting the goals that have been studied in the past. Certain goals may be measured objectively and quantitatively. For example, effectiveness may be measured as the change of a user’s rating of (or reported interest in) an item before and after consuming that item [3, 6], efficiency may be measured by time spent on rating an item [13] or reading an explanation [6], and persuasiveness may be measured in terms of click through rate [30]. Here, we aim to compare different goals on equal footing, and thus focus on the subjective perception of the recipient—measured at the time when a recommendation and explanation are shown.

<narr> Narrative:

</top>

<top>
<num> Number: 340103206
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
Most past studies are concerned with a single goal [20], and there is evidence each can be achieved individually [26]. The interactions between two or more goals, however, are much less understood. The most common explanation purpose, according to a large-scale literature review by [20], is transparency, which is also considered key to building user trust [12]. Concerning the relationship between the two, one previous study indicates that transparency increases user trust [23], while another study finds that transparency and trust are not related [8]. The second most frequent explanation purpose is effectiveness [20], which can be conflicting with persuasiveness [7]. A systematic evaluation of explanations with respect to all goals has not been performed before.

<narr> Narrative:

</top>

<top>
<num> Number: 340103207
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
There is an important recognized difference between explanations (why a certain suggestion is given) and justifications (why the user may be interested in the item) [19, 27]. The former consist of an honest account of the mechanism that generated the suggestion, while the latter provides a plausible reason, which may be decoupled from the underlying recommendation algorithm.

<narr> Narrative:

</top>

<top>
<num> Number: 340103208
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
There is a growing interest in generating natural language explanations and justifications. Given a sophisticated recommendation system, justifications may often be provided by filling in natural language templates, for example, by considering simple features such as actor and director names [24] or by extracting relevant and distinguishing characteristics from reviews [19]. However, our work focuses on explanations. Justifications have in the past been created manually using crowdsourcing [6]. A main difference between that and ours, is that we ask humans to pick the recommendation as well as explain it, while [6] perform only the latter.

<narr> Narrative:

</top>

<top>
<num> Number: 340103209
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
Subjective perceptions of explanations are often evaluated qualitatively based on user surveys, with responses typically given on Likert scales [6, 8, 10, 17, 21–23]. Following standard practice, we design a user survey to capture the subjective perception of users regarding the seven goals.

<narr> Narrative:

</top>

<top>
<num> Number: 340119101
<title> Hier-SPCNet: A Legal Statute Hierarchy-based Heterogeneous Network for Computing Legal Case Document Similarity

<desc> Description:
A key step for developing these legal IR systems is to estimate the similarity between two legal case documents, which is challenging because legal documents are long, complicated and unstructured [3, 4, 6, 8]. Also, there is no well defined notion of legal similarity – two legal case documents are considered similar if legal experts judge them to be similar. In this work, we focus on the challenge of automating this similarity computation.

<narr> Narrative:

</top>

<top>
<num> Number: 340119102
<title> Hier-SPCNet: A Legal Statute Hierarchy-based Heterogeneous Network for Computing Legal Case Document Similarity

<desc> Description:
Although there exists several supervised methods for general document similarity (e.g., for measuring similarity of news articles [5]), having such supervised methods for legal document similarity is not practical. This is because training such supervised models need a gold standard containing thousands of similar document pairs. Since legal document similarity can be verified only by legal experts, developing such a gold standard is prohibitively expensive. Existing methodologies for finding similar legal documents are hence unsupervised [3, 4, 6, 8].

<narr> Narrative:

</top>

<top>
<num> Number: 340119103
<title> Hier-SPCNet: A Legal Statute Hierarchy-based Heterogeneous Network for Computing Legal Case Document Similarity

<desc> Description:
The existing methods for computing legal document similarity and can be broadly classified into network-based methods that rely on citation to prior case documents [3, 8], and text-based methods that rely on the textual content of the documents [6], and hybrid [4].

<narr> Narrative:

</top>

<top>
<num> Number: 340119105
<title> Hier-SPCNet: A Legal Statute Hierarchy-based Heterogeneous Network for Computing Legal Case Document Similarity

<desc> Description:
To estimate the similarity between legal documents, we propose to apply the graph embedding algorithm Metapath2vec [1] on the heterogeneous Hier-SPCNet. Our method relies on the key idea that if two documents cite a common statute/precedent or if two documents cite different statutes/precedents that are themselves structurally similar in the network, then the two documents may be discussing similar legal issues, which is a strong signal for estimating document similarity. We evaluate our approach on a set of 100 document pairs comprising of case judgments from the Supreme Court of India, whose similarities have been annotated by legal experts. Results show that our proposed method achieves significant improvement over prior methods that use the PCNet alone.

<narr> Narrative:

</top>

<top>
<num> Number: 340119106
<title> Hier-SPCNet: A Legal Statute Hierarchy-based Heterogeneous Network for Computing Legal Case Document Similarity

<desc> Description:
We also compare our proposed network-based method with a state-of-the-art text-based method for computing legal document similarity using document embeddings [6]. We observe that the proposed network-based method can give complimentary insights compared to what is given by the text-similarity method. Combining the two is a promising way of estimating legal document similarity from multiple aspects.

<narr> Narrative:

</top>

<top>
<num> Number: 340119108
<title> Hier-SPCNet: A Legal Statute Hierarchy-based Heterogeneous Network for Computing Legal Case Document Similarity

<desc> Description:
Bibliographic Coupling [3]: It is defined as the Jaccard similarity index between the sets of precedent citations (out-citations) from the two documents whose similarity is to be inferred.

<narr> Narrative:

</top>

<top>
<num> Number: 340119109
<title> Hier-SPCNet: A Legal Statute Hierarchy-based Heterogeneous Network for Computing Legal Case Document Similarity

<desc> Description:
Co-citation [3]: Similar to bibliographic coupling, but it is defined on the sets of in-citations from the two documents.

<narr> Narrative:

</top>

<top>
<num> Number: 340119110
<title> Hier-SPCNet: A Legal Statute Hierarchy-based Heterogeneous Network for Computing Legal Case Document Similarity

<desc> Description:
Dispersion [8]: This measure measures to what extent the out-neighbours (out-citation documents) of the two documents are themselves similar, i.e., occurs in the same community/cluster. We use the NetworkX implementation for this measure.

<narr> Narrative:

</top>

<top>
<num> Number: 340105201
<title> Query Rewriting for Voice Shopping Null Queries

<desc> Description:
In the past few years, speech has emerged has a natural mean for communicating information need to various search engines via voice assistants such as Amazon Alexa, Apple Siri, and Google Assistant. Among various experiences, voice assistants enable customers to search and shop for products in an intuitive way using natural language. Providing a free-form shopping experience is a challenging task. This is especially true because the voice interface lacks assisting mechanisms, such as query completion and refinement, that can help customers easily express their need and iterate on it. As a consequence, a non-negligible portion of all voice shopping queries are null queries, that is, queries that result with no offers. Such interactions clearly have negative impact on customers shopping experience [40–42]. Query rewriting (QR) attempts to seamlessly replace null queries with alternatives that lead to relevant offers for the customer intent, and by that, help customers progress on their shopping journey.

<narr> Narrative:

</top>

<top>
<num> Number: 340105204
<title> Query Rewriting for Voice Shopping Null Queries

<desc> Description:
Our alternative queries generation component is based on identifying web and voice shopping queries that frequently lead to positive events (e.g., purchases), and indexing them in a search engine. Those positive queries are indexed using various analyzers that target different potential failures in voice shopping (e.g., analyzers based on textual, n-grams, and phonetic similarities). Given a query, one can retrieve multiple alternatives from the index in hope that one of them can amend it, without the need to isolate the exact error. Conceptually, the core of our generation approach is by mapping tail (low frequency) queries to alternative head (high frequency) queries. The main motivation for this approach comes from the fact that head queries are known to exhibit much better performance than tail queries, due to richer historical behavioral features [23]. In fact, the distinction is even more extreme in voice due to the aforementioned strong presentation bias. In addition, [20] recently observed that products purchased through voice are much more limited in terms of diversity, namely, products purchased on a regular basis such as groceries, and not niche long-tail products. This provides another motivation for our approach as positive head queries correspond well with commonly and regularly purchased products.

<narr> Narrative:

</top>

<top>
<num> Number: 340105205
<title> Query Rewriting for Voice Shopping Null Queries

<desc> Description:
The alternative queries ranking component then ranks the alternatives that are more probable to fix the original query. This machine learning-based component utilizes multiple features (like textual and semantic similarities between the originating query and the alternatives, behavioral features, and more) to make its decisions. While our alternative queries generation component aims to improve the recall, the alternative queries ranking component is in charge of tuning the precision. For instance, in an e-commerce rewriting scenario, it is essential for the alternative queries to retrieve offers that capture the same intent as the originating query [41]. Rewriting that leads to offers that do not respect the desired product type are clearly poor. Our ranking approach considers features that help preserve the original customer’s intent (like, extracting the product type from queries), and by that, provides quality guarantees on the alternatives.

<narr> Narrative:

</top>

<top>
<num> Number: 340105206
<title> Query Rewriting for Voice Shopping Null Queries

<desc> Description:
We provide an experimental evaluation for both voice and web null queries based on data logs of a commercial voice assistant and an e-commerce website. Our evaluation demonstrates that our voice query rewriting (VQR) approach outperforms several baselines by large margins. For instance, we show that VQR improves over the effectiveness of a simple textual similarity retrieval-based QR system by roughly 22% on voice data, and a term-dropping QR system by roughly 46% on web data. Although our focus is on voice QR, the improvements observed on web data, reaffirms the utility of our approach. In fact, we believe that our proposed framework is generic enough to be successfully applied in other domains beyond e-commerce. One notable highlight from our evaluation is that a term-dropping QR approach applied to a random set of web null queries attains much better performance than when it is employed to a random set of voice null queries (by roughly 56%). This indicates that web e-commerce null queries are considerably different than voice null queries, and apparently easier to fix. This observation adds to previous line of research identifying differentiating factors between the voice and web domains. For example, it was observed that voice queries are closer to natural language than text queries in general search [15], voice reformulations are distinguishable from textual reformulations [17, 22], and that shopping categories and behavioral patterns defer between voice and web e-commerce search [20]. In summary, we make the following key contributions:

<narr> Narrative:

</top>

<top>
<num> Number: 340105207
<title> Query Rewriting for Voice Shopping Null Queries

<desc> Description:
Query rewriting has long been an important research area in information retrieval [3]. Extensive analysis has been done for handling and rewriting of queries in web search. The notion of query refinement, expansion, suggestion, substitution, and reformulation are sometime overloaded and have been commonly used synonymously with query rewriting. Most of the previous methods are not particularly suitable for e-commerce queries, which are shorter and more sensitive to context [34], let alone voice e-commerce queries. Focusing on tail low-frequency e-commerce queries highlights additional unique challenges and opportunities, especially around finding and ranking good query alternatives [13]. Using voice as a new medium for search also reveals differences from traditional search in both web [15, 17, 22] and e-commerce [20, 21]. In this work, we concentrate on studying voice e-commerce null (tail) queries.

<narr> Narrative:

</top>

<top>
<num> Number: 340105208
<title> Query Rewriting for Voice Shopping Null Queries

<desc> Description:
One notable research direction in QR, which is also applicable for e-commerce, focuses on increasing the recall. This direction is especially important for null queries that yield no results. Alternative queries are generated by dropping [4, 24, 28, 46, 47] or substituting [7, 16, 25] tokens from the original query. For example, [25] proposed generating query alternatives by using a large set of ordered query pairs obtained from consecutive queries in web-search sessions. Then, various alternatives are generated by breaking a given query into segments and either dropping or generating substitutions for each of them separately. For dealing with null e-commerce queries, [41] suggested a post-retrieval approach for dropping terms from a given query that restricts the search results to the same taxonomy of results returned in the past for the original query. [43] suggested generating sub-queries by dropping unimportant terms based on their part-of-speech (POS) tag and additional features. Our results hint that term-dropping methods for e-commerce null queries do not adjust well to the voice domain. Other ideas for substitution-based solutions, using the query-flow graph [6], were also proposed [7, 16]. However, finding good recommendations for tail e-commerce queries based on session co-occurrence turns to be difficult [16]. For addressing also the long tail of the query distribution, [8] conceptually extend the query-flow graph with term nodes in addition to query nodes. [9] generate an inverted index of “successful” queries, i.e., ending query of a session with a click on its search result, and recommends queries retrieved from that index. Our approach has similarities with the later in using an index of successful queries, and extends the use of inverted index to include phonetic, sub-words, and semantic similarities upon retrieval.

<narr> Narrative:

</top>

<top>
<num> Number: 340105209
<title> Query Rewriting for Voice Shopping Null Queries

<desc> Description:
Recently, several attempts were made to apply deep learning to various query rewriting tasks. [14] proposed to use embedding techniques to expand a query via a k-nearest neighbor search. [19] proposed a framework that learns to rewrite queries by unsupervised candidate generation and supervised candidate ranking. For unsupervised candidate generation, they presented a a sequence-to-sequence LSTM model, but also incorporated several existing QR systems suggestions. Their scoring function required training over a large web click data. [44] applied a similar technique based on post-retrieval method for e-commerce web search. The applicability of these techniques to voice queries is still unclear, especially in light of the data sparsity challenges that still exist as voice interfaces are not yet widely adopted. Indeed, users do not tend to switch between voice and text when reformulating queries [39]. [22] showed that reformulation patterns of voice queries are different from those in conventional textual searches using both lexical and phonetic changes. [17] developed classifiers for distinguishing reformulation of voice query pairs from textual query pairs. They extended text-based approaches with voice signals such as phonetic similarity. This hints regarding the importance of phonetic representations in voice query rewriting. Our alternative queries generation approach does not require prior training and adjusts to the voice medium characteristics, considering its phonetic representation.

<narr> Narrative:

</top>

<top>
<num> Number: 340105210
<title> Query Rewriting for Voice Shopping Null Queries

<desc> Description:
One related direction in QR focuses on improving its precision by narrowing down a search query. In this case, the goal is to refine the query such that the refined alternative retrieves a more relevant subset of results. Approaches towards this task include learning rewritings based on past users’ query refinements [2, 31, 32] and applying pseudo-relevance feedback techniques [10, 29, 33, 45]. Those latter techniques commonly employ post-retrieval methods and iteratively query the search engine for newly added terms [12, 35]. In general, this direction is not suitable for handling null queries since the main problem with those queries is recall rather than precision. Those query refinement and rewriting techniques are mostly applicable to head queries.

<narr> Narrative:

</top>

<top>
<num> Number: 340133002
<title> Sentiment-guided Sequential Recommendation

<desc> Description:
As an initial attempt at applying deep learning to sequential recommendation, GRU4Rec [2] concatenates the behavior sequences of different users in a reasonable manner, thereby solving the difficult problem of uniformly modeling user behavior sequences of different lengths. This method illustrates the important role of recurrent neural networks (RNNs) [7] in sequential recommendation. Taking this research as a starting point, subsequent advanced approaches, such as memory-based RNNs [3, 12] and self-attention-based RNNs [5, 11], have taken sequential recommendation technology to a new level. These advanced technologies not only complete the modeling of pure behavior (item) sequences but also fully characterize additional information such as knowledge [3] and features [11] related to items to improve the sequence prediction performance. Some recent models based on the self-attention mechanism [8] perform particularly well in sequential recommendation. For example, SASRec [5] effectively captures users’ long-term preferences from both sparse and dense data sets, and in FDSA [11], two separated self-attention blocks (one for item sequences and one for features) were designed that achieved remarkable predictive effects.

<narr> Narrative:

</top>

<top>
<num> Number: 340133003
<title> Sentiment-guided Sequential Recommendation

<desc> Description:
Despite their enhanced performances, most existing methods consider only the objective information of sequential items; they rarely consider the subjective influence of human sentiments on sequential recommendation. Specifically, there is a potential correlation between the temporal changes in a user’s sentiments and that user’s sequential behavior. However, most of the existing models based on sentiment factors [4, 10] focus only on non-sequential recommendations. In other words, they ignore the influence of the temporal sentiment change pattern on the sequence of user behavior; however, this temporal influence sometimes plays a decisive role in generating the final preference. For example, under the influence of continuous positive sentiments, a user may review a series of purchased items positively; in contrast, under the influence of continuous negative sentiments, the same user is more likely to consume some items that can usher in a good mood.

<narr> Narrative:

</top>

<top>
<num> Number: 340105102
<title> Fairness-Aware Explainable Recommendation over Knowledge Graphs

<desc> Description:
One reason for this relates to the issue of data imbalance. Some users are disinclined to make a large number of purchases, which leads to insufficient historical user–item interactions. For instance, on e-commerce platforms such as Amazon, eBay, or Taobao, economically disadvantaged groups often make fewer purchases in light of their limited income and credit opportunities [20]. Under such circumstances, when making recommendation decisions, explainable RS models will be subject to algorithmic bias. The lack of user–item interactions implies that the corresponding user preferences are barely captured, causing weak visibility of such users to the RS model. This leads to the risk of such users being treated unfairly in terms of both recommendation performance and explanation diversity. In this paper, we aim at alleviating such algorithmic bias and improving the fairness of explainable recommendations.

<narr> Narrative:

</top>

<top>
<num> Number: 340105103
<title> Fairness-Aware Explainable Recommendation over Knowledge Graphs

<desc> Description:
Unfortunately, it is challenging to study fairness in recommendation systems due to the lack of unifying definitions and means of quantifying unfairness. [17] claim that no model can be fair in every aspect of metrics. Previous work has explored the fairness problem in recommendation from the perspective of selection aspects [21, 33, 35], marketing bias [36], popularity bias [42], multiple stakeholders [5] in terms of consumers and providers, among others. Existing research on fairness has shown that protected groups, defined as the population of vulnerable individuals in terms of sensitive features such as gender, age, race, religion, etc., are easily treated in a discriminatory way. However, it is generally not easy to obtain access to such sensitive attributes, as users often prefer not to disclose such personal information. In this study, we instead consider a directly observable property, the visibility of the user to the explainable RS model, which relates to a user’s level of activity on the platform, and may directly entail subpar treatment by the recommendation engine.

<narr> Narrative:

</top>

<top>
<num> Number: 340105104
<title> Fairness-Aware Explainable Recommendation over Knowledge Graphs

<desc> Description:
We are interested in solving the fairness problem on the user side specifically for knowledge graph (KG) enhanced explainable recommender systems. Since KGs preserve structured and relational knowledge, they make it easy to trace the reason for specific recommendations. KG-based approaches have thus grown substantially in popularity in explainable recommendation. Their explicit explanations take the form of reasoning paths, consisting of a sequence of relationships that start from a user and ultimately lead to a recommended item. State-of-the-art KG-based explainable RS methods [1, 37, 38, 40, 41, 44] utilize rich entity and relation information within the KG to augment the modeling of user–item interactions, so as to better understand the user preferences to make satisfactory recommendation decisions, accompanied by explainable reasoning paths. However, due to the fundamental nature of collaborative filtering, current KG-based explainable recommendation methods heavily rely on users’ collective historical interactions for model learning, so the recommendations and corresponding explanations tend to be more consistent with the dominating historical user interactions. Because of this, current RS methods tend to neglect the user–item interactions of less visible, inactive users, since they are easily overwhelmed by more visible, active users.

<narr> Narrative:

</top>

<top>
<num> Number: 340105105
<title> Fairness-Aware Explainable Recommendation over Knowledge Graphs

<desc> Description:
Growing interest in fairness has arisen in several research domains. Most notably, for data-driven decision-making algorithms, there are concerns about biases in data and models affecting minority groups and individuals [13]. Group fairness, also known as demographic parity, requires that the protected groups be treated equally to advantaged groups or the general population [23, 31, 35]. In contrast, individual fairness requires that similar individuals with similar attributes be treated similarly [4, 14, 27, 28]. Several prior works have sought to quantify unfairness both at the group and individual level [26]. Model bias has in fact been shown to amplify biases in the original data [2, 18, 47]. For each specific domain, there is a need to design suitable metrics to quantify fairness and develop new debiasing methods to mitigate inequity for both groups and individuals.

<narr> Narrative:

</top>

<top>
<num> Number: 340105106
<title> Fairness-Aware Explainable Recommendation over Knowledge Graphs

<desc> Description:
In the field of recommendation systems, the concept of fairness has been extended to multiple stakeholders [5]. [29] defined fairness measures in recommendation and proposed a Pareto optimization framework for fair recommendation. [30] addresses the supplier fairness in two-sided marketplace platforms and proposed heuristic strategies to jointly optimize fairness and relevance. Different aspects of fairness have been explored. [3] investigated pairwise recommendation with fairness constraints. [6] addressed the polarization in personalized recommendations, formalized as a multi-armed bandit problem. As for the fairness ranking, [43] proposed a fair top-k ranking task that ensures that the proportion of protected groups in the top-k list remains above a given threshold. [35] presented a conceptual and computational framework for fairness ranking that maximizes the utility for the user while satisfying specific fairness constraints. [21] developed a fairness-aware ranking framework that improves the fairness for individuals without affecting business metrics. [39] draw on causal graphs to detect and remove both direct and indirect rank bias, and show that a casual graph approach outperforms statistical parity-based approaches in terms of the identification and mitigation of rank discrimination. In our work, we are particular interested in the disparity of user visibility to modern ranking algorithms in recommendation systems.

<narr> Narrative:

</top>

<top>
<num> Number: 340105107
<title> Fairness-Aware Explainable Recommendation over Knowledge Graphs

<desc> Description:
Explainable recommendation [45] has been an important direction in recommender system research. Past work has considered explaining latent factor models [46], explainable deep models [19], social explainable recommendations [32], visual explanations [10], sequential explanations [11], and dynamic explanations [12]. An important line of research leverages entities, relationships, and paths in knowledge graphs to make explainable decisions. Within this field, [1] incorporated TransE-based knowledge graph representations for explainable recommendation. [38] proposed an attention-based knowledge-aware model to infer user preferences over KGs for recommendation. [41] adopted reinforcement learning for path inference in knowledge graphs. [7] improved the efficiency of KG-based recommendation based on non-sampling learning. However, none of these works considered model bias, which may lead to both recommendations and explanations that fail to satisfy basic principles of fairness.

<narr> Narrative:

</top>

<top>
<num> Number: 340133302
<title> Feature Transformation for Neural Ranking Models

<desc> Description:
In the learning-to-rank setting, tree-based models [6, 11, 17] have been extensively studied in the past and remain competitive on public data sets which primarily consist of numerical features. The tree-based model architecture is generally immune to the adverse impact of directly using raw features. Recently, neural network based deep learning models attract lots of attention for learning-to-rank tasks [1, 5]. However, few of them investigate the impact of feature transformation. A possible reason is that neural ranking models are regarded as universal function approximators [14], which leads to the misconception that the optimal ranking function can be automatically learned by current algorithms without feature transformation. Therefore, it is still unclear whether feature transformation is important for neural ranking models.

<narr> Narrative:

</top>

<top>
<num> Number: 340133305
<title> Feature Transformation for Neural Ranking Models

<desc> Description:
In information retrieval, feature transformation is also a common practice. For example, the YAHOO Learning to Rank Challenge data set [8] applies cumulative distribution-based transformation on all features; the LETOR [23] data set also applies query-level min-max scaling on each feature. In traditional information retrieval, feature transformation has been extensively studied on both term frequency and inverse document frequency (e.g., BM25). However, such a study is still missing for neural ranking models.

<narr> Narrative:

</top>

<top>
<num> Number: 340128101
<title> How Useful are Reviews for Recommendation? A Critical Review and Potential Improvements

<desc> Description:
Previously, there largely have been two schools of thought regarding employing user reviews for better recommendation. The first type considers reviews as “explanations" for the user giving that specific rating and tries to incorporate them into matrix factorization (MF). HFT [9] is such a model which tries to regularize the latent features being learned through MF by reusing the same latent features for modeling the reviews’ likelihood using LDA [1]. The other type of methods are based on the philosophy that textual reviews are much more expressive than a single rating, and can be used to learn better latent features to perform better MF. [2, 3, 11, 13] are all popular methods which, in some different way, try to extract features from user reviews and item reviews through deep learning architectures like TextCNN [7], and use these extracted features to perform MF. All the methods used for analysis in this paper are discussed in more detail in Section 2.2.

<narr> Narrative:

</top>

<top>
<num> Number: 340128102
<title> How Useful are Reviews for Recommendation? A Critical Review and Potential Improvements

<desc> Description:
Our work also connects to recent discussions [4] on the reproducibility of recent neural methods for recommendation. Note that the topic of this paper is different from [4] since, in addition to the correctness of recent works, we also deal with a more general meta-question about the utility of reviews for recommendation.

<narr> Narrative:

</top>

<top>
<num> Number: 340132201
<title> A Study of Neural Matching Models for Cross-lingual IR

<desc> Description:
CLIR is the task of retrieving documents in target language Lt with queries written in source language Ls. The increasing popularity of projection-based weakly-supervised [4, 6, 14] and unsupervised [1, 2] cross-lingual word embeddings has spurred unsupervised frameworks [8] for CLIR, while in the realm of monolingual IR, interaction-based neural matching models [5, 10, 15] that utilize semantics contained in word embeddings have been the dominant force. This study fills the gap of utilizing CLWEs in neural IR models for CLIR.

<narr> Narrative:

</top>

<top>
<num> Number: 340132202
<title> A Study of Neural Matching Models for Cross-lingual IR

<desc> Description:
Traditional CLIR approaches translate either document or query using off-the-shelf SMT system such that query and document are in the same language. A number of researchers [12, 13] later investigated utilizing translation table to build a probabilistic structured query [3] in the target language. Recently, [8] showed that CLWEs are good translation resources by experimenting with a CLIR method (dubbed TbT-QT) that translates each query term in the source language to the nearest target language term in the CLWE space. CLWEs are obtained by aligning two separately trained embeddings for two languages in the same latent space, where a term in Ls is proximate to its synonyms in Ls and its translations in Lt, and vice versa. TbT-QT takes only the top-1 translation of a query term and uses the query likelihood model [11] for retrieval. The overall retrieval performance can be damaged by vocabulary mismatch magnified with translation error. Using closeness measurement between query and document terms in the shared CLWE space as matching signal for relevance can alleviate the problem, but this area has not been extensively studied.

<narr> Narrative:

</top>

<top>
<num> Number: 340132203
<title> A Study of Neural Matching Models for Cross-lingual IR

<desc> Description:
Representation learning: models in which interaction features are built with differentiable operations (e.g., kernel pooling [15]) allow customizing word embeddings via end-to-end learning from large-scale training data.

<narr> Narrative:

</top>

<top>
<num> Number: 340132204
<title> A Study of Neural Matching Models for Cross-lingual IR

<desc> Description:
Although representation learning is capable of further improving overall retrieval performance [15], it was shown in the same study that updating word embeddings requires large-scale training data to work well (more than 100k search sessions in their case). In CLIR, however, datasets usually have fewer than 200 queries per available language pair and can only support training neural models with smaller capacity. Therefore, we focus on the pattern learning aspect of neural models.

<narr> Narrative:

</top>

<top>
<num> Number: 340132205
<title> A Study of Neural Matching Models for Cross-lingual IR

<desc> Description:
Two unsupervised CLIR approaches using CLWEs are proposed by [8]. BWE-Agg ranks documents with respect to a query using the cosine similarity of query and document embeddings, obtained by aggregating the CLWEs of their constituent terms. The simpler version, namely BWE-Agg-Add, takes the average embeddings of all terms for queries and documents, while the more advanced version BWE-Agg-IDF builds document embeddings by weighting terms with their inverse document frequencies. TbT-QT, as described in §1, first translates each query term to its nearest cross-lingual neighbor term and then adopts query-likelihood in mono-lingual setting. These two approaches represent different perspectives towards CLIR using CLWEs. BWE-Agg builds query and document representations out of CLWEs but completely neglects exact matching signals, which play important roles in IR. Also, although query and document terms are weighted based on IDF, using only one representation for a long document can fail to emphasize the section of a document that is truly relevant to the query. TbT-QT only uses CLWEs as query translation resources and adopts exact matching in a mono-lingual setting, so its performance is heavily dependent on the translation accuracy (precision@1) of CLWEs. Analytically, an interaction-based neural matching model that starts with word level query-document interactions and considers both exact and similar matching can make up for the shortcomings of the above two methods.

<narr> Narrative:

</top>

<top>
<num> Number: 340132206
<title> A Study of Neural Matching Models for Cross-lingual IR

<desc> Description:
For interaction-based matching models, we select three representative models (MatchPyramid [9, 10], DRMM [5] and KNRM [15]) from the literature for analysis and experiments.

<narr> Narrative:

</top>

<top>
<num> Number: 340132208
<title> A Study of Neural Matching Models for Cross-lingual IR

<desc> Description:
The DRMM [5] model uses a matching histogram to capture the interactions of a query term with the whole document. The valid interval of cosine similarity (i.e., [−1, 1]) is discretized into a fixed number of bins such that a matching histogram is essentially a fixed-length integer vector. Features from different histograms are weighted based on attention calculated on query terms. DRMM is not position-preserving, as the authors claim that relevance matching is not related to term order.

<narr> Narrative:

</top>

<top>
<num> Number: 340132209
<title> A Study of Neural Matching Models for Cross-lingual IR

<desc> Description:
The KNRM [15] model takes matrix representation for query-document interaction (similar to MP), but “categorizes” interactions into different levels of cosine similarities (similar to DRMM), using Gaussian kernels with different mean value μ. The distinct advantage of KNRM over DRMM is that the former allows gradient to pass through Gaussian kernels, and therefore supports end-to-end learning of embeddings.

<narr> Narrative:

</top>

<top>
<num> Number: 340132210
<title> A Study of Neural Matching Models for Cross-lingual IR

<desc> Description:
According to results reported in respective studies [5, 10, 15], the relative performance of three models for mono-lingual IR should be KNRM > DRMM > MP, even when embedding learning is turned off with KNRM. Tweaking a neural model for support of CLIR is trivial: instead of considering interaction value as two terms’ similarity in a mono-lingual embedded space, we consider the proximity of their representations in the shared cross-lingual embedded space. However, there are several matters to consider while making the transition:

<narr> Narrative:

</top>

<top>
<num> Number: 340132211
<title> A Study of Neural Matching Models for Cross-lingual IR

<desc> Description:
Query translation based CLIR methods (e.g., TbT-QT [8]) first translate queries fromLs to Lt, then use mono-lingual retrieval in Lt. Apart from the inherent vocabulary mismatch problem within Lt, the translation error from Ls to Lt has to be also counted. Looking at the example in Table 1, TbT-QT would look for occurrence of “telefónicos” in the collection, and documents containing only the correct translation (“teléfono”) would be overlooked. Interaction-based neural matching models alleviate this issue by giving partial credit to suboptimal nearest neighbors, which in many cases are the correct translations. To demonstrate the necessity of directly using cross-lingual word embedding similarity as interaction for neural models, we conduct comparative experiments where queries are first translated term-by-term like TbT-QT using CLWEs, then used for retrieval in mono-lingual setting. Such models are referred to as {MP,DRMM,K-NRM}-TbT-QT, respectively.

<narr> Narrative:

</top>

<top>
<num> Number: 340105701
<title> Attentional Graph Convolutional Networks for Knowledge Concept Recommendation in MOOCs in a Heterogeneous View

<desc> Description:
In recent years, massive open online courses (MOOCs) are gradually becoming a mode of alternative education worldwide. For example, Coursera, edX, and Udacity, the three pioneering MOOC platforms, offer millions of user accesses to numerous courses from internationally renowned universities. In China, millions of users study in XuetangX, which is one of the largest MOOC platforms [20], where thousands of courses are offered on various subjects. Although the number of students in MOOCs is continuously growing, there are still some straits with MOOCs. A challenging problem for MOOCs is how to attract students to study continuously and efficiently on the platforms, where the overall course completion rate is lower than 5% [34]. Therefore, it requires better understanding and capturing of student interests.

<narr> Narrative:

</top>

<top>
<num> Number: 340105702
<title> Attentional Graph Convolutional Networks for Knowledge Concept Recommendation in MOOCs in a Heterogeneous View

<desc> Description:
To understand and capture student interests on MOOCs platforms, multiple efforts have been done, including course recommendation [13, 35], behavior prediction [20], user intentions understanding [34], etc. Among these efforts, recommendation system is applied by MOOCs provider to recommend courses to students. However, a course usually consists of a number of video lectures with each one covering some specific knowledge concepts. Direct course recommendation overlooks students’ interest to specific knowledge concept, e.g., computer vision courses taught by different instructors may be quite different in a microscopic view (cover different sets of knowledge concepts): someone instructor may only cover geometry based methods while other one may only cover deep learning based methods, and thus recommending the computer vision course only covering geometry based methods to the student interested in the deep learning based methods will not be a good match. Therefore, it requires to study students’ online learning interests from a microscopic view and conduct knowledge concept recommendation.

<narr> Narrative:

</top>

<top>
<num> Number: 340105703
<title> Attentional Graph Convolutional Networks for Knowledge Concept Recommendation in MOOCs in a Heterogeneous View

<desc> Description:
Traditional recommendation strategy, such as collaborative filtering (CF), which considers user (students) historical interactions and makes recommendations based on potential common preferences from users with similar interests, has achieved great success. However, CF based methods suffer from the sparsity of user-item (student-knowledge concept) relationships, which limits the recommendation performance. To overcome this problem, a number of efforts have been done by leveraging side information, such as social networks [11], user/item attributes [27], images [33], contexts [25], etc. In a MOOCs platform, we observe that in addition to the user and knowledge concept, there exist multiple types of entities (video, course, teacher) and multiple types of relationships between pair of different entities. Table 1 shows the statistics of the real-world XuetangX data collected between January 1st, 2018 and March 31st, 2018. This data consists of 9,986 users, 43,405 videos, 7,020 courses, 5,038 teachers, 1,029 knowledge concepts, and corresponding multiple types of relationships. As shown in Figure 1, the “course: V_9e77179” includes the “knowledge concept: c++”, the “student: 207256” is taking the “course: CaltechX”, the “video: V_1a9aa686” is related to the “knowledge concept: binary tree”, and the “course: CaltechX” is taught by the “teacher: Smith”. Further more, taking users’ behavior history into consideration, we can discover additional relationships. For example, the “user: 207256” clicked the “knowledge concept: c++”, “knowledge concept: binary tree”, and “knowledge concept: depth-first search”. Accounting for above multiple types of relationships, we can get much more fruitful facts and interactions between the user and knowledge concepts. If we merely depend on the basic structures, it is difficult to find the significant interaction between “knowledge concept: depth-first search” and “knowledge concept: time complexity”, which belong to different courses but are clicked by one user. As shown in Figure 1, different knowledge concepts contain different context. Only utilizing single type of interaction may overlook the significant relations between user and knowledge concept. For example, “knowledge concept: c++” and “knowledge concept: binary tree” have dissimilar semantics even though they are included in the same video. These heterogeneous relationships provide rich side information and can benefit the recommendation system in three folds: (1) semantic relatedness among knowledge concepts can be introduced and help to identify the latent interaction; (2) a user’s interests can be reasonably extended and the diversity of recommended knowledge concepts can be increased; and (3) a user’s interest can be interpreted by tracking a user’s historical records along these relationships. Thus, it requires to incorporate these heterogeneous relationships into the representation learning of the entities.

<narr> Narrative:

</top>

<top>
<num> Number: 340105704
<title> Attentional Graph Convolutional Networks for Knowledge Concept Recommendation in MOOCs in a Heterogeneous View

<desc> Description:
Based on above observation, we propose Attentional Heterogeneous Graph Convolutional Deep Knowledge Recommender (ACKRec), an end-to-end framework for knowledge concept recommendation on MOOCs platform. To capture heterogeneous complex relationships, we model the MOOCs platform data as a heterogeneous information network (HIN) [23]. Then, we propose an attention-based graph convolutional networks (GCNs) to learn the representation of different entities. Traditional GCNs can only capture the homogeneous relationships among homogeneous entities, which overlooks the rich information among heterogeneous relationships. To address this issue, we use meta-paths [25] as the guidance to capture the heterogeneous context information in a HIN via GCN. In this way, the heterogeneous relationships are utilized in a more natural and intuitive way. Moreover, considering that different students may have different interests, we further propose an attention mechanism to adaptively leverage context in multiple meta-paths. In the end, we propose to optimize the parameters of proposed model via an extended matrix factorization and obtain the final recommendation list.

<narr> Narrative:

</top>

<top>
<num> Number: 340105705
<title> Attentional Graph Convolutional Networks for Knowledge Concept Recommendation in MOOCs in a Heterogeneous View

<desc> Description:
Graphs play a crucial role in modern machine learning [5, 6]. Recently, graph neural networks [1, 4, 15, 26, 30, 31, 36] have become recurrent topics in machine learning, and both have broad applicability. However, in the real world, the graphs are usually heterogeneous. There are a few attempts heterogeneous information network setting. [28] proposed DeepHGNN, an attentional heterogeneous graph neural network model to learn from the heterogeneous program behavior graph to guide the reidentification process. [29] presented HAGNN, a Hierarchical Attentional Graph Neural Encoder and used it for program behavior graph analysis. Additionally, the GEM [17] model, a heterogeneous graph neural network approach for detecting malicious accounts at Alipay, has been presented. Unlike these approaches, our proposed model utilizes attentional graph convolutional networks for the representations of users and knowledge concepts in heterogeneous information networks.

<narr> Narrative:

</top>

<top>
<num> Number: 340105706
<title> Attentional Graph Convolutional Networks for Knowledge Concept Recommendation in MOOCs in a Heterogeneous View

<desc> Description:
Some information recommendation models are based on heterogeneous information networks. [19] proposed Heaters, a graph-based model, to solve the general recommendation problem in heterogeneous networks. [32] proposed to use meta-paths based latent features to represent the connectivity between users and items along with different types of paths. Additionally, Follow previous work, [10, 23, 24] proposed to use meta-path concept to mode the heterogeneous information in HIN. Different from previous methods, this study focuses on capture the representations of different types of entities on the heterogeneous information network and fuses themselves content feature of different types of entities and the structure features of entities in MOOCs data together for the recommendation task of the knowledge concept.

<narr> Narrative:

</top>

<top>
<num> Number: 340110601
<title> The Cortical Activity of Graded Relevance

<desc> Description:
Relevance is a key concept in Information Science and Retrieval [45, 57, 59, 66]. While relevance is considered to be multidimensional [12, 45, 57], dynamic and complex [11, 20, 46, 60], there are still debates around the granularity level of relevance judgements that should be collected [44]. To answer this question, it is crucial to understand what each grade of relevance actually means. The value of evaluating information based on graded relevance has begun to receive attention in recent years both from system [40, 55] and user [2, 15, 48] point of views. This is particularly important since the granularity of relevance judgements in previous studies have been based on investigating this phenomenon indirectly, via some sort of mediator [29, 71]. This, therefore, limits the understanding of how searchers perceive different degrees of information relevance [55]. This paper aims to investigate the neural underpinnings of graded relevance directly.

<narr> Narrative:

</top>

<top>
<num> Number: 340110602
<title> The Cortical Activity of Graded Relevance

<desc> Description:
Relevance is also known to be subjective and difficult to quantify [48] since it depends on a searcher’s perception of information relating to a specific Information Need (IN) at a certain point in time [8, 57]. However, given the semantic gap between a searcher’s IN and their formulated queries [7, 27, 52], IR systems have employed various techniques to capture the subjective aspect of relevance [2] to improve the effectiveness of retrieved results. Examples of such techniques are explicit [38], implicit (e.g. [24, 36]) and physiological [47] feedback. More recently, researchers have shown the possibility of capturing the neural processes associated with relevance, using brain imaging techniques [2, 15, 16, 22, 25, 28, 33, 37, 48, 65]. These studies have either investigated relevance in the context of word associations (i.e. relevance of a word with respect to another) [15, 16, 65] without subjects experiencing any IN; or investigated relevance in the context of Information Retrieval (IR) when IN has been introduced to subjects. In the latter scenario, relevance was investigated only as a binary notion [2, 19, 22, 24, 25, 28, 37, 48, 49] leaving the graded nature of it unexplored. In this paper, we aim to investigate three fundamental research questions:

<narr> Narrative:

</top>

<top>
<num> Number: 340110603
<title> The Cortical Activity of Graded Relevance

<desc> Description:
Relevance is the fundamental concept in IR [45, 57–59]. It plays a crucial role in the user-system interaction since it is a substantial indicator of system retrieval performance [8, 57]. Despite significant attention dedicated to examining this concept, relevance is still not fully understood, and it is a subject of many ongoing scientific debates. Past research has investigated the concept of relevance at different granularity levels from both the user [29, 71] and system [35, 40] perspective. Within the system side, graded relevance (in comparison to the binary one) has been shown to improve ranking functions [34, 55]. Within the user side, recent research supports the idea of categorical thinking [71], suggesting that users divide retrieved results into 3-5 categories based on relevance [41]. However, levels of granularity were decided based on a self-report mechanism, without clear evidence that those levels have different physical manifestations in the brain. In this paper, we aim to provide evidence for different grades of relevance from a neuroscience perspective.

<narr> Narrative:

</top>

<top>
<num> Number: 340110604
<title> The Cortical Activity of Graded Relevance

<desc> Description:
Given the importance of the user side of relevance, IR systems have been employing mechanisms and techniques to capture this phenomenon, namely explicit and implicit feedback. Explicit feedback is easy to use, however, difficult to obtain due to the cognitive burden associated with it [47], as the user is required to explicitly state whether presented content is subjectively perceived as relevant or not [67]. Implicit feedback is an unobtrusive data collection method. Popular techniques used to measure implicit relevance feedback are, for example, dwell time (i.e. [36]), eye-tracking and pupillometry [24], and/or the measurements of affective [4, 47] and physiological signals [47]. However, implicit feedback is often found to be noisy, which decreases its accuracy [2]. The findings of novel studies employing neuroscience have shown that brain imaging is an effective method to capture relevance judgement in-real time.

<narr> Narrative:

</top>

<top>
<num> Number: 340110605
<title> The Cortical Activity of Graded Relevance

<desc> Description:
Recent research has begun to apply brain imaging methods to study aspects of the IR process from a neuroscience perspective. One particular area of emphasis for this research has been to examine the IN process [50, 51]. In addition, it has been found that prediction of the IN state experienced by a user is possible using brain signals [50]. Apart from IN, recent studies have employed brain imaging techniques to gain a better understanding of other parts of the information seeking and retrieval process, such as query formulation [28], search [49, 70] and relevance (e.g. [33]).

<narr> Narrative:

</top>

<top>
<num> Number: 340110606
<title> The Cortical Activity of Graded Relevance

<desc> Description:
Recent research using a neuroscience approach to investigate relevance might be categorised in two ways based on the context within which the relevance was measured. The first line of brain-imaging research has position relevance within the IR task. For instance, [48] employed functional magnetic resonance imaging (fMRI), to localise differences in brain activity in cortical regions during the processing of relevant vs non-relevant images. The research was able to identify regions engaged in the relevance judgement processing and the increased activation of these regions for relevant items was related to visuospatial working memory [49, 51].

<narr> Narrative:

</top>

<top>
<num> Number: 340110608
<title> The Cortical Activity of Graded Relevance

<desc> Description:
Relevance has been inferred using EEG [25] or in combination with pupillometry or/and eye-tracking devices [22] within the context of the IR task, not only for textual stimuli but also for videos [37] and images [2]. For instance, [2] examined the processing of relevant vs non-relevant images, finding the most significant differences to occur between 500 – 800ms. [37] explored the ERPs associated with topical relevance of video skims and classified the data based on two specific ERP components (N400 and P600), which have been shown to be indicators of relevant and non-relevant judgements. Moreover, recent findings have shown that relevance can be predicted in real-time from EEG brain signals and eye movements while the user engages with the system and IR task [28].

<narr> Narrative:

</top>

<top>
<num> Number: 340110609
<title> The Cortical Activity of Graded Relevance

<desc> Description:
Another line of research has examined relevance in the context of word associations, employing EEG in isolation, or in combination with eye gaze [15, 16, 65]. In these scenarios, participants did not experience IN, but they engaged in judging word association to the topic. The findings of these studies have shown that brain signals differ when subjects process relevant vs. non-relevant words across time [16]. Later, [15] introduced a brain-relevance paradigm enabling recommendation of information to users without any explicit user interaction, based on EEG signals alone evoked by users’ engagement with the textual content.

<narr> Narrative:

</top>

<top>
<num> Number: 340126602
<title> Reranking for Efficient Transformer-based Answer Selection

<desc> Description:
In this paper, we study and propose solutions to improve the efficiency and cost of modern QA systems based on search engines and Transformer models. Though we mainly focus on AS2, the proposed solution is general, and can be applied to other QA paradigms, including machine reading tasks. Our main idea follows the successful cascade approach for ad-hoc document retrieval [19], which considers fast but less accurate rerankers together with more accurate but slower models. In particular, we use (i) simple models, e.g., Jaccard similarity, as well as light neural models such as Compare-Aggregate [22], for reranking answer sentence candidates; and (ii) BERT models as our final AS2 step.

<narr> Narrative:

</top>

<top>
<num> Number: 340126604
<title> Reranking for Efficient Transformer-based Answer Selection

<desc> Description:
Neural models for AS2 typically apply a series of non-linear transformations to the input question and answer, represented as compositions of word or character embeddings and then measure the similarity between the obtained representations. For example, the Rel-CNN [16] has two separate embedding layers for the question and answer, and relational embedding, which aims at connecting them. Recent work has shown that Transformer-based models, e.g., BERT [5], can highly improve inference. [23] applied it to Ad Hoc Document Retrieval, obtaining significant improvement. [8] fine-tuned BERT for AS2, achieving the state of the art. However, BERT’s high computational cost prevents its use in most real-word applications. Some solutions rely on leveraging knowledge distillation in the pre-training step, e.g., [15]. In contrast, we propose an alternative (and compatible with the initiatives above) approach following previous work in document retrieval, e.g., the use of sequential rerankers [19]. [21] focused on quickly identifying a set of good candidate documents to be passed to the second and further rerankers of the cascade. [4] proposed two stage approaches using a limited set of textual features and a final model trained using a larger set of query- and document-dependent features. [7] presented a new general framework for learning an end-to-end cascade of rankers using backpropagation. [1] studied effectiveness/efficiency trade-offs with three candidate selection approaches. All the methods above are in line with our study, but they target very different settings: document retrieval, linear models or just basic neural models. In contrast, the main contribution of our paper is to show that simple and efficient neural sentence rerankers are compatible with expensive Transformer models, enabling their efficient use.

<narr> Narrative:

</top>

<top>
<num> Number: 340106101
<title> Guided Transformer: Leveraging Multiple External Sources for Representation Learning in Conversational Search

<desc> Description:
Conversational search has recently attracted much attention as an emerging information retrieval (IR) field. The ultimate goal of conversational search systems is to address user information needs through multi-turn natural language conversations. This goal is partially addressed in previous work with several simplifying assumptions. For example, the TREC Conversational Assistance Track (CAsT) in 2019 has focused on multi-turn conversational search, in which users submit multiple related search queries [16]. Similarly, conversational question answering based on a set of related questions about a given passage has been explored in the natural language processing (NLP) literature [7, 40, 44]. However, the existing settings are still far from the ideal mixed-initiative scenario, in which both user and system can take any permitted action at any time to perform a natural conversation. In other words, most existing work in conversational search assumes that users always ask a query and the system only responds with an answer or a ranked list of documents.

<narr> Narrative:

</top>

<top>
<num> Number: 340106102
<title> Guided Transformer: Leveraging Multiple External Sources for Representation Learning in Conversational Search

<desc> Description:
Recent conversational information seeking platforms, such as Macaw [59], provide support for multi-turn, multi-modal, and mixed-initiative interactions. There have been recent efforts to go beyond the “user asks, system responds” paradigm by asking clarifying questions from the users, including offline evaluation of search clarification [1], clarifying question generation for open-domain search queries [61], and preference elicitation in conversational recommender systems [8, 46, 64]. Past research in the area of search clarification has shown significant promise in asking clarifying questions. However, utilizing user responses to clarifying questions to improve the search performance has been relatively unstudied. In this paper, we propose a model that learns an accurate representation for a given user-system conversation. We focus on the conversations in which the user submits a query, and due to uncertainty about the query intent or the search quality, the system asks one or more clarifying questions to reveal the actual information need of the user. This is one of the many necessary steps that should be taken to achieve an ideal mixed-initiative conversational search system.

<narr> Narrative:

</top>

<top>
<num> Number: 340106103
<title> Guided Transformer: Leveraging Multiple External Sources for Representation Learning in Conversational Search

<desc> Description:
Motivated by previous research on improving query representation by employing other information sources, such as the top retrieved documents in pseudo-relevance feedback [2, 14, 27], we propose a neural network architecture that uses multiple information sources for learning accurate representations of user-system conversations. We extend the Transformer architecture [51] by proposing a novel attention mechanism. In fact, the sequence transformation in Transformer networks are guided by multiple external information sources in order to learn more accurate representations. Therefore, we call our network architecture Guided Transformer or GT. We train an end to end network based on the proposed architecture for two downstream target tasks: document retrieval and next clarifying question selection. In the first target task, the model takes a user-system conversation and scores documents based on their relevance to the user information need. On the other hand, the second task focuses on selecting the next clarifying question that would lead to higher search quality. For each target task, we also introduce an auxiliary task and train the model using a multi-task loss function. The auxiliary task is identifying the actual query intent description for a given user-system conversation. For text representation, our model takes advantage of BERT [18], a state-of-the-art text representation model based on the Transformer architecture, modified by adding a “task embedding” vector to the BERT input to adjust the model for the multi-task setting.

<narr> Narrative:

</top>

<top>
<num> Number: 340106104
<title> Guided Transformer: Leveraging Multiple External Sources for Representation Learning in Conversational Search

<desc> Description:
In our experiments, we use two sets of information sources, the top retrieval documents (similar to pseudo-relevance feedback) and the pool of different clarifying questions for the submitted search query. The rational is that these sources may contain some information that helps the system better represent the user information needs. We evaluate our models using the public Qulac dataset and follow the offline evaluation methodology recently proposed by [1].  ur experiments demonstrate that the proposed model achieves over 29% relative improvement in terms of MRR compared to competitive baselines, including state-of-the-art pseudo-relevance feedback models and BERT, for the document retrieval task. We similarly observe statistically significant improvements in the next clarifying question selection task compared to strong baselines, including learning to rank models that incorporate both hand-crafted and neural features, including BERT scores.

<narr> Narrative:

</top>

<top>
<num> Number: 340106106
<title> Guided Transformer: Leveraging Multiple External Sources for Representation Learning in Conversational Search

<desc> Description:
More recently, [42] introduced a theoretical framework and a set of potentially desirable features for a conversational information retrieval system. [50] studied real user conversations and provided suggestions for building conversational systems based on human conversations. The recent improvements in neural models has made it possible to train conversation models for different applications, such as recommendation [64], user intent prediction [41], next user query prediction [58], and response ranking [57].

<narr> Narrative:

</top>

<top>
<num> Number: 340106108
<title> Guided Transformer: Leveraging Multiple External Sources for Representation Learning in Conversational Search

<desc> Description:
Asking clarifying questions has attracted much attention in different domains and applications. To name a few, [6] studied user intents, and clarification in community question answering (CQA) websites. [49] also focused on detecting ambiguous CQA posts, which need further follow-up and clarification. There is other line of research related to machine reading comprehension (MRC) task, that given a passage, generating questions which point out missing information in the passage. [43] proposed a reinforcement learning solution for clarifying question generation in a closed-domain setting. We highlight that most of the techniques in this area assume that a passage is given, and the model should point out the missing information. Hence, it is completely different form clarifying the user information needs in IR. Clarification has also studied in dialog systems and chat-bots [5, 17, 29], computer vision [31], and speech recognition [47]. However, since non of the above-mentioned systems are information seeking, their challenges are fundamentally different from challenges that the IR community faces in this area.

<narr> Narrative:

</top>

<top>
<num> Number: 340106109
<title> Guided Transformer: Leveraging Multiple External Sources for Representation Learning in Conversational Search

<desc> Description:
In the realm of IR, the user study done by [24] showed that clarifying questions do not cause user dissatisfaction, and in fact, they sometimes increase the satisfaction. [10] studied the task of clarification for entity disambiguation. However, the clarification format in their work was restricted to a “did you mean A or B?” template, which makes it non-practical for many open-domain search queries. More recently, [1] introduced an offline evaluation methodology and a benchmark for studying the task of clarification in information seeking conversational systems. They have also introduced a method for selecting the next clarifying question which is used in this paper as a baseline. [61] proposed an approach based on weak supervision to generate clarifying questions for open-domain search queries. User interaction with clarifying questions has been later analyzed in [62].

<narr> Narrative:

</top>

<top>
<num> Number: 340106110
<title> Guided Transformer: Leveraging Multiple External Sources for Representation Learning in Conversational Search

<desc> Description:
A common application of clarification is in conversational recommendation systems, where the system asks about different attributes of the items to reveal the user preferences. For instance, [8] designed an interactive system for venue recommendation. [48] utilized facet-value pairs to represent a conversation history for conversational recommendation, and [64] extracted facet-value pairs from product reviews automatically, and considered them as questions and answers. In this work, we focus on conversational search with open-domain queries which is different from preference elicitation in recommendation, however, the proposed solution can be potentially used for the preference elicitation tasks as well.

<narr> Narrative:

</top>

<top>
<num> Number: 340106111
<title> Guided Transformer: Leveraging Multiple External Sources for Representation Learning in Conversational Search

<desc> Description:
Improving the representations learned by neural models with the help of external resources has been explored in a wide range of tasks. [54] proposed a text matching model based on recurrent and convolution networks that has a knowledge acquisition gating function that uses a knowledge base for accurate text matching. [57] studied the use of community question answering data as external knowledge base for response ranking in information seeking conversations. They proposed a model based on convolutional neural networks on top the interaction matrix. More recently, [55] exploited knowledge bases to improve LSTM based networks for machine reading comprehension tasks. Our work is different from prior work in multiple dimensions. From the neural network architecture, we extend Transformer by proposing a novel architecture for learning attention weights from external information sources. In addition, we do not use external knowledge bases in our experiments. For example, we use the top retrieved documents as one information source, which is similar to the pseudo-relevance feedback (PRF) methods [2, 14, 27, 60]. We showed that our method significantly outperforms state-of-the-art PRF methods.

<narr> Narrative:

</top>

<top>
<num> Number: 340146701
<title> Deep Reinforcement Learning for Information Retrieval: Fundamentals and Advances

<desc> Description:
Recent years have witnessed the increased popularity and explosive growth of the World Wide Web, which has generated huge amounts of data and leaded to progressively severe information overload problem [4]. In consequence, how to extract information (products or services) that satisfy users’ information requirements at the proper time and place has become increasingly important. This motivates several information retrieval mechanisms, such as search, recommendation, and online advertising. These retrieval mechanisms could generate a set of objects that best match users’ explicit or implicit preferences [10]. Efforts have been made on developing supervised or unsupervised methods for these information retrieval mechanisms [21]. However, since the widely use of mobile applications during the recent years, more and more information retrieval services have provided interactive functionality and products [41], these conventional techniques typically face several common challenges. First, most of traditional approaches consider information retrieval tasks in a static environment and extract information via a fixed greedy strategy, which may fail to catch the dynamic characteristics of users’ preferences (or environment). Second, the majority of existing methods aims to maximize user’s immediate satisfaction, while completely overlooking whether the generate information can benefit more to user’s preference in the long run [24]. Thus, learning from interaction becomes a crucial machine learning paradigm for interactive IR, which is based on reinforcement learning [27].

<narr> Narrative:

</top>

<top>
<num> Number: 340146702
<title> Deep Reinforcement Learning for Information Retrieval: Fundamentals and Advances

<desc> Description:
Driven by recent advances in reinforcement learning theories and the prevalence of deep learning technologies, there has been tremendous interest in resolving complex problems by deep reinforcement leaning methods, such as the game of Go [25, 26], video games [16, 17], and robotics [14]. By integrating deep learning into reinforcement learning, DRL is not only capable of continuing sensing and learning to act, but also capturing complex patterns with the power of deep learning. Under the DRL schema, complex problems are addressed by acquiring experiences through interactions with a dynamic environment. The result is an optimal policy that can provide decision making solutions to complex tasks without any specific instructions [13]. Introducing DRL to information retrieval community can naturally tackle the above-mentioned challenges. First, DRL considers information retrieval tasks as sequential interactions between an RL agent (system) and users (environment), where the agent continuously update the information retrieval strategies based on users’ real-time feedback, so as to generate information best match users’ dynamic preferences. Second, the DRL-based techniques targets to optimize users’ long-term satisfaction or engagement. Therefore, the agent could identify information to achieve the trade-off between users’ short-term and long-term satisfaction.

<narr> Narrative:

</top>

<top>
<num> Number: 340146703
<title> Deep Reinforcement Learning for Information Retrieval: Fundamentals and Advances

<desc> Description:
Given the advantages of reinforcement learning, there have been tremendous interests in developing RL based information retrieval techniques [3, 5, 11, 12, 15, 38–40]. While these successes show the promise of DRL, applying learning from game-based DRL to information retrieval is fraught with unique challenges, including, but not limited to, extreme data sparsity, power-law distributed samples, and large state and action spaces.

<narr> Narrative:

</top>

<top>
<num> Number: 340146704
<title> Deep Reinforcement Learning for Information Retrieval: Fundamentals and Advances

<desc> Description:
Search targets at retrieving and ranking a set of items (e.g. documents, records) according to a user query [7, 29]. For query understanding, [19] proposed a reinforcement learning based query reformulation task, which maximizes the number of recalled relevant documents via rewriting a query. In [18], a multi-agent reinforcement learning framework is proposed to increase the diverse query reformulation efficiency, where each agent learns a local policy that performs well on a subset of examples, and all agents are trained with parallelism to make the learning faster. For relevance ranking, conventional methods typically optimize the evaluation metric before a predefined position (e.g. NDCG@K), which ignores the information after rank K. MDPRank [31] is proposed to address this problem by using the metrics calculated upon all the positions as reward function, and the model parameters are be optimized via maximizing the accumulated rewards for all decisions. Beyond relevance ranking, another important goal is to increase the diversity of search results [8, 22], which needs to capture the utility of information users have perceived from the preceding documents in a sequential document selection. MDP-DIV [34] formalized diverse ranking as a continuous state Markov decision process, and policy gradient algorithm of REINFORCE is leveraged to maximize the accumulated long-term rewards in terms of the diversity metric.

<narr> Narrative:

</top>

<top>
<num> Number: 340146705
<title> Deep Reinforcement Learning for Information Retrieval: Fundamentals and Advances

<desc> Description:
Recommender systems aim to learn users’ preferences based on their feedback and suggest items to match their preferences. User’s preference is assumed to be static in traditional recommendation algorithms such as collaborative filtering, which is usually not true in real-world recommender systems where users’ preferences are highly dynamic. Bandit methods [33, 37] usually utilizes a variable reward function to delineate the dynamic nature of the environment (reward distributions). Another solution is to introduce the MDP setting [6, 9, 42], where state represents user’s preference and state transition depicts the dynamic nature of user’s preference over time. In [39], a user’s dynamic preference (state) is learned from her browsing history and feedback. Each time a user provides feedback (skip, click or purchase) to an item, the recommender system will update the state to capture user’s new preferences. Conventional recommender algorithms also suffer from the exploitation-exploration dilemma, where exploitation is to suggest items that best match users’ preferences, while exploration is to randomly suggest items to mine more users’ possible preferences. The contextual bandit method is introduced to achieve the trade-off between exploitation and exploration with strategies such as ε-greedy [30], EXP3 [2], and UCB1 [1].

<narr> Narrative:

</top>

<top>
<num> Number: 340146706
<title> Deep Reinforcement Learning for Information Retrieval: Fundamentals and Advances

<desc> Description:
Online advertising is to suggest the right ads to the right users so as to maximize the click-through rate (CTR) or return on investment (ROI) of the advertising campaign, which consists of two main marketing strategy, i.e., guaranteed delivery (GD) and real-time bidding (RTB). In guaranteed delivery setting, ads that grouped into campaigns are charged on a pay-per-campaign basis for the pre-specified number of deliveries [23]. A multi-agent reinforcement learning approach [32] is proposed to derive cooperative policies for the publisher, where impression allocation problem is formulated as an auction problem, and publishers can submit virtual bids for impressions. In Real-Time Bidding setting, an advertiser submits a bid for each impression in a very short time frame. The ad selection task is typically modeled as multi-armed bandit (MAB) problem [20, 28, 35, 36], which neglects the fact that bidding actions would continuously occur before the budget running out. Thus, the MDP setting is introduced. For example, a model-based RL framework is proposed in RTB setting [3], where the state value is approximated by neural network to address the scalability problem of large auction amounts and the limited budget. In [12], a multi-agent bidding model is proposed to jointly consider all the advertisers’ biddings in the system, and a clustering approach is introduced to deal with a large number of advertisers.

<narr> Narrative:

</top>

<top>
<num> Number: 340110301
<title> An Eye Tracking Study of Web Search by People With and Without Dyslexia

<desc> Description:
Dyslexia is a cognitive diference that impacts about 15% of English speakers [7] (incidence rates vary by language [30]). People with dyslexia tend to experience challenges in tasks involving reading, writing, spelling, and memory, despite having normal intelligence. These challenges often manifest in a slower reading rate and lower reading comprehension [35]. However, because dyslexia is a spectrum disorder, diferent people may experience diferent subsets and degrees of symptoms [7].

<narr> Narrative:

</top>

<top>
<num> Number: 340110302
<title> An Eye Tracking Study of Web Search by People With and Without Dyslexia

<desc> Description:
Relatively little is known about how dyslexia impacts web search, but several recent studies have begun to shed some light on this topic. Interviews with people with dyslexia suggest that search engine use -including query formulation, search result triage and information extraction from target webpages- is particularly challenging for this population [4, 19, 35, 37, 43]. Online experiments comparing search behaviors of people with and without dyslexia have identifed some features of webpages, such as average line length and the ratio of images to text, that impact page readability for people with dyslexia [25].

<narr> Narrative:

</top>

<top>
<num> Number: 340110303
<title> An Eye Tracking Study of Web Search by People With and Without Dyslexia

<desc> Description:
To address these research questions, we conducted an eye tracking study with 27 participants (14 with dyslexia, 13 control). Each participant completed 6 informational search tasks using a modern, English-language, interactive search engine. Our analysis of eye tracking data, together with participants’ self-reports about their experiences, extend fndings from prior studies and contribute new insight into the diferences in search behavior between people with and without dyslexia. Our fndings validate prior self-report findings that Searchers with Dyslexia (SWD) struggle with all stages of the search process: query formulation, search results triage, and information extraction [37, 43]. Adding to prior work, we find SWD visually attend to pages in a markedly diferent fxation pattern than searchers without dyslexia (for e.g. see Figure 1). We conclude the paper by discussing the design implications of our fndings to improve cognitive accessibility of search for people with dyslexia.

<narr> Narrative:

</top>

<top>
<num> Number: 340110304
<title> An Eye Tracking Study of Web Search by People With and Without Dyslexia

<desc> Description:
Researchers in information retrieval and HCI have extensively studied user interaction with web search systems, particularly for complex informational [16] or exploratory [55] search tasks. Such tasks typically comprise three stages [3, 43]: query formulation (i.e., generating and refining search keywords), search results triage (i.e., determining which parts of the search engine results page - the SERP - are most relevant to the task at hand, and which link to open), and information extraction (i.e., gathering and making sense of the sought-after content). In this study, we gather data about this complete query-triage-extraction search pipeline for searchers with and without dyslexia.

<narr> Narrative:

</top>

<top>
<num> Number: 340110305
<title> An Eye Tracking Study of Web Search by People With and Without Dyslexia

<desc> Description:
Researchers have employed a variety of methods to study web search, including analyzing search engine and web browser logs (e.g., [32, 53, 54]), gathering self-report data from surveys, interviews, or diary studies of end-users (e.g., [42, 43]), and recruiting participants to perform controlled search tasks (e.g., [3, 25, 44]). As with any methodology, there are trade-offs: logs can provide in-situ data for a large set of users, but lack qualitative depth; self-report data may have gaps or inconsistencies with actual observed behavior; controlled, in-lab task performance may difer from natural search behavior in unanticipated ways, etc. Several researchers have begun to use eye tracking to understand which aspects of the SERP users attend to [22, 23, 36, 52]. Eye tracking allows us to log and track the amount of attention paid to specifc parts of the pages and interactions at a granular level of space and time. For example, eye tracking studies have revealed that searchers usually fxate on SERPs and webpages in an F-shape pattern [45, 46]. These studies have also shown that searchers distribute their visual attention diferently across organic and ad results on a SERP [24], and that one can determine a webpage’s most salient parts by looking at the amount of visual attention paid to its diferent elements [17]. This paper builds on prior eye-tracking studies to understand how diferent searchers attend to diferent elements of SERPs and webpages. We complement our eye tracking data with participants’ comments immediately after searching to gain qualitative insight into the meaning of the eye tracking results.

<narr> Narrative:

</top>

<top>
<num> Number: 340110306
<title> An Eye Tracking Study of Web Search by People With and Without Dyslexia

<desc> Description:
Query Formulation: Since spelling and query formulation are closely related, this stage of search has been reported to be challenging for those with dyslexia. From their interview study, [43] reported SWD have trouble spelling words at the phonetic level. They also found SWD report a heavy reliance on voice input and on autocomplete when forming queries. In 2015, [13] compared search logs of 21 students with and 21 without dyslexia who had formulated Norwegian queries for a Norwegian academic library system with no query-formulation aids. They found that SWD took longer to search, possibly because of spelling errors in their queries. Consequently, they also issued more queries overall. In their 2016 qualitative study, [19] confrmed these fndings for English queries in a system without any query formulation aids. They reported that SWD found choosing keywords, spelling, and forming/refning complex queries using Boolean search strategies of AND and OR operators to be more challenging than a control group. However, in 2016, [14] found that when SWD used Google, a modern interactive search engine with query formulation aids, for formulating Norwegian queries, there were no diferences in query formulation behavior. This suggests query formulation aids could help those with dyslexia. Through our eye-tracking study, we validate these self-report results for a modern interactive English-language search engine with query-formulation aids.

<narr> Narrative:

</top>

<top>
<num> Number: 340110308
<title> An Eye Tracking Study of Web Search by People With and Without Dyslexia

<desc> Description:
Furthermore, prior work suggests a strong correlation between dyslexia and lower phonological working memory (i.e., the ability to hold words in short-term memory) [10, 38]. Work done to investigate the efects of working memory on search results triage echoes MacFarlane et al.’s findings. In 2019, a search log study of participants with low and high working memory found that those with lower working memory take more time to frst click on the SERP, open fewer links, and take more time between events [18].

<narr> Narrative:

</top>

<top>
<num> Number: 340110309
<title> An Eye Tracking Study of Web Search by People With and Without Dyslexia

<desc> Description:
Information Extraction: In 2007, [4] interview study observing searchers with dyslexia navigate multiple pages within a website found navigational trails (such as site maps, back and forward buttons) and menus helped SWD locate where they were within a site. Similarly, in 2008, an eye tracking study by [5], observed 7 participants (2 with dyslexia and 5 controls) navigate webpages within 6 websites to extract information. They found SWD took longer to complete the tasks, had more fxations on the page, looked at the page for longer, and their scan paths were markedly diferent than the control group. A follow-up analysis reported SWD changed scan direction more on the webpage than the control group [39]. They suggest this is an indication of short term memory problems and adds to prior research on backtracking [4]. However, the small number of participants (2 SWD) makes it hard to extrapolate definitive quantitative diferences from these results.

<narr> Narrative:

</top>

<top>
<num> Number: 340110310
<title> An Eye Tracking Study of Web Search by People With and Without Dyslexia

<desc> Description:
In 2018 [25] found SWD’s relevance ratings of webpages were highly correlated with their readability scores. They identifed several visual and textual features such as line length, number of headings, and ratio of images to text, that impact SWDs’ readability and relevance judgements of webpages. In 2019, [35] found using the "Reader View" mode in Firefox web browser, which simplifes a page’s visual structure, improved reading speed for SWD without reducing comprehension.

<narr> Narrative:

</top>

<top>
<num> Number: 340120701
<title> Retrieving Potential Causes from a Query Event

<desc> Description:
A number of existing approaches extract cause-effect patterns using lexical, syntactic, and more recently, semantic relations [3–5, 12], primarily taken from headlines or single sentences (refer to [1] for a survey). The cause-effect pattern approach was extended in [7], where a set of patterns are initially used to create a network of causes and effects, and then a relational embedding method (similar to TransE [2]) is used to jointly embed causes and effects. Causal IR works in the reverse direction, where a query describes a cause (e.g., current situation or proposed action) and the results provide a list of possible effects was studied in [9, 10].

<narr> Narrative:

</top>

<top>
<num> Number: 340116402
<title> Web-to-Voice Transfer for Product Recommendation on Voice

<desc> Description:
A fundamental task in voice shopping is product recommendation, where the goal is to recommend relevant products to customers by inferring their preferences. While a growing body of research has addressed the voice-based recommendation problem from the dialogue perspective, i.e., improving the effectiveness of question-answering between the customer and system [7, 8, 11, 23, 25, 44, 45], relatively little work has been focused on addressing the specific challenges arising in recommendation on Voice [40].

<narr> Narrative:

</top>

<top>
<num> Number: 340116403
<title> Web-to-Voice Transfer for Product Recommendation on Voice

<desc> Description:
Due to the unique characteristics of voice interfaces (e.g., narrow information channel), customers tend to explore fewer products and choose fewer long-tail products, as compared to Web-based channels [45]. Consequently, products purchased through Voice are much more limited in terms of both quantity and diversity. Due to the fact that voice interfaces are new and not yet widely adopted, customers on Voice do not have a long history as compared with Web. These problems pose a bigger-than-ever data sparsity challenge that impedes effective recommendation. To mitigate the data sparsity issue, a promising approach is transfer learning: a customer is likely to share similar shopping behaviors on the Web and Voice in terms of favored product types and purchase patterns; by transferring the shared shopping patterns from Web, the system can readily generate recommendations for customers with limited historical purchases on Voice, or even those new to Voice.

<narr> Narrative:

</top>

<top>
<num> Number: 340116404
<title> Web-to-Voice Transfer for Product Recommendation on Voice

<desc> Description:
Despite its obvious potential, transfer learning from Web to Voice is non-trivial due to customers’ distinct shopping behaviors on Voice [19]. For example, customers are more inclined to purchase low-consideration products (e.g., paper towel and toothpaste) than high-consideration ones (e.g., computer monitors) on Voice. This is in part due to the recency of Voice as a shopping medium that customers are not used to making complex shopping decisions by voice, in part due to the lack of technology for supporting effective interactions. On the other hand, the convenience of voice interactions triggers a strong tendency of repeated purchases in voice shopping: many products are purchased by the same customers over and over, especially those consumables that need to be purchased on a regular basis. We note that repeated purchase behaviors have also been observed on the Web, which is mainly driven by customers’ loyalty to certain brands [5, 10, 42].

<narr> Narrative:

</top>

<top>
<num> Number: 340116405
<title> Web-to-Voice Transfer for Product Recommendation on Voice

<desc> Description:
In the recommendation literature, transfer learning has been implemented by extending recommendation models, e.g., factorization models [28, 29, 33] or neural networks [14, 21, 26], with shared user1 representations for cross-domain recommendation tasks. While being different in the underlying recommendation models (see Section 2 for a detailed discussion), both classes of methods are designed for transferring user representations with less emphasis on transferring the interaction patterns, which has to be carefully considered in our Web-to-Voice transfer context. More recent work [18] attempts to address the problem by modeling the transfer of the purchase patterns from one domain to another using a linear transformation. However, it fails to capture the relationships of interaction patterns across domains, such as similarity and dissimilarity, which are essential for Web to Voice transfer.

<narr> Narrative:

</top>

<top>
<num> Number: 340116407
<title> Web-to-Voice Transfer for Product Recommendation on Voice

<desc> Description:
With the rapid increase of personal assistants, a considerable amount of literature has grown up around conversational recommendation. The focal point of research efforts has been enabling the system to effectively and efficiently infer users’ intents and satisfy their information needs [35, 47]. Due to the complexity of the problem, it has been studied by several research communities including natural language processing [11, 23, 25], human-computer interaction [7, 45], and information retrieval (including recommender systems) [8, 44]. Existing work mainly takes a dialogue perspective with the goal of improving the question-answering process, i.e., asking the most relevant questions to collect user feedback.

<narr> Narrative:

</top>

<top>
<num> Number: 340116408
<title> Web-to-Voice Transfer for Product Recommendation on Voice

<desc> Description:
From the recommendation perspective, most existing work assumes a cold-start setting that ignores long-term preferences of users. For example, [47] studies the effect of in-session aspect-based questions for product recommendation using memory networks [39]. [25] introduce a neural dialogue model that classifies the sentiment of a user with respect to movies discussed in the conversation session, and based on that, it generates movie recommendations with a pre-trained autoencoder recommender [37]. A recent paper by [40] shows that the integration of users’ past purchasing behaviors boosts the effectiveness of voice-based recommendation. Their work, however, concentrates on methods for integrating recommendation techniques into the dialogue system. Our work takes a step back and aims at bridging the conventional recommendation techniques with the recommendation task on Voice, with a specific focus on Web-to-Voice transfer which is of key importance for successful voice shopping in practice.

<narr> Narrative:

</top>

<top>
<num> Number: 340116409
<title> Web-to-Voice Transfer for Product Recommendation on Voice

<desc> Description:
Transfer learning has been a popular approach for tackling the data sparsity problem by transferring the knowledge (e.g., user preferences) in a source domain to the task in the target domain [6, 24]. In recommendation, transfer learning is generally implemented through multi-task learning [48], i.e., joint model training for recommendation in source and target domains, with a specific focus on transferring user and item representations, or interaction patterns across the domains.

<narr> Narrative:

</top>

<top>
<num> Number: 340116410
<title> Web-to-Voice Transfer for Product Recommendation on Voice

<desc> Description:
Early work focuses on adapting matrix factorization techniques for transfer learning [28, 29, 33]. [28] introduce a model based on collective matrix factorization [38], where user latent factors are shared across different domains. The observed interactions in the source domain help to train better latent factors, thus transferring the knowledge to the target domain. [32, 33] propose to model the interaction patterns in different domains as independent parameter matrices. Factorization models, however, only learn latent factors and parameter matrices in a linear fashion, which are oversimplified in capturing the complex user-item interaction patterns. More importantly, these methods fail to capture the relationship between user interactions in different domains.

<narr> Narrative:

</top>

<top>
<num> Number: 340116411
<title> Web-to-Voice Transfer for Product Recommendation on Voice

<desc> Description:
Neural network-based methods are more capable of learning non-linear latent representations for users and items and potentially also their interactions (see a recent survey [46]). Specific to neural transfer learning for cross-domain recommendation, [14] introduce a multi-view deep learning method that learns shared user representations from user-item interactions in different domains. [26] propose to incorporate content information into the multi-view neural network. [21] go further in this direction and formulate cross-domain recommendation as extreme multi-class classification, where only content features are used for adapting a classifier trained in the source domain to the target domain. These methods focus on learning better representations for users and items, while emphasizing less learning their interaction patterns, which is important for voice shopping.

<narr> Narrative:

</top>

<top>
<num> Number: 340116412
<title> Web-to-Voice Transfer for Product Recommendation on Voice

<desc> Description:
A recent paper [18], perhaps the most closely related work to ours, models the transfer of interactions across multiple domains as a linear transformation using cross-stitch networks [30]. In the context of Web-to-Voice transfer, since the same products appear in both Web and Voice, we adopt a tri-factorization approach [12, 31] that fixes the product representations across channels, and extend the approach into a multi-level scheme, which allows to capture channel-independent and channel-specific interaction patterns.

<narr> Narrative:

</top>

<top>
<num> Number: 340116413
<title> Web-to-Voice Transfer for Product Recommendation on Voice

<desc> Description:
Due to the importance for business profitability, repeated purchases are an important customer behavior studied in marketing as a signal of brand loyalty [20, 34]. In Web-based information systems, repeated item consumption has been shown to be most affected by the recency and quality of the item, with recency being more critical [1]. [4] study such a behavior in more detail and reveals the increasing inter-arrival gaps of repeated item consumption that eventually lead to abandonment. In online shopping, [5] study repeated purchases for consumable products, e.g., toothpaste and diapers, and propose a prediction model that helps increase the product click-through rate. Our work extends the study to voice shopping and the model to collaborative filtering that recommends both repeated and novel products.

<narr> Narrative:

</top>

<top>
<num> Number: 340116414
<title> Web-to-Voice Transfer for Product Recommendation on Voice

<desc> Description:
Repeated purchases have only been considered in recommender system literature recently. [42] introduce a recommendation algorithm, adaLoyal, a personalized grocery recommender. In adaLoyal, the repeated purchase is leveraged in a post-processing procedure to adapt the prediction of purchase probability over an item using the customer’ historical purchases of the item. The adaptation is implemented through a posterior calculation that accounts for both probabilities of general and repeated purchases. [36] propose a unified neural network model that jointly learns repeated and novel consumption for session-based recommendation. Our method is different in that we consider the general sequential recommendation scenario and further model the impact of recency of historical purchases for voice-based recommendation.

<narr> Narrative:

</top>

<top>
<num> Number: 340120402
<title> Context-Aware Term Weighting For First Stage Passage Retrieval

<desc> Description:
Most first-stage retrieval models such as BM25 and query likelihood use term frequencies (tf) to term importance in a document. A popular alternative to tf are graph-based methods, e.g., TextRank [6]. A few recent work investigated using word embeddings [5] for document term weighting, but most of them only learn a global idf -like term weight because the word embeddings are context-independent. Our work aims to learn tf-like term weights that are context-specific.

<narr> Narrative:

</top>

<top>
<num> Number: 340120403
<title> Context-Aware Term Weighting For First Stage Passage Retrieval

<desc> Description:
Most neural ranking models are cost-prohibitive to be used in the first stage [1, 2, 10]. Recent research addresses this efficiency problem in two ways. One way is to learn latent embedding representations of queries and documents [13]. However, fix-dimension representations introduce the specificity vs. exhaustiveness trade-off [14]. Another approach modifies the bag-of-words document representations using neural network. [8] uses neural rankers to generate term-document scores, but it is time-consuming when applied at a large-scale. [11] proposed to generate queries from documents using neural machine translation and index queries as document expansion terms [11, 12]. Our work are orthogonal to [11, 12] – their approaches add terms to documents, while our method weights existing terms; future work may consider combining the two approaches.

<narr> Narrative:

</top>

<top>
<num> Number: 340119801
<title> Bundle Recommendation with Graph Convolutional Networks

<desc> Description:
Most existing works for bundle recommendation [2, 6, 7] regard item and bundle recommendation as two separate tasks, and associate them by sharing model parameters. A recent study [3] proposed a multi-task framework that transfers the benefits of the item recommendation task to the bundle recommendation to alleviate the scarcity of user-bundle interactions. Despite effectiveness, we argue that they suffer from three major limitations:

<narr> Narrative:

</top>

<top>
<num> Number: 340119802
<title> Bundle Recommendation with Graph Convolutional Networks

<desc> Description:
Although bundles are currently widely used everywhere, few efforts have been made in solving the bundle recommendation problem. List Recommendation Model (LIRE) [6] and Embedding Factorization Machine (EFM) [2] simultaneously utilized the users’ interactions with both items and bundles under the BPR framework. The Bundle BPR (BBPR) Model [7] made use of the parameter previously learned through an item BPR model. Recently, Deep Attentive Multi-Task Model (DAM) [3] jointly modeled user-bundle interactions and user-item interactions in a multi-task manner.

<narr> Narrative:

</top>

<top>
<num> Number: 340119803
<title> Bundle Recommendation with Graph Convolutional Networks

<desc> Description:
The basic idea of graph convolutional networks (GCN) [5] is to reduce the high-dimensional adjacency information of a node in the graph to a low-dimensional vector representation. With the strong power of learning structure, GCN is widely applied in recommender systems. [1] first applied GCN to the recommendation to factorize several rating matrices. [10] extended it to web-scale recommender systems with neighbor-sampling. Recently, [9] further approached a more general model that uses high-level connectivity learned by GCN to encode CF signals.

<narr> Narrative:

</top>

<top>
<num> Number: 340118801
<title> Choppy: Cut Transformer for Ranked List Truncation

<desc> Description:
While much of the work in information retrieval has been centered around ranking, there is growing interest in methods for ranked list truncation - the problem of determining the appropriate cutoff 𝑘 of candidate results [1, 9]. This problem has garnered attention in fields like legal search [14] and sponsored search [3, 16], where there could be a monetary cost for users looking into an irrelevant tail of documents or where showing too many irrelevant ads could result in ad blindness. The fundamental importance of this problem has led to development of methods that are automatically able to learn 𝑘 in a data-driven fashion [9]. The focus of this paper is to design more effective models for accurate and dynamic truncation of ranked lists.

<narr> Narrative:

</top>

<top>
<num> Number: 340118802
<title> Choppy: Cut Transformer for Ranked List Truncation

<desc> Description:
The present state-of-the-art for this task is BiCut [9], a recurrent-based neural model that formulates the problem as a sequential decision process over the list. BiCut trains a bidirectional LSTM [8] model with a predefined loss that serves as a proxy to the user-defined target evaluation metric. At every position in the ranked list, BiCut makes a binary decision conditioned on both forward and backward context: to continue to the next position, or to end the output list.

<narr> Narrative:

</top>

<top>
<num> Number: 340118803
<title> Choppy: Cut Transformer for Ranked List Truncation

<desc> Description:
While BiCut outperforms non-neural methods [1], we argue it has several drawbacks. Firstly, the model is trained with teacher-forcing, i.e. with ground truth context, but it is deployed auto-regressively at test time, where it is conditioned on its own pre-dictions. Thus, the model suffers from a train / test distribution mismatch, often referred to as exposure bias [12], resulting in poor model generalization. Secondly, the loss function used does not capture the mutual exclusivity among the candidate cut positions. In other words, the loss does not capture the condition that the list can only be cut in at most one position. Furthermore, the proposed training loss is unaligned with the user-defined evaluation metric. Last but not least, BiCut employs BiLSTMs which are not only slow and non-parallelizable, but also do not take into account global long-range dependencies.

<narr> Narrative:

</top>

<top>
<num> Number: 340118805
<title> Choppy: Cut Transformer for Ranked List Truncation

<desc> Description:
Across the rich history of information retrieval research, there has been extensive work focused on modeling score distributions of IR systems. Early work in this area primarily focused on fitting parametric probability distributions to score distributions [1, 10]. This is often achieved by making the assumption that the overall distribution can be expressed as a mixture of a relevant and a non-relevant distribution. The expectation-maximization (EM) algorithm is often adopted to learn the parameters.

<narr> Narrative:

</top>

<top>
<num> Number: 340118806
<title> Choppy: Cut Transformer for Ranked List Truncation

<desc> Description:
There has been considerable recent interest in adopting machine learning based models to optimize and improve the ranked list truncation problem. For instance, cascade-style IR systems [17] seek to achieve a balance between efficiency and effectiveness. Notably, [5] investigates a number of machine learning approaches for learning dynamic cutoffs within cascade-style ranking systems. Another recent study investigated how to leverage bidirectional Long Short-Term Memory (LSTM) models to identify the best position to truncate a given list [9]. This model, BiCut, can be considered the present state-of-the-art approach.

<narr> Narrative:

</top>

<top>
<num> Number: 340118807
<title> Choppy: Cut Transformer for Ranked List Truncation

<desc> Description:
Our work is closely related to the task of query performance prediction [4]. In this task, the objective is to automatically determine the effectiveness of a given query. This could be leveraged to determine the optimal set of results to the user for any given measure. Methods for query performance prediction include pre-retrieval-based approaches [7], relevance-based approaches [4, 19], and neural approaches [18].

<narr> Narrative:

</top>

<top>
<num> Number: 340118808
<title> Choppy: Cut Transformer for Ranked List Truncation

<desc> Description:
A system that determines the best number of results to display to users has the potential to benefit a wide number of applications. For example, in sponsored search, displaying too many irrelevant ads to users may cause frustration, resulting in so-called query blindness. This motivated research that investigated whether any ads should be displayed at all [3]. It is also easy to see that a similar and related problem formulation is to determine how many ads should be displayed to the users [16]. Moreover, determining the optimal number of ranked results is also important in a number of other IR applications such as legal e-discovery [14], where there is an significant financial or labor cost associated with reviewing results. Finally, the ability to calibrate scores across queries and different corpora has also been studied in the context of federated search tasks [13] such as meta-search [11].

<narr> Narrative:

</top>

<top>
<num> Number: 340982001
<title> Taking the Counterfactual Online: Efficient and Unbiased Online Evaluation for Ranking

<desc> Description:
Evaluation is essential for the development of search and recommendation systems [8, 14]. Before any ranking model is widely deployed it is important to first verify whether it is a true improvement over the currently-deployed model. A traditional way of evaluating relative differences between systems is through A/B testing, where part of the user population is exposed to the current system (“control") and the rest to the altered system (“treatment") during the same time period. Differences in behavior between these groups can then indicate if the alterations brought improvements, e.g. if the treatment group showed a higher Click-Through-Rate (CTR) or more revenue was made with this system [4].

<narr> Narrative:

</top>

<top>
<num> Number: 340982002
<title> Taking the Counterfactual Online: Efficient and Unbiased Online Evaluation for Ranking

<desc> Description:
Interleaving has been introduced in Information Retrieval (IR) as a more efficient alternative to A/B testing [11]. Interleaving algorithms take the rankings produced by two ranking systems, and for each query create an interleaved ranking by combining the rankings from both systems. Clicks on the interleaved rankings directly indicate relative differences. Repeating this process over a large number of queries and averaging the results, leads to an estimate of which ranker would receive the highest CTR [10]. Previous studies have found that interleaving requires fewer interactions than A/B testing, which enables them to make consistent comparisons in a much shorter timespan [4, 21].

<narr> Narrative:

</top>

<top>
<num> Number: 340982003
<title> Taking the Counterfactual Online: Efficient and Unbiased Online Evaluation for Ranking

<desc> Description:
More recently, counterfactual evaluation for rankings has been proposed by [13] to evaluate a ranking model based on clicks gathered using a different model. By correcting for the position bias introduced during logging, the counterfactual approach can unbiasedly estimate the CTR of a new model on historical data. To achieve this, counterfactual evaluation makes use of Inverse-Propensity-Scoring (IPS), where clicks are weighted inversely to the probability that a user examined them during logging [22]. A big advantage compared to interleaving and A/B testing, is that counterfactual evaluation does not require online interventions.

<narr> Narrative:

</top>

<top>
<num> Number: 340982006
<title> Taking the Counterfactual Online: Efficient and Unbiased Online Evaluation for Ranking

<desc> Description:
Each interleaving method attempts to use randomization to counter position bias, without deviating too much from the original rankings so as to maintain the user experience [11]. Team-draft interleaving (TDI) randomly selects one ranker to place their top document first, then the other ranker places their top (unplaced) document next [20]. Then it randomly decides the next two documents, and this process is repeated until all documents are placed in the interleaved ranking. Clicks on the documents are attributed to the ranker that placed them. The ranker with the most attributed clicks is inferred to be preferred by the user. Probabilistic interleaving (PI) treats each ranking as a probability distribution over documents; at each rank a distribution is randomly selected and a document is drawn from it [9]. After clicks have been received, probabilistic interleaving computes the expected number of clicks documents per ranking system to infer preferences. Optimized interleaving (OI) casts the randomization as an optimization problem, and displays rankings so that if all documents are equally relevant no preferences are found [19].

<narr> Narrative:

</top>

<top>
<num> Number: 340982007
<title> Taking the Counterfactual Online: Efficient and Unbiased Online Evaluation for Ranking

<desc> Description:
While every interleaving method attempts to deal with position bias, none is unbiased according to our definition (Section 2.2). This may be confusing because previous work on interleaving makes claims of unbiasedness [9, 10, 19]. However, they use different definitions of the term. More precisely, TDI, PI, and OI provably converge on the correct outcome if all documents are equally relevant [9, 10, 19, 20]. Moreover, if one assumes binary relevance and π1 ranks all relevant documents equal to or higher than π2, the binary outcome of PI and OI is proven to be correct in expectation [10, 19]. However, beyond the confines of these unambiguous cases, we can prove that these methods do not meet our definition of unbiasedness: for every method one can construct an example where it converges on the incorrect outcome. The rankers π1, π2 and position bias parameters θ can be chosen so that in expectation the wrong (binary) outcome is estimated; see Appendix A for a proof for each of the three interleaving methods. Thus, while more efficient than A/B testing, interleaving methods make systematic errors in certain circumstances and thus should not be considered to be unbiased w.r.t. CTR differences.

<narr> Narrative:

</top>

<top>
<num> Number: 340982008
<title> Taking the Counterfactual Online: Efficient and Unbiased Online Evaluation for Ranking

<desc> Description:
Counterfactual evaluation is based on the idea that if certain biases can be estimated well, they can also be adjusted [12, 22]. While estimating relevance is considered the core difficulty of ranking evaluation, estimating the position bias terms θ is very doable. By randomizing rankings, e.g., by swapping pairs of documents [12] or exploiting data logged during A/B testing [1], differences in CTR for the same item on different positions can be observed directly. Alternatively, using Expectation Maximization (EM) optimization [23] or a dual learning objective [2], position bias can be estimated from logged data as well. Once the bias terms θ have been estimated, logged clicks can be weighted so as to correct for the position bias during logging. Hence, counterfactual evaluation can work with historically logged data. Existing counterfactual evaluation algorithms do not dictate which rankings should be displayed during logging: they do not perform interventions and thus we do not consider them to be online methods.

<narr> Narrative:

</top>

<top>
<num> Number: 340982009
<title> Taking the Counterfactual Online: Efficient and Unbiased Online Evaluation for Ranking

<desc> Description:
Counterfactual evaluation assumes that the position bias θ and the logging policy π0 are known, in order to correct for both position bias and item-selection bias. Clicks are gathered with π0 which decides which rankings are displayed to the user. We follow [16] and use as propensity scores the probability of observance in expectation over the displayed rankings:

<narr> Narrative:

</top>

<top>
<num> Number: 340982010
<title> Taking the Counterfactual Online: Efficient and Unbiased Online Evaluation for Ranking

<desc> Description:
Besides Requirement 15 the existing counterfactual method [12, 22] is completely indifferent to π0 and hence we do not consider it to be an online method. In the next section, we will introduce an algorithm for choosing and updating π0 during logging to minimize the variance of the estimator. By doing so we turn counterfactual evaluation into an online method.

<narr> Narrative:

</top>

<top>
<num> Number: 340983702
<title> Efficient Test Collection Construction via Active Learning

<desc> Description:
To create a new IR test collection at minimal cost, it is valuable to identify a minimal set of documents for human relevance judging. This is typically accomplished by running a shared task campaign, such as NIST TREC, then pooling search results from many participating systems (and often interactive runs) to identify the most likely relevant documents for judging [10]. While this approach is now canonized in IR practice, organizing the community to run a shared task is complicated, slow, and requires many hours of work by organizers and participants. This hidden, real-world cost may far exceed simple judging costs, which are often the only measure of cost reported. This suggests a more complete accounting of cost ought to be considered, if not quantified, wrt. building IR test collections. Shared tasks have many other benefits, but if one’s primary goal is merely to build a new test collection, it would be useful if this could be achieved without needing to run a shared task [24].

<narr> Narrative:

</top>

<top>
<num> Number: 340983704
<title> Efficient Test Collection Construction via Active Learning

<desc> Description:
Our approach involves learning a topic-specific document classification model for each search topic. We consider two distinct applications of AL. Firstly, we apply AL to select which documents assessors should judge, and we explore two document selection strategies [6]: continuous active learning (CAL) and simple active learning (SAL). Secondly, we consider use of AL to automatically classify relevance of additional unjudged documents. This differs from traditional IR evaluation, which often ignores unjudged documents or assumes them to be non-relevant. Moreover, the ability to use any hybrid combination of human and automatic judgments in evaluation provides a flexible tradeoff space for balancing cost vs. accuracy [19]. Though others have pursued automatic or semi-automatic relevance labeling [1, 2, 9, 12, 13], prior studies do not use AL for i) selecting documents for annotations and ii) inferring relevance labels for unjudged documents simultaneously in constructing IR test collections.

<narr> Narrative:

</top>

<top>
<num> Number: 340983705
<title> Efficient Test Collection Construction via Active Learning

<desc> Description:
Because AL is supervised, an initial seed set of labeled documents is needed to bootstrap learning. We consider two distinct scenarios for how these seed judgments might be obtained: interactive search (IS) and Rank-based Document Selection (RDS). We emphasize that these represent alternative scenarios rather than competing methods. IS assumes topic assessors utilize an IS system during a careful topic creation process, as traditionally practiced in TREC. This produces seed judgments as a free by-product. RDS, on the other hand, assumes a scenario like the TREC Million Query Track [4] in which topic formation is extremely brief and assessors are not provided an IS system in which to explore the collection. In this scenario, an off-the-shelf IR system is used instead to produce a single document ranking; assessors then judge documents in this rank-order until enough seed judgments have been collected to kickstart AL.

<narr> Narrative:

</top>

<top>
<num> Number: 340983706
<title> Efficient Test Collection Construction via Active Learning

<desc> Description:
Ever-larger document collections challenge systems-based Cranfield [5] evaluation of IR systems due to needing to collect so many relevance judgments. While many methods now exist to intelligently select which documents to judge, these methods typically assume a shared task context (e.g., TREC) in which document rankings from many participating systems are available. In contrast, we want to be able to construct a new test collection without needing to run a shared task [24, 26].

<narr> Narrative:

</top>

<top>
<num> Number: 340983707
<title> Efficient Test Collection Construction via Active Learning

<desc> Description:
[1] propose labeling unjudged documents using a classifier trained on a subset of pool documents. This subset of pool documents is developed by considering documents ranked by a subset of the submitted rank systems. The trained classifier is then used to predict relevance labels of documents which are ranked by the remaining set of rank systems in the shared task. We both report results for the same 2006 Terabyte Track run, but our results are not directly comparable to theirs because they assume a traditional machine learning setup, whereas we motivate and adopt the finite-pool evaluation setting proposed in [6]. However, we effectively reproduce their method as a baseline, using logistic regression and random document selection. We show strong improvement over this baseline.

<narr> Narrative:

</top>

<top>
<num> Number: 340983708
<title> Efficient Test Collection Construction via Active Learning

<desc> Description:
While [13] use document rankings information in their own proposed method, they also reproduce [1]’s SVM method as a baseline, reporting results on the same WebTrack 2013 and 2014 collections we use in this study. However, as with [1], they do not evaluate their approach under a finite-pool scenario. Though this means that our results are not directly comparable, our same baseline configuration described above roughly reproduces their SVM approach.

<narr> Narrative:

</top>

<top>
<num> Number: 340983709
<title> Efficient Test Collection Construction via Active Learning

<desc> Description:
For AL document selection, we evaluate the same CAL and SAL methods [21] that [6] assess in the domain of e-discovery, where they focus on set-based rather than ranked retrieval. Moreover, judging cost is also measured differently in e-discovery: no document can be “screened in” automatically since all must be reviewed for privilege following discovery. Recently, [8] propose a variant of “S-CAL” [7], which rather than selecting the highest-scoring documents for relevance judgment, randomly samples some documents from those the highest-scoring documents for annotation. They report results on the collected human relevance judgments (e.g. TREC pool documents) but not hybrid judging.

<narr> Narrative:

</top>

<top>
<num> Number: 340983710
<title> Efficient Test Collection Construction via Active Learning

<desc> Description:
[2] apply [3]’s document selection method to iteratively collect relevance judgments. Based on the cluster hypothesis, their per-topic logistic regression classifier estimates the probability of relevance of an unjudged document conditional on its similarity to other judged documents in the cluster (e.g. relevant and non-relevant document clusters). A key difference with our work is that their document selection strategy relies on having run a shared task.

<narr> Narrative:

</top>

<top>
<num> Number: 340983712
<title> Efficient Test Collection Construction via Active Learning

<desc> Description:
[22] develop a framework for constructing a test collection using an iterative process between updating nuggets and annotating documents. However, because their automatic nugget extraction fails to extract nuggets from documents which are difficult to parse (e.g. TREC Web Track), the authors fall back to using document rankings from participating systems of a shared task evaluation. [17] also utilize a shared task by inducing a probability distribution from the participating systems and a probability distribution over the ranks of the documents. They then actively sample documents from the joint distribution to construct an unbiased test collection.

<narr> Narrative:

</top>

<top>
<num> Number: 340982701
<title> Optimizing Hyper-Phrase Queries

<desc> Description:
Variable length pattern matching is an allied area with respect to our problem setting. Prior works [8, 20] have studied how in-memory data structures can help in the design of efficient matching algorithms. For instance, [20] considered matching-lookup table while [8] considered a wavelet tree as an in-memory index to speed up the matching process. Our work in contrast, leverages large-scale inverted indexes that are part of modern IR systems to efficiently execute a more difficult problem. A straight-forward approach to spotting evidences for KG facts is to index document collections annotated with named entities linked to KGs. However, using such an approach we can not spot facts for out-of-KG entities or their emerging relations. A recent work on spotting KG facts uses regular expression based operators at word-level [15, 16]. However, their approach disregards any optimization for efficient execution of hyper-phrase queries. [13, 19] propose a system that retrieves witness documents given a KG fact as a query. However, a limitation of their system is that documents need to be processed apriori and linked to KG facts for their retrieval. Put another way, out-of-KG facts or entities can not be processed with their system. Our approach solves this issue by relying on a data model that can represent n-grams, skip-grams, and sentence boundaries. Relying on our data model, we can then retrieve text regions as evidences for KG facts. [17] investigate how to model query execution plans with respect to recall of relevant documents and the query’s execution time. Their approach contrasts between two models: inverted index based approach versus scanning the entire document collection. [7] describes an algorithm that identifies a relevant set of documents for named entities by finding a token-set-cover for various surface forms of the named entity and computing a join of the retrieved documents. [21, 23] describe approaches to query phrases using combinations of inverted, phrase, nextword, and direct indexes. Our work in contrast explores ways to compute an optimal plan of hyper-phrase query execution using dictionaries and indexes over n-grams and skip-grams.

<narr> Narrative:

</top>

<top>
<num> Number: 340983002
<title> Towards Memorable Information Retrieval

<desc> Description:
Prior studies in online learning have revealed that conversational systems can significantly improve learning outcomes [13, 16, 28]. As the goal of learning is to develop a deep understanding of some information, memorization is an important element [4, 15]. Although conversation can produce unique context linked with information, the effect of conversational systems on human memorability needs further exploration. A recent study has investigated the role of text-based conversational interfaces in online information finding tasks [22]. Authors demonstrated that a conversational interface could better engage online users. However, the question of whether improved user engagement through conversational interfaces leads to better memorability of information remains unanswered.

<narr> Narrative:

</top>

<top>
<num> Number: 340983004
<title> Towards Memorable Information Retrieval

<desc> Description:
Augmenting human memory has also been studied from an information systems standpoint. Many previous studies have used context as a key aspect to improve human memorability [9, 23]. The ‘Remembrance Agent’ is an automatic system which uses the role of context in memory to augment human memory, by listing documents related to the user’s current context [23]. [5] have performed experiments to find the attributes (e.g. file name, time, title, location, size, etc.) that help memorability for a document search tool. Previous works have also shown that many strategies, such as time-aware contextualization [8, 29], and optimizing recollection by generating analogies [24], have a positive effect on human memorability. Furthermore, a recent study built an application named ReflectiveDiary’, to investigate how self-generated daily summaries can improve memorability [25]. Predictive methods have also been proposed to consolidate human memory in the workplace environment [3]. Since memorization is an essential element of the learning process [4, 15], we also examined relevant literature in online learning. Across multiple studies, conversational systems were found to be useful in facilitating learning effects [13, 16, 28] and in effectively improving user engagement in information retrieval tasks [22]. These previous works with regard to aiding memorability or improving learning effects in information systems are not directly applicable in the current information retrieval ecosystems. Inspired by these prior works, we propose novel search interfaces and design experiments to study human memorability in information retrieval.

<narr> Narrative:

</top>

<top>
<num> Number: 340982502
<title> Cluster-Based Document Retrieval with Multiple Queries

<desc> Description:
There are two main categories of cluster-based document retrieval methods [22]. The first includes methods that rank document clusters by the estimated percentage of relevant documents they contain; then, the cluster ranking is transformed to document ranking [11, 14, 17, 20–23, 27–30, 35, 43–45]. A cluster-based document retrieval method using supervised learning was the best performing run in the 2013 TREC Web track [9].

<narr> Narrative:

</top>

<top>
<num> Number: 340982503
<title> Cluster-Based Document Retrieval with Multiple Queries

<desc> Description:
One of the main motivations for pursuing the cluster ranking task is the optimal cluster phenomenon [12, 20, 28, 36, 43]: if the documents most highly ranked by an initial search are clustered, some of the clusters tend to contain a high percentage of relevant documents; the cluster with the highest percentage is referred to as the optimal cluster. Positioning the constituent documents of the optimal cluster at the top of the final result list results in much higher precision at top ranks performance than that of other commonly used document-based retrieval methods [20, 28, 43]. A case in point, for a standard TREC corpus, the average precision of the top five (P@5) that results from identifying the optimal cluster can reach 0.8 in comparison to 0.46 attained with standard language model retrieval [20].

<narr> Narrative:

</top>

<top>
<num> Number: 340982504
<title> Cluster-Based Document Retrieval with Multiple Queries

<desc> Description:
The second category of cluster-based document retrieval methods includes those that enrich the document representation with information induced from the clusters [19, 22, 27, 39]; e.g., in the language modeling framework, document language models can be smoothed using cluster language models [19, 22, 27]. The motivation is to reduce potential vocabulary mismatches between queries and relevant documents by enriching a document representation with information induced from similar documents.

<narr> Narrative:

</top>

<top>
<num> Number: 340982505
<title> Cluster-Based Document Retrieval with Multiple Queries

<desc> Description:
As in most prior work on ad hoc document retrieval, work on the cluster hypothesis and cluster-based document retrieval was confined to the standard setting where a single query represents an information need. However, combining multiple queries which represent the same information need can dramatically improve retrieval effectiveness [4, 5]. Recently, there has been a renewed interest in the importance of the multiple-queries retrieval setting [2, 3, 6, 7, 26, 31, 42, 47], with growing evidence to its operational feasibility and importance. The feasibility of operationalizing this idea was initially explored nearly a decade ago in the Bing search engine [38]. It was recently shown that query variations automatically selected from a query log of a commercial search engine can be, on average, as effective as human curated query variations [26].

<narr> Narrative:

</top>

<top>
<num> Number: 340982506
<title> Cluster-Based Document Retrieval with Multiple Queries

<desc> Description:
The merits of applying fusion to document lists retrieved for queries representing the same information need is now well understood [3–7, 34]; reciprocal rank fusion (RRF) [10] consistently yields state-of-the-art performance in this setting [6]. Our best performing methods outperform this fusion approach. Furthermore, some of our suggested retrieval templates apply RRF before or after cluster-based re-ranking is applied to document lists retrieved for multiple queries. We note that reciprocal rank fusion is an unsupervised fusion method. One could potentially further improve the performance of our methods that utilize fusion of document lists by using supervised fusion (e.g., [38]). We leave this exploration for future work.

<narr> Narrative:

</top>

<top>
<num> Number: 340982507
<title> Cluster-Based Document Retrieval with Multiple Queries

<desc> Description:
It was recently shown that the relative prediction quality posted by various query performance predictors can significantly vary when varying the effectiveness of a query used to represent an information need [47]. In a conceptually similar vein, we show that state-of-the-art cluster-based document retrieval methods can actually be outperformed by standard bag-of-words document retrieval models if highly effective queries are used to represent information needs.

<narr> Narrative:

</top>

<top>
<num> Number: 340982508
<title> Cluster-Based Document Retrieval with Multiple Queries

<desc> Description:
There was work on improving search efficiency when using multiple queries by clustering queries offline [7]. In contrast, we use document clusters created at query time.

<narr> Narrative:

</top>

<top>
<num> Number: 340982509
<title> Cluster-Based Document Retrieval with Multiple Queries

<desc> Description:
Work on (i) studying the cluster hypothesis [13, 15, 17, 36, 40, 44], (ii) analyzing optimal document clusters [12, 20, 28, 36, 43], and (iii) devising cluster-based document retrieval methods (e.g., [11, 17, 19–23, 28–30, 32, 33, 35, 43–45]) was confined to the standard setting of using a single query to represent an information need. We address these tasks where multiple queries representing the same information need are available.

<narr> Narrative:

</top>

<top>
<num> Number: 340982510
<title> Cluster-Based Document Retrieval with Multiple Queries

<desc> Description:
Clusters of documents in lists retrieved by applying different retrieval approaches for a single query were used to fuse the lists [18]. This fusion approach can be easily instantiated from one of the retrieval templates we present for retrieval using multiple queries. While the resultant performance is effective, we present much more effective cluster-based approaches for utilizing multiple queries.

<narr> Narrative:

</top>

<top>
<num> Number: 340982510
<title> Cluster-Based Document Retrieval with Multiple Queries

<desc> Description:
Cluster-based document retrieval methods can also be used to improve search results diversification [35]. Integrating fusion of ranked lists and topic modeling was also shown to be effective in improving diversification [25]. Diversification of search results is outside the scope of this paper.

<narr> Narrative:

</top>

<top>
<num> Number: 340981901
<title> Permutation Equivariant Document Interaction Network for Neural Learning to Rank

<desc> Description:
While much of the research in LTR has been devoted to the evolution of ranking loss functions [11], the nature of the learned scoring function has largely remained the same: a univariate scoring function that computes a relevance score for a document in isolation. How to capture cross-document interactions is a promising but less well-studied research topic in LTR. Naturally, when cross-document interactions are considered in a model, the score of each individual document is influenced by other documents that are scored together. A desired property for such a model is being permutation equivariant, that is, the score of each document should not be affected by the order of the input documents, and shuffling the input documents produces an identical shuffle on the output scores.

<narr> Narrative:

</top>

<top>
<num> Number: 340981902
<title> Permutation Equivariant Document Interaction Network for Neural Learning to Rank

<desc> Description:
Recently, neural network based approaches have proven effective for LTR applications [4, 14, 15]. In this context, we formally define the permutation equivariance requirement for a scoring function that models cross-document interactions. We propose a novel self-attentive Document Interaction Network (attn-DIN) that extends any univariate scoring function to combine query-document features with contextual cross-document features generated from a self-attention mechanism [17], and show that it not only satisfies the permutation equivariance requirement, but also applies to the ranking setting where queries may have varying number of documents. We conduct our experiments on four ranking datasets: benchmarks WEB30K and Istella, a Gmail search dataset, and a Google Drive Quick Access dataset. The first three are in a search setting, and the last one is in a recommendation setting. On all of them, our proposed method significantly improves over neural network baselines.

<narr> Narrative:

</top>

<top>
<num> Number: 340981903
<title> Permutation Equivariant Document Interaction Network for Neural Learning to Rank

<desc> Description:
Most of the previous work in LTR [11] focuses on designing loss functions, ranging from pointwise to pairwise to listwise ones. Gradient Boosted Decision Trees (e.g., [10]) are regarded as the state-of-the-art models for LTR on benchmark datasets. Recently, neural network based models have attracted considerable attention [8, 12].

<narr> Narrative:

</top>

<top>
<num> Number: 340981904
<title> Permutation Equivariant Document Interaction Network for Neural Learning to Rank

<desc> Description:
There are two settings for modeling cross-document interactions: re-ranking and full ranking. In the former setting, a base ranking is provided and the documents are reordered using the ranker. For example, [1] applies sequence modeling on the top k documents of the base ranking and then uses the final state vector to enrich each document for the re-ranking scoring. In the latter setting, we do not have a base ranking but start with a set of documents. For example, RankProb [6] takes a pair of documents as input and uses a DNN to produce a preference score for the input documents, while [2] propose a groupwise scoring function to model document interactions, sampling a subset of all permutations of each group and thus not guaranteeing permutation equivariance.

<narr> Narrative:

</top>

<top>
<num> Number: 340984701
<title> Using Sentiment Analysis for Pseudo-Relevance Feedback in Social Book Search

<desc> Description:
Book search is a difficult Information Retrieval problem due to the vocabulary mismatch between book descriptions and user queries. Pseudo-relevance feedback (PRF), also known as blind relevance feedback, is considered as one of the most effective techniques for improving retrieval performance by query reformulation [13, 16]. As such, PRF provides a way to bridge this semantic gap. Typical PRF methods assume the top retrieved documents in the initial retrieval outcome are relevant, and terms are extracted from the pseudo relevant documents based on their term/document statistics. These are then employed in the query reformulation process. However, in the context of book search, where the goal is to rank books given a query [8], the usual application of PRF [4, 18] may not be appropriate, considering that the book’s descriptions may not adequately convey the experience and emotion attached to the story line that a reader may be looking to enjoy.

<narr> Narrative:

</top>

<top>
<num> Number: 340984702
<title> Using Sentiment Analysis for Pseudo-Relevance Feedback in Social Book Search

<desc> Description:
Book social applications (e.g., LibraryThing, Goodreads) offer, in addition to the catalogue of books’ characteristics and/or their partial content, the information generated by users about the books. This information is typically constituted by reviews, which include opinions/sentiments and personal descriptions about books that can highlight certain aspects not included in the content of the books’ representations. Therefore, once extracted, this information may disclose the experiential and emotional aspects of books that can be used to enrich the query with valuable information. However, the extraction of useful information for query expansion from book reviews is problematic. The quantity of reviews associated with a book (especially if it is popular) can be very large – and these reviews can be very noisy as they often include content unrelated to book information. To alleviate these problems, a number of methods have been proposed, not for query expansion, but to reduce the subset of reviews to be presented to users or for selecting which parts of the reviews to present [3, 17]. For example, [17] used Sentiment Analysis (SA) to highlight sentences with positive or negative sentiment polarity in reviews, to reduce the information overload while reading. While [3] made use of SA to identify emotionally loaded characters and entities given their proximity to emotional terms (e.g., love, hate) for the purpose of extracting interesting aspects from user comments. Those works, and others before [19], deduced that the SA can be a key factor in the mining and summarization of reviews. Given this prior related work, we posit that SA could help by acting as a filter – to limit the set of candidate terms used for expansion – and thus focus on the experiential and emotional aspects of the book.

<narr> Narrative:

</top>

<top>
<num> Number: 340984703
<title> Using Sentiment Analysis for Pseudo-Relevance Feedback in Social Book Search

<desc> Description:
In this paper we present an exploratory study aimed at exploiting SA to identify, in large collections of book reviews, those sentences from which the query expansion terms can be extracted. Our intuition is that the writers of book reviews are often guided by the experience and emotions provoked by the book’s content, characters, plot, etc., which they express in a similar way to how readers of the book express their expectations regarding the book. For example, given the review: [... my son sat still, absorbing every word. The book has awesome pictures and it delivers a superb message at the end ...], where the user expresses a sentiment for the book’s content with strongly positive expressions, while sharing information about the book. The strongly positive sentence in the example is in bold, since it includes strong positive terms underlined. The dashed, underlined terms within the strong positive sentence, would be the target to expand the initial query. Therefore, we hypothesise that locating sentences within book reviews, which include terms of strong sentiment polarity, may help in identifying useful terms for query expansion. On the other hand, using sentiment or emotion in documents to improve the effectiveness of the system has been explored in the past in other domains, such as recommender systems, where [11, 12] used the emotion in reviews to improve the effectiveness of their recommender systems, while in this work we focus on terms’ sentiment intensity rather than general emotion. Also, in the opinion retrieval domain, [7] employed a query expansion method by adding a set of extracted opinion words (e.g., good, like) to the query, extracted from the top retrieved documents in a pseudo relevance feedback method. In their suggestion, [7] served of terms frequency and word weighting techniques, but they did not use any SA methods to classify the documents terms, and they did not go beyond the opinion words extraction to explore the extraction of informative words.

<narr> Narrative:

</top>

<top>
<num> Number: 340982902
<title> Declarative Experimentation in Information Retrieval using PyTerrier

<desc> Description:
Yet reproducibility is key to impactful science. [10] define reproducibility as the ability for a different team to reproduce the measurement in a different experimental setup. Therefore, focussing evaluation solely on datasets that extract key aspects of a problem using a standard dataset – for instance, evaluating LTR techniques solely on LETOR datasets [25] with common features – does not allow us to understand the wider context, such as how an approach will fare when integrated into a fully-fledged search engine’s retrieval stack. This highlights the importance of end-to-end retrieval experiments – understanding what data are needed for a given approach, and how it interacts with others components (e.g., how many documents should be re-ranked [19] for a LTR approach), reduces the uncertainties when a technique should be deployed to an operational search engine.

<narr> Narrative:

</top>

<top>
<num> Number: 340982903
<title> Declarative Experimentation in Information Retrieval using PyTerrier

<desc> Description:
IR platforms have a long history, dating back to at least SMART [2]. These days, among the open source platforms, Apache Lucene is widely deployed. Implemented in Java, it provides indexing and single-search APIs, and in recent years has adopted BM25 along with LTR [7] and dynamic pruning techniques [11]. However, its ability to handle standard test collections was for many years a known limitation [8], and has been advanced by efforts such as Anserini [29]. Indeed Anserini facilitates the deployment of a number of replicable information retrieval techniques, on standard test collection, on top of the Lucene backend.

<narr> Narrative:

</top>

<top>
<num> Number: 340982905
<title> Declarative Experimentation in Information Retrieval using PyTerrier

<desc> Description:
All of the discussed IR platforms mix the design of experimental retrieval activities with the implementation and optimisations required to make such activities efficient. This approach has been shown to limit the reproducibility of IR experiments. For example, [23] show that different implementations of the same BM25 weighting models in different IR platforms result in different values for the same effectiveness metric. They propose to decouple the IR experiments from the IR platform implementation by storing the inverted index in a column-oriented relational database and by implementing ranking models using SQL. [12] take a step forward and propose the adoption of an IR-specific declarative language to provide higher level abstractions in the implementation of the IR experiments based on a graph query language. In contrast to this and the Indri/Galago domain-specific query language, we propose a declarative framework to express basic retrieval operations and their composition using queries and documents as inputs and outputs. It is built upon Python, which is expressive, readily accessible and allows integration with other modern Python toolkits such as those for deep learning. Together, this allows for rapid prototyping and improved reproducibility in IR. We then show how the elements of the proposed declarative language can be compiled into a DAG representation, which can be efficiently implemented on specific IR platforms.

<narr> Narrative:

</top>

<top>
<num> Number: 340982908
<title> Declarative Experimentation in Information Retrieval using PyTerrier

<desc> Description:
The most similar work to our own is that in Terrier-Spark [16, 17], where retrieval pipelines for the Terrier platform were created in Scala using Apache Spark. In that work, retrieval operation were expressed as operations on dataframes (relations). However, adoption of that framework was hindered by two factors: firstly, the use of Apache Spark, which is designed for processing massive scale datasets, and introduces significant interactive overheads making Terrier-Spark unsuitable for notebook-style agile development; secondly, the use of the Scala programming language, which is not as popular as Python. In this paper, we extend the notion of retrieval operations on dataframes, but instead, operate on Python, and create a domain-specific programming environment where complex retrieval pipelines can be formulated as operations on Python objects.

<narr> Narrative:

</top>

<top>
<num> Number: 340981701
<title> Analysing the Effect of Clarifying Questions on Document Ranking in Conversational Search

<desc> Description:
The rise of voice-based digital assistants such as Amazon Alexa and Google Assistant, has intensified the need for agents that can hold meaningful conversations with users. Towards this direction, researchers have developed conversational systems that support question-answering and task-oriented dialogue, among others [3, 4]. However, it is often the case that in such information-seeking conversations, users fail to express their information need adequately. This makes the ability of a conversational search system to support mixed-initiative interactions imperative [6, 8]. Such a system can assist users to refine their information need, i.e., by disclosing new information to them [8], or posing clarifying questions [1].

<narr> Narrative:

</top>

<top>
<num> Number: 340981702
<title> Analysing the Effect of Clarifying Questions on Document Ranking in Conversational Search

<desc> Description:
Clarifying questions trigger users’ explicit feedback in the form of an answer, and have been shown to improve user experience [1, 2, 6, 9]. In Figure 1, we demonstrate examples of clarification-based conversations appearing in the conversational search dataset Qulac [1]. Specifically, we plot the most frequent user responses (4−grams) to clarifying questions. Responses can be read starting from the circle centre (START) and moving outwards (e.g., “no I am looking...”). We observe that user responses often start with a “yes” or a “no”, but frequently provide additional information (e.g., “No, I want...”). We hypothesise that this explicit feedback can be used to improve ranking, even when the question asked ranges from being partially relevant to completely irrelevant w.r.t. the information need.

<narr> Narrative:

</top>

<top>
<num> Number: 340981703
<title> Analysing the Effect of Clarifying Questions on Document Ranking in Conversational Search

<desc> Description:
In this paper, we study the effect of the user’s feedback in mixed-initiative conversations. We categorise answers w.r.t. their polarity and length. Answer polarity indicates whether the question points to a relevant direction or not, while answer length enables us to (noisily) identify the presence of additional information in the response. We conduct our analysis on the Qulac dataset [1], using a query likelihood model chosen because of its simplicity and transparency [7].

<narr> Narrative:

</top>

<top>
<num> Number: 340983803
<title> Understanding BERT Rankers Under Distillation

<desc> Description:
Deep pre-trained language models (LM) are large neural networks trained on surrounding text signals from large text corpora [3]. These models can then be fine-tuned over other target tasks. Notably, deep LMs such as BERT [3] have achieved state-of-the-art performance in several natural language tasks, including text search [2, 7]. In general, BERT rankers are trained by fine-tuning BERT over search logs, using query and passage as the two input sentences and making relevance prediction conditioned on the output sentence/word representations. Using hundreds of millions of parameters, BERT learns rich language patterns that are useful for ranking. However, the high complexity makes it computationally expensive to run BERT rankers at a large scale [8].

<narr> Narrative:

</top>

<top>
<num> Number: 337185501
<title> Addressing Marketing Bias in Product Recommendations

<desc> Description:
By connecting users to relevant products across the vast range available on e-commerce platforms, modern recommender systems are already ubiquitous and critical on both sides of the market, i.e., consumers and product sellers. Among recommendation algorithms used in practice, many fall under the umbrella of collaborative filtering [13, 17, 20, 25], which collect and generalize users’ preference patterns from logged consumer-product interactions (e.g. purchases, ratings). These feedback interactions can be biased by multiple factors, potentially surfacing unfair (or irrelevant) recommendations to users or items underrepresented in the input data. Such phenomena have already raised some attention from the recommender system community: a handful of types of algorithmic biases have been addressed, including selection bias [26], popularity bias [29], and several fairness-aware recommendation algorithms have been proposed [3, 6]. In this paper, we focus on a relatively underexplored factor—marketing bias—in consumer-product interaction data, and study how recommendation algorithms respond to its effect.

<narr> Narrative:

</top>

<top>
<num> Number: 337185504
<title> Addressing Marketing Bias in Product Recommendations

<desc> Description:
Our analysis is related to previous work which examines particular types of biases in real-world interactions and their effects in recommendation algorithms, including the popularity effect and catalog coverage [14], the bias regarding the book author gender for book recommenders [7], and the herding effect in product ratings [31].

<narr> Narrative:

</top>

<top>
<num> Number: 337185505
<title> Addressing Marketing Bias in Product Recommendations

<desc> Description:
Another closely related line of work includes developing evaluation metrics and algorithms to address fairness issues in recommendations. ‘Unbiased’ recommender systems with missing-not-at-random training data are developed by considering the propensity of each item [15, 26]. A fairness-aware tensor-based algorithm is proposed to address the absolute statistical parity (i.e., items are expected to be presented at the same rate across groups) [32]. Several fairness metrics and their corresponding algorithms are proposed for both pointwise prediction frameworks [6, 30] and pairwise ranking frameworks [3]. Methodologically, these algorithms can be summarized as reweighting schemes where underrepresented samples are upweighted [6, 15, 26] or schemes where additional fairness terms are added to regularize the model [1, 3, 30].

<narr> Narrative:

</top>

<top>
<num> Number: 337185506
<title> Addressing Marketing Bias in Product Recommendations

<desc> Description:
Note that most of the above studies focus on bias and fairness on one side of the market only (i.e., either user or producer). Our concern about marketing bias is that it could affect fairness for both consumers and product providers. Without global market fairness in mind, the imbalance of the consumer-product segment distribution could be exacerbated through the deployment of recommendation algorithms. Multi-sided fairness is addressed by [3] by considering C(onsumer)-fairness and P(rovider)-fairness. Trade-off between accuracy and fairness in two-sided marketplaces is further explored and a counterfactual framework is proposed to evaluate different recommendation policies without extensive A/B tests [22]. However the CP-fairness condition where fairness is protected for both sides at the same time still remains an open question.

<narr> Narrative:

</top>

<top>
<num> Number: 337184401
<title> A Stochastic Treatment of Learning to Rank Scoring Functions

<desc> Description:
Learning-to-rank algorithms generally address the ranking problem using a score-and-sort approach [4, 5, 7, 20, 21, 25, 40]. The goal is to learn a scoring function to compute relevance scores which, in turn, induce a ranking. In its most general form, the domain of learning-to-rank functions is a set rather than a single item. However, virtually all learning-to-rank methods with a few exceptions [1, 10, 33] simplify the problem further by learning a univariate function that produces a relevance score for a document independently of other documents in the input set.

<narr> Narrative:

</top>

<top>
<num> Number: 337184402
<title> A Stochastic Treatment of Learning to Rank Scoring Functions

<desc> Description:
It is true then that learning-to-rank can be formulated as classification or regression—in fact, many early learning-to-rank methods such as RankSVM [20] or RankNet [4] take a very similar approach. These algorithms reduce the ranking problem to one of correctly predicting relevance scores by optimizing a “pointwise” loss [13] or correctly classifying ordered pairs of documents by optimizing a “pairwise” loss [4, 5, 20]. These simplified reformulations of learning-to-rank are, however, misaligned with the ranking utilities.

<narr> Narrative:

</top>

<top>
<num> Number: 337184403
<title> A Stochastic Treatment of Learning to Rank Scoring Functions

<desc> Description:
Ranking utilities such as Normalized Discounted Cumulative Gain [19] or Expected Reciprocal Rank [9] work with permutations (i.e., ranked lists) which are discrete structures. As a result, ranking utilities, as a function of a set of input documents, are flat almost everywhere and discontinuous at some finite set of points.

<narr> Narrative:

</top>

<top>
<num> Number: 337184404
<title> A Stochastic Treatment of Learning to Rank Scoring Functions

<desc> Description:
The non-smoothness of ranking utilities pose a challenge that the learning-to-rank community has sought to study. The literature offers a range of methods from direct optimization of metrics using coordinate ascent over parameters of linear models [29], to optimizing an exponential upper-bound of ranking metrics using boosted weak learners [41], to optimizing a differentiable surrogate loss function [7, 32, 36, 38, 40]. Other methods, such as LambdaRank [6] and its gradient boosted regression tree-based [12] variant LambdaMART [39], assume the existence of an unknown loss function whose gradients are however designed based on some heuristic. The list of so-called “listwise” algorithms goes on but the individual methods fall into one of the above categories.

<narr> Narrative:

</top>

<top>
<num> Number: 337184405
<title> A Stochastic Treatment of Learning to Rank Scoring Functions

<desc> Description:
Despite these differences, existing listwise learning-to-rank algorithms agree on one element: scores computed by the learned scoring function are deterministically mapped to a ranked list by way of a sort operation. One exception is SoftRank [36]. [36] consider a score to be the mean of a Gaussian distribution. With scores being smooth in this way, they go on to estimate position distributions and ultimately define a smoothed version of ranking metrics. We note that while our work bears some superficial resemblance with SoftRank, our approach is fundamentally different: SoftRank considers each score to itself be a Gaussian distribution—an arbitrary choice—whereas in this work, we take a set of scores to define a distribution from which a permutation may be sampled. Furthermore, our method is efficient while in SoftRank, estimating position distributions given score distributions requires an inefficient construction.

<narr> Narrative:

</top>

<top>
<num> Number: 337184406
<title> A Stochastic Treatment of Learning to Rank Scoring Functions

<desc> Description:
Another work that uses additive noise is YetiRank [16]. In particular, YetiRank perturbs relevance scores by a noise sampled from the Logistic distribution, and uses the perturbed scores to weight document pairs. YetiRank is different from our work in the following ways: (a) while the authors demonstrated that additive noise results in an improved model, the use of Logistic distribution was not justified, whereas in this work we mathematically motivate the use of the Gumbel distribution; and (b) YetiRank uses noise to identify and re-weight document pairs, whereas our methodology could be used to sample from the space of permutations, thereby presenting a more general, ranking-appropriate framework.

<narr> Narrative:

</top>

<top>
<num> Number: 337184407
<title> A Stochastic Treatment of Learning to Rank Scoring Functions

<desc> Description:
Finally, another related work is the LambdaLoss framework [38]. [38] propose a probabilistic framework to model ranking loss functions and show that existing ranking losses are instances of LambdaLoss. One term in LambdaLoss captures the probability of a permutation given a set of scores , p(π|f(x)). In their work, however, [38] use a degenerate distribution where this probability is 1 for a permutation (deterministically) obtained by sorting scores in decreasing order. Our proposed stochastic framework allows one to construct a non-degenerate distribution over permutations, from which a permutation may be sampled directly and efficiently.

<narr> Narrative:

</top>

<top>
<num> Number: 337177001
<title> JNET: Learning User Representations via Joint Network Embedding and Topic Embedding

<desc> Description:
Inferring user intent from recorded user behavior data has been studied extensively for user modeling [11, 22, 31, 39, 40]. Essentially, user modeling builds up conceptual representations of users, which help automated systems to better capture users’ needs and enhance user experience in such systems [9, 17]. The rapid development of social media enables users to participate in online activities and create vast amount of observational data, such as social interactions [15, 16] and opinionated text content [8, 12, 27], which in turn provides informative signs about user intents and enables more accurate user representation learning. Extensive efforts have proved the value of user representation learning in various real-world applications, such as latent factor models for collaborative filtering [18, 29], topic models for content modeling [23, 38], network embedding models for social link prediction [5, 20], and many more [31, 42].

<narr> Narrative:

</top>

<top>
<num> Number: 337177002
<title> JNET: Learning User Representations via Joint Network Embedding and Topic Embedding

<desc> Description:
User representation learning is challenging, and it can never be a straightforward application of existing statistical learning algorithms on user-generated data. First, user-generated data is noisy, incomplete, highly unstructured, and tied with social interactions [34], which imposes serious challenges in modeling such data. For example, in an environment where users are connected, e.g., social network, user-generated data is potentially related, which directly breaks the popularly imposed independent and identically distributed assumptions in most learning solutions [10, 20, 32]. Second, users often participate in various online activities simultaneously, which creates instrumental contextual signals across different modalities. Although oftentimes scattered and sparse, such multi-modal observations reflect users’ underlying intents as a whole and call for a holistic modeling approach [19]. Ad-hoc data-driven solutions inevitably isolate the dependency and hence fail to create a comprehensive representation of users. For example, users’ social interactions [5, 28] and their generated text data [4, 23, 38] have been extensively studied for user representation learning, but they are largely modeled in isolation. Third, consequently, a unified user representation learning solution is preferred to serve different applications, by taking advantage of data-rich applications to help those data-poor applications.

<narr> Narrative:

</top>

<top>
<num> Number: 337177003
<title> JNET: Learning User Representations via Joint Network Embedding and Topic Embedding

<desc> Description:
Even among a few attempts for joint modeling of different types of user-generated data [12, 43], explicit modeling of dependency among multiple behavior modalities is still missing. For example, [43] incorporated user-generated text content into network representation learning via joint matrix factorization. In their solution, content modeling is only used as a regularization for network modeling; and thus the learnt model is not in a position to predict unseen text content. [12] paired the task of sentiment classification with that of social network modeling, and represented each user as a mixture over the instances of these paired tasks. Though text and network are jointly considered, they are only correlated by sharing the same mixing component, without explicitly modeling of the mutual influence between them.

<narr> Narrative:

</top>

<top>
<num> Number: 337177005
<title> JNET: Learning User Representations via Joint Network Embedding and Topic Embedding

<desc> Description:
To realize this new perspective of user representation learning, we exploit two most widely available and representative forms of user-generated data, i.e., text content and social interactions. We develop a probabilistic generative model to integrate user modeling with content and network embedding. Due to the unstructured nature of text, we appeal to statistical topic models to model user-generated text content [4, 38], with a goal to capture the underlying semantics. We define a topic as a probability distribution over a fixed vocabulary [4]. We embed both users and topics to the same low-dimensional space to capture of their mutual dependency. On one hand, a user’s affinity to a topic is characterized by his/her proximity to the topic’s embedding in this latent space, which is utilized to generate each text document of the user. On the other hand, the affinity between users is directly modeled by the proximity between users’ embeddings, which are utilized to generate the corresponding social network connections. In this latent space, the two modalities of user-generated data are correlated explicitly, indicated by the user’s topical preferences. The user representation is obtained by posterior inference of those embedding vectors over a set of training data, via variational Bayesian. To reflect the nature of our proposed user representation learning method, we name the solution Joint Network Embedding and Topic Embedding, or JNET for short.

<narr> Narrative:

</top>

<top>
<num> Number: 337177006
<title> JNET: Learning User Representations via Joint Network Embedding and Topic Embedding

<desc> Description:
When performing user representation learning in an isolated way, much attention has been paid on exploring user-user interactions to learn users’ distributed representations, which are essential for better understanding users’ interactive preferences in social network analysis. Inspired from word embedding techniques [25], random walk models are exploited to generate random paths over a network to learn dense, continuous and low-dimensional representations of users [13, 28, 35]. Matrix factorization technique is also commonly used to learn user embeddings [26, 41], as learning a low-rank space for an adjacency matrix representing the network naturally fits the need of learning low-rank user/node embeddings. For instance, [36] factorize an input network’s modularity matrix and use discriminative training to extract representative dimensions for learning user representation.

<narr> Narrative:

</top>

<top>
<num> Number: 337177007
<title> JNET: Learning User Representations via Joint Network Embedding and Topic Embedding

<desc> Description:
In parallel, the user-generated text data is utilized to understand users’ emphasis on specific entities or aspects. Topic models [4, 14] serve as a building block for statistical modeling of text data. Typical solutions model individual users as a bag of topics [30], which govern the generation of associated text documents. [38] combine topic modeling with collaborative filtering to estimate topical user representations with additional observations from user-item ratings. [39] use topic modeling to estimate users’ detailed aspect-level preferences from their opinionated review content. [21] learn users’ personalized topical compositions to differentiate user’s subjectivity from item’s intrinsic property in the review documents. [23] uncover the implicit preferences of each user as well as the properties of each product by mapping users and items into a shared topic space. Some recent works use deep neural networks to obtain user embedding from their generated text data [7, 33].

<narr> Narrative:

</top>

<top>
<num> Number: 337177008
<title> JNET: Learning User Representations via Joint Network Embedding and Topic Embedding

<desc> Description:
Although most previous works studied social networks and user-generated text content in isolation, little attention has been paid in combining the two sources for better user modeling. Earlier work [24] regularizes a statistical topic model with a harmonic regularizer defined on the network structure. [43] incorporate text features of users into network representation learning via joint matrix factorization. [12] pair tasks of opinionated content modeling and network structure modeling in a group-wise fashion, and model each user as a mixture over the tasks. Though both text and network are utilized for user modeling in the aforementioned works, explicit modeling of dependence among different modalities is still missing. [1] explore the dependency among documents and network but on a per-community basis instead of a per-user basis. Our work proposes a holistic view to model users’ social preferences and topical interests jointly, thus to provide a more general understanding of user intents from multiple perspectives.

<narr> Narrative:

</top>

<top>
<num> Number: 337182202
<title> User Recommendation in Content Curation Platforms

<desc> Description:
By connecting to curators, users can discover new items, new collections, and new connections among items built via human (rather than algorithmic) power. For example, as illustrated in Figure 1, a Spotify user can follow other users and thus keep track of their listening activities (like songs, albums, and playlists). In Goodreads, users will see updates including new bookshelves, ratings and text reviews from those whom they follow. Indeed, around 50% of Spotify’s 100 million users listen to human-curated playlists [37] and researchers have shown how the power of human curation can serve as a significant component of modern recommender systems to connect users to items [16, 24].

<narr> Narrative:

</top>

<top>
<num> Number: 337182203
<title> User Recommendation in Content Curation Platforms

<desc> Description:
But how can we recommend interesting curators to follow? This challenge of user recommendation in content curation platforms is vitally important and yet most existing methods that rely on traditional item-level recommendation [2, 3, 9, 35, 38] or on expert-finding approaches [8, 12, 26, 29] may not capture the important relationships among both curators and the items they curate. Users in curation platforms are complex amalgamations of the specific items they interact with (e.g., sci-fi books), their style of curation (e.g., reflecting personal interests), and the complex interactions between items and the curated lists themselves. For example, a specific item type like a fantasy novel may be curated by someone with an interest in novels with strong female protagonists, while the same novel may be curated by someone else with an interest in space warfare. Compared to previous works on friend recommendation [10, 32], topical user recommendation (e.g., finding other users interested in fashion) [14, 30], and expert finding [8, 12, 26, 29], there is a research gap in curator recommendation that carefully balances user preferences for specific item types and preferences for different curator specialties.

<narr> Narrative:

</top>

<top>
<num> Number: 337182204
<title> User Recommendation in Content Curation Platforms

<desc> Description:
Recently there have been efforts to study curation platforms. In [5, 25], the authors recommend user-generated lists based on the occurrences of items among lists and interactions of users on items. Work in [18, 44] focuses on “board” recommendation in Pinterest. However, there is a gap in our understanding of finding interesting users to follow. The connections between users and curators are amalgamations of curated contents, individual items and personal style, which pose new challenges compared to traditional friend recommendation in social networks [10, 32]. Somewhat similar to our notion of curator is research on finding expertise to improve search and recommendation, including topical user recommendation [14, 30, 45, 46] and expert finding [8, 12, 26, 29]. For example, UserRec [46] models users’ similarity based on the tag-graph and topic distributions, with which it can help in connecting users sharing similar interest. [43] propose to improve friend recommendation by capturing the relationships among users, their friends and interest with tensor factorization. However, these and related methods usually rely on users’ explicit (topical) tags on experts, or the semantics of tags and content created by users, which are not always available in content curation platforms. In contrast, we focus on curation decisions of these users to model users and the items they curate simultaneously.

<narr> Narrative:

</top>

<top>
<num> Number: 337182205
<title> User Recommendation in Content Curation Platforms

<desc> Description:
CuRe jointly learns user preferences on curators and items akin to multitask learning [6], which has been widely adopted in different recommendation scenarios [2, 5, 19, 27, 34, 40]. By sharing feature representations across different tasks, it enables the recommender system to fully leverage hidden signals from the sparse data through regularization. [19] set item correlation prediction and next interaction prediction as supplementary tasks, to improve the performance of sequential item recommendation. In GRU-MTL [2], they train the recurrent model with two tasks – tag prediction and text recommendation, to ultimately improve the text recommendation. Similarly, in [27, 40], they combine personalized item recommendation with opinionated text content modeling together to achieve better results in the recommendation. Enhanced with transferring knowledge between different social media sites, Crossfire [34] generates recommendations of friends and items at the same time. In contrast, our proposed approach combines user recommendation in curation platforms with the supplementary task of item recommendation to better model user preferences.

<narr> Narrative:

</top>

<top>
<num> Number: 337182001
<title> Parameter Tuning in Personal Search Systems

<desc> Description:
Modern search engines usually have multiple processing stages in their systems. A typical flow has a retrieval stage followed with a ranking stage, where the retrieval stage selects N documents and passes them to the ranking stage. The ranking stage often employs a machine learning model based on query, document, and user features. In this work, we present a parameter tuning approach which can be used for either stage. This approach is especially impactful for the retrieval stage – while a large amount of work focuses on optimizing the parameters of the ranking stage, relatively little work [3, 8] covers parameter tuning at the retrieval stage.

<narr> Narrative:

</top>

<top>
<num> Number: 337182002
<title> Parameter Tuning in Personal Search Systems

<desc> Description:
Whereas retrieval work in the literature primarily studies approaches such as BM25 [26], search engines in industry have an entirely different set of challenges. Commercial web search engines have been developed for decades by many engineers. The various search system components quickly become complicated and typically have numerous parameters to be tuned. As [7, 13] note that even small variations in parameters of information retrieval systems lead to large variations in retrieval effectiveness, it motivates thoroughly tuning parameters. Another motivation for this work comes from infrastructure reuse in commercial settings, which leads to the same retrieval system being used for multiple applications and not tuned optimally for each one.

<narr> Narrative:

</top>

<top>
<num> Number: 337182003
<title> Parameter Tuning in Personal Search Systems

<desc> Description:
Given that an industrial search system can be very complex, a natural and common approach for parameter tuning is to treat the entire system as a black box and run A/B experiments with either some sort of parameter sweep (e.g. grid search, coordinate ascent) [22] or black-box optimization [17] over various parameters in a guess-and-check manner. The drawback to this is that 1) the user experience can be degraded due to exposure to poor quality results, 2) separate online experiments are required for each test set of parameters, and 3) the tuning process can take months.

<narr> Narrative:

</top>

<top>
<num> Number: 337182004
<title> Parameter Tuning in Personal Search Systems

<desc> Description:
Offline tuning using a validation set is another option [21]. For instance, as the retrieval component of a search system usually works with query strings and document contents directly, offline tuning in this setting involves collecting raw queries and historical click data and simulating how retrieval effectiveness changes when utilizing different parameters. However, in the personal search setting [2, 5, 12, 28], where both queries and documents are private, building a representative validation set is a challenge, as it involves either relying upon donated data (which can be limited and biased) or utilizing a validation set that only contains partial information (where any sensitive raw data is not logged). In this paper, we introduce a methodology for utilizing a partial validation set to do parameter tuning for the personal search setting.

<narr> Narrative:

</top>

<top>
<num> Number: 337182006
<title> Parameter Tuning in Personal Search Systems

<desc> Description:
[7, 13] discuss the importance of parameter tuning, and [27] gives more insight into the difficulty of parameter management. Since new features are often added to search systems to improve the performance of retrieval functions, these features often increase the number of parameters which makes it more challenging to find optimal parameter values.

<narr> Narrative:

</top>

<top>
<num> Number: 337182007
<title> Parameter Tuning in Personal Search Systems

<desc> Description:
The majority of work regarding parameter tuning is for blackbox systems, where no knowledge of the internal implementation is known. For these approaches, given an unknown function f, we are allowed to evaluate f(x) for any value x ∈ X in an effort to maximize (or minimize) f(x). Typical approaches include Bayesian optimization [11, 17] as well as hybrid methods using random search alongside multi-armed bandit techniques [19]. In particular, [17] discusses how Bayesian optimization can be used for optimizing retrieval systems. These approaches generally assume some prior belief over f and draw samples to get a posterior that better approximates f. Other Bayesian optimization work consists of that of [15], which remarks on the importance of determining the impactfulness of different hyperparameters in order to reduce the exploration needed and speed up the optimization process. Bayesian optimization techniques differ from our work as our work assumes some (though incomplete) knowledge about the function f is known.

<narr> Narrative:

</top>

<top>
<num> Number: 337182011
<title> Parameter Tuning in Personal Search Systems

<desc> Description:
Offline evaluation is critical for production search systems to sanity check any new experiments and prevent system behavior that may be detrimental to the users’ experience. [14] use previously collected click data in order to perform interleaved comparison methods between various rankers and find that it can be less expensive than running live interleaving experiments. [18] provides a method of doing offline evaluation of different contextual bandit based article recommendations, where a primary motivation is to not hurt user experience by exposing potentially poor-quality algorithms.

<narr> Narrative:

</top>

<top>
<num> Number: 337177601
<title> Consistency-Aware Recommendation for User-Generated Item List Continuation

<desc> Description:
Human curation is a widely used feature in platforms like Spotify, Pinterest, YouTube, and Goodreads. Users can curate items like songs, images, videos and books to form lists that provide a unique perspective into how items can be grouped together. For example, Figure 1 shows two book lists on the book sharing platform Goodreads; one is organized around a genre (fantasy) while the other collects a personal list of favorites spanning genres. Since correlated items can be explored and consumed together, these item lists directly power user engagement. For example, more than 50% of Spotify users listen to playlists, accounting for more than 1 billion plays per week [38]; and Pinterest users have curated more than 3 billion pins to about 4 billion boards [10].

<narr> Narrative:

</top>

<top>
<num> Number: 337177602
<title> Consistency-Aware Recommendation for User-Generated Item List Continuation

<desc> Description:
In these platforms, user-generated item lists are manually created, curated, and managed by users. Typically, users must first identify candidate items, determine if they are a good fit for a list, add them to a list, and then potentially provide ongoing updates to the list (e.g., by adding or deleting items over time). To accelerate this process and assist users to explore more related items for their lists, we study the important yet challenging problem of user-generated item list continuation. That is, how can we recommend items that are related to the list and fit the user’s preferences? Compared with traditional item-based recommendation [34], list continuation faces complexities, since the length of lists varies from several items to even thousands of items and the user preference on items may dynamically evolve as a list develops. Moreover, the individual preference of how items are grouped together also varies for each user and across different platforms. Facing these challenges, we propose a consistency-aware recommender for user-generated item list continuation that is motivated by three key observations.

<narr> Narrative:

</top>

<top>
<num> Number: 337177603
<title> Consistency-Aware Recommendation for User-Generated Item List Continuation

<desc> Description:
First, we observe that some lists are strongly consistent while others are only weakly consistent. Traditional song-based playlist continuation usually aims to generate strongly consistent lists, where each new song naturally fits with the previous ones [1, 4, 6, 12, 13, 21, 29– 31, 33, 37]. A typical example is in [33], which generates a playlist with songs that are similar to the seed songs provided by the user. Indeed, some user-generated item lists may be organized around a specific theme, genre, or mood. However, some lists are organized by more personalized patterns and are seemingly inconsistent. To illustrate, List A in Figure 1(a) has strong consistency between recent books and previous books. The books are from either the Harry Potter series or the Twilight series, organized around genres like “Fantasy". List B in Figure 1(b) is only weakly consistent with a mystery book Binds That Tie following two books about dogs. Indeed, we find in Figure 2 that list consistency varies greatly both within a single platform and across different platforms. As a result, we require new methods that can dynamically adapt to this heterogeneity of list consistency.

<narr> Narrative:

</top>

<top>
<num> Number: 337177604
<title> Consistency-Aware Recommendation for User-Generated Item List Continuation

<desc> Description:
Third, we observe that the definition of what makes a list consistent should arise from community norms rather than be imposed top-down. Prior work in song-based playlists has found that neither audio signal-based similarity nor social tag-based similarity accurately reflect the consistency of manually constructed playlists [6, 30]. Our example so far in Figure 1 has highlighted how books in a single list may be drawn from different (seemingly inconsistent) genres. However, the consistency of items should depend on how users in the community perceive those items; so, if many users curate two items together, then those items should be considered consistent regardless of their superficial similarity. Hence, item list continuation methods should seek to model consistency based on the curation patterns arising from the community itself.

<narr> Narrative:

</top>

<top>
<num> Number: 337177605
<title> Consistency-Aware Recommendation for User-Generated Item List Continuation

<desc> Description:
Considerable prior research has focused on automatic song-based playlist generation and continuation, aligned along three branches. The first branch focuses on generative models for estimating the likelihood of a new playlist by treating training playlists as a set of song sequences. For example, [30, 31] apply a first-order Markov Chain for modeling playlists, which is improved by [6] via introducing metric embeddings. The second branch mainly relies on song-based audio features (e.g., Mel-frequency cepstral coefficients) to generate new playlists. Examples include [12] and [29], where [29] train classifiers using audio-based features to determine if a sequence of songs can form a playlist. The third branch is most similar to our work, often applying information retrieval or recommendation methods to predict (or continue) the next N items. These approaches often are enhanced by content-based methods [13, 21, 33, 40–42]. A typical example by [21] uses collaborative filtering and incorporates content features like social tags from Last.fm and popularity of songs.

<narr> Narrative:

</top>

<top>
<num> Number: 337177606
<title> Consistency-Aware Recommendation for User-Generated Item List Continuation

<desc> Description:
There are two key differences between our work and traditional song-based playlist generation. First, we focus on not only song-based lists but propose a general framework that can be applied to other user-generated item lists, like book-based (Goodreads book lists), video-based (YouTube playlists), image-based (Pinterest boards) and answer-based (Zhihu collections) lists. Like song-based playlists, each collection of these item lists also provides a unique resource where correlated items can be easily explored and consumed together, directly empowering user engagement. Therefore, automatic generation and continuation for these item lists should be equally important as song-based playlists. Second, most traditional playlist continuation work assumes lists are always consistent [6, 12, 13, 21, 29–31, 33]. Except for [33] introduced in the introduction, examples include [6, 30, 31] that apply language models to generate coherent playlists and [21] that recommends a set of songs whose tempo distribution is as similar as possible to the current playlist. However, we observe that the consistency varies greatly for lists both within and across different platforms, meaning that list continuation methods should dynamically adapt to these scenarios.

<narr> Narrative:

</top>

<top>
<num> Number: 337177607
<title> Consistency-Aware Recommendation for User-Generated Item List Continuation

<desc> Description:
Recently, user-generated item lists have received more and more interest. [43] study the motivations of human curation to reveal the social values of user-generated item lists. [11] study the characteristics of item lists and claim there are two kinds of lists: for personal information management and for public expression. [27] analyze the growth of image collections on Pinterest. [25] and [10] distill user preference from Pinterest image-based lists to enhance individual image recommendation. Another interesting problem is to recommend existing item lists to users. [17] propose a hierarchical self-attentive model for recommending user-generated item lists (e.g., book lists and playlists) to right users. Besides, the List Recommending Model in [26] is proposed for recommending book lists and the Embedding Factorization Model in [3] is for recommending song playlists.

<narr> Narrative:

</top>

<top>
<num> Number: 337177608
<title> Consistency-Aware Recommendation for User-Generated Item List Continuation

<desc> Description:
Recently, neural networks have been widely applied in recommendation. [16] apply multilayer perceptron and generalized matrix factorization for implicit top-k recommendation. [9] apply memory networks for recommendation. [18] propose a GRU-based model for session-based recommendation and [36] propose a CNN-based model for sequential recommendation. Attention networks are often used for weighted-summing elements in a model. [5] propose an attentive collaborative filtering framework, where each item is segmented into component-level elements, and attention scores are learned for these components for obtaining a better representation of items. Attention networks are also applied in group recommendation [2] and sequential recommendation [19, 22].

<narr> Narrative:

</top>

<top>
<num> Number: 337177501
<title> Separate and Attend in Personal Email Search

<desc> Description:
Email has long been an important means of daily communication. Personal email search, which helps users to quickly retrieve the emails they are looking for from their own corpora, has been an intriguing research topic in information retrieval (IR) for years. Email search is formulated as a learning-to-rank problem, which has been tackled with different learning models, such as boosted trees [8], SVM-based linear models [10, 12, 23], and shallow neural networks [9, 11].

<narr> Narrative:

</top>

<top>
<num> Number: 337177502
<title> Separate and Attend in Personal Email Search

<desc> Description:
Recently, deep neural networks (DNNs) have shown great success in learning-to-rank tasks. They significantly improve the performance of search engines in the presence of large-scale query logs in both web search [19] and email settings [39, 45, 51]. The advantages of DNNs over traditional models are mainly two-fold: (1) DNNs have strong power to learn embedded representations from sparse features, including words [33] and characters [6]. This allows effective and accurate matching of textual features between queries and documents. (2) DNNs are proved to have universal approximation capability [21] and thus are able to capture high-order interactions between query and document features.

<narr> Narrative:

</top>

<top>
<num> Number: 337177503
<title> Separate and Attend in Personal Email Search

<desc> Description:
In the personal email search scenario, user queries impose different requirements on different aspects of email documents to be retrieved. For example, the query “my recent flight to the US” requires the email search system to focus on both the textual contents and the recency of email documents, while queries such as “medical history” expect emails to be retrieved regardless of the recency. In email search models, different properties of email documents are reflected by different types of features, including dense numerical ones (e.g., document age) and sparse categorical ones (e.g., n-grams). However, there have been few efforts that study how to effectively exploit both dense and sparse features in the learning-to-rank setting, probably because a natural approach exists—simply concatenating dense features with embedded sparse features and feeding them into the DNNs. Indeed, many previous deep neural email search models use direct concatenation of dense features with embedded sparse features [15, 38, 39, 45].

<narr> Narrative:

</top>

<top>
<num> Number: 337177504
<title> Separate and Attend in Personal Email Search

<desc> Description:
Learning-to-rank refers to building ranking models with machine learning algorithms. In early years, learning-to-rank has been studied with different models, such as boosted trees [8], SVM-based linear models [10, 12, 23] and shallow neural networks [9, 11]. Recent years have witnessed great success of applying DNNs to learning-to-rank, such as [7, 15, 36, 38]. For a complete literature review on neural ranking models for information retrieval, please refer to a survey by [34].

<narr> Narrative:

</top>

<top>
<num> Number: 337177505
<title> Separate and Attend in Personal Email Search

<desc> Description:
There have been several studies in the IR community focusing on the task of email search. The Enterprise tracks of TREC 2005 [40] and TREC 2006 [41] provide public datasets containing email data and summarize some early explorations [14, 31, 35]. A typical trade-off in email search system is to balance the importance of content-based relevance and other features, e.g. freshness. [12] proposed an email search framework with a learning-to-rank re-ranking module that combines freshness with relevance signals of emails as well as other features such as user actions. Alternatively, [13] studied to present users with both the relevance-ranked results as well as the time-ranked results in two separate lists for better user experience. A number of studies specifically focus on improving the content-based relevance signals in email search. [27] explored several methods to expand the usually short and sparse queries by finding more related terms to improve the relevance results. [29] studied a more specific synonym expansion problem to improve email search performance.

<narr> Narrative:

</top>

<top>
<num> Number: 337177506
<title> Separate and Attend in Personal Email Search

<desc> Description:
User interaction data such as clicks is another important signal for learning-to-rank models in email search. [4] leveraged user interactions by attribute parameterization. [48] mitigated the position bias in click data for better training of the model. In addition, [51] showed that contexts such as search request time and location of users were helpful for email search quality.

<narr> Narrative:

</top>

<top>
<num> Number: 337177507
<title> Separate and Attend in Personal Email Search

<desc> Description:
There are also studies on understanding and leveraging query intent information in email search. [2] conducted a thorough survey of search intent by analyzing user logs of email search. [39] categorized email search queries into different clusters before adding the query cluster information to improve email ranking.

<narr> Narrative:

</top>

<top>
<num> Number: 337177508
<title> Separate and Attend in Personal Email Search

<desc> Description:
Recently, neural attention mechanisms have demonstrated enormous power on sequence modeling. They derived the optimal sequence representation by learning to focus on the important tokens in the sequence and down-weighting unimportant ones for downstream tasks. The attention mechanism was first proposed by [3] in machine translation, where attention was used on top of RNN encoders for input-output alignment. Later, the attention mechanism has been adapted to a wide range of compelling sequence modeling tasks, including image caption generation [49], text classification [50] and natural language question answering [20, 26, 43].

<narr> Narrative:

</top>

<top>
<num> Number: 337178501
<title> Interpretable Click-Through Rate Prediction through Hierarchical Attention

<desc> Description:
Click-through rate (CTR) is defined as the probability of a user clicking through a particular recommended item or an advertisement on a web page. It plays a significant role in recommender systems, such as online advertising, since it directly affects the revenue of advertising agencies [7, 12, 13, 16, 25, 25, 30, 37, 38]. Consequently, CTR prediction, which attempts to accurately estimate the CTR given information describing a user-item scenario, is critical for achieving precise recommendations and increasing good revenue for enterprises.

<narr> Narrative:

</top>

<top>
<num> Number: 337178502
<title> Interpretable Click-Through Rate Prediction through Hierarchical Attention

<desc> Description:
The development of deep learning provides a new machine learning paradigm that utilizes deeper neural network structure to capture more complex information from the training data. Therefore, the architectural and computational complexity of existing CTR prediction models has been ever increasing in order to learn the joint effect of multiple features, i.e., high-order features (a.k.a. cross features), and attain better prediction accuracy. Specifically, a k-th order feature (k ∈ N) refers to a latent variable that is a k-th degree polynomial of the raw features [4, 31]. Deep neural networks provide strong capability to capture rich high-order information due to the large number of layers and units. For example, DeepFM [9] and xDeepFM [19] learn high-order features by multi-layer feedforward neural networks (FNN) and multi-block compressed interaction networks (CIN).

<narr> Narrative:

</top>

<top>
<num> Number: 337178503
<title> Interpretable Click-Through Rate Prediction through Hierarchical Attention

<desc> Description:
However, the ever-growing model complexity has two drawbacks: impaired interpretability and poor efficiency. For interpretability, the prediction-making processes are hard to be reasonably explained since the weights and activations of the neural network layers are usually deemed unexplainable. For example, the wide component of Wide&Deep [4] applies cross-product transformations to feature embeddings but fails to quantify and justify its effectiveness to the actual click-through rate prediction performance. The lack of persuasive rationales for the predictions of the models casts shadow on their reliability and security. In many applications, e.g., medication recommendation [20] and financial services [39], untrustworthy and unreliable advertisements can mislead users to click through the statistically popular but actually useless or even harmful links which can result in serious consequences such as economic or health losses.

<narr> Narrative:

</top>

<top>
<num> Number: 337178504
<title> Interpretable Click-Through Rate Prediction through Hierarchical Attention

<desc> Description:
The second defect of existing approaches is the poor efficiency since the high-order interaction feature generation by deep neural networks involves extremely heavy matrix computations in deep neural networks (DNN). For example, the compressed interaction network (CIN) in xDeepFM [19] computes the (k + 1)-th order feature matrix by an outer product layer and a fully-connected layer which entails a cubic complexity to the embedding dimension. The deep component in Wide&Deep has a number of fully-connected layers each of which involves a quadratic number of multiplications.

<narr> Narrative:

</top>

<top>
<num> Number: 337178507
<title> Interpretable Click-Through Rate Prediction through Hierarchical Attention

<desc> Description:
CTR prediction has drawn great attention from both academia and industry [4, 7, 12, 18, 19, 23, 24, 26, 30–32, 36–38] due to its significant impact on online advertisements. The advancement of CTR prediction algorithms essentially shows a trend towards deeper model architectures since they are more powerful in feature interaction learning [27].

<narr> Narrative:

</top>

<top>
<num> Number: 337178508
<title> Interpretable Click-Through Rate Prediction through Hierarchical Attention

<desc> Description:
Factorization Machine (FM) [24] assigns a d-dimensional trainable continuous-valued representation to each distinct feature, learns the representations of distinct features, and makes predictions by a linear aggregation of first- and second-order features. Although FM can be generalized to high-order cases, it suffers from computational cost of exponential complexity [3] and low model capability of shallow architecture. Field-aware Factorization Machine (FFM) [16] assumes that features may have dissimilar semantics under distinct fields and extends the idea of FM by making the feature representation field-specific. Although it achieves better CTR result than FM, the parameter size and complexity are also increased and overfitting is easier to happen. Attentional Factorization Machine (AFM) [32] extends FM with an “attention net” that improves not only the performance but also interpretability. The authors argue that the feature salience provided by the attention network greatly enhance the transparency of FM. That said, AFM can only learn up to the second-order attention-based salience due to the inherit architectural limit of FM.

<narr> Narrative:

</top>

<top>
<num> Number: 337178509
<title> Interpretable Click-Through Rate Prediction through Hierarchical Attention

<desc> Description:
Wide&Deep [4] consists of a wide and a deep component, which are essentially a generalized linear model and a multi-layer perceptron (MLP), respectively. The CTR prediction is made by a weighted combination of the outcomes of the two components. Note that the deep component, i.e., the MLP, ruins the possibility of explaining the prediction because the layer-wise transformations are conducted on unit level instead of feature level and individual unit level values can not carry concrete and complete semantic information of features. Deep&Cross Network (DCN) [31] slightly differs from Wide&Deep in that DCN replaces the linear model with a cross-product transformation to integrate high-order information with non-linear deep features. DeepFM [9] improves these two models by replacing the polynomial production with an FM component. The deep MLP component captures the high-order feature interaction and the FM analyzes the second-order feature interaction. xDeepFM [19] claims that MLP parameters are actually arbitrarily modeling the “implicit” feature interactions. The authors hence introduce compressed interaction network (CIN) to model the “explicit” features alongside the implicit ones. Recent works from industry practice include DIN [38] and DIEN [37] that respectively model the static and dynamic shopping interest of users. Both work heavily rely on deep feed-forward networks which are typically unexplainable.

<narr> Narrative:

</top>

<top>
<num> Number: 337181401
<title> Listwise Learning to Rank by Exploring Unique Ratings

<desc> Description:
Learning-to-rank is one of the most classical research topics in information retrieval, and researchers have put tremendous efforts into modeling ranking behaviors. In training, existing ranking models learn a scoring function from query-document features and multi-level ratings/labels, e.g., 0, 1, 2. During inference, the learned scoring function is used to obtain prediction scores for ordering documents. There are two major challenges for learning-to-rank. The first challenge is that there can be a mismatch between ratings and the correct ranking orders in training. Although it is straightforward to infer partial ranking orders from ratings and prediction scores, it is not easy to design loss functions modeling the order of ratings and the order of prediction scores. Many prediction scores indicate the same ranking, i.e., the order of documents. This implies that a model does not necessarily have to match ratings, opening opportunities and ambiguities. Moreover, the top ranking positions are more important. The second challenge is that raw features may not be representative enough for learning a reasonable scoring function. Existing ranking models tackle the two challenges by: (1) designing loss functions or reward functions to map prediction scores with correct ranking orders in training, and (2) tuning loss functions with evaluation metrics such as NDCG [24], or ERR [10], and (3) calculating prediction scores using richer features such as a local ranking context [1, 3, 5, 18, 38].

<narr> Narrative:

</top>

<top>
<num> Number: 337181402
<title> Listwise Learning to Rank by Exploring Unique Ratings

<desc> Description:
Depending on how prediction scores in training are compared with ratings, there are three types of loss functions: pointwise, pairwise, and listwise. Pointwise learning maps the prediction scores of individual documents with their exact ratings [31], which is not necessary for obtaining correct orders. Pairwise learning [7, 8, 14, 20, 28, 43, 44, 46, 50] naturally compares pairs of documents to minimize the number of inversions. Earlier pairwise models such as RankSVM [20], RankBoost [14], RankNet [7], and Ordinal Regression [28] may overly update weights for different pairs as they treat all pairs with equal importance. For instance, suppose the correct order is (a -> b -> c -> d). When a pairwise model catches an inversion (c -> b) in a predicted order (a -> c -> b -> d), it tries to update weights to increase the score of b and decrease the score of c. However, if the score of b becomes too high – higher than a – this causes another inversion (b, a). LambdaMart [8, 22, 43] and NDCG-LOSS++ [46] largely limit this issue by assigning different weights for different pairs when calculating their gradients [8]. Their best models rely on using gradient boosting regression trees [11, 26, 35], which are effective but very sensitive to hyper-parameters. Listwise learning [9, 17, 25, 27, 34, 36, 45, 48] tries to learn the best document permutation based on permutation probabilities proposed by [40] and [32]. The classical Plackett-Luce model has a constraint that the permutation probabilities are targeted for unique ratings. For instance, maximizing the likelihood of choosing a document from a set of documents that have the same rating can confuse a model. Since the number of unique rating levels is typically much smaller than the number of candidate documents per query, there can be a large number of ties. Also, in order to calculate the joint probability of a ranking sequence, the number of steps a Plackett-Luce model, such as ListMLE [48], needs to go through is bound by the number of candidate documents per query. Therefore, obtaining one permutation can be computationally inefficient. Furthermore, top documents are more important, but each step of a Plackett-Luce model is equally important along the entire sequence. Variants such as SoftRank [45], p-ListMLE [27], and ApproxNDCG [6] use NDCG or ranking positions to tune their loss functions. Nevertheless, when the number of documents in a permutation is large, gradients can vanish or explode very fast as the product of their permutation probabilities is close to 0. Highlights from research studies in recent years for scoring functions include ensemble scoring functions [2, 16, 31], ranking refinement [1], and reinforcement learning [13, 30, 33, 37, 47, 49]. Despite being effective, training efficiency is still their common bottleneck, which limits their usage in real-world applications.

<narr> Narrative:

</top>

<top>
<num> Number: 337181403
<title> Listwise Learning to Rank by Exploring Unique Ratings

<desc> Description:
ListNet Since learning the complete n! permutations is intractable, ListNet [9] generally minimizes the cross-entropy of top-one probabilities of prediction scores and ratings using a softmax function. Given a set of n documents for a specific query D = {di}i , their ratings Y = {yi}i , and a global scoring function f, the loss function for ListNet using top-one probabilities is.

<narr> Narrative:

</top>

<top>
<num> Number: 337181405
<title> Listwise Learning to Rank by Exploring Unique Ratings

<desc> Description:
The Vanilla RNN model takes a sequence of feature vectors X = (xt)t as input, where xt indicates the feature vector of the document at step t, and computes the hidden output ht at each step. We use ht = rnn(xt,ht−1,W) in this paper to represent an RNN function, where W is a set of trainable weight matrices. Although RNNs can learn the conditional/hidden transitions, it is intractable to apply an RNN to the complete order of documents for a query because of the following two reasons. (1) Some documents have the same rating due to ties. (2) Training a long sequence can be time and memory consuming. It still easily suffers gradient vanishing even if it utilizes more advanced RNN models such as a Long Short-term Memory network (LSTM) [21] or a Gated Recurrent Unit network (GRU) [12]. A common practice of applying RNNs in learning-to-rank is by refining the top positions of a ranked list using two training phases [1]. The novelty of our RNN-based model is that we apply RNN and pooling functions to multiple documents at each step.

<narr> Narrative:

</top>

<top>
<num> Number: 337181001
<title> Improving the Estimation of Tail Ratings in Recommender System with Multi-Latent Representations

<desc> Description:
While the importance of the distribution of ratings on RS has been long recognized, e.g., [1, 2, 15, 36], many popular methods based on latent factor models and recently introduced neural variants [3, 14, 20, 22, 25, 39] optimize for the head of these distributions, potentially leading to large estimation errors for tail ratings. As we will show in Section 3, these tail estimation errors are common across multiple domains and datasets, leading to large over-estimations of the ratings of items with very low ratings, and large under-estimations of the ratings of items with very high ratings. For example, Figure 1(c) shows large RMSE prediction errors for these tail ratings when using two popular latent factor models. These errors can lead to bad recommendations, degrade trust in the recommender, and for controversial items, potentially expose users to items they are diametrically opposed to.

<narr> Narrative:

</top>

<top>
<num> Number: 337181002
<title> Improving the Estimation of Tail Ratings in Recommender System with Multi-Latent Representations

<desc> Description:
In terms of dealing with tail ratings, there have been a few complementary works. For example, Gediminas et al. investigated the impact of rating characteristics like rating density, rating frequency distribution, and value distribution, on the accuracy of popular collaborative filtering techniques [1]. [15] observed that product ratings tend to fit a ‘J-shaped’ distribution since users provide reviews are more likely to “brag or moan” compared to all purchasers. As an extreme case of the ‘J-shaped’ distribution is the ‘U-shape’ of controversial items with many extreme ratings on both sides of the distribution. [36] formalized the concept of controversial items in recommendation systems and then compared the performance of several trust-enhanced techniques for personalized recommendations for controversial items with polarized ratings (bi-modal distribution) versus other items. Similar to our observations, they showed that predicting ratings for controversial items is much worse than for other items. [2] surveyed state-of-the-art research on the polarization, finding that many trust-based RS attempts to improve recommendation for controversial items by defining a trusted network for each user, e.g., [11, 27, 30, 35]. Recently, [4] proposed a focused learning model to improve the recommendation quality for a specified subset of items, through hyper-parameter optimization and a customized matrix factorization objective.

<narr> Narrative:

</top>

<top>
<num> Number: 337181003
<title> Improving the Estimation of Tail Ratings in Recommender System with Multi-Latent Representations

<desc> Description:
Latent factor model is one of the cornerstones of RS, critical for traditional approaches [6, 19] as well as recent neural variants like NCF [14] and others [3, 14, 21, 23, 33, 39]. Furthermore, these latent factor models have been adapted in a number of directions, including location-aware recommendation systems [5, 26, 29], aspect-aware latent factor models [8], and bioinspired approaches [31, 32], among many others. As we will demonstrate in the following section, latent factor models typically depend on an assumption of a single latent representation. That is, every item and user has only a single latent representation. We refer to such approaches as Single Latent Representation (SLR)-based methods.

<narr> Narrative:

</top>

<top>
<num> Number: 337181004
<title> Improving the Estimation of Tail Ratings in Recommender System with Multi-Latent Representations

<desc> Description:
More recently, neural variants like Neural Collaborative Filtering (NCF) have been proposed to combine deep learning architectures with traditional matrix factorization [14]. In particular, NCF is structured with two sub-models: Generalized Matrix Factorization (GMF) and a Multi-Layer Perceptron. The GMF submodel corresponds to a neural version of MF, and so also relies on a single latent vector for representing a user’s preference or an item’s characteristics.

<narr> Narrative:

</top>
