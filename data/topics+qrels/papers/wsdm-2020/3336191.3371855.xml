<doc>
	<doi>10.1145/3336191.3371855</doi>
	<title>Addressing Marketing Bias in Product Recommendations</title>
	<abstract>Modern collaborative filtering algorithms seek to provide personalized product recommendations by uncovering patterns in consumer-product interactions. However, these interactions can be biased by how the product is marketed, for example due to the selection of a particular human model in a product image. These correlations may result in the underrepresentation of particular niche markets in the interaction data; for example, a female user who would potentially like motorcycle products may be less likely to interact with them if they are promoted using stereotypically 'male' images. In this paper, we first investigate this correlation between users' interaction feedback and products' marketing images on two real-world e-commerce datasets. We further examine the response of several standard collaborative filtering algorithms to the distribution of consumer-product market segments in the input interaction data, revealing that marketing strategy can be a source of bias for modern recommender systems. In order to protect recommendation performance on underrepresented market segments, we develop a framework to address this potential marketing bias. Quantitative results demonstrate that the proposed approach significantly improves the recommendation fairness across different market segments, with a negligible loss (or better) recommendation accuracy.</abstract>
	<contexts>
		<context id="01" section="introduction">
			<s>By connecting users to relevant products across the vast range available on e-commerce platforms, modern recommender systems are already ubiquitous and critical on both sides of the market, i.e., consumers and product sellers.</s>
			<s cites="13,17,20,25">Among recommendation algorithms used in practice, many fall under the umbrella of collaborative filtering [13, 17, 20, 25], which collect and generalize users’ preference patterns from logged consumer-product interactions (e.g. purchases, ratings).</s>
			<s>These feedback interactions can be biased by multiple factors, potentially surfacing unfair (or irrelevant) recommendations to users or items underrepresented in the input data.</s>
			<s cites="26,29,3,6">Such phenomena have already raised some attention from the recommender system community: a handful of types of algorithmic biases have been addressed, including selection bias [26], popularity bias [29], and several fairness-aware recommendation algorithms have been proposed [3, 6].</s>
			<s>In this paper, we focus on a relatively underexplored factor—marketing bias—in consumer-product interaction data, and study how recommendation algorithms respond to its effect.</s>
		</context>
		<context id="02" section="introduction">
			<s cites="5,11,12">We are particularly interested in the human factors, such as the profile of the human model in a product image, reflected in a product’s marketing strategies, which (as indicated in previous marketing studies) could possibly affect consumers’ interactions and satisfaction [5, 11, 12].</s>
			<s cites="12">A common hypothesis (known as ‘selfcongruence’) is that a consumer may tend to buy a product because its public impression (in our case a product image), among other alternatives, is consistent with one’s self-perceptions (user identity) [12].</s>
			<s>Based on this assumption, the selection of human models for a product (as shown in Figure 1, a product can be represented by models with different body shapes or different genders) could influence a consumer’s behavior.</s>
			<s>For example, a female user may be less likely to interact with an armband product which is presumably gender-neutral but marketed exclusively via ‘male’ images.</s>
			<s>As with many other types of bias, this could lead to underrepresentation of some niche market segments in the input data for a recommender system.</s>
			<s>Note if undesired patterns are propagated into recommendation results (e.g. even fewer male-represented products are recommended to the potential female users), utility from both sides of the marketplace could be harmed.</s>
			<s>That is, product retailers may lose potential consumers while users may be struggling to find relevant products.</s>
			<s>As a consequence, serious ethical and social concerns could be raised as well.</s>
		</context>
		<context id="03" section="related work">
			<s cites="5,11,12">This work is partially motivated by the well-known ‘self-congruity’ theory in marketing research, which is defined as the match between the product/brand image and the consumer’s true identity and the perception about oneself [5, 11, 12].</s>
			<s cites="18,21,27,28">Many previous marketing studies focus on assessing this theory by quantifying and validating it through statistical analysis on a small amount purchase transaction data or the feedback in questionnaires [18, 21, 27, 28].</s>
			<s cites="10">Following self-congruity theory, products can be advertised in a way to match their target consumers’ images thus establishing product stereotypes [10].</s>
			<s>Our work is distinguished with these studies from a more computational perspective, by identifying and studying the potential marketing bias for recommender systems on large-scale e-commerce interaction datasets.</s>
		</context>
		<context id="04" section="related work">
			<s cites="14,7,31">Our analysis is related to previous work which examines particular types of biases in real-world interactions and their effects in recommendation algorithms, including the popularity effect and catalog coverage [14], the bias regarding the book author gender for book recommenders [7], and the herding effect in product ratings [31].</s>
		</context>
		<context id="05" section="related work">
			<s>Another closely related line of work includes developing evaluation metrics and algorithms to address fairness issues in recommendations.</s>
			<s cites="15,26">‘Unbiased’ recommender systems with missing-not-at-random training data are developed by considering the propensity of each item [15, 26].</s>
			<s cites="32">A fairness-aware tensor-based algorithm is proposed to address the absolute statistical parity (i.e., items are expected to be presented at the same rate across groups) [32].</s>
			<s cites="6,30,3">Several fairness metrics and their corresponding algorithms are proposed for both pointwise prediction frameworks [6, 30] and pairwise ranking frameworks [3].</s>
			<s cites="6,15,26,1,3,30">Methodologically, these algorithms can be summarized as reweighting schemes where underrepresented samples are upweighted [6, 15, 26] or schemes where additional fairness terms are added to regularize the model [1, 3, 30].</s>
		</context>
		<context id="06" section="related work">
			<s>Note that most of the above studies focus on bias and fairness on one side of the market only (i.e., either user or producer).</s>
			<s>Our concern about marketing bias is that it could affect fairness for both consumers and product providers.</s>
			<s>Without global market fairness in mind, the imbalance of the consumer-product segment distribution could be exacerbated through the deployment of recommendation algorithms.</s>
			<s cites="3" anonymised="true">Multi-sided fairness is addressed by [3] by considering C(onsumer)-fairness and P(rovider)-fairness.</s>
			<s cites="22">Trade-off between accuracy and fairness in two-sided marketplaces is further explored and a counterfactual framework is proposed to evaluate different recommendation policies without extensive A/B tests [22].</s>
			<s>However the CP-fairness condition where fairness is protected for both sides at the same time still remains an open question.</s>
		</context>
	</contexts>
	<references>
		<reference id="1">10.1145/3109859.3109912</reference>
		<reference id="2">None</reference>
		<reference id="3">10.1145/3292500.3330745</reference>
		<reference id="4">10.1145/3306618.3314234</reference>
		<reference id="5">https://www.jstor.org/stable/2351957</reference>
		<reference id="6">http://proceedings.mlr.press/v81/burke18a/burke18a.pdf</reference>
		<reference id="7">10.1145/3240323.3240373</reference>
		<reference id="8">None</reference>
		<reference id="9">10.5555/3020847.3020882</reference>
		<reference id="10">10.1080/02650487.2016.1203556</reference>
		<reference id="11">10.1177/002224296703100405</reference>
		<reference id="12">10.1177/002224376800500107</reference>
		<reference id="13">10.1145/3130348.3130372</reference>
		<reference id="14">10.1007/s11257-015-9165-3</reference>
		<reference id="15">10.1145/3018661.3018699</reference>
		<reference id="16">https://cyberleninka.org/article/n/834508.pdf</reference>
		<reference id="17">10.1109/MC.2009.263</reference>
		<reference id="18">10.1016/j.jbusres.2006.06.001</reference>
		<reference id="19">https://www.jstor.org/stable/2236703</reference>
		<reference id="20">10.1109/MIC.2003.1167344</reference>
		<reference id="21">10.1016/0167-4870(88)90029-3</reference>
		<reference id="22">10.1145/3269206.3272027</reference>
		<reference id="23">10.1145/3240323.3240398</reference>
		<reference id="24">10.18653/v1/D19-1018</reference>
		<reference id="25">10.1145/371920.372071</reference>
		<reference id="26">10.5555/3045390.3045567</reference>
		<reference id="27">10.1086/208924</reference>
		<reference id="28">10.1177/0092070397253004</reference>
		<reference id="29">10.1145/3240323.3240355</reference>
		<reference id="30">10.5555/3294996.3295052</reference>
		<reference id="31">10.1145/3109859.3109885</reference>
		<reference id="32">10.1145/3269206.3271795</reference>
	</references>
</doc>