<doc>
	<doi>10.1145/3409256.3409825</doi>
	<title>Cluster-Based Document Retrieval with Multiple Queries</title>
	<abstract>The merits of using multiple queries representing the same information need to improve retrieval effectiveness have recently been demonstrated in several studies. In this paper we present the first study of utilizing multiple queries in cluster-based document retrieval; that is, using information induced from clusters of similar documents to rank documents. Specifically, we propose a conceptual framework of retrieval templates that can adapt cluster-based document retrieval methods, originally devised for a single query, to leverage multiple queries. The adaptations operate at the query, document list and similarity-estimate levels. Retrieval methods are instantiated from the templates by selecting, for example, the clustering algorithm and the cluster-based retrieval method. Empirical evaluation attests to the merits of the retrieval templates with respect to very strong baselines: state-of-the-art cluster-based retrieval with a single query and highly effective fusion of document lists retrieved for multiple queries. In addition, we present findings about the impact of the effectiveness of queries used to represent an information need on (i) cluster hypothesis test results, (ii) percentage of relevant documents in clusters of similar documents, and (iii) effectiveness of state-of-the-art cluster-based retrieval methods.</abstract>
	<contexts>
		<context id="01" section="introduction">
			<s cites="17">The cluster hypothesis for ad hoc retrieval is: “closely associated documents tend to be relevant to the same requests” [17].</s>
			<s>The operational interpretation of the hypothesis is that relevant documents are more similar to each other than to non-relevant documents.</s>
			<s>This interpretation has driven a large body of work on document retrieval methods that utilize information induced from clusters of similar documents.</s>
		</context>
		<context id="02" section="introduction">
			<s cites="22">There are two main categories of cluster-based document retrieval methods [22].</s>
			<s cites="11,14,17,20,21,22,23,27,28,29,30,35,43,44,45">The first includes methods that rank document clusters by the estimated percentage of relevant documents they contain; then, the cluster ranking is transformed to document ranking [11, 14, 17, 20–23, 27–30, 35, 43–45].</s>
			<s cites="9">A cluster-based document retrieval method using supervised learning was the best performing run in the 2013 TREC Web track [9].</s>
		</context>
		<context id="03" section="introduction">
			<s cites="12,20,28,36,43">One of the main motivations for pursuing the cluster ranking task is the optimal cluster phenomenon [12, 20, 28, 36, 43]: if the documents most highly ranked by an initial search are clustered, some of the clusters tend to contain a high percentage of relevant documents; the cluster with the highest percentage is referred to as the optimal cluster.</s>
			<s cites="20,28,43">Positioning the constituent documents of the optimal cluster at the top of the final result list results in much higher precision at top ranks performance than that of other commonly used document-based retrieval methods [20, 28, 43].</s>
			<s cites="20">A case in point, for a standard TREC corpus, the average precision of the top five (P@5) that results from identifying the optimal cluster can reach 0.8 in comparison to 0.46 attained with standard language model retrieval [20].</s>
		</context>
		<context id="04" section="introduction">
			<s cites="19,22,27,39">The second category of cluster-based document retrieval methods includes those that enrich the document representation with information induced from the clusters [19, 22, 27, 39]; e.g., in the language modeling framework, document language models can be smoothed using cluster language models [19, 22, 27].</s>
			<s>The motivation is to reduce potential vocabulary mismatches between queries and relevant documents by enriching a document representation with information induced from similar documents.</s>
		</context>
		<context id="05" section="introduction">
			<s>As in most prior work on ad hoc document retrieval, work on the cluster hypothesis and cluster-based document retrieval was confined to the standard setting where a single query represents an information need.</s>
			<s cites="4,5">However, combining multiple queries which represent the same information need can dramatically improve retrieval effectiveness [4, 5].</s>
			<s cites="2,3,6,7,26,31,42,47">Recently, there has been a renewed interest in the importance of the multiple-queries retrieval setting [2, 3, 6, 7, 26, 31, 42, 47], with growing evidence to its operational feasibility and importance.</s>
			<s cites="38">The feasibility of operationalizing this idea was initially explored nearly a decade ago in the Bing search engine [38].</s>
			<s cites="26">It was recently shown that query variations automatically selected from a query log of a commercial search engine can be, on average, as effective as human curated query variations [26].</s>
		</context>
		<context id="06" section="related work">
			<s cites="3,4,5,6,7,34,10,6">The merits of applying fusion to document lists retrieved for queries representing the same information need is now well understood [3–7, 34]; reciprocal rank fusion (RRF) [10] consistently yields state-of-the-art performance in this setting [6].</s>
			<s>Our best performing methods outperform this fusion approach.</s>
			<s>Furthermore, some of our suggested retrieval templates apply RRF before or after cluster-based re-ranking is applied to document lists retrieved for multiple queries.</s>
			<s>We note that reciprocal rank fusion is an unsupervised fusion method.</s>
			<s cites="38">One could potentially further improve the performance of our methods that utilize fusion of document lists by using supervised fusion (e.g., [38]).</s>
			<s>We leave this exploration for future work.</s>
		</context>
		<context id="07" section="related work">
			<s cites="47">It was recently shown that the relative prediction quality posted by various query performance predictors can significantly vary when varying the effectiveness of a query used to represent an information need [47].</s>
			<s>In a conceptually similar vein, we show that state-of-the-art cluster-based document retrieval methods can actually be outperformed by standard bag-of-words document retrieval models if highly effective queries are used to represent information needs.</s>
		</context>
		<context id="08" section="related work">
			<s cites="7">There was work on improving search efficiency when using multiple queries by clustering queries offline [7].</s>
			<s>In contrast, we use document clusters created at query time.</s>
		</context>
		<context id="09" section="related work">
			<s cites="13,15,17,36,40,44,12,20,28,36,43,11,17,19,20,21,22,23,28,29,30,32,33,35,43,44,45">Work on (i) studying the cluster hypothesis [13, 15, 17, 36, 40, 44], (ii) analyzing optimal document clusters [12, 20, 28, 36, 43], and (iii) devising cluster-based document retrieval methods (e.g., [11, 17, 19–23, 28–30, 32, 33, 35, 43–45]) was confined to the standard setting of using a single query to represent an information need.</s>
			<s>We address these tasks where multiple queries representing the same information need are available.</s>
		</context>
		<context id="10" section="related work">
			<s cites="18">Clusters of documents in lists retrieved by applying different retrieval approaches for a single query were used to fuse the lists [18].</s>
			<s>This fusion approach can be easily instantiated from one of the retrieval templates we present for retrieval using multiple queries.</s>
			<s>While the resultant performance is effective, we present much more effective cluster-based approaches for utilizing multiple queries.</s>
		</context>
		<context id="10" section="related work">
			<s cites="35">Cluster-based document retrieval methods can also be used to improve search results diversification [35].</s>
			<s cites="25">Integrating fusion of ranked lists and topic modeling was also shown to be effective in improving diversification [25].</s>
			<s>Diversification of search results is outside the scope of this paper.</s>
		</context>
	</contexts>
	<references>
		<reference id="1">10.1145/2983323.2983739</reference>
		<reference id="2">10.1145/2911451.2914671</reference>
		<reference id="3">10.1145/3077136.3080839</reference>
		<reference id="4">10.1145/160688.160760</reference>
		<reference id="5">10.1016/0306-4573(94)00057-A</reference>
		<reference id="6">10.1145/3166072.3166084</reference>
		<reference id="7">10.1145/3345001</reference>
		<reference id="8">10.1145/3331184.3331297</reference>
		<reference id="9">http://www.cs.cmu.edu/~pbennett/papers/trec-2013-proceedings-overview-final.pdf</reference>
		<reference id="10">10.1145/1571941.1572114</reference>
		<reference id="11">10.1016/0306-4379(80)90010-1</reference>
		<reference id="12">10.1145/133160.133214</reference>
		<reference id="13">10.1177/016555158701300607</reference>
		<reference id="14">10.1093/comjnl/32.3.220</reference>
		<reference id="15">10.1007/s10791-011-9173-9</reference>
		<reference id="16">10.1145/2766462.2767877</reference>
		<reference id="17">10.1016/0020-0271(71)90051-9</reference>
		<reference id="18">10.1145/2009916.2010035</reference>
		<reference id="19">10.1007/s10791-008-9065-9</reference>
		<reference id="20">10.1145/1390334.1390428</reference>
		<reference id="21">10.5555/2051237.2051248</reference>
		<reference id="22">10.1145/1008992.1009027</reference>
		<reference id="23">10.1145/1148170.1148188</reference>
		<reference id="24">10.1145/383952.383970</reference>
		<reference id="25">10.1145/2600428.2609561</reference>
		<reference id="26">10.1145/3341981.3344223</reference>
		<reference id="27">10.1145/1008992.1009026</reference>
		<reference id="28">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.366.7984&amp;rep=rep1&amp;type=pdf</reference>
		<reference id="29">10.1145/1148170.1148310</reference>
		<reference id="30">10.5555/1793274.1793330</reference>
		<reference id="31">10.1145/3341981.3344224</reference>
		<reference id="32">10.5555/1793274.1793362</reference>
		<reference id="33">10.1016/j.ipm.2006.07.003</reference>
		<reference id="34">10.1145/1390334.1390389</reference>
		<reference id="35">10.1145/2484028.2484042</reference>
		<reference id="36">10.1145/2600428.2609533</reference>
		<reference id="37">10.1145/1835449.1835493</reference>
		<reference id="38">10.1145/1935826.1935930</reference>
		<reference id="39">10.1145/312624.312645</reference>
		<reference id="40">10.1007/978-3-642-04417-5_27</reference>
		<reference id="41">10.1145/319950.320022</reference>
		<reference id="42">10.1145/3166072.3166079-17</reference>
		<reference id="43">10.1016/S0306-4573(01)00048-6</reference>
		<reference id="44">10.1145/253495.253524</reference>
		<reference id="45">10.1145/1183614.1183713</reference>
		<reference id="46">10.1016/S1389-1286(99)00054-7</reference>
		<reference id="47">10.1145/3331184.3331253</reference>
		<reference id="48">10.1145/383952.384019</reference>
	</references>
</doc>