<doc>
	<doi>10.1145/3409256.3409817</doi>
	<title>Analysing the Effect of Clarifying Questions on Document Ranking in Conversational Search</title>
	<abstract>Recent research on conversational search highlights the importance of mixed-initiative in conversations. To enable mixed-initiative, the system should be able to ask clarifying questions to the user. However, the ability of the underlying ranking models (which support conversational search) to account for these clarifying questions and answers has not been analysed when ranking documents, at large. To this end, we analyse the performance of a lexical ranking model on a conversational search dataset with clarifying questions. We investigate, both quantitatively and qualitatively, how different aspects of clarifying questions and user answers affect the quality of ranking. We argue that there needs to be some fine-grained treatment of the entire conversational round of clarification, based on the explicit feedback which is present in such mixed-initiative settings. Informed by our findings, we introduce a simple heuristic-based lexical baseline, that significantly outperforms the existing naive baselines. Our work aims to enhance our understanding of the challenges present in this particular task and inform the design of more appropriate conversational ranking models.</abstract>
	<contexts>
		<context id="01" section="introduction">
			<s>The rise of voice-based digital assistants such as Amazon Alexa and Google Assistant, has intensified the need for agents that can hold meaningful conversations with users.</s>
			<s cites="3,4">Towards this direction, researchers have developed conversational systems that support question-answering and task-oriented dialogue, among others [3, 4].</s>
			<s>However, it is often the case that in such information-seeking conversations, users fail to express their information need adequately.</s>
			<s cites="6,8">This makes the ability of a conversational search system to support mixed-initiative interactions imperative [6, 8].</s>
			<s cites="8,1">Such a system can assist users to refine their information need, i.e., by disclosing new information to them [8], or posing clarifying questions [1].</s>
		</context>
		<context id="02" section="introduction">
			<s cites="1,2,6,9">Clarifying questions trigger users' explicit feedback in the form of an answer, and have been shown to improve user experience [1, 2, 6, 9].</s>
			<s cites="1">In Figure 1, we demonstrate examples of clarification-based conversations appearing in the conversational search dataset Qulac [1].</s>
			<s>Specifically, we plot the most frequent user responses (4âˆ’grams) to clarifying questions.</s>
			<s>Responses can be read starting from the circle centre (START) and moving outwards (e.g., "no I am looking...").</s>
			<s>We observe that user responses often start with a "yes" or a "no", but frequently provide additional information (e.g., "No, I want...").</s>
			<s>We hypothesise that this explicit feedback can be used to improve ranking, even when the question asked ranges from being partially relevant to completely irrelevant w.r.t. the information need.</s>
		</context>
		<context id="03" section="introduction">
			<s>In this paper, we study the effect of the user's feedback in mixed-initiative conversations.</s>
			<s>We categorise answers w.r.t. their polarity and length. Answer polarity indicates whether the question points to a relevant direction or not, while answer length enables us to (noisily) identify the presence of additional information in the response.</s>
			<s cites="1,7">We conduct our analysis on the Qulac dataset [1], using a query likelihood model chosen because of its simplicity and transparency [7].</s>
		</context>
	</contexts>
	<references>
		<reference id="1">10.1145/3331184.3331265</reference>
		<reference id="2">10.1145/3020165.3022149</reference>
		<reference id="3">10.18653/v1/D18-1547</reference>
		<reference id="4">10.18653/v1/D18-1241</reference>
		<reference id="5">10.1145/3397271.3401061</reference>
		<reference id="6">10.1145/3209978.3210160</reference>
		<reference id="7">10.1145/290941.291008</reference>
		<reference id="8">10.1145/3020165.3020183</reference>
		<reference id="9">10.1145/3397271.3401160</reference>
	</references>
</doc>