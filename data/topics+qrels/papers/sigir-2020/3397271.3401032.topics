<top>
<num> Number: 340103201
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
Recommendations are part of everyday life. Be they made by a person, or by an automated system, the recommendations are often accompanied with an explanation, or reason, underlying the suggestions provided. Explanations are known to strongly impact how the recipient of a recommendation responds [13, 14, 23, 28], yet the effect is still not well understood.

<narr> Narrative:

</top>

<top>
<num> Number: 340103202
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
Most previous studies on generating explanations optimize a single goal [20], and only a handful consider multiple goals [8, 13, 26]. Yet, depending on the perspective of the explanation generator, different goals may be appropriate, and may need to be traded off.


<narr> Narrative:

</top>

<top>
<num> Number: 340103203
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
The ability for an artificially intelligent system to explain recommendations has been shown to be an important factor for user acceptance and satisfaction [13, 14, 23, 28]. Explanations can be characterized along a number of dimensions, including their content, form of presentation, and system’s intended purpose [20]. Our interest is in the latter category, where we use the term goal to refer to the objective or purpose of the explanation. Specifically, our focus is on natural language explanations, the most commonly used way of presentation both historically [20] and recently [2, 6, 19].

<narr> Narrative:

</top>

<top>
<num> Number: 340103204
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
For example, in [20] satisfaction is not considered as a single objective, but is split into ease to use, enjoyment, and usefulness. Nonetheless, these seven goals are regarded as the canonical categorization within explainability research for recommender systems, accurately reflecting the goals that have been studied in the past. Certain goals may be measured objectively and quantitatively. For example, effectiveness may be measured as the change of a user’s rating of (or reported interest in) an item before and after consuming that item [3, 6], efficiency may be measured by time spent on rating an item [13] or reading an explanation [6], and persuasiveness may be measured in terms of click through rate [30].

<narr> Narrative:

</top>

<top>
<num> Number: 340103205
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
Concerning the relationship between the two, one previous study indicates that transparency increases user trust [23], while another study finds that transparency and trust are not related [8]. The second most frequent explanation purpose is effectiveness [20], which can be conflicting with persuasiveness [7].

<narr> Narrative:

</top>

<top>
<num> Number: 340103206
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
There is an important recognized difference between explanations (why a certain suggestion is given) and justifications (why the user may be interested in the item) [19, 27]. The former consist of an honest account of the mechanism that generated the suggestion, while the latter provides a plausible reason, which may be decoupled from the underlying recommendation algorithm.

<narr> Narrative:

</top>

<top>
<num> Number: 340103207
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
Justifications have in the past been created manually using crowdsourcing [6]. A main difference between that and ours, is that we ask humans to pick the recommendation as well as explain it, while [6] perform only the latter.

<narr> Narrative:

</top>

<top>
<num> Number: 340103208
<title> Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations

<desc> Description:
Subjective perceptions of explanations are often evaluated qualitatively based on user surveys, with responses typically given on Likert scales [6, 8, 10, 17, 21–23]. Following standard practice, we design a user survey to capture the subjective perception of users regarding the seven goals.

<narr> Narrative:

</top>
