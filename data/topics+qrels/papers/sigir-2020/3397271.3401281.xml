<doc>
	<doi>10.1145/3397271.3401281</doi>
	<title>How Useful are Reviews for Recommendation? A Critical Review and Potential Improvements</title>
	<abstract>We investigate a growing body of work that seeks to improve recommender systems through the use of review text. Generally, these papers argue that since reviews 'explain' users' opinions, they ought to be useful to infer the underlying dimensions that predict ratings or purchases. Schemes to incorporate reviews range from simple regularizers to neural network approaches. Our initial findings reveal several discrepancies in reported results, partly due to (e.g.) copying results across papers despite changes in experimental settings or data pre-processing. First, we attempt a comprehensive analysis to resolve these ambiguities. Further investigation calls for discussion on a much larger problem about the "importance" of user reviews for recommendation. Through a wide range of experiments, we observe several cases where state-of-the-art methods fail to outperform existing baselines, especially as we deviate from a few narrowly-defined settings where reviews are useful. We conclude by providing hypotheses for our observations, that seek to characterize under what conditions reviews are likely to be helpful. Through this work, we aim to evaluate the direction in which the field is progressing and encourage robust empirical evaluation.</abstract>
	<contexts>
		<context id="01" section="introduction">
			<s>Previously, there largely have been two schools of thought regarding employing user reviews for better recommendation.</s>
			<s>The first type considers reviews as “explanations" for the user giving that specific rating and tries to incorporate them into matrix factorization (MF).</s>
			<s cites="9,1">HFT [9] is such a model which tries to regularize the latent features being learned through MF by reusing the same latent features for modeling the reviews’ likelihood using LDA [1].</s>
			<s>The other type of methods are based on the philosophy that textual reviews are much more expressive than a single rating, and can be used to learn better latent features to perform better MF.</s>
			<s cites="2,3,11,13,7">[2, 3, 11, 13] are all popular methods which, in some different way, try to extract features from user reviews and item reviews through deep learning architectures like TextCNN [7], and use these extracted features to perform MF.</s>
			<s>All the methods used for analysis in this paper are discussed in more detail in Section 2.2.</s>
		</context>
		<context id="02" section="introduction">
			<s cites="4">Our work also connects to recent discussions [4] on the reproducibility of recent neural methods for recommendation.</s>
			<s cites="4">Note that the topic of this paper is different from [4] since, in addition to the correctness of recent works, we also deal with a more general meta-question about the utility of reviews for recommendation.</s>
		</context>
	</contexts>
	<references>
		<reference id="1">10.5555/944919.944937</reference>
		<reference id="2">10.1145/3109859.3109878</reference>
		<reference id="3">10.1145/3178876.3186070</reference>
		<reference id="4">10.1145/3298689.3347058</reference>
		<reference id="5">10.1145/2872427.2883037</reference>
		<reference id="6">10.1145/3038912.3052569</reference>
		<reference id="7">10.3115/v1/D14-1181</reference>
		<reference id="8">10.1109/MC.2009.263</reference>
		<reference id="9">10.1145/2507157.2507163</reference>
		<reference id="10">10.1109/ICDM.2012.110</reference>
		<reference id="11">10.1145/3219819.3220086</reference>
		<reference id="12">10.1145/3240323.3240369</reference>
		<reference id="13">10.1145/3018661.3018665</reference>
	</references>
</doc>