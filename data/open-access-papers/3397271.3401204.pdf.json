{
  "name" : "3397271.3401204.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Context-Aware TermWeighting For First Stage Passage Retrieval",
    "authors" : [ "Zhuyun Dai", "Jamie Callan" ],
    "emails" : [ "zhuyund@cs.cmu.edu", "callan@cs.cmu.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "KEYWORDS Deep Retrieval, Document Understanding, Term Weighting\nACM Reference Format: Zhuyun Dai and Jamie Callan. 2020. Context-Aware Term Weighting For First Stage Passage Retrieval . In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’20), July 25–30, 2020, Virtual Event, China. ACM, New York, NY, USA, 4 pages. https://doi.org/10.1145/3397271.3401204"
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "State-of-the-art search engines use ranking pipelines in which an efficient first stage uses a query to fetch an initial set of documents, and one or more re-ranking algorithms to improve and prune the ranking. Typically the first stage ranker is bag-of-words retrieval model that use term frequency (tf ) to determine the documentspecific importance of terms. However, tf does not necessarily indicate whether a term essential to the meaning of the document, especially when the frequency distribution is flat, e.g., passages. In essence, tf ignores the interactions between a term and its text context, which is key to estimating document-specific term weights.\nThis paper seeks to improve term importance estimation in firststage retrieval models by using deep language models like BERT [3] to capture a term’s contextual features. We present the Deep Contextualized Term Weighting framework (DeepCT). DeepCT learns a contextualized term representation model based on BERT, and a mapping function from representations to term weights. The transformer encoder of BERT allows DeepCT to capture semantic and syntactic features from a term’s linguistic context, helping DeepCT to identify semantically important terms from the text. DeepCT\nSIGIR ’20, July 25–30, 2020, Virtual Event, China © 2020 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-8016-4/20/07. https://doi.org/10.1145/3397271.3401204\ngenerates deep, context-aware document-specific term weights that can replace the standard tf.\nThis paper also present a novel approach that runs DeepCT at offline index time, making it possible to use it in first-stage retrieval where efficiency is crucial. Our approach applies DeepCT over each passage in the corpus, and stores the context-aware term weights in an ordinary inverted index to replace tf. The index can be searched efficiently using common bag-of-words retrieval models such as BM25 or statistical query likelihood models.\nExperiments demonstrate that DeepCT significantly improves the accuracy of first-stage retrieval. More accurate first-stage document rankings also provide better candidates for downstream reranking, and improves end-to-end accuracy and/or efficiency. Analysis shows that DeepCT’s main advantage is the ability to differentiate between key terms and other frequent but non-central terms. Code and data are made public available 1."
    }, {
      "heading" : "2 RELATED WORK",
      "text" : "Document Term Weighting. Most first-stage retrieval models such as BM25 and query likelihood use term frequencies (tf ) to term importance in a document. A popular alternative to tf are graphbased methods, e.g., TextRank [6]. A few recent work investigated using word embeddings [5] for document term weighting, but most of them only learn a global idf -like term weight because the word embeddings are context-independent. Our work aims to learn tf - like term weights that are context-specific.\nNeural Approaches for First Stage Ranking. Most neural ranking models are cost-prohibitive to be used in the first stage [1, 2, 10]. Recent research addresses this efficiency problem in two ways. One way is to learn latent embedding representations of queries and documents [13]. However, fix-dimension representations introduce the specificity vs. exhaustiveness trade-off [14]. Another approach modifies the bag-of-words document representations using neural network. Mitra et al. [8] uses neural rankers to generate term-document scores, but it is time-consuming when applied at a large-scale. Nogueira et al. [11] proposed to generate queries from documents using neural machine translation and index queries as document expansion terms [11, 12]. Our work are orthogonal to [11, 12] – their approaches add terms to documents, while our method weights existing terms; future work may consider combining the two approaches."
    }, {
      "heading" : "3 DeepCT",
      "text" : "DeepCT Framework DeepCT leverages the transformer encoder of BERT to extract a word’s contextual features. In the transformer, a term gradually absorbs contextual information based on its attention to every other term in the same text. At the last layer, the transformer generates a contextualized term embedding for every\n1https://github.com/AdeDZY/DeepCT\nThis work is licensed under a Creative Commons Attribution International 4.0 License.\nterm in the input text, which can be viewed as a feature vector that characterizes the term’s syntactic and semantic role in a given context.\nDeepCT then linearly combines a term’s contextualized embedding into a term importance score:\nŷt ,d = ®wTt ,d + b (1)\nwhere Tt ,d is term t ’s contextualized embedding in text d ; and, ®w and b are the linear combination weights and bias.\nTrain DeepCT DeepCT is trained end-to-end using a per-token regression task. Given the ground truth term weight for every word in text d , denoted as {y1,d , . . . ,yn,d }, DeepCT aims to minimize the mean square error (MSE) between the predicted weights ŷ and the ground truth weights y:\nlossMSE = ∑ d ∑ t (yt ,d − ŷt ,d )2. (2)\nIt is an open question how to obtain the ground truth term weights y. As search queries can reflect the key idea of a document, we propose query term recall as an estimation of the ground truth term weights:\nyt ,d = QTR(t,d) = |Qd ,t | |Qd | . (3)\nQd is the set of queries for which passage d is judged relevant.Qd ,t is the subset of Qd that contains term t . In other words, QTR(t,d) is the percentage of d’s queries that mention term t .\nIndex with DeepCT The queries are only used to generate training labels. During testing, the model is query-independent – the prediction is solely based on the document content. This allows estimated term weights to be calculated and stored during offline indexing.\nWe run the trained DeepCT model over all passages in the collection. Most predictions fall into 0-1 (because the ground truth weights are in 0-1, as shown in Eq.3). The predicted weights are then scaled into an integer that can be used with existing retrieval models. We call the scaled weight tfDeepCT to convey that it is an alternate way of representing the importance of term t in d :\ntfDeepCT(t,d) = round(ŷt ,d ∗ N ). (4)\nN scales the predicted weights into a integer range. We use N = 100 in this work as two digits of precision is sufficient for this task. Terms with negative weights are discarded.\ntfDeepCT is used to replace the original tf in the inverted index. The new index, DeepCT-Index, can be searched by mainstream bag-of-words retrieval model like BM25 or query likelihood model. The context-aware term weight tfDeepCT is expect to bias the retrieval models to central terms in the pasessag, preventing off-topic passages being retrieved.\nEfficiency The main difference between DeepCT-Index and a typical inverted index is that the term weight is based on tfDeepCT instead of tf. This calculation is done offline. No new posting lists are created, thus the query latency does not become longer. To the contrary, a side-effect of Eq 4 is that tfDeepCT of some terms becomes negative, which may be viewed as a form of index pruning. We leave that aspect of this work for future investigation."
    }, {
      "heading" : "4 EXPERIMENTAL METHODOLOGY",
      "text" : "Datasets used MSMARCO [9] and TREC-CAR [4].MSMARCO is a passage retrieval dataset with 8.8M passages [9]. The training set contains approximately 0.5M pairs of queries and relevant passages. The development (dev) set contains 6,980 queries and their relevance labels. The test set contains 6,900 queries, but the relevance labels are hidden byMicrosoft. Therefore, the dev set is our main evaluation set. In a few experiments, we also evaluated on the test set by submitting our rankings to the MS MARCO competition. TRECCAR [4] consists of 29.7M English Wikipedia passages. Following prior work [10, 11], we use the automatic relevance judgments. The training set have 3.3M query-passage pairs. The test set contains 1,860 queries.\nFirst-Stage Retrieval Baselines. We compare DeepCT term weights with three popular term weighting methods used in firststage retrieval.\n• tf uses standard term frequency weights, e.g., as used by BM25. • TextRank [6] is a widely-used graph-based term weighting approach. We use the open source PyTextRank implementation2. Term weights from TextRank are in the range (0, 1); we scale them to integers as described in Eq. 4 for indexing. • Doc2Query [11] is a supervised baseline. It trains a neural sequence-to-sequence model to generate potential queries from passages, and indexes the queries as document expansion terms. We use the Doc2Query MS MARCO index released by the authors. No such index is available for TRECCAR, so we use published values for that dataset [11].\nWe used the Anserini toolkit to index documents using the above three term weights as well as the proposed DeepCT term weights. First-stage ranking was done by two popular retrieval models: BM25 and query likelihood with Jelinek-Mercer smoothing (QL). We finetuned BM25 parameters k1 andb, and QL smoothing factor λ through a parameter sweep on 500 queries from the training set.\nThe transformer of DeepCTwas initializedwith pre-trained BERT parameters. For MS MARCO, we used the official pre-trained BERT (uncased, base model) [3]. For TREC-CAR, we follow Nogueira and Cho [10] and used a pre-trained BERT model released by the authors. DeepCT was trained for 3 epochs on the training split of our datasets, using a learning rate of 2e−5 and a max input text length of 128 tokens.\nEvaluation used MRR@10, the official MS MARCO evaluation metric. For TREC-CAR, we also reportMAP at depth 1,000 following the evaluation methodology used in previous work [10, 11]."
    }, {
      "heading" : "5 EXPERIMENTAL RESULTS",
      "text" : "Three experiments investigate DeepCT’s first-stage retrieval accuracy, its impacts on down-stream rerankers, and why DeepCT term weights are effective."
    }, {
      "heading" : "5.1 First-Stage Retrieval using DeepCT",
      "text" : "The first experiment examines whether DeepCT improves first-stage retrieval accuracy over baseline retrieval methods. It also compares DeepCT to several supervised rerankers.\n2https://github.com/DerwenAI/pytextrank\nComparison to First-stageRetrieval Baselines. Table 1 shows the first-stage retrieval accuracy of BM25 and QL using indexes generated by four methods. The TextRank index failed to beat the common tf index. The Doc2Query index was effective for MS MARCO, but only marginally better for TREC-CAR. On the other hand, DeepCT outperformed the baselines by large margins. It improved BM25 by 27% on MS MARCO and 46% on TREC-CAR. It produced similar gains for QL, showing that DeepCT is useful to different retrieval models. DeepCT-Index also surpassed Doc2Query by large margins, which also used deep neural networks and supervised training.\nIt is uncommon in prior research for a non-tf term weighting method to generate such substantially better rankings. These results show that tf is no longer sufficient, and that better term importance signals can be generated with deep document understanding.\nComparision to SupervisedRerankers.We further compared the single-stage DeepCT retrieval to several multi-stage reranking pipelines. Table 2 shows results from the MS MARCO leaderboard4. It lists representative reranking approaches for featurebased learning-to-rank, previous state-of-the-art neural rerankers (non-ensemble versions), and BERT-based rerankers. All rerankers used the top 1,000 passages from BM25.\nA single-stage BM25 retrieval from DeepCT-Index was better than several reranking pipelines. It is more accurate than featurebased LeToR, a widely used reranking approach in modern search engines. It is also more accurate than a popular neural reranking\n3Statistical significance is unknown because the MS MARCO website publishes only summary results. 4http://www.msmarco.org/leaders.aspx\nmodel K-NRM [15]. Compared to Duet V2 (the official reranking baseline) and Conv-KNRM [2], DeepCT achieves similar accuracy while being more efficient as it does not need the reranking stage. The results demonstrate that it is possible to move some of the complex ranking process to offline analysis, building deep yet simple text representations that can be retrieved very efficiently.\nFinally, strong neural rerankers like the BERT reranker were much more effective than DeepCT BM25. The next section studies whether the two approaches can be used together.\n5.2 Combine DeepCT with Rerankers This experiment examines whether a first-stage ranking produced by DeepCT BM25 can be used together with later-stage rerankers to improve end-to-end performance. Table 3 reports the performance of two rerankers applied to candidate passages retrieved from the standard tf and the DeepCT index. The two rerankers were Conv-KNRM [2], which has medium accuracy, and BERT ReRanker [10], which has high accuracy. We tested various reranking depths. Reranking at a shallower depth has higher efficiency but may miss more relevant passages.\nThe recall values show the percentage of relevant passages in the reranking passage set. DeepCT had higher recall at all depths, meaning a ranking from DeepCT provided more relevant passages to a reranker. Both rerankers consistently achieved higher MRR@10 by using DeepCT compared to using tf. For Conv-KNRM, the best\n4We did not run this experiment on MS MARCO test set because test set results can only be evaluated by submitting to the MS MARCO competition. The organizers discourage too many submission from the same group to avoid \"P-hacking\".\nMRR@10 improved from 0.256 to 0.278, and the required reranking depth decreased from 100 to 50. For BERT ReRanker, DeepCT enabled it to achieve similar accuracy using much fewer passages. Reranking the top 100-200 passages from DeepCT produced similar MRR@10 as reranking the top 1,000 passages from tf index, meaning that the reranker can be 5-10× more efficient.\nIn summary, DeepCT puts relevant passages at the top, so that downstream rerankers can achieve similar or higher accuracy with much smaller candidate sets, leading to lower computational cost in the retrieval pipeline."
    }, {
      "heading" : "5.3 Sources of Effectiveness",
      "text" : "The last experiment aims to understand the sources of effectiveness of DeepCT-Index through several analyses.\nTable 4 visualizes DeepCTweights. It shows that DeepCT is able to emphasize central terms and suppress non-central terms. Non-central terms are assigned with low weight even they are frequent. For example, in the off-topic passage, “DNA” has low DeepCT weight even though it is mentioned 3 times. On the other hand, “Genomics” has higher weight even though is is mentioned fewer times. This extent of independence from frequency signals is uncommon in previous term weighting approaches.\nFigure 1 compares the termweight distribution of DeepCT-Index and tf index.The original tf distribution is flat. DeepCT-Index assigns high weights to a few central terms, resulting in a skewed term weight distribution. Such skewed distribution confirms our observations from the case study that DeepCT-Index aggressively emphasizes a few central terms and supresses the others."
    }, {
      "heading" : "6 CONCLUSION",
      "text" : "Most first-stage rankers are efficient bag-of-words retrieval models that use term frequency signals. This paper presents DeepCT, a deep learning approach that better estimates term importance for first stage retrieval. DeepCT uses the transformer encoder of BERT to capture contextual features of words, and maps the features into document-specific term weights. Trained on a supervised per-token regression task, DeepCT is capable of producing context-aware term weights that reflect the essential meanings of the document. Importantly, DeepCT moves the neural document processing to the offline indexing time – the term weights can be stored in a typical inverted index and used with efficient retrieval models such as BM25.\nExperimental results show that DeepCT improves the accuracy of popular first-stage retrieval algorithms by up to 40%. Running BM25 on DeepCT-Index can be as effective as several previous state-ofthe-art rankers that need to run slow deep learning models at the query time. The higher-quality ranking enabled by DeepCT-Index improves the accuracy/efficiency tradeoff for later-stage re-rankers. Analysis shows that DeepCT is capable of finding the central words in a text even if they are mentioned only once. We view DeepCT as an encouraging step from “frequencies” to “ meanings”.\nFor several decades, first-stage retrieval models have relied on term frequency signals (tf ). Results from this paper indicate that tf is no longer sufficient. With recent advances in deep learning and NLP, it is time to revisit the indexers and retrieval models, towards building new deep and efficient first stage rankers.\nAcknowledgments. This work was supported by the National Science Foundation (NSF) grant IIS-1815528."
    } ],
    "references" : [ {
      "title" : "Deeper Text Understanding for IR with Contextual Neural Language Modeling",
      "author" : [ "Zhuyun Dai", "Jamie Callan" ],
      "venue" : "In Proc. SIGIR",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2019
    }, {
      "title" : "Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search",
      "author" : [ "Zhuyun Dai", "Chenyan Xiong", "Jamie Callan", "Zhiyuan Liu" ],
      "venue" : "In Proc. WSDM",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2018
    }, {
      "title" : "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova" ],
      "venue" : "In Proc. ACL",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2019
    }, {
      "title" : "TREC complex answer retrieval overview",
      "author" : [ "Laura Dietz", "Manisha Verma", "Filip Radlinski", "Nick Craswell" ],
      "venue" : "In Proc. TREC",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2017
    }, {
      "title" : "A Deep Relevance Matching Model for Ad-hoc Retrieval",
      "author" : [ "Jiafeng Guo", "Yixing Fan", "Qingyao Ai", "andW. Bruce Croft" ],
      "venue" : "In Proc. CIKM",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2016
    }, {
      "title" : "Textrank: Bringing order into text",
      "author" : [ "Rada Mihalcea", "Paul Tarau" ],
      "venue" : "In Proc. EMNLP",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2004
    }, {
      "title" : "An Updated Duet Model for Passage Re-ranking",
      "author" : [ "Bhaskar Mitra", "Nick Craswell" ],
      "venue" : "arXiv preprint arXiv:1903.07666",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2019
    }, {
      "title" : "Incorporating Query Term Independence Assumption for Efficient Retrieval and Ranking using Deep Neural Networks",
      "author" : [ "Bhaskar Mitra", "Corby Rosset", "David Hawking", "Nick Craswell", "Fernando Diaz", "Emine Yilmaz" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2019
    }, {
      "title" : "2016. MS MARCO: A human generated machine reading comprehension",
      "author" : [ "Tri Nguyen", "Mir Rosenberg", "Xia Song", "Jianfeng Gao", "Saurabh Tiwary", "Rangan Majumder", "Li Deng" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2016
    }, {
      "title" : "Passage Re-ranking with BERT",
      "author" : [ "Rodrigo Nogueira", "Kyunghyun Cho" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2019
    }, {
      "title" : "Document Expansion by Query Prediction",
      "author" : [ "Rodrigo Nogueira", "Kyunghyun Cho", "Yang Wei", "Lin Jimmy" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2019
    }, {
      "title" : "Introduction to Modern Information Retrieval",
      "author" : [ "Gerard Salton", "Michael McGill" ],
      "venue" : null,
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1984
    }, {
      "title" : "End-to-End Neural Ad-hoc Ranking with Kernel Pooling",
      "author" : [ "Chenyan Xiong", "Zhuyun Dai", "Jamie Callan", "Zhiyuan Liu", "Russell Power" ],
      "venue" : "In Proc. SIGIR. Short Research Papers I SIGIR",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2017
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "This paper seeks to improve term importance estimation in firststage retrieval models by using deep language models like BERT [3] to capture a term’s contextual features.",
      "startOffset" : 126,
      "endOffset" : 129
    }, {
      "referenceID" : 4,
      "context" : "A few recent work investigated using word embeddings [5] for document term weighting, but most of them only learn a global idf -like term weight because the word embeddings are context-independent.",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 0,
      "context" : "Most neural ranking models are cost-prohibitive to be used in the first stage [1, 2, 10].",
      "startOffset" : 78,
      "endOffset" : 88
    }, {
      "referenceID" : 1,
      "context" : "Most neural ranking models are cost-prohibitive to be used in the first stage [1, 2, 10].",
      "startOffset" : 78,
      "endOffset" : 88
    }, {
      "referenceID" : 9,
      "context" : "Most neural ranking models are cost-prohibitive to be used in the first stage [1, 2, 10].",
      "startOffset" : 78,
      "endOffset" : 88
    }, {
      "referenceID" : 7,
      "context" : "[8] uses neural rankers to generate term-document scores, but it is time-consuming when applied at a large-scale.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 10,
      "context" : "[11] proposed to generate queries from documents using neural machine translation and index queries as document expansion terms [11, 12].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[11] proposed to generate queries from documents using neural machine translation and index queries as document expansion terms [11, 12].",
      "startOffset" : 128,
      "endOffset" : 136
    }, {
      "referenceID" : 10,
      "context" : "Our work are orthogonal to [11, 12] – their approaches add terms to documents, while our method weights existing terms; future work may consider combining the two approaches.",
      "startOffset" : 27,
      "endOffset" : 35
    }, {
      "referenceID" : 8,
      "context" : "Datasets used MSMARCO [9] and TREC-CAR [4].",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 3,
      "context" : "Datasets used MSMARCO [9] and TREC-CAR [4].",
      "startOffset" : 39,
      "endOffset" : 42
    }, {
      "referenceID" : 9,
      "context" : "Following prior work [10, 11], we use the automatic relevance judgments.",
      "startOffset" : 21,
      "endOffset" : 29
    }, {
      "referenceID" : 10,
      "context" : "Following prior work [10, 11], we use the automatic relevance judgments.",
      "startOffset" : 21,
      "endOffset" : 29
    }, {
      "referenceID" : 5,
      "context" : "• TextRank [6] is a widely-used graph-based term weighting approach.",
      "startOffset" : 11,
      "endOffset" : 14
    }, {
      "referenceID" : 10,
      "context" : "• Doc2Query [11] is a supervised baseline.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 10,
      "context" : "No such index is available for TRECCAR, so we use published values for that dataset [11].",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 2,
      "context" : "For MS MARCO, we used the official pre-trained BERT (uncased, base model) [3].",
      "startOffset" : 74,
      "endOffset" : 77
    }, {
      "referenceID" : 9,
      "context" : "For TREC-CAR, we follow Nogueira and Cho [10] and used a pre-trained BERT model released by the authors.",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 9,
      "context" : "For TREC-CAR, we also reportMAP at depth 1,000 following the evaluation methodology used in previous work [10, 11].",
      "startOffset" : 106,
      "endOffset" : 114
    }, {
      "referenceID" : 10,
      "context" : "For TREC-CAR, we also reportMAP at depth 1,000 following the evaluation methodology used in previous work [10, 11].",
      "startOffset" : 106,
      "endOffset" : 114
    }, {
      "referenceID" : 1,
      "context" : "Compared to Duet V2 (the official reranking baseline) and Conv-KNRM [2], DeepCT achieves similar accuracy while being more efficient as it does not need the reranking stage.",
      "startOffset" : 68,
      "endOffset" : 71
    }, {
      "referenceID" : 1,
      "context" : "The two rerankers were Conv-KNRM [2], which has medium accuracy, and BERT ReRanker [10], which has high accuracy.",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 9,
      "context" : "The two rerankers were Conv-KNRM [2], which has medium accuracy, and BERT ReRanker [10], which has high accuracy.",
      "startOffset" : 83,
      "endOffset" : 87
    } ],
    "year" : 2020,
    "abstractText" : "Term frequency is a commonmethod for identifying the importance of a term in a document. But term frequency ignores how a term interacts with its text context, which is key to estimating documentspecific term weights. This paper proposes a Deep Contextualized Term Weighting framework (DeepCT) that maps the contextualized term representations fromBERT to into context-aware termweights for passage retrieval. The new, deep term weights can be stored in an ordinary inverted index for efficient retrieval. Experiments on two datasets demonstrate that DeepCT greatly improves the accuracy of first-stage passage retrieval algorithms.",
    "creator" : "LaTeX with hyperref"
  }
}