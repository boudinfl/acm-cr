{
  "name" : "3397271.3401052.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Query Rewriting for Voice Shopping NullQueries",
    "authors" : [ "Iftah Gamzu", "Marina Haikin", "Nissim Halabi" ],
    "emails" : [ "iftah@amazon.com", "mhaikin@amazon.com", "nissimh@amazon.com", "permissions@acm.org." ],
    "sections" : [ {
      "heading" : null,
      "text" : "Voice shopping using natural language introduces new challenges related to customer queries, like handling mispronounced, misexpressed, and misunderstood queries. Voice null queries, which result in no offers, have negative impact on customers shopping experience. Query rewriting (QR) attempts to automatically replace null queries with alternatives that lead to relevant results. We present a new approach for pre-retrieval QR of voice shopping null queries. Our proposed QR framework first generates alternative queries using a search index-based approach that targets different potential failures in voice queries. Then, a machine-learning component ranks these alternatives, and the original query is amended by the selected alternative. We provide an experimental evaluation of our approach based on data logs of a commercial voice assistant and an e-commerce website, demonstrating that it outperforms several baselines by more than 22%. Our evaluation also highlights an interesting phenomenon, showing that web shopping null queries are considerably different, and apparently easier to fix, than voice queries. This further substantiates the use of specialized mechanisms for the voice domain. We believe that our proposed framework, mapping tail queries to head queries, is of independent interest since it can be extended and applied to other domains.\nCCS CONCEPTS\n• Information systems → Information retrieval query processing.\nKEYWORDS\nquery rewriting, voice assistant, e-commerce search, null query, voice search\nACM Reference Format: Iftah Gamzu, Marina Haikin, and Nissim Halabi. 2020. Query Rewriting for Voice Shopping Null Queries. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’20), July 25–30, 2020, Virtual Event, China. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3397271.3401052"
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "In the past few years, speech has emerged has a natural mean for communicating information need to various search engines via\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR ’20, July 25–30, 2020, Virtual Event, China © 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-8016-4/20/07. . . $15.00 https://doi.org/10.1145/3397271.3401052\nvoice assistants such as Amazon Alexa, Apple Siri, and Google Assistant. Among various experiences, voice assistants enable customers to search and shop for products in an intuitive way using natural language. Providing a free-form shopping experience is a challenging task. This is especially true because the voice interface lacks assisting mechanisms, such as query completion and refinement, that can help customers easily express their need and iterate on it. As a consequence, a non-negligible portion of all voice shopping queries are null queries, that is, queries that result with no offers. Such interactions clearly have negative impact on customers shopping experience [40–42]. Query rewriting (QR) attempts to seamlessly replace null queries with alternatives that lead to relevant offers for the customer intent, and by that, help customers progress on their shopping journey.\nThe voice interface introduces technical and architectural challenges that are either unique or more emphasized compared to textual interfaces (e.g., web search). For example, the voice interface lacks assisting mechanisms that are common in the web, resulting in more shopping queries that contain erroneous attributes such as product brand, quantity, and others; While automatic speech recognition (ASR) and natural language understanding (NLU) techniques have made considerable progress in recent years (see, e.g., [27, 30, 36]), they still have failures that exhibit different patterns (e.g., phonetic) than common textual errors; Finally, customers fail in formulating a coherent spoken query in real-time, resulting in new types of speech imperfection errors such as stammered or misspronounced words. All these motivate the application of specialized mechanisms for the voice domain. Our contribution.We introduce a pre-retrieval QR approach designed to handle voice shopping null queries, as illustrated in Figure 1. In a pre-retrieval approach [11], QR happens without knowledge about the offers that return for the original query or any of the generated alternatives. This approach is more efficient than postretrieval methods, inducing less overhead to the search system. Upon receiving a transcribed query q, our QR framework applies a two step process of alternative queries generation and alternative queries ranking. As voice-user interface introduces a strong presentation bias towards the top-ranked offer [20], in most cases, only a single offer is communicated back to the customer. Therefore, practically, it is sufficient to identify a single “hero” alternative query to amend the customer query. The top-ranked alternative is passed along with the original query to a controller, which ensures the quality of the selected alternative. Specifically, the controller implements quality safeguards that prevent replacing the original query with an alternative query that is likely to retrieve irrelevant results to the intent of the original query. Then, the original query q is sent along with the selected alternative query r∗ for retrieving offers from the e-commerce search engine. If q turns to be a null\nquery with no offers, the customer is presented with the offers retrieved for r∗.\nOur alternative queries generation component is based on identifying web and voice shopping queries that frequently lead to positive events (e.g., purchases), and indexing them in a search engine. Those positive queries are indexed using various analyzers that target different potential failures in voice shopping (e.g., analyzers based on textual, n-grams, and phonetic similarities). Given a query, one can retrieve multiple alternatives from the index in hope that one of them can amend it, without the need to isolate the exact error. Conceptually, the core of our generation approach is by mapping tail (low frequency) queries to alternative head (high frequency) queries. The main motivation for this approach comes from the fact that head queries are known to exhibit much better performance than tail queries, due to richer historical behavioral features [23]. In fact, the distinction is even more extreme in voice due to the aforementioned strong presentation bias. In addition, Ingber et al. [20] recently observed that products purchased through voice are much more limited in terms of diversity, namely, products purchased on a regular basis such as groceries, and not niche long-tail products. This provides another motivation for our approach as positive head queries correspond well with commonly and regularly purchased products.\nThe alternative queries ranking component then ranks the alternatives that are more probable to fix the original query. This machine learning-based component utilizes multiple features (like textual and semantic similarities between the originating query and the alternatives, behavioral features, and more) to make its decisions. While our alternative queries generation component aims to improve the recall, the alternative queries ranking component is in charge of tuning the precision. For instance, in an e-commerce rewriting scenario, it is essential for the alternative queries to retrieve offers that capture the same intent as the originating query [41]. Rewriting that leads to offers that do not respect the desired product type are clearly poor. Our ranking approach considers features that help preserve the original customer’s intent (like, extracting the product type from queries), and by that, provides quality guarantees on the alternatives.\nConsider for example the following scenario, which demonstrates the ability to fix ASR errors outside the ASR system. A customer that is interested in purchasing “epilepsy bracelets” communicates her need to a voice assistant. Due to ambient noise, the ASR transcribed query results in “apple upci uhhh bracelets”, which turns to be a null query. However, “epilepsy bracelets” is a frequent positive query, and has the same phonetic representation, “APLPSPRSLTS”, as the transcribed query. Among the various alternatives,\nour QR framework selects “epilepsy bracelets”, which is retrieved by a phonetic analyzer, and a relevant offer is presented.\nWe provide an experimental evaluation for both voice and web null queries based on data logs of a commercial voice assistant and an e-commerce website. Our evaluation demonstrates that our voice query rewriting (VQR) approach outperforms several baselines by large margins. For instance, we show that VQR improves over the effectiveness of a simple textual similarity retrieval-based QR system by roughly 22% on voice data, and a term-dropping QR system by roughly 46% on web data. Although our focus is on voice QR, the improvements observed on web data, reaffirms the utility of our approach. In fact, we believe that our proposed framework is generic enough to be successfully applied in other domains beyond e-commerce. One notable highlight from our evaluation is that a term-dropping QR approach applied to a random set of web null queries attains much better performance than when it is employed to a random set of voice null queries (by roughly 56%). This indicates that web e-commerce null queries are considerably different than voice null queries, and apparently easier to fix. This observation adds to previous line of research identifying differentiating factors between the voice and web domains. For example, it was observed that voice queries are closer to natural language than text queries in general search [15], voice reformulations are distinguishable from textual reformulations [17, 22], and that shopping categories and behavioral patterns defer between voice and web e-commerce search [20]. In summary, we make the following key contributions:\n(1) We propose a new pre-retrieval QR framework for voice\nshopping null queries. Our approach maps tail queries to head queries, targets different potential failures in a voiceuser interface, and aims to maintain the customer’s intent. (2) We reveal interesting insights regarding differences between\nvoice and web null queries, establishing the need for specialized mechanisms treating the voice domain.\nThe rest of the paper is organized as follows: In Section 2, we review related work for QR. In Section 3, we describe our alternative queries generation approach, and in Section 4 we present our machine-learning model for ranking the alternatives. Section 5 presents an experimental evaluation of our proposed VQR approach. We discuss the positive findings of an online A/B tests that was conducted with our VQR approach on a commercial voice assistant in Section 6. We conclude the paper in Section 7.\nWe note that all processes performed as part of our analyses were conducted in accordance with strict privacy guidelines and all methods for handling the data are automated. We cannot share our data with the community due to its sensitivity."
    }, {
      "heading" : "2 RELATEDWORK",
      "text" : "Query rewriting has long been an important research area in information retrieval [3]. Extensive analysis has been done for handling and rewriting of queries in web search. The notion of query refinement, expansion, suggestion, substitution, and reformulation are sometime overloaded and have been commonly used synonymously with query rewriting. Most of the previous methods are not particularly suitable for e-commerce queries, which are shorter and more sensitive to context [34], let alone voice e-commerce\nqueries. Focusing on tail low-frequency e-commerce queries highlights additional unique challenges and opportunities, especially around finding and ranking good query alternatives [13]. Using voice as a new medium for search also reveals differences from traditional search in both web [15, 17, 22] and e-commerce [20, 21]. In this work, we concentrate on studying voice e-commerce null (tail) queries.\nOne notable research direction in QR, which is also applicable for e-commerce, focuses on increasing the recall. This direction is especially important for null queries that yield no results. Alternative queries are generated by dropping [4, 24, 28, 46, 47] or substituting [7, 16, 25] tokens from the original query. For example, Jones et al. [25] proposed generating query alternatives by using a large set of ordered query pairs obtained from consecutive queries in web-search sessions. Then, various alternatives are generated by breaking a given query into segments and either dropping or generating substitutions for each of them separately. For dealing with null e-commerce queries, Singh et al. [41] suggested a post-retrieval approach for dropping terms from a given query that restricts the search results to the same taxonomy of results returned in the past for the original query. Tan et al. [43] suggested generating sub-queries by dropping unimportant terms based on their part-of-speech (POS) tag and additional features. Our results hint that term-dropping methods for e-commerce null queries do not adjust well to the voice domain. Other ideas for substitution-based solutions, using the query-flow graph [6], were also proposed [7, 16]. However, finding good recommendations for tail e-commerce queries based on session co-occurrence turns to be difficult [16]. For addressing also the long tail of the query distribution, Bonchi et al. [8] conceptually extend the query-flow graph with term nodes in addition to query nodes. Broccolo et al. [9] generate an inverted index of “successful” queries, i.e., ending query of a session with a click on its search result, and recommends queries retrieved from that index. Our approach has similarities with the later in using an index of successful queries, and extends the use of inverted index to include phonetic, sub-words, and semantic similarities upon retrieval.\nRecently, several attempts were made to apply deep learning to various query rewriting tasks. Grbovic et al. [14] proposed to use embedding techniques to expand a query via a k-nearest neighbor search. He et al. [19] proposed a framework that learns to rewrite queries by unsupervised candidate generation and supervised candidate ranking. For unsupervised candidate generation, they presented a a sequence-to-sequence LSTM model, but also incorporated several existing QR systems suggestions. Their scoring function required training over a large web click data. Xiao et al. [44] applied a similar technique based on post-retrieval method for e-commerce web search. The applicability of these techniques to voice queries is still unclear, especially in light of the data sparsity challenges that still exist as voice interfaces are not yet widely adopted. Indeed, users do not tend to switch between voice and text when reformulating queries [39]. Jiang et al. [22] showed that reformulation patterns of voice queries are different from those in conventional textual searches using both lexical and phonetic changes. Hassan et al. [17] developed classifiers for distinguishing reformulation of voice query pairs from textual query pairs. They extended text-based approaches with voice signals such as phonetic\nsimilarity. This hints regarding the importance of phonetic representations in voice query rewriting. Our alternative queries generation approach does not require prior training and adjusts to the voice medium characteristics, considering its phonetic representation.\nOne related direction in QR focuses on improving its precision by narrowing down a search query. In this case, the goal is to refine the query such that the refined alternative retrieves a more relevant subset of results. Approaches towards this task include learning rewritings based on past users’ query refinements [2, 31, 32] and applying pseudo-relevance feedback techniques [10, 29, 33, 45]. Those latter techniques commonly employ post-retrieval methods and iteratively query the search engine for newly added terms [12, 35]. In general, this direction is not suitable for handling null queries since the main problem with those queries is recall rather than precision. Those query refinement and rewriting techniques are mostly applicable to head queries."
    }, {
      "heading" : "3 GENERATING ALTERNATIVE QUERIES",
      "text" : "The alternative queries generation component is responsible for identifying queries that have potential to successfully amend the original query. Our general approach is as follows.We build a search engine index (e.g., based on Elasticsearch [1]) that holds both web and voice queries that led to positive events, such as purchases or an adds-to-cart, with sufficient number of occurrences in the past. In practice, we indexed tens of millions of queries that were collected over a period of several months. Those queries are indexed while applying various analyzers that enable efficient retrieval. We discuss the specifics of those analyzers later on. Given a query q, an alternative queries set Rq is generated by utilizing each of the analyzers to retrieve a query with a maximal score (for that specific analyzer). We only consider the query with the highest score for each analyzer since we only need to identify a single “hero” offer by a single “hero” alternative to be presented to the customer due to the strong presentation bias in a voice-user interface.\nWe explore and combine multiple analyzers that target different potential types of errors in voice queries. An analyzer is typically composed of a tokenizer that splits the text into tokens, and a filter that is applied to the tokens, resulting with terms for indexing and retrieval. Arguably, the simplest analyzer that we utilize, referred to as MLT (more-like-this), splits the queries to their word-level. Then, given a query, the top retrieved queries are selected according to the Okapi BM25 scoring function [38] on the underlying terms. This analyzer can identify good alternative queries if the most distinctive words in the query are kept. For example, rewriting over-specified queries or miss-pronounced queries. Such a method, based on word tokens, fails when important distinctive words are corrupted, e.g., suffer from spelling mistakes. In such cases, it is much better to apply methods that focus on more local patterns. Taking this observation into consideration, we also utilize an analyzer based on character n-grams, that is, an analyzer that breaks the query into (partially overlapping) terms of character length n. When working with voice queries, there are additional special failures, like phonetic errors that originate in ASR systems. In order to cope with such errors, we also employ few phonetic analyzers based on Double Metaphone phonetic encoding [37]. One such analyzer works similarly to MLT, but on a phonetic encoding level.\nIt can successfully replace a query if the main keywords preserve their phonetic representation. Two additional phonetic analyzers that are used are a so-called full phonetic analyzer that considers the entire phonetic representation of a query as a single term, and a phonetic n-grams analyzer, which breaks the query into parts of length n and translates them into their phonetic representation. The former analyzer handles ASR errors that result in splitting or merging of words. For concreteness, we focus on n-grams-type analyzers with n ∈ {3, 4}. Table 1 presents a simple example illustrating the way different analyzers generate terms for indexing and retrieval. Table 2 outlines few synthetic examples that demonstrate the strengths of the various analyzers."
    }, {
      "heading" : "4 RANKING ALTERNATIVE QUERIES",
      "text" : "Once the set of alternative queries Rq has been retrieved, the alternative queries ranking component evaluates the probability of each of the alternatives to successfully amend the originating query q. While our component provides a complete ordering between the alternatives, for our voice scenario, we are only interested in the top-ranked alternative r∗ ∈ Rq . The reason lies in the presentation bias towards a single top-ranked offer.\nEvery alternative is retrieved as the top option by some analyzer to replace q. However, it may occur that a retrieved alternative is irrelevant for the originating customer intent. This is especially true for phonetic-based analyzers that due to their generality of soundsalike retrieval may result in an alternative query with different intent, but it is also true for the other types of analyzers. For this reason, we build a machine learning approach that not only ranks the alternatives, but also provides a confidence score regarding their probability to properly replace q. In a sense, the alternative queries generation component aims to improve the recall of our system, while our pointwise ranking component is in charge of tuning its precision. Table 3 exhibits an example in which textual and character-based analyzers fail to generate relevant alternatives, but phonetic-based analyzers do. Notice that the product type “strips” appears in the original query and in the alternatives retrieved from the phonetic-based analyzers. Having agreement between extracted product types from queries is a strong indicator for keeping the customer’s intent intact.\nWe assume to have a labeled dataset for voice shopping queries. Given a null query q, the dataset consists of a label y(q,r ) for every (q, r ) query pair, where r ∈ Rq is a generated alternative for q. This dataset is the result of annotation by an internal team dedicated to voice shopping related annotation tasks. The annotators are given the customer’s utterance that corresponds to q along with the top\nretrieved offers for each alternative r ∈ Rq . For each such offer, the annotators indicate whether it is relevant to the utterance of q or not. Because the annotators classify the relevance based on both the customer intent as implied by the utterance and the returned offers for the alternatives, the classification label captures both up-stream errors due to the voice interface and down-stream errors due to the products search engine. The relevance label y(q,r ) is set to be the relevance annotation between q and the top returned offer for r .\nWe collect features associated to each alternative r as well as various features relating to the relation between q and r (e.g., their textual similarities). Those features are utilized in conjunction with the dataset to optimize over several machine learning models and hyper-parameters. We describe the details of the features and the ranking models in the following subsections."
    }, {
      "heading" : "4.1 Features For Ranking",
      "text" : "We evaluated a large family of tens of handcrafted features as well as different standard manipulations of them for our alternative queries ranking approach. We refrain from providing an exhaustive list of evaluated features due to space constraints and since most of them had marginal contribution to the performance of the models. Instead, we provide an overview of the main feature categories that guided the feature engineering, and focus on a small subset of carefully selected features that were able to extract most of our performance improvements. Our main feature categories include:\nTextual similarities between the originating query and an alternative query, and between their extracted metadata (e.g., product type and brand). We consider variants of the Jaccard similarity and Edit distance. We consider distance variants on both word-level and character-level. We also consider distances of lemmatized queries, and distances of the lexicographic representations of queries (i.e., ordering of words by lexicographic order). Finally, we use the BM25 relevance score of the specific analyzer that retrieved the alternative as another tokens similarity measure.\nSemantic similarities between the originating query and an alternative query, and between their extracted metadata. We generated a specialized word embedding trained using the FastText algorithm [5, 26] on a proprietary e-commerce corpus that included shopping queries, product titles, and a concatenation of queries with the title of the product that was purchased as result of them. The semantic similarity between two sentences is defined as the cosine similarity between the average vector of their underlying normalized word embedding vectors.\nHistorical behavioral features of the alternative queries. Those\nfeatures capture the aggregated past performance of the alternative queries. We consider the number of past occurrences and positive actions (purchase or add-to-cart) of a query on both web and voice shopping logs, and its implied conversion rate (i.e., the rate between positive actions and its overall number of occurrences). We note that the behavioral features of the alternative queries are rich as those queries are head queries.\nWe used standard feature selection techniques to avoid overfitting due to small amount of available labeled data (i.e., few thousands). In what follows, we focus on a short list of 7 features that were able to extract most of our performance improvement. Table 4 lists those features. In feature f1 the sorted version of a query is the\none in which the words are lexicographically ordered. Note that in feature f5, PT(q) indicates the product type implied for the query q as extracted by a specialized model. A key challenge in mapping a tail query to a head query is to maintain the purchase intent of the query. Product type alignment is arguably the most coarse way to keep the intent intact."
    }, {
      "heading" : "4.2 The Ranking Model",
      "text" : "Our machine learning approach for the alternative queries ranking problem is a two-tier solution. First, for each analyzer type, we train a machine learning model that predicts whether an alternative r , generated by that analyzer, is a suitable replacement for a\nnull query q. Then, we rank all alternative queries according to the different models predictions, and effectively, return the alternative with the highest prediction score. For the purpose of building each analyzer’s model, we have experimented with several machine learning approaches (e.g., logistic regression, support vector machine, random forest) and various hyper-parameters (e.g., the main hyper-parameters for random forest were maximal depth and the number of estimators in the forest). Following an exhaustive search, we identified the best model for this task as a random forest model optimized over a cross-entropy loss. Further technical details about the models are provided in Section 5.3."
    }, {
      "heading" : "5 EXPERIMENTAL EVALUATION",
      "text" : ""
    }, {
      "heading" : "5.1 Baselines",
      "text" : "We compare our VQR approach against two baselines. The first is a term-dropping based QR system, which is common in various usecases, especially when dealing with null queries [4, 24, 28, 41, 43, 46]. Term-dropping approaches have been demonstrated to be good for increasing the recall of search systems, but they often result in lower precision. The second baseline is a simple retrieval-based approach, build on top of our positive queries index, which only considers word-level textual similarity. This baseline has the ability to both relax or extend the originating query, taking into account the importance of words with respect to a reference collection of queries. This baseline is expected to have better precision than the term-dropping baseline.\nTerm-Dropping QR (TDQR). Alternative queries are generated by exhaustively considering all options to drop different set of terms from the originating query. Selecting a top alternative is done using a post-retrieval method that gives preference to alternatives that lead to more focused set of offers (i.e., having high query scope measure [18, 28]).\nRetrieval-Based QR (RQR). An alternative query is selected based on a retrieval process that uses the same search index as VQR with an Okapi BM25 scoring function on the words. To guarantee high precision from this system, we required alternatives to have a sufficiently high relevance (specifically, a relevance score of 20). This threshold was identified as leading to good separation between higher and lower quality alternatives by manual annotation."
    }, {
      "heading" : "5.2 Datasets",
      "text" : "For the purpose of evaluating our approach, we collected two datasets based on a random sample of voice null queries and a random sample of web (text) null queries. All sampled queries were unique, appearing only once in the sample, as expected from tail queries. Each query in the dataset is appended with a list of its alternative queries and their annotated relevance ranking. We relied on an internal team of annotators, dedicated to voice shopping related annotation tasks in order to produce those datasets.\nThe relevance annotations of alternative queries for an originating query were performed as follows. The annotators were given the customer’s utterance (voice query)U that resulted in the textual query q, along with a list of product offers. They were asked to rate the relevance of each offer with respect to the customer intent as implied by the utteranceU on a three-points-scale: 0 indicates a no match betweenU and the offer, 1 indicates a match that (at least) respects the requested product type, and 2 indicates a full match (i.e., the offered product contains all the attributes mentioned in the utterance). The list of product offers consists of the top-ranked offer retrieved for every alternative query r generated for the query q. The alternative queries were generated by the different approaches under evaluation, that is, the baselines and a set of 6 analyzers (MLT, full phonetic, phonetic, 4-grams, 3-grams, and phonetic 4-grams). The relevance label for each (q, r ) query pair was set to be the relevance score between utterance U , which resulted in q, and the top returned offer for the alternative r , as agreed by majority of 3 annotators. Note that because the annotators classify the relevance of offers with respect to the customer utterance, the annotations\nalso capture failures due to the voice interface, like ASR errors and user mispronunciations.\nVoice null queries. A set of voice shopping null queries uniformly sampled at random over a period of one month from query logs of a commercial voice assistant. We consider only queries identified by the annotators to include a shopping intent. The dataset contains 3,564 unique null shopping queries along with their alternative queries rankings. The methods presented in this paper were developed using this dataset of voice null queries.\nWeb (text) null queries. A set of textual shopping null queries uniformly sampled at random over a period of one month from query logs of a commercial e-commerce website. The dataset contains 1,362 unique null shopping queries alongwith their alternative queries rankings. Note that this dataset is only used to evaluate the performance of the different methods for web e-commerce traffic. In this case, we consider multiple offers for each alternative (instead of only a single top-ranked offer) in order to evaluate the resulting offers ranking. This is motivated by the fact that the presentation bias on the web is much lower than on a voice interface, and thus, associating relevance only with a top offer makes less sense."
    }, {
      "heading" : "5.3 Training Random Forest Models",
      "text" : "The models for predicting the quality of alternatives of each analyzer type were only trained on the voice null queries dataset. We split the dataset so that 75% of the examples are used for training and validation, and 25% are used for testing, and translated the three-points relevance labeling to a binary labeling by assigning double weight for full match cases. Because the dataset is relatively small, we train the model by using 2 repetitions of 3-fold crossvalidation. Each of the random forest models for the analyzers were trained separately with same features and model parameters.\nIt is interesting to observe that some features have different importance for different analyzers. For example, for the full phonetic analyzer, textual similarity without words sorting is much more important than the one with sorting. This makes a lot of sense because full phonetic method retrieves alternatives that have very similar ordering of words, and therefore evaluating them based on a modified order can be detrimental. On the other hand, for the MLT analyzer, textual similarity with words sorting is more important than the one without sorting. Again, this is reasonable since MLT focuses on identifying alternatives that have similar intent but not necessarily with the same order of words.\nWe considered different combinations of analyzers and corresponding prediction models in order to understand the performance trade-offs. To simplify the presentation, we focus on two variants of VQR, differing by the set of employed analyzers:\nVQR-4. Utilizes a set of arguably the most basic analyzers (phonetic, full phonetic, 4-grams, and MLT) that spans the 3 families of similarities (word-level, character-level, and phoneme-level). In this setting, all random forest classifiers achieved the best results when the maximal tree depth was 6 and the number of estimators in the forest was bounded by 130.\nVQR-6. Uses 6 analyzers (those of VQR-4 appended with 3- grams and phonetic 4-grams). As the two additional analyzers have higher retrieval latency, this variant provides some insight regarding latency-performance trade-offs. In this setting, all random forest\nclassifiers achieved the best results with a maximal tree depth of 6 and number of estimators in the forest bounded by 170."
    }, {
      "heading" : "5.4 Evaluation Metrics",
      "text" : "We evaluate all approaches using 3 key metrics:\n• Coverage – The ratio between the number of null queries\nfor which an underlying method generates an alternative, and the overall number of null queries. • Precision (P@1) – The ratio between the number of alter-\nnative queries that were identified as suitable replacements and the overall number of alternative queries. • Effectiveness (E@1) – The multiplication between the cov-\nerage and precision. This metric essentially captures the impact on the customer, namely, the rate of null queries that were changed for the better.\nFor the evaluation of the approaches on the web null queries dataset, we also consider fewmetrics that measure the quality of the resulting ranked offers. These metrics include Pmax@3, which captures the ratio of alternative queries that have at least one relevant offer within their top 3 offers, and the corresponding effectiveness metric Emax@3. We also consider nDCG3, which uses a graded relevance scale, and its corresponding effectiveness metric EnDCG3."
    }, {
      "heading" : "5.5 Experimental Results",
      "text" : "We report our results on the test sets of both the voice and web null queries datasets. For confidentiality reasons, we report the evaluation metrics relative to the RQR baseline, omitting absolute metrics numbers. We begin by noting that although the effectiveness measure captures the direct impact on the customer, there is a subtle point here. Optimizing the effectiveness measure can be achieved by providing alternative queries whenever possible. However, from a customer point of view, it may be better that the system will not select an alternative when that query results in irrelevant offers. This observation is especially true on voice, when the presentation of irreverent offers create much higher friction than a graceful failure. This is one of the reasons for the existence of a controller component (recall Figure 1), safeguarding the quality. Consequently, although the best effectiveness is achieved by not setting any safeguard, we restrict our attention to solutions whose precision is around that of the RQR baseline.\nBased on performance analysis on the validation set, we chose a conservative quality threshold of 0.4 on the prediction score of the VQR-6 model. Note that although we concentrate on a specific operating point, VQR-6 model has a wide-range of operating points that have higher precision, coverage and effectiveness than the RQR baseline. Figure 2 illustrates the effectiveness and precision trade-off curves of VQR-6 model (relative to RQR) as a function of the threshold given by the prediction score of the VQR-6 model (x-axis). Notice that the shape of the curve suggests that the model can adjust for different business use-cases by a careful selection of the threshold, e.g., one can optimize for higher-precision customerfacing scenarios. The selected operating point where the prediction score (threshold) equals 0.4 is visualized upon the knee of the effectiveness curve, and as claimed, its achieved precision is higher than the baseline RQR.\nFigure 3 provides an alternative view, exhibiting the trade-offs of precision and effectiveness (y-axis) against the coverage (x-axis). The curves are generated by different thresholds on the prediction score of the VQR-6 model. It is evident that the VQR model has a wide range of operating points that have higher precision, coverage and effectiveness than RQR. Note that the precision of VQR-6 decreases as the coverage increases, indicating that high prediction scores of the model correspond to more confident query rewritings.\nFigure 4 illustrates the cumulative distributions of the prediction scores of the selected alternatives by the VQR-6 model over the validation set. One curve corresponds to the selected alternative queries labeled as relevant, and the second curve corresponds to less-relevant selected alternative queries. We notice that setting a quality threshold at 0.4 blocks many less-relevant alternatives while keeping almost all relevant alternatives. This trend can also be inferred from Figure 2, where the precision is consistently rising\nwhile the threshold increases towards 0.4, but the effectiveness hardly decreases. It seems important to note that each of the cumulative distribution curves is self-contained in the sense that it only takes into account either the number of relevant cases or the less-relevant cases.\nTable 5 presents an evaluation of the different methods on the voice null queries test set. Reported values are statistically significant with p < 0.05. As can be observed, the baseline RQR approach significantly outperforms the effectiveness of TDQR baseline.While the coverage of TDQR is higher than RQR by more than 22%, its precision is significantly lower, resulting in an overall decrease in effectiveness. Both VQR-4 and VQR-6 models outperform the effectiveness of RQR by more than 22% and 26%, respectively. Note that the improvements in the effectiveness and coverage are statistically significant at the 0.05 level using a student’s t-test. The fact that the improvement in precision is not statistically significant is by our design decision, restricting our attention to an operating point that achieves similar precision to that of RQR. Note that there are operating points in which our models improve over the RQR baseline in both precision, coverage and effectiveness in a statistically significant way.\nWhen we dive deeper into the contribution of each analyzer towards the output of VQR-6, we notice that in 26.0% of the cases the analyzer whose alternative had the highest score was phonetic 4-grams, in 21.7% it was MLT, in 18.8% it was 3-grams, in 17.2% it was phonetic, in 12.3% it was 4-grams, and only in 4.0% it was\nfull phonetic. From a precision point of view, the analyzer with the lowest precision is 3-grams. We consider its precision as a reference point. Then, full phonetic has a 2.5% better precision, MLT has a 6% better precision, phonetic has a 12.8% better precision, 4-grams has a 13.2% better precision, and phonetic 4-grams has a 19.6% better precision. Notice that the phonetic 4-grams alternatives have the highest traffic share and precision. This immediately raises the question how VQR-4 still maintains such high precision and effectiveness. It turns out that in many cases, the alternative with the highest score is also identified by other analyzers (with lower score). In VQR-4, the ranking model adjusts so that most of the traffic that phonetic 4-grams and 3-grams handled is spread between 4-grams (34.5%), MLT (32.0%), and phonetic (28.3%) with relatively small changes in precision.\nTable 6 presents an evaluation of the TDQR and VQR-4 methods relative to the RQR baseline on the web null queries test set. Reported values are statistically significant with p < 0.05. Again, RQR significantly outperforms the effectiveness of TDQR in-spite of the significant coverage increase, and VQR-4 outperforms RQR in all metrics with a statistically significant improvement in the coverage and various effectiveness measures at the 0.05 level. We decided not to report the results for VQR-6 as they follow the same trends presented for the voice dataset, and thus, carry a light conceptual message.\nOne especially interesting observation relates to the performance differences of TDQR on voice and web data. We first note that the performance of RQR on the voice and web test sets is roughly the same, having no difference in coverage and only small increase of 3.9% in precision and effectiveness for the web data. So, essentially, our reference performance does not change between voice and web. However, we observe that the degradations in precision and effectiveness of TDQR over the voice test set is much more significant than over the web test set. We see a −43.4% and −56.6% decrease in E@1 and P@1 over voice compared to −15.3% and −34.8% decrease over web. This is a statistically significant difference, hinting that web queries are considerably different, and apparently easier to fix, than voice queries. This important insight adds to previous line of research [15, 17, 20, 22], highlighting differentiating factors between the voice and web domains, and supporting the need for specialized mechanisms for voice."
    }, {
      "heading" : "6 ONLINE EVALUATION",
      "text" : "Variants of the proposed QR framework were evaluated for their effectiveness in handling null queries as part of an online A/B test on a commercial voice assistant. In that test, the control group experienced a RQR-like approach, while the treatment group experienced a VQR-4-like approach. The experiment ran for about a month. The A/B test demonstrated positive impact on customers, reducing null queries by 40.5%. While increasing the overall traffic coverage and providing customers with product offers, the quality metrics also demonstrated an improvement. The relevance of the queries handled by the QR system (P@1) increased by about 20%, as evaluated by internal annotators. Furthermore, the rate of positive actions (e.g., purchases) across the entire traffic increased by 1.7%, although the fraction of null queries was relatively small. All those\nresults were shown to be statistically significant at the 0.05 level using a student’s t-test."
    }, {
      "heading" : "7 CONCLUSIONS",
      "text" : "We presented a new framework for pre-retrieval query rewriting of voice shopping null queries. Our approach takes the characteristics of the voice-user interface into consideration. We conducted experiments with both voice and web data of a commercial voice assistant and an e-commerce website. Those experiments demonstrated that our approach outperforms several baselines by large margins in both offline and online settings. We also provided empirical evidence for a fundamental difference between voice null queries and web null queries, substantiating the use of specialized mechanisms for the voice domain. We believe that our proposed framework, mapping tail to head queries, is of independent interest as it can be extended and applied to other domains beyond voice shopping. As future work, we plan to explore more advanced mapping techniques. For example, one natural approach is to apply sequence-to-sequence deep learning techniques to learn a mapping from null queries to alternatives. It can be particularly valuable to work with phoneme representations of queries on top of textual ones. Another intention is to identify better ranking techniques. Since voice interfaces are new and not yet widely adopted, there is still a data sparsity issue that limits the ability to tackle those plans. There is a need to research ways to bypass this issue. One such approach may be to massively produce semi-supervised weak labels, e.g., use the relevance score that a search engine assigns to a (query, offer) pair to create labeled data for the ranking. Another promising approach is to use transfer learning from web to voice."
    }, {
      "heading" : "ACKNOWLEDGMENTS",
      "text" : "The authors would like to thank their colleagues Natali Arieli, Sagi Bernstein, Anna Chalupowicz, Anna Farberman, David Shamouilian, and Yochai Zvik for their fruitful collaboration, discussions, and help in implementation."
    } ],
    "references" : [ {
      "title" : "Voice query refinement",
      "author" : [ "Cyril Allauzen", "Edward Benson", "Ciprian Chelba", "Michael Riley", "Johan Schalkwyk" ],
      "venue" : "In Thirteenth Annual Conference of the International Speech Communication Association",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2012
    }, {
      "title" : "Discovering key concepts in verbose queries",
      "author" : [ ],
      "venue" : "In Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2008
    }, {
      "title" : "Enriching Word Vectors with Subword Information",
      "author" : [ "Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov" ],
      "venue" : "Transactions of the Association for Computational Linguistics",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2017
    }, {
      "title" : "The Query-flow Graph: Model and Applications",
      "author" : [ "Paolo Boldi", "Francesco Bonchi", "Carlos Castillo", "Debora Donato", "Aristides Gionis", "Sebastiano Vigna" ],
      "venue" : "In Proceedings of the 17th ACM Conference on Information and Knowledge Management",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2008
    }, {
      "title" : "Query Suggestions Using Query-flow Graphs",
      "author" : [ "Paolo Boldi", "Francesco Bonchi", "Carlos Castillo", "Debora Donato", "Sebastiano Vigna" ],
      "venue" : "In Proceedings of the 2009 Workshop on Web Search Click Data",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2009
    }, {
      "title" : "Efficient Query Recommendations in the Long Tail via Center-Piece Subgraphs",
      "author" : [ "Francesco Bonchi", "Raffaele Perego", "Fabrizio Silvestri", "Hossein Vahabi", "Rossano Venturini" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2012
    }, {
      "title" : "Generating suggestions for queries in the long tail with an inverted index",
      "author" : [ "Daniele Broccolo", "Lorenzo Marcon", "Franco Maria Nardini", "Raffaele Perego", "Fabrizio Silvestri" ],
      "venue" : "Information Processing & Management 48,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2012
    }, {
      "title" : "Selecting Good Expansion Terms for Pseudo-Relevance Feedback",
      "author" : [ "Guihong Cao", "Jian-Yun Nie", "Jianfeng Gao", "Stephen Robertson" ],
      "venue" : "In Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2008
    }, {
      "title" : "Estimating the query difficulty for information retrieval. Synthesis Lectures on Information Concepts, Retrieval, and Services",
      "author" : [ "David Carmel", "Elad Yom-Tov" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2010
    }, {
      "title" : "Pseudo-Query Reformulation",
      "author" : [ "Fernando Diaz" ],
      "venue" : "In Advances in Information Retrieval. Springer International Publishing,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2016
    }, {
      "title" : "Anatomy of the Long Tail: Ordinary People with Extraordinary Tastes",
      "author" : [ "Sharad Goel", "Andrei Broder", "Evgeniy Gabrilovich", "Bo Pang" ],
      "venue" : "In Proceedings of the Third ACM International Conference on Web Search and Data Mining",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2010
    }, {
      "title" : "Context- and Content-aware Embeddings for Query Rewriting in Sponsored Search",
      "author" : [ "Mihajlo Grbovic", "Nemanja Djuric", "Vladan Radosavljevic", "Fabrizio Silvestri", "Narayan Bhamidipati" ],
      "venue" : "In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2015
    }, {
      "title" : "Searching by Talking: Analysis of Voice Queries on Mobile Web Search",
      "author" : [ "Ido Guy" ],
      "venue" : "In Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2016
    }, {
      "title" : "Query Suggestion for E-commerce Sites",
      "author" : [ "Mohammad Al Hasan", "Nish Parikh", "Gyanit Singh", "Neel Sundaresan" ],
      "venue" : "In Proceedings of the Fourth ACM International Conference on Web Search and Data",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2011
    }, {
      "title" : "Characterizing and Predicting Voice Query Reformulation",
      "author" : [ "Ahmed Hassan Awadallah", "Ranjitha Gurunath Kulkarni", "Umut Ozertem", "Rosie Jones" ],
      "venue" : "In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2015
    }, {
      "title" : "Inferring Query Performance Using Pre-retrieval Predictors",
      "author" : [ "Ben He", "Iadh Ounis" ],
      "venue" : "In String Processing and Information Retrieval",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2004
    }, {
      "title" : "Learning to Rewrite Queries",
      "author" : [ "Yunlong He", "Jiliang Tang", "Hua Ouyang", "Changsung Kang", "Dawei Yin", "Yi Chang" ],
      "venue" : "In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2016
    }, {
      "title" : "The Challenges of Moving fromWeb to Voice in Product Search",
      "author" : [ "Amir Ingber", "Arnon Lazerson", "Liane Lewin-Eytan", "Alexander Libov", "Eliyahu Osherovich" ],
      "venue" : "In Proc. 1st International Workshop on Generalization in Information Retrieval",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2018
    }, {
      "title" : "Offline vs. Online Evaluation in Voice Product Search",
      "author" : [ "Amir Ingber", "Liane Lewin-Eytan", "Alexander Libov", "Yoelle Maarek", "Eliyahu Osherovich" ],
      "venue" : "In 1st International Workshop on Generalization in Information Retrieval",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2018
    }, {
      "title" : "HowDo Users Respond to Voice Input Errors? Lexical and Phonetic Query Reformulation in Voice Search",
      "author" : [ "Jiepu Jiang", "Wei Jeng", "Daqing He" ],
      "venue" : "In Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2013
    }, {
      "title" : "Optimizing search engines using clickthrough data",
      "author" : [ "Thorsten Joachims" ],
      "venue" : "In Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2002
    }, {
      "title" : "Query word deletion prediction",
      "author" : [ "Rosie Jones", "Daniel C. Fain" ],
      "venue" : "In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2003
    }, {
      "title" : "Generating Query Substitutions",
      "author" : [ "Rosie Jones", "Benjamin Rey", "Omid Madani", "Wiley Greiner" ],
      "venue" : "In Proceedings of the 15th International Conference on World Wide Web",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2006
    }, {
      "title" : "Bag of Tricks for Efficient Text Classification. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers (Valencia, Spain). Association for Computational Linguistics, 427–431",
      "author" : [ "Armand Joulin", "Edouard Grave", "Piotr Bojanowski", "Tomas Mikolov" ],
      "venue" : "Session 8B: Multi-modal Retrieval and Ranking SIGIR",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2017
    }, {
      "title" : "Reducing long queries using query quality predictors",
      "author" : [ "Giridhar Kumaran", "Vitor R. Carvalho" ],
      "venue" : "In Proceedings of the 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2009
    }, {
      "title" : "Relevance Based Language Models",
      "author" : [ "Victor Lavrenko", "W. Bruce Croft" ],
      "venue" : "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2001
    }, {
      "title" : "Jasper: An End-to-End Convolutional",
      "author" : [ "Jason Li", "Vitaly Lavrukhin", "Boris Ginsburg", "Ryan Leary", "Oleksii Kuchaiev", "Jonathan M. Cohen", "Huyen Nguyen", "Ravi Teja Gadde" ],
      "venue" : "Neural Acoustic Model. CoRR",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2019
    }, {
      "title" : "Exploring Query Auto-Completion and Click Logs for Contextual-Aware Web Search and Query Suggestion",
      "author" : [ "Liangda Li", "Hongbo Deng", "Anlei Dong", "Yi Chang", "Ricardo Baeza-Yates", "Hongyuan Zha" ],
      "venue" : "In Proceedings of the 26th International Conference on World Wide Web",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2017
    }, {
      "title" : "Intent Term Weighting in E-Commerce Queries",
      "author" : [ "Saurav Manchanda", "Mohit Sharma", "George Karypis" ],
      "venue" : "In Proceedings of the 28th ACM International Conference on Information and Knowledge Management",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2019
    }, {
      "title" : "Latent Concept Expansion Using Markov Random Fields",
      "author" : [ "Donald Metzler", "W. Bruce Croft" ],
      "venue" : "In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2007
    }, {
      "title" : "Similarity Measures for Short Segments of Text",
      "author" : [ "Donald Metzler", "Susan Dumais", "Christopher Meek" ],
      "venue" : "In Advances in Information Retrieval,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2007
    }, {
      "title" : "Task-Oriented Query Reformulation with Reinforcement Learning",
      "author" : [ "Rodrigo Nogueira", "Kyunghyun Cho" ],
      "venue" : "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2017
    }, {
      "title" : "SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition",
      "author" : [ "Daniel S. Park", "William Chan", "Yu Zhang", "Chung-Cheng Chiu", "Barret Zoph", "Ekin D. Cubuk", "Quoc V. Le" ],
      "venue" : "CoRR abs/1904.08779",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2019
    }, {
      "title" : "Hanging on the Metaphone",
      "author" : [ "Lawrence Philips" ],
      "venue" : "Computer Language Magazine 7,",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 1990
    }, {
      "title" : "The Probabilistic Relevance Framework: BM25 and Beyond",
      "author" : [ "Stephen E. Robertson", "Hugo Zaragoza" ],
      "venue" : "Foundations and Trends in Information Retrieval 3,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 2009
    }, {
      "title" : "Mobile Query Reformulations",
      "author" : [ "Milad Shokouhi", "Rosie Jones", "Umut Ozertem", "Karthik Raghunathan", "Fernando Diaz" ],
      "venue" : "In Proceedings of the 37th International ACM SIGIR Conference on Research & Development in Information Retrieval",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 2014
    }, {
      "title" : "User behavior in zerorecall ecommerce queries",
      "author" : [ "Gyanit Singh", "Nish Parikh", "Neel Sundaresan" ],
      "venue" : "In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 2011
    }, {
      "title" : "Rewriting Null e- Commerce Queries to Recommend Products",
      "author" : [ "Gyanit Singh", "Nish Parikh", "Neel Sundaresan" ],
      "venue" : "In Proceedings of the 21st International Conference on World Wide Web",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 2012
    }, {
      "title" : "User Intent, Behaviour, and Perceived Satisfaction in Product Search",
      "author" : [ "Ning Su", "Jiyin He", "Yiqun Liu", "Min Zhang", "Ma Shaoping" ],
      "venue" : "In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining",
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 2018
    }, {
      "title" : "Query Rewrite for Null and Low Search Results in eCommerce",
      "author" : [ "Zehong Tan", "Canran Xu", "Mengjie Jiang", "Hua Yang", "Xiaoyuan Wu" ],
      "venue" : "In Proceedings of the SIGIR Workshop On eCommerce",
      "citeRegEx" : "43",
      "shortCiteRegEx" : "43",
      "year" : 2017
    }, {
      "title" : "Weakly Supervised Co-Training of Query Rewriting andSemantic Matching for e-Commerce",
      "author" : [ "Rong Xiao", "Jianhui Ji", "Baoliang Cui", "Haihong Tang", "Wenwu Ou", "Yanghua Xiao", "Jiwei Tan", "Xuan Ju" ],
      "venue" : "In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining",
      "citeRegEx" : "44",
      "shortCiteRegEx" : "44",
      "year" : 2019
    }, {
      "title" : "Query Expansion Using Local and Global Document Analysis",
      "author" : [ "Jinxi Xu", "W. Bruce Croft" ],
      "venue" : "In Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "citeRegEx" : "45",
      "shortCiteRegEx" : "45",
      "year" : 1996
    }, {
      "title" : "Improving verbose queries using subset distribution",
      "author" : [ "Xiaobing Xue", "Samuel Huston", "W. Bruce Croft" ],
      "venue" : "In Proceedings of the 19th ACM Conference on Information and Knowledge Management",
      "citeRegEx" : "46",
      "shortCiteRegEx" : "46",
      "year" : 2010
    }, {
      "title" : "Term necessity prediction",
      "author" : [ "Le Zhao", "Jamie Callan" ],
      "venue" : "In Proceedings of the 19th ACM Conference on Information and Knowledge Management",
      "citeRegEx" : "47",
      "shortCiteRegEx" : "47",
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 26,
      "context" : ", [27, 30, 36]), they still have failures that exhibit different patterns (e.",
      "startOffset" : 2,
      "endOffset" : 14
    }, {
      "referenceID" : 32,
      "context" : ", [27, 30, 36]), they still have failures that exhibit different patterns (e.",
      "startOffset" : 2,
      "endOffset" : 14
    }, {
      "referenceID" : 8,
      "context" : "In a pre-retrieval approach [11], QR happens without knowledge about the offers that return for the original query or any of the generated alternatives.",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 17,
      "context" : "tation bias towards the top-ranked offer [20], in most cases, only a single offer is communicated back to the customer.",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 20,
      "context" : "The main motivation for this approach comes from the fact that head queries are known to exhibit much better performance than tail queries, due to richer historical behavioral features [23].",
      "startOffset" : 185,
      "endOffset" : 189
    }, {
      "referenceID" : 17,
      "context" : "[20] recently observed that products purchased through voice are much more limited in terms of diversity, namely, products purchased on a regular basis such as groceries, and not niche long-tail products.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 37,
      "context" : "queries to retrieve offers that capture the same intent as the originating query [41].",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 12,
      "context" : "For example, it was observed that voice queries are closer to natural language than text queries in general search [15], voice reformulations are distinguishable from textual reformulations [17, 22], and that shopping categories and behavioral patterns defer between voice and web e-commerce search [20].",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 14,
      "context" : "For example, it was observed that voice queries are closer to natural language than text queries in general search [15], voice reformulations are distinguishable from textual reformulations [17, 22], and that shopping categories and behavioral patterns defer between voice and web e-commerce search [20].",
      "startOffset" : 190,
      "endOffset" : 198
    }, {
      "referenceID" : 19,
      "context" : "For example, it was observed that voice queries are closer to natural language than text queries in general search [15], voice reformulations are distinguishable from textual reformulations [17, 22], and that shopping categories and behavioral patterns defer between voice and web e-commerce search [20].",
      "startOffset" : 190,
      "endOffset" : 198
    }, {
      "referenceID" : 17,
      "context" : "For example, it was observed that voice queries are closer to natural language than text queries in general search [15], voice reformulations are distinguishable from textual reformulations [17, 22], and that shopping categories and behavioral patterns defer between voice and web e-commerce search [20].",
      "startOffset" : 299,
      "endOffset" : 303
    }, {
      "referenceID" : 30,
      "context" : "Most of the previous methods are not particularly suitable for e-commerce queries, which are shorter and more sensitive to context [34], let alone voice e-commerce Session 8B: Multi-modal Retrieval and Ranking SIGIR ’20, July 25–30, 2020, Virtual Event, China",
      "startOffset" : 131,
      "endOffset" : 135
    }, {
      "referenceID" : 10,
      "context" : "Focusing on tail low-frequency e-commerce queries highlights additional unique challenges and opportunities, especially around finding and ranking good query alternatives [13].",
      "startOffset" : 171,
      "endOffset" : 175
    }, {
      "referenceID" : 12,
      "context" : "Using voice as a new medium for search also reveals differences from traditional search in both web [15, 17, 22] and e-commerce [20, 21].",
      "startOffset" : 100,
      "endOffset" : 112
    }, {
      "referenceID" : 14,
      "context" : "Using voice as a new medium for search also reveals differences from traditional search in both web [15, 17, 22] and e-commerce [20, 21].",
      "startOffset" : 100,
      "endOffset" : 112
    }, {
      "referenceID" : 19,
      "context" : "Using voice as a new medium for search also reveals differences from traditional search in both web [15, 17, 22] and e-commerce [20, 21].",
      "startOffset" : 100,
      "endOffset" : 112
    }, {
      "referenceID" : 17,
      "context" : "Using voice as a new medium for search also reveals differences from traditional search in both web [15, 17, 22] and e-commerce [20, 21].",
      "startOffset" : 128,
      "endOffset" : 136
    }, {
      "referenceID" : 18,
      "context" : "Using voice as a new medium for search also reveals differences from traditional search in both web [15, 17, 22] and e-commerce [20, 21].",
      "startOffset" : 128,
      "endOffset" : 136
    }, {
      "referenceID" : 1,
      "context" : "Alternative queries are generated by dropping [4, 24, 28, 46, 47] or substituting [7, 16, 25] tokens from the original query.",
      "startOffset" : 46,
      "endOffset" : 65
    }, {
      "referenceID" : 21,
      "context" : "Alternative queries are generated by dropping [4, 24, 28, 46, 47] or substituting [7, 16, 25] tokens from the original query.",
      "startOffset" : 46,
      "endOffset" : 65
    }, {
      "referenceID" : 24,
      "context" : "Alternative queries are generated by dropping [4, 24, 28, 46, 47] or substituting [7, 16, 25] tokens from the original query.",
      "startOffset" : 46,
      "endOffset" : 65
    }, {
      "referenceID" : 42,
      "context" : "Alternative queries are generated by dropping [4, 24, 28, 46, 47] or substituting [7, 16, 25] tokens from the original query.",
      "startOffset" : 46,
      "endOffset" : 65
    }, {
      "referenceID" : 43,
      "context" : "Alternative queries are generated by dropping [4, 24, 28, 46, 47] or substituting [7, 16, 25] tokens from the original query.",
      "startOffset" : 46,
      "endOffset" : 65
    }, {
      "referenceID" : 4,
      "context" : "Alternative queries are generated by dropping [4, 24, 28, 46, 47] or substituting [7, 16, 25] tokens from the original query.",
      "startOffset" : 82,
      "endOffset" : 93
    }, {
      "referenceID" : 13,
      "context" : "Alternative queries are generated by dropping [4, 24, 28, 46, 47] or substituting [7, 16, 25] tokens from the original query.",
      "startOffset" : 82,
      "endOffset" : 93
    }, {
      "referenceID" : 22,
      "context" : "Alternative queries are generated by dropping [4, 24, 28, 46, 47] or substituting [7, 16, 25] tokens from the original query.",
      "startOffset" : 82,
      "endOffset" : 93
    }, {
      "referenceID" : 22,
      "context" : "[25] proposed generating query alternatives by using a large set of ordered query pairs obtained from consecutive queries in web-search sessions.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 37,
      "context" : "[41] suggested a post-retrieval approach for dropping terms from a given query that restricts the search results to the same taxonomy of results returned in the past for the original query.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 39,
      "context" : "[43] suggested generating sub-queries by dropping unimportant terms based on their part-of-speech (POS) tag and additional features.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 3,
      "context" : "Other ideas for substitution-based solutions, using the query-flow graph [6], were also proposed [7, 16].",
      "startOffset" : 73,
      "endOffset" : 76
    }, {
      "referenceID" : 4,
      "context" : "Other ideas for substitution-based solutions, using the query-flow graph [6], were also proposed [7, 16].",
      "startOffset" : 97,
      "endOffset" : 104
    }, {
      "referenceID" : 13,
      "context" : "Other ideas for substitution-based solutions, using the query-flow graph [6], were also proposed [7, 16].",
      "startOffset" : 97,
      "endOffset" : 104
    }, {
      "referenceID" : 13,
      "context" : "However, finding good recommendations for tail e-commerce queries based on session co-occurrence turns to be difficult [16].",
      "startOffset" : 119,
      "endOffset" : 123
    }, {
      "referenceID" : 5,
      "context" : "[8] conceptually extend the query-flow graph with term nodes in addition to query nodes.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "[9] generate an inverted index of “successful” queries, i.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 11,
      "context" : "[14] proposed to use embedding techniques to expand a query via a k-nearest neighbor search.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[19] proposed a framework that learns to rewrite queries by unsupervised candidate generation and supervised candidate ranking.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 40,
      "context" : "[44] applied a similar technique based on post-retrieval method for e-commerce web search.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "[22] showed that reformulation patterns of voice queries are different from those in conventional textual searches using both lexical and phonetic",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 14,
      "context" : "[17] developed classifiers for distinguishing reformulation of voice query pairs from textual query pairs.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 0,
      "context" : "Approaches towards this task include learning rewritings based on past users’ query refinements [2, 31, 32] and applying pseudo-relevance feedback techniques [10, 29, 33, 45].",
      "startOffset" : 96,
      "endOffset" : 107
    }, {
      "referenceID" : 27,
      "context" : "Approaches towards this task include learning rewritings based on past users’ query refinements [2, 31, 32] and applying pseudo-relevance feedback techniques [10, 29, 33, 45].",
      "startOffset" : 96,
      "endOffset" : 107
    }, {
      "referenceID" : 28,
      "context" : "Approaches towards this task include learning rewritings based on past users’ query refinements [2, 31, 32] and applying pseudo-relevance feedback techniques [10, 29, 33, 45].",
      "startOffset" : 96,
      "endOffset" : 107
    }, {
      "referenceID" : 7,
      "context" : "Approaches towards this task include learning rewritings based on past users’ query refinements [2, 31, 32] and applying pseudo-relevance feedback techniques [10, 29, 33, 45].",
      "startOffset" : 158,
      "endOffset" : 174
    }, {
      "referenceID" : 25,
      "context" : "Approaches towards this task include learning rewritings based on past users’ query refinements [2, 31, 32] and applying pseudo-relevance feedback techniques [10, 29, 33, 45].",
      "startOffset" : 158,
      "endOffset" : 174
    }, {
      "referenceID" : 29,
      "context" : "Approaches towards this task include learning rewritings based on past users’ query refinements [2, 31, 32] and applying pseudo-relevance feedback techniques [10, 29, 33, 45].",
      "startOffset" : 158,
      "endOffset" : 174
    }, {
      "referenceID" : 41,
      "context" : "Approaches towards this task include learning rewritings based on past users’ query refinements [2, 31, 32] and applying pseudo-relevance feedback techniques [10, 29, 33, 45].",
      "startOffset" : 158,
      "endOffset" : 174
    }, {
      "referenceID" : 9,
      "context" : "Those latter techniques commonly employ post-retrieval methods and iteratively query the search engine for newly added terms [12, 35].",
      "startOffset" : 125,
      "endOffset" : 133
    }, {
      "referenceID" : 31,
      "context" : "Those latter techniques commonly employ post-retrieval methods and iteratively query the search engine for newly added terms [12, 35].",
      "startOffset" : 125,
      "endOffset" : 133
    }, {
      "referenceID" : 34,
      "context" : "Then, given a query, the top retrieved queries are selected according to the Okapi BM25 scoring function [38] on the underlying terms.",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 33,
      "context" : "In order to cope with such errors, we also employ few phonetic analyzers based on Double Metaphone phonetic encoding [37].",
      "startOffset" : 117,
      "endOffset" : 121
    }, {
      "referenceID" : 2,
      "context" : "We generated a specialized word embedding trained using the FastText algorithm [5, 26] on a proprietary e-commerce corpus that included shopping queries, product titles, and a concatenation of queries with the title of the product that was purchased as result of them.",
      "startOffset" : 79,
      "endOffset" : 86
    }, {
      "referenceID" : 23,
      "context" : "We generated a specialized word embedding trained using the FastText algorithm [5, 26] on a proprietary e-commerce corpus that included shopping queries, product titles, and a concatenation of queries with the title of the product that was purchased as result of them.",
      "startOffset" : 79,
      "endOffset" : 86
    }, {
      "referenceID" : 1,
      "context" : "The first is a term-dropping based QR system, which is common in various usecases, especially when dealing with null queries [4, 24, 28, 41, 43, 46].",
      "startOffset" : 125,
      "endOffset" : 148
    }, {
      "referenceID" : 21,
      "context" : "The first is a term-dropping based QR system, which is common in various usecases, especially when dealing with null queries [4, 24, 28, 41, 43, 46].",
      "startOffset" : 125,
      "endOffset" : 148
    }, {
      "referenceID" : 24,
      "context" : "The first is a term-dropping based QR system, which is common in various usecases, especially when dealing with null queries [4, 24, 28, 41, 43, 46].",
      "startOffset" : 125,
      "endOffset" : 148
    }, {
      "referenceID" : 37,
      "context" : "The first is a term-dropping based QR system, which is common in various usecases, especially when dealing with null queries [4, 24, 28, 41, 43, 46].",
      "startOffset" : 125,
      "endOffset" : 148
    }, {
      "referenceID" : 39,
      "context" : "The first is a term-dropping based QR system, which is common in various usecases, especially when dealing with null queries [4, 24, 28, 41, 43, 46].",
      "startOffset" : 125,
      "endOffset" : 148
    }, {
      "referenceID" : 42,
      "context" : "The first is a term-dropping based QR system, which is common in various usecases, especially when dealing with null queries [4, 24, 28, 41, 43, 46].",
      "startOffset" : 125,
      "endOffset" : 148
    }, {
      "referenceID" : 15,
      "context" : ", having high query scope measure [18, 28]).",
      "startOffset" : 34,
      "endOffset" : 42
    }, {
      "referenceID" : 24,
      "context" : ", having high query scope measure [18, 28]).",
      "startOffset" : 34,
      "endOffset" : 42
    }, {
      "referenceID" : 12,
      "context" : "line of research [15, 17, 20, 22], highlighting differentiating factors between the voice and web domains, and supporting the need for specialized mechanisms for voice.",
      "startOffset" : 17,
      "endOffset" : 33
    }, {
      "referenceID" : 14,
      "context" : "line of research [15, 17, 20, 22], highlighting differentiating factors between the voice and web domains, and supporting the need for specialized mechanisms for voice.",
      "startOffset" : 17,
      "endOffset" : 33
    }, {
      "referenceID" : 17,
      "context" : "line of research [15, 17, 20, 22], highlighting differentiating factors between the voice and web domains, and supporting the need for specialized mechanisms for voice.",
      "startOffset" : 17,
      "endOffset" : 33
    }, {
      "referenceID" : 19,
      "context" : "line of research [15, 17, 20, 22], highlighting differentiating factors between the voice and web domains, and supporting the need for specialized mechanisms for voice.",
      "startOffset" : 17,
      "endOffset" : 33
    } ],
    "year" : 2020,
    "abstractText" : "Voice shopping using natural language introduces new challenges related to customer queries, like handling mispronounced, misexpressed, and misunderstood queries. Voice null queries, which result in no offers, have negative impact on customers shopping experience. Query rewriting (QR) attempts to automatically replace null queries with alternatives that lead to relevant results. We present a new approach for pre-retrieval QR of voice shopping null queries. Our proposed QR framework first generates alternative queries using a search index-based approach that targets different potential failures in voice queries. Then, a machine-learning component ranks these alternatives, and the original query is amended by the selected alternative. We provide an experimental evaluation of our approach based on data logs of a commercial voice assistant and an e-commerce website, demonstrating that it outperforms several baselines by more than 22%. Our evaluation also highlights an interesting phenomenon, showing that web shopping null queries are considerably different, and apparently easier to fix, than voice queries. This further substantiates the use of specialized mechanisms for the voice domain. We believe that our proposed framework, mapping tail queries to head queries, is of independent interest since it can be extended and applied to other domains.",
    "creator" : "Preview"
  }
}