{
  "name" : "3397271.3401057.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Attentional Graph Convolutional Networks for Knowledge Concept Recommendation in MOOCs in a Heterogeneous View",
    "authors" : [ "Jibing Gong", "Shen Wang", "Jinlong Wang", "Wenzheng Feng", "Hao Peng", "Jie Tang", "Philip S. Yu" ],
    "emails" : [ "gongjibing@ysu.edu.cn", "swang224@uic.edu", "wangjinlong@stumail.ysu.edu.cn", "fwz17@mails.tsinghua.edu.cn", "penghao@act.buaa.edu.cn", "jietang@tsinghua.edu.cn", "psyu@uic.edu", "permissions@acm.org." ],
    "sections" : [ {
      "heading" : null,
      "text" : "∗The first two authors contributed equally. †Corresponding author.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR ’20, July 25–30, 2020, Virtual Event, China © 2020 Association for Computing Machinery. ACM ISBN 978-1-4503-8016-4/20/07. . . $15.00 https://doi.org/10.1145/11221.27\ninformation from different meta-paths, in order to capture the different interests of different students. To learn the parameters of the proposedmodel, we propose to utilize extendedmatrix factorization (MF). A series of experiments are conducted, demonstrating the effectiveness of ACKRec across multiple popular metrics compared with state-of-the-art baseline methods. The promising results show that the proposedACKRec is able to effectively recommend knowledge concepts to students pursuing online learning in MOOCs.\nCCS CONCEPTS • Information systems → Recommender systems; Collaborative filtering; Personalization; Social recommendation; • Computing methodologies → Neural networks.\nKEYWORDS Recommender System; Graph Neural Networks; Heterogeneous Information Network\nACM Reference Format: Jibing Gong, Shen Wang, Jinlong Wang, Wenzheng Feng, Hao Peng, Jie Tang, and Philip S. Yu. 2020. Attentional Graph Convolutional Networks for Knowledge Concept Recommendation in MOOCs in a Heterogeneous View. In 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’20), July 25–30, 2020, Virtual Event, China. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/11221.27"
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "In recent years, massive open online courses (MOOCs) are gradually becoming a mode of alternative education worldwide. For example, Coursera, edX, and Udacity, the three pioneering MOOC platforms, offer millions of user accesses to numerous courses from internationally renowned universities. In China, millions of users study in XuetangX1, which is one of the largest MOOC platforms[20], where thousands of courses are offered on various subjects. Although the number of students in MOOCs is continuously growing, there are still some straits withMOOCs. A challenging problem forMOOCs is how to attract students to study continuously and efficiently on the platforms, where the overall course completion rate is lower than\n1http://www.xuetangx.com\n5% [34]. Therefore, it requires better understanding and capturing of student interests.\nTo understand and capture student interests on MOOCs platforms, multiple efforts have been done, including course recommendation [13, 35], behavior prediction [20], user intentions understanding [34], etc. Among these efforts, recommendation system is applied by MOOCs provider to recommend courses to students. However, a course usually consists of a number of video lectures with each one covering some specific knowledge concepts. Direct course recommendation overlooks students’ interest to specific knowledge concept, e.g., computer vision courses taught by different instructors may be quite different in a microscopic view (cover different sets of knowledge concepts): someone instructor may only cover geometry based methods while other one may only cover deep learning based methods, and thus recommending the computer vision course only covering geometry based methods to the student interested in the deep learning based methods will not be a good match. Therefore, it requires to study students’ online learning interests from a microscopic view and conduct knowledge concept recommendation.\nTraditional recommendation strategy, such as collaborative filtering (CF), which considers user (students) historical interactions and makes recommendations based on potential common preferences from users with similar interests, has achieved great success. However, CF based methods suffer from the sparsity of user-item (student-knowledge concept) relationships, which limits the recommendation performance. To overcome this problem, a number of efforts have been done by leveraging side information, such as social networks [11], user/item attributes [27], images [33], contexts [25], etc. In a MOOCs platform, we observe that in addition to the user and knowledge concept, there exist multiple types of entities (video, course, teacher) and multiple types of relationships between pair of different entities. Table 1 shows the statistics of the real-world XuetangX data collected between January 1st, 2018 and March 31st, 2018. This data consists of 9,986 users, 43,405 videos, 7,020 courses, 5,038 teachers, 1,029 knowledge concepts, and corresponding multiple types of relationships. As shown in Figure 1, the “course: V_9e77179” includes the “knowledge concept: c++”, the “student: 207256” is taking the “course: CaltechX”, the “video: V_1a9aa686” is related to the “knowledge concept: binary tree”, and the “course: CaltechX” is taught by the “teacher: Smith”. Further more, taking users’ behavior history into consideration, we can discover additional relationships. For example, the “user: 207256” clicked the “knowledge concept: c++”, “knowledge concept: binary\ntree”, and “knowledge concept: depth-first search”. Accounting for above multiple types of relationships, we can get much more fruitful facts and interactions between the user and knowledge concepts. If we merely depend on the basic structures, it is difficult to find the significant interaction between “knowledge concept: depth-first search” and “knowledge concept: time complexity ”, which belong to different courses but are clicked by one user. As shown in Figure 1, different knowledge concepts contain different context. Only utilizing single type of interaction may overlook the significant relations between user and knowledge concept. For example, “knowledge concept: c++” and “knowledge concept: binary tree” have dissimilar semantics even though they are included in the same video. These heterogeneous relationships provide rich side information and can benefit the recommendation system in three folds: (1) semantic relatedness among knowledge concepts can be introduced and help to identify the latent interaction; (2) a user’s interests can be reasonably extended and the diversity of recommended knowledge concepts can be increased; and (3) a user’s interest can be interpreted by tracking a user’s historical records along these relationships. Thus, it requires to incorporate these heterogeneous relationships into the representation learning of the entities.\nBased on above observation, we propose Attentional Heterogeneous Graph Convolutional Deep Knowledge Recommender (ACKRec ), an end-to-end framework for knowledge concept recommendation on MOOCs platform. To capture heterogeneous complex relationships, we model the MOOCs platform data as a heterogeneous information network (HIN) [23]. Then, we propose an attentionbased graph convolutional networks (GCNs) to learn the representation of different entities. Traditional GCNs can only capture the homogeneous relationships among homogeneous entities, which overlooks the rich information among heterogeneous relationships. To address this issue, we use meta-paths [25] as the guidance to capture the heterogeneous context information in a HIN via GCN. In this way, the heterogeneous relationships are utilized in a more natural and intuitive way. Moreover, considering that different students may have different interests, we further propose an attention mechanism to adaptively leverage context in multiple meta-paths. In the end, we propose to optimize the parameters of proposed model via an extended matrix factorization and obtain the final recommendation list.\nThe key contributions of this paper can be summarized as follows:• We identify the important problem of knowledge concept\nrecommendation, which is often overlooked by the existing MOOCs recommendation system. Knowledge concept recommendation fills this gap and provides a more microscope level recommendation.\n• We propose ACKRec , a novel end-to-end framework utilizing rich heterogeneous context side information to assist knowledge concept recommendation. • We develop a heterogeneous information network modeling to capture various complex interactions among different types of entities in the MOOCs platform. • We design an attention-based graph convolutional network, which can incorporate both content and heterogeneous context together into the representation learning of different entities. The proposed model can automatically discovers user potential interests by propagating users’ preferences under the guide of meta-path in an attentional way. • We conduct numerous experimental studies using real-world data collected from XuetangX to fully evaluate the performance of the proposed model. We study the parameters, including meta-path combination, representation dimension, number of latent factories, and number of GCNs layers. We synthetically demonstrate the effectiveness of the proposed model compared with a series of strong baselines."
    }, {
      "heading" : "2 PROBLEM STATEMENT AND SYSTEM ARCHITECTURE",
      "text" : ""
    }, {
      "heading" : "2.1 Problem Statement",
      "text" : "Given a target user with corresponding interactive data in MOOCs, the goal is to calculate the interest score about the user and a series of knowledge concepts, and the recommend results – a top \uD835\uDC41 list of knowledge concepts. More formally, given interactive data of a user \uD835\uDC62, a predict function \uD835\uDC53 is learned and used to generate a recommend list of knowledge concepts \uD835\uDC3E (e.g., \"c++\", \"binary tree\", \"linked list\", ect.), such that \uD835\uDC53 : \uD835\uDC62 → {\uD835\uDC58\uD835\uDC56 |\uD835\uDC58\uD835\uDC56 ∈ \uD835\uDC3E, \uD835\uDC56 < \uD835\uDC41 }."
    }, {
      "heading" : "2.2 System Architecture",
      "text" : "The architecture of our proposed knowledge concept recommendation system, ACKRec, is shown in Figure 2. It consists of the following components:\n• Feature Extraction. By using the data collected from the MOOCs, we first extract content information as content feature from the knowledge concepts’ name, and then analyze various relationships (e.g., \uD835\uDC50\uD835\uDC5C\uD835\uDC5B\uD835\uDC50\uD835\uDC52\uD835\uDC5D\uD835\uDC61 − \uD835\uDC63\uD835\uDC56\uD835\uDC51\uD835\uDC52\uD835\uDC5C and \uD835\uDC50\uD835\uDC5C\uD835\uDC5B\uD835\uDC50\uD835\uDC52\uD835\uDC5D\uD835\uDC61 − \uD835\uDC50\uD835\uDC5C\uD835\uDC62\uD835\uDC5F\uD835\uDC60\uD835\uDC52 relations) among different types of entities (e.g., knowledge concept, video, course) to describe the knowledge concept. Similarly, we also generate the concept features and context feature for the user. (See Section 3.1 for details regarding feature extraction.) • Meta-path Selection. Based on the features extracted from the data, in this module we construct a structural HIN to model the relationships among different types of entities, and then select different meta-paths from the HIN to depict the relatedness over knowledge concept (i.e., with different meanings). For example, if two different users enrolled in the same course, we brings an edge between two users. (See Section 3.2 for details regarding the meta-path builder on HIN.)\n• Representation Learning ofHeterogeneous Entities.Based on the meta-paths constructed in the previous step, a representation learning model is proposed to learn the lowdimensional representations of the entities in a heterogeneous view. The model is capable of capturing the structural correlations between heterogeneous entities. Specifically, we leverage the selected meta-paths to guide the entity representation learning via graph convolutional networks. Later, we utilize the attention mechanism to adaptively fuse the learned entity representations from different meta-paths. (See Section 3.3 for details regarding our proposed model ACKRec .) • Rating Prediction. After generating the low-dimensional representations of users and knowledge concepts, the dense vectors of entities are fed to an extended matrix factorization to learn the parameters of the model. Moreover, we predict users’ interests in the unclicked knowledge concepts base on the user-item (student-knowledge concept) rating matrix."
    }, {
      "heading" : "3 PROPOSED METHOD",
      "text" : "In this section, we introduce the details of how we learn the representation of knowledge concepts and users based on the generated content feature and context feature, and how we perform knowledge concept recommendation based on the learned representations."
    }, {
      "heading" : "3.1 Feature Extraction",
      "text" : "3.1.1 Content Feature. In general, names of knowledge concepts are almost a generalization of knowledge concepts (e.g., “c++,” “binary tree,” “linked list”), which contains rich semantic information. Hence, we generate the word embedding of the name of the knowledge concept and use it as content feature for knowledge concept. Specifically, we use Word2vector [18] to generate the word embedding. For the user concept, we generate the content feature in a similar way.\n3.1.2 Context Feature. Content feature such as word embedding of knowledge concept names can be used to represent information of a knowledge concept. Besides, there exist rich context information, such as relationships between different entities in the network structure (e.g., user: 207256 watched video: v_9e77179 and video: v_1a9aa686; this behavior implies a relation between two videos). To include these complex relationships among different types of entities, we further model the context information as the feature. Specifically, we consider the following relationships in a user learning activities.\n• \uD835\uDC45\uD835\uDC621 : Based on the data of users’ online learning behaviors, we build the user-click-knowledge concept matrix A\uD835\uDC621 , where each element \uD835\uDC50\uD835\uDC56, \uD835\uDC57 ∈ {0, 1} implies that a user \uD835\uDC56 clicked a knowledge concept \uD835\uDC57 during his learning activities. • \uD835\uDC45\uD835\uDC622 : To describe the relation between a user and a course, we generate the user-learn-course matrix A\uD835\uDC622 , where each element \uD835\uDC59\uD835\uDC56, \uD835\uDC57 ∈ {0, 1}. It indicates that a user \uD835\uDC56 is taking a course \uD835\uDC57 . • \uD835\uDC45\uD835\uDC623 : Similarly, we generate the user-watch-videomatrixA \uD835\uDC62 3 ,\nwhere each element \uD835\uDC64\uD835\uDC56, \uD835\uDC57 ∈ {0, 1} denotes that a user \uD835\uDC56 has watched a video \uD835\uDC57 .\n• \uD835\uDC45\uD835\uDC624 : To describe the behavior that a user is taking a course, which is taught by a teacher, we generate the user-learncourse-taught by-teacher matrix A\uD835\uDC624 , where element \uD835\uDC61\uD835\uDC56, \uD835\uDC57 ∈ {0, 1} denotes that a user \uD835\uDC56 is taking a course taught by a teacher \uD835\uDC57 .\nWe generate these relationship to describe the user related interactions in the heterogeneous information network. For knowledge concepts, we also discover a number of knowledge concepts related relationships. For example, the relation knowledge conceptincluded by-video denotes that a knowledge concept is included in a video, and the relation knowledge concept-involved-course indicates that a knowledge concepts is covered in a course."
    }, {
      "heading" : "3.2 Meta-path Based Relationship",
      "text" : "To model different types of entities and their complex relationships in a proper manner, we first describe how to utilize a HIN to depict users, knowledge concepts, and corresponding heterogeneous relations among them. Before proceeding to our approach, we first introduce some related concepts.\nDefinition 1. Heterogeneous information network (HIN) [23]. A HIN is denoted as G = {V, E} consisting of an object set V and a link set E. A HIN is also associated with an object type mapping function \uD835\uDF19 : V → N and a link type mapping function \uD835\uDF11 : E → R. N and R denote the sets of the predefined object and link types, where |N | + |R| > 2.\nIn this study, wemodel theMOOCs data as the a HIN. Specifically, the constructed HIN includes five entities (i.e., user (U), course (C), video (V), teacher (T), knowledge concept (K) as shown in Figure 2) and a series of relationships among them (e.g., \uD835\uDC45\uD835\uDC621 , \uD835\uDC45 \uD835\uDC62 2 , \uD835\uDC45 \uD835\uDC62 3 , \uD835\uDC45 \uD835\uDC62 4 ). Based on the constructed HIN, we can obtain the network schema, where their definitions are as followed.\nDefinition 2. Network schema [28]. The network schema is denoted as S = (N ,R). It is a meta-template for an information network G = {V, E} with the object type mapping \uD835\uDF19 : V → N\nand the link type mapping \uD835\uDF11 : E → R, which is a directed graph defined over object types N with edges as relations from R.\nWe defined our network schema in Figure 3, which represents semantic and relation information comprehensively in the MOOCs dataset. Based on the the network schema, we can discover the semantic paths between a pair of entities, which is called metapath.\nDefinition 3.Meta-path [5]. Ameta-path is defined on a network\nschema S = (N ,R) and is denoted as a path in the form of \uD835\uDC411 \uD835\uDC451→ \uD835\uDC412 \uD835\uDC452→ · · · \uD835\uDC45\uD835\uDC59→ \uD835\uDC41\uD835\uDC59+1 (abbreviated as\uD835\uDC411, \uD835\uDC412, · · ·\uD835\uDC41\uD835\uDC59+1), which describes a composite relation R = R1 ◦ \uD835\uDC452 · · · ◦ \uD835\uDC45\uD835\uDC59 between object \uD835\uDC411 and \uD835\uDC41\uD835\uDC59+1 , where ◦ denotes the composition operator on relations.\nTypical meta-paths between two users can be defined as follows:\n\uD835\uDC48 click−→ \uD835\uDC3E click −1 −→ \uD835\uDC48 , which means that two different users are related because they click the same knowledge concept; \uD835\uDC48 learn−→ \uD835\uDC36 taught by −→ \uD835\uDC47 taught by −1 −→ \uD835\uDC36 learn −1 −→ \uD835\uDC48 , which denotes that two users are related through paths containing different courses taught by the same teacher. Notice that, the potential meta-paths induced from the HIN can be infinite, but not everyone is relevant and useful for the specific task of interest. Fortunately, there are some algorithms [2] proposed recently for automatically selecting the meta-paths for particular tasks. Given all the concepts about the HIN, we now proceed to our problem of Heterogeneous Information Network Representation Learning. The notations we will use throughout the article are summarized in Table 2."
    }, {
      "heading" : "3.3 Attention-based Graph Convolutional Networks for HIN Representation Learning",
      "text" : "After the content features and context features are obtained, we feed the entity content features to the graph convolutional networks to learn the latent entity representation. Given the heterogeneous information network G = (V, E) associated with a set of meta-paths MP = { \uD835\uDC40\uD835\uDC431, \uD835\uDC40\uD835\uDC432, · · ·\uD835\uDC40\uD835\uDC43 ∥\uD835\uDC40\uD835\uDC43 ∥ } and the corresponding adjacency\nTable 2: Notations and explanations.\nNotation Explanation\nG heterogeneous information network V set of entities E set of relations S network schema\nMP set of meta-paths A, D̃ adjacency matrix and degree matrix\nbase different meta-paths X the features matrix of entities h\uD835\uDC59 \uD835\uDC59 − \uD835\uDC61ℎ layer of entity representation W\uD835\uDC59 weights of \uD835\uDC59 − \uD835\uDC61ℎ GCN layer e the representation of entities \uD835\uDEFC the weights of meta-paths x\uD835\uDC62 the latent factors of user \uD835\uDC62 y\uD835\uDC58 the latent factors of knowledge concept \uD835\uDC58 \uD835\uDC5A,\uD835\uDC5B the number of users and knowledge concepts in MOOCs dataset \uD835\uDC51 the representation dimension \uD835\uDC37 the number of latent factors r\uD835\uDC62,\uD835\uDC58 the true rating of user \uD835\uDC62 to knowledge concept \uD835\uDC58 r̂\uD835\uDC62,\uD835\uDC58 predicted rating of user \uD835\uDC62 to knowledge concept \uD835\uDC58\nt the matrix to integrate the e \uD835\uDC62 and e\uD835\uDC58 be in the same space \uD835\uDEFD the tuning parameter\nFigure 3: Network schema for HINs in MOOCs. The MOOCs include user, course, video, teacher and knowledge concept. Different types line indicate different type of relationships among different types entities.\nmatrixA = { A1,A2, · · ·A |\uD835\uDC40\uD835\uDC43 | } . |\uD835\uDC40\uD835\uDC43 | denotes the number of metapaths. We adopt a multiple-layer graph convolutional network (GCN) with the following layer-wise propagation rule:\nh(\uD835\uDC59+1) = \uD835\uDF0E ( Ph\uD835\uDC59W\uD835\uDC59 ) , (1)\nHere we remove the subscripts of meta-path indicator, user indicator and knowledge concept indicator for all the graph related symbols for simplification. h(\uD835\uDC59+1) denotes the new representation of an entity. In particular, h0 is the content feature we have extracted at the first step. P = D̃−1/2ÃD̃−1/2, Ã = A+I is the adjacency matrix corresponds to a specific meta-path with self-connections and I is the identity matrix, D̃ = diag(Ã1), and 1 is the all-ones vector. Here \uD835\uDF0E (·) is defined as \uD835\uDC45\uD835\uDC52\uD835\uDC3F\uD835\uDC48 (·), where \uD835\uDC45\uD835\uDC52\uD835\uDC3F\uD835\uDC48 (\uD835\uDC4E) = max {0, \uD835\uDC4E} is an entry-wise rectified linear activation function. \uD835\uDC59 is the layer number indicator.W\uD835\uDC59 is the shared trainable weight matrix for all the entities at layer \uD835\uDC59 . Weight sharing is beneficial since it is statistically and computationally more efficient than the traditional embedding\nmethods. With the help of the weight sharing, the model can be well regularized and the number of parameters is significantly reduced.\nThe information propagation process of content or context can be regarded as a Markov process converges to a stationary distribution P ∈ R\uD835\uDC5B×\uD835\uDC5B and the row \uD835\uDC56 indicating a likelihood of spreading from the knowledge concept \uD835\uDC56 . This stationary distribution of the diffusion process is proven to have a closed form solution. When considering the 1-step truncation of the diffusion process, the propagation layer computes the weighted sum of the contexts’ current representation. We set P0 = P1 = P2 = D̃−1/2ÃD̃−1/2, and the three propagation layers are defined as follows:\nh1 = \uD835\uDC45\uD835\uDC52\uD835\uDC3F\uD835\uDC48 ((P0X)W0), (2)\nh2 = \uD835\uDC45\uD835\uDC52\uD835\uDC3F\uD835\uDC48 ((P1H1)W1), (3)\nh3 = \uD835\uDC45\uD835\uDC52\uD835\uDC3F\uD835\uDC48 ((P2H2)W2), (4)\ne\uD835\uDC40\uD835\uDC43 = h3, (5)\nwhere e\uD835\uDC40\uD835\uDC43 ∈ R\uD835\uDC51 is the final representations of an entity. Going through the three propagation layers, we learn the rep-\nresentations for each meta-path. However, different meta-paths should not be considered equally. To address this problem, we utilize the attention mechanism to fuse the representation of entities learned under the guide of different meta-paths and generate the attentional joint representation. Specifically, we learn the attention weights for different meta-paths as follows:\ne = |\uD835\uDC40\uD835\uDC43 |∑ \uD835\uDC56=1 att ( e\uD835\uDC40\uD835\uDC43\uD835\uDC56 ) e\uD835\uDC40\uD835\uDC43\uD835\uDC56 , (6)\nHere, att(·) indicates the attention function. e indicates final representation of an entity, which has integrated the attention weights of different meta-paths. Since in this problem, we mainly focus on the user and knowledge concept. The target entity is user or knowledge concept. Formally, given the corresponding representation e\uD835\uDC40\uD835\uDC43\uD835\uDC56 for each meta-path\uD835\uDC40\uD835\uDC43\uD835\uDC56 ∈ {\uD835\uDC40\uD835\uDC431, \uD835\uDC40\uD835\uDC432, · · · , \uD835\uDC40\uD835\uDC43 |MP |}, we define the attention weights as follows:\n\uD835\uDEFC\uD835\uDC40\uD835\uDC43\uD835\uDC56 = exp\n( \uD835\uDF0E (ae\uD835\uDC40\uD835\uDC43\uD835\uDC56 ) )∑ \uD835\uDC57 ∈ |\uD835\uDC40\uD835\uDC43 | exp ( \uD835\uDF0E (ae\uD835\uDC40\uD835\uDC43 \uD835\uDC57 )\n) , (7) where e\uD835\uDC40\uD835\uDC43\uD835\uDC56 is the representation of an entity based on the target meta-path, and e\uD835\uDC40\uD835\uDC43 \uD835\uDC57 denotes the representation based on the other meta-paths. a denotes a trainable attention vector, and \uD835\uDF0E denotes the nonlinear gating function. We formulate a feed-forward neural network to compute the correlation between one meta-path and the other meta-paths. This correlation is normalized by a softmax function. The attentional joint representation can be represented as follows:\ne = |\uD835\uDC40\uD835\uDC43 |∑ \uD835\uDC56=1 \uD835\uDEFC\uD835\uDC40\uD835\uDC43\uD835\uDC56 e\uD835\uDC40\uD835\uDC43\uD835\uDC56 , (8)\nwhere \uD835\uDEFC = ∑ |\uD835\uDC40\uD835\uDC43 | \uD835\uDC56=1 \uD835\uDEFC\uD835\uDC40\uD835\uDC43\uD835\uDC56 , and e denotes the final representation ofknowledge concepts. The meta-path attention allows us to better infer the importance of different meta-paths by leveraging their correlations and learning the entities representations.The algorithm framework is shown in Algorithm 1.\nAlgorithm 1 Generating the representations of entities. Input:\nthe given meta-paths set\uD835\uDC40\uD835\uDC43 ; the corresponding adjacency matrix set A; the features matrix x of target entities; the dimension of representations \uD835\uDC51 .\nOutput: The representations of target entities e.\n1: Initialize e; 2: \uD835\uDC5D\uD835\uDC4E\uD835\uDC61ℎ\uD835\uDC60 ⇐ []; 3: for each\uD835\uDC40\uD835\uDC43\uD835\uDC56 ∈ \uD835\uDC40\uD835\uDC43 do 4: Calculate Ã, D̃ and P according to Eq.1; 5: h0 ⇐ x; 6: Calculate h1 by Eq.2; 7: Calculate h2 by Eq.3; 8: Calculate h3 by Eq.4; 9: Add h3 to \uD835\uDC5D\uD835\uDC4E\uD835\uDC61ℎ\uD835\uDC60 ; 10: end for 11: Generate e by Eq.8; 12: return e."
    }, {
      "heading" : "3.4 Matrix Factorization for Knowledge Concept Recommendation",
      "text" : "So far, we have studied how to extract content feature and context feature of users and knowledge concepts, respectively. Using attention-based GCNs for representation learning, we can obtain the representation of knowledge concepts e\uD835\uDC58 , and the representation of users e\uD835\uDC62 . In this part, we propose to utilize an extended matrix factorization (MF) based method to perform knowledge concept recommendation for the users. We consider the number of times users click on the knowledge concepts as a rating matrix. The rating of a user on a knowledge concept can be defined as follows:\nr̂\uD835\uDC62,\uD835\uDC58 = x ⊤ \uD835\uDC62 y\uD835\uDC58 , (9)\nwhere x\uD835\uDC62 ∈ R\uD835\uDC37×\uD835\uDC5A indicates latent factors of the user and y\uD835\uDC58 ∈ R\uD835\uDC37×\uD835\uDC5B denotes latent factors of the knowledge concept. \uD835\uDC37 is the number of latent factors. And\uD835\uDC5A and \uD835\uDC5B are the number of the user entities and knowledge concept entities. Because we have also obtained the representations for user u and knowledge concept k, we further feed them into the rating predictor as follows:\nr̂\uD835\uDC62,\uD835\uDC58 = x ⊤ \uD835\uDC62 y\uD835\uDC58 + \uD835\uDEFD\uD835\uDC62 · e\uD835\uDC62⊤t\uD835\uDC58 + \uD835\uDEFD\uD835\uDC58 · t\uD835\uDC62⊤e\uD835\uDC58 , (10)\nwhere e\uD835\uDC62 and e\uD835\uDC58 are the representation of users and knowledge concepts. The trainable parameters t\uD835\uDC62 and t\uD835\uDC58 are introduced to make sure e\uD835\uDC62 and e\uD835\uDC58 be in the same space. \uD835\uDEFD\uD835\uDC62 and \uD835\uDEFD\uD835\uDC58 are the tuning parameters. The purpose is to achieve a suitable ratings prediction, so the object function of MF is defined as follows:\nmin \uD835\uDC48 ,\uD835\uDC3E 1 \uD835\uDC5A × \uD835\uDC5B \uD835\uDC5B∑ \uD835\uDC62=1 \uD835\uDC5A∑ \uD835\uDC58=1 ( r\uD835\uDC62,\uD835\uDC58 − r̂\uD835\uDC62,\uD835\uDC58 )2 . (11)\nWe further add regularization terms to the function. Therefore, the final objective function is formulated as follows:\nmin \uD835\uDC48 ,\uD835\uDC3E 1 \uD835\uDC5A × \uD835\uDC5B \uD835\uDC5B∑ \uD835\uDC62=1 \uD835\uDC5A∑ \uD835\uDC58=1 ( r\uD835\uDC62,\uD835\uDC58 − r̂\uD835\uDC62,\uD835\uDC58 )2 + \uD835\uDF06( | |x\uD835\uDC62 | |2 +||y\uD835\uDC58 | |2 + ||t\uD835\uDC62 | |2 + ||t\uD835\uDC58 | |2),\n(12)\nwhere \uD835\uDF06 is the regularization parameter. We then utilize the sto-\nchastic gradient descent algorithm to optimize the local minimum of the final objective function."
    }, {
      "heading" : "4 EXPERIMENTS",
      "text" : ""
    }, {
      "heading" : "4.1 Datasets",
      "text" : "We collected real world data from \uD835\uDC4B\uD835\uDC62\uD835\uDC52\uD835\uDC61\uD835\uDC4E\uD835\uDC5B\uD835\uDC54\uD835\uDC4B MOOC platform. We select enrollment behaviors occurring between October 1st, 2016 and December 30th, 2017 as the training set, and those occurring between January 1st, 2018 and March 31st, 2018 as the test set. Each instance in the training set or test set is a sequence representing a user’s history of click behaviors. In the training process, for each sequence in the training data, we treat the last clicked knowledge concept as the target and the remainders as the past behaviors. Moreover, for each positive instance, we randomly generate one negative instance to replace the target knowledge concept. In the testing process, we treat each enrolled knowledge concept in the test set as the target knowledge concept; the corresponding knowledge concepts of the same user in the training set are treated as the sequence representing the history of clicked knowledge concepts. To evaluate the recommendation performance, each positive instance in the test set is paired with 99 randomly sampled negative instances, and outputs prediction scores for the 100 instances (1 positive and 99 negatives)[7]."
    }, {
      "heading" : "4.2 Evaluation Metrics",
      "text" : "We evaluate all the methods in terms of the widely used metrics, including Hit Ratio of top-K items (HR@K) and Normalized Discounted Cumulative Gain of top-K items (NDCG@K) [12]. HR@K is a recall-based metric that measures the percentage of ground truth instances that are successfully recommended in the top K, and NDCG@K is a precision-based metric that accounts for the predicted position of the ground truth instance. We set K to 5, 10, and 20, and calculate all metrics for every 100 instances (1 positive plus 99 negatives). The final recommendation list for user \uD835\uDC62 is \uD835\uDC45\uD835\uDC62 = { \uD835\uDC5F1\uD835\uDC62 , \uD835\uDC5F 2 \uD835\uDC62 , · · · , \uD835\uDC5F\uD835\uDC3E\uD835\uDC62 } . \uD835\uDC5F \uD835\uDC56\uD835\uDC62 denotes rank at the \uD835\uDC56 − \uD835\uDC61ℎ position in \uD835\uDC45\uD835\uDC62 based on the predict score. \uD835\uDC47\uD835\uDC62 is the interacted items set of user \uD835\uDC62 in the test data, and \uD835\uDC41 is the total number of users in our test data.\n\uD835\uDC3B\uD835\uDC45@\uD835\uDC3E = 1 \uD835\uDC41 ∑ \uD835\uDC62 \uD835\uDC3C ( |\uD835\uDC45\uD835\uDC62 ∩\uD835\uDC47\uD835\uDC56 |), (13)\nwhere, \uD835\uDC3C (\uD835\uDC65) is an indicator function whose value is 1 when \uD835\uDC65 > 0 and 0 otherwise. The large the value of \uD835\uDC3B\uD835\uDC45@\uD835\uDC3E the better the performance of the model.\n\uD835\uDC41\uD835\uDC37\uD835\uDC36\uD835\uDC3A@\uD835\uDC3E = 1 \uD835\uDC4D \uD835\uDC37\uD835\uDC36\uD835\uDC3A@\uD835\uDC3E = 1 \uD835\uDC4D \uD835\uDC3E∑ \uD835\uDC57=1 2\uD835\uDC3C ( | {\uD835\uDC5F \uD835\uDC57 \uD835\uDC62 }∩\uD835\uDC47\uD835\uDC62 |) − 1 \uD835\uDC59\uD835\uDC5C\uD835\uDC542 ( \uD835\uDC57 + 1) , (14)\nwhere\uD835\uDC4D is a normalization constant which is themaximumpossible value of \uD835\uDC37\uD835\uDC36\uD835\uDC3A@\uD835\uDC3E . We also use the mean reciprocal rank (MRR). From the definition, we can see that a larger MRR value indicates a better performance of the model[7].\nMRR = 1 \uD835\uDC41 \uD835\uDC41∑ \uD835\uDC56=1 1 rank\uD835\uDC56 , (15)\nwhere \uD835\uDC5F\uD835\uDC4E\uD835\uDC5B\uD835\uDC58\uD835\uDC56 refers to the rank position of the one positive instance for the \uD835\uDC56 − \uD835\uDC61ℎ user in 100 instances. In addition, we also add the area under the curve of ROC (AUC) as a metric."
    }, {
      "heading" : "4.3 Detailed Analysis of the Proposed Approach",
      "text" : "4.3.1 Evaluation of Different Meta-paths Combination. In this part of the experiments, we analyze how selection of meta-path combinations affect the performance of ACKRec , since a small number of high-quality meta-paths can lead to considerable performance [23]. We consider both single meta-path and their combinations. Specifically, We select four types of meta-paths to characterize the relatedness between pair of users, including \uD835\uDC40\uD835\uDC431: \uD835\uDC48 → \uD835\uDC3E\n-1−→ \uD835\uDC48 , \uD835\uDC40\uD835\uDC432: \uD835\uDC48 → \uD835\uDC36 -1−→ \uD835\uDC48 , \uD835\uDC40\uD835\uDC433: \uD835\uDC48 → \uD835\uDC49 -1−→ \uD835\uDC48 , and \uD835\uDC40\uD835\uDC434: \uD835\uDC48 → \uD835\uDC36 → \uD835\uDC47 -1−→ \uD835\uDC36 -1−→ \uD835\uDC48 . We also select three types of meta-path to characterize the relatedness between pair of knowledge concepts, including \uD835\uDC3E ↔ \uD835\uDC3E , \uD835\uDC3E → \uD835\uDC48 -1−→ \uD835\uDC58 and \uD835\uDC3E → \uD835\uDC36 -1−→ \uD835\uDC3E . To analyze the impact of different combinations in a small number of meta-paths, we use all three meta-paths to model the knowledge concept and study the performance with single user related meta-path and their combinations. The experiments results are shown in Table 3. From Table 3, we can find that each single meta-path (i.e., \uD835\uDC40\uD835\uDC431, \uD835\uDC40\uD835\uDC432, \uD835\uDC40\uD835\uDC433,\uD835\uDC40\uD835\uDC434) exhibits different performance, where the performance ranking is\uD835\uDC40\uD835\uDC433 >\uD835\uDC40\uD835\uDC431 >\uD835\uDC40\uD835\uDC432 >\uD835\uDC40\uD835\uDC434, and the combinations of single meta-paths follow the same tendency (e.g., the performance of \uD835\uDC40\uD835\uDC431&\uD835\uDC40\uD835\uDC433 > \uD835\uDC40\uD835\uDC431&\uD835\uDC40\uD835\uDC432, \uD835\uDC40\uD835\uDC431&\uD835\uDC40\uD835\uDC432&\uD835\uDC40\uD835\uDC433 > \uD835\uDC40\uD835\uDC431&\uD835\uDC40\uD835\uDC432&\uD835\uDC40\uD835\uDC434). This illustrates that different meta-paths indicate different relations Further, although the growth of performance is not quite obvious, we can observe that the combination including more metapaths will exhibit better performance, and the best performance is achieved by combining all four meta-paths.\n4.3.2 Evaluation of Model Parameters. In a matrix factorizationbased method, the number of latent factors is an important parameter. Therefore, we present a comparison of the performance obtained with different numbers of latent factors. As shown in Figure 4, we select the metrics \uD835\uDC3B\uD835\uDC45@\uD835\uDC3E , \uD835\uDC41\uD835\uDC37\uD835\uDC36\uD835\uDC3A@\uD835\uDC3E ,\uD835\uDC40\uD835\uDC45\uD835\uDC45, and \uD835\uDC34\uD835\uDC48\uD835\uDC36 to show how the performance of ACKRec changes with changes in the number of latent factors. We tune the number from 10 to 40 in increments of 10. We can see the increase in performance becomes\nflat as the number of latent factors increases. We find that using 30 latent factors can produce optimal performance.\nAfter setting the number of latent factors as 30, we study the dimension settings of the entities representation. The experiment results are shown in Figure 5. We conducted the experiments using different numbers of dimensions (i.e., 20, 50, 100, 150, 200), and found that optimal performance was achieved with 100. Therefore, both the user and the knowledge concepts are represented as 100- dimensional vectors. The results also show that the representation of user and knowledge concepts in the heterogeneous information network is an important factor in improving the performance of the recommendation task.\nWe also examine how the number of GCN layers influence the performance of the model. As shown in Figure 6, we can clearly see that the performance of the proposed model changes with different numbers of layers (i.e., 1, 2, 3, and 4). It illustrates that the optimal number of GCN layers is around 3."
    }, {
      "heading" : "4.4 Baseline Methods",
      "text" : "To evaluate the performance of the proposed approach, we consider various of baseline methods as follows:\n• \uD835\uDC35\uD835\uDC43\uD835\uDC45 [22]: It optimizes a pairwise ranking loss for the recommendation task in a Bayesian manner. • \uD835\uDC40\uD835\uDC3F\uD835\uDC43 [8]: It applies amulti-layer perceptron (MLP) to a pair of user representations and corresponding knowledge concept representations to learn the probability of recommending a knowledge concept to the user. • \uD835\uDC39\uD835\uDC40 [21]: This is a principled approach that can easily incorporate any heuristic features. However, to ensure a fair comparison to other methods, we only use the representations of users and knowledge concepts. • \uD835\uDC39\uD835\uDC3C\uD835\uDC46\uD835\uDC40 [14]: This is an item-to-item collaborative filtering algorithm that conducts recommendations based on the average embeddings of all behavior histories and the embeddings of the target knowledge concept. • \uD835\uDC41\uD835\uDC34\uD835\uDC3C\uD835\uDC46 [7]: This is also an item-to-item collaborative filtering algorithm, but distinguishes the weights of different online learning behaviors using an attention mechanism method. • \uD835\uDC41\uD835\uDC34\uD835\uDC46\uD835\uDC45 [16]: This is an improved GRU [9] model that estimates an attention coefficient for each behavior history based on the corresponding hidden vector output by GRU. And GRU is a gated recurrent unit model which receives a list of historical behavior as input. • \uD835\uDC5A\uD835\uDC52\uD835\uDC61\uD835\uDC4E\uD835\uDC5D\uD835\uDC4E\uD835\uDC61ℎ2\uD835\uDC63\uD835\uDC52\uD835\uDC50 [3]: This is a meta-paths based representation method in heterogeneous information network by random walk and skip-gram. With the same meta-path of user and knowledge concept inACKRecmodel, we usemetapath2vec to generate the representations of users and knowledge concepts with the same dimension of ACKRec. • \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50ℎ : A variant of ACKRec , which ignores the heterogeneity of entities in the heterogeneous information network. We regenerate the adjacency matrix to represent the relationship between different entities. • \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50\uD835\uDC50 : This can be viewed as a variant of ACKRec without the attention mechanism method, and concatenates different meta-paths together.\nTable 4: Results obtained with different models using the MOOC dataset.\nHR@1 HR@5 HR@10 HR@20 NDCG@5 NDCG@10 NDCG@20 MRR AUC\n\uD835\uDC35\uD835\uDC43\uD835\uDC45 0.1699 0.4633 0.6246 0.7966 0.3217 0.3736 0.4151 0.3156 0.8610 \uD835\uDC40\uD835\uDC3F\uD835\uDC43 0.0660 0.3680 0.5899 0.7237 0.2231 0.2926 0.3441 0.2146 0.8595 \uD835\uDC39\uD835\uDC40 0.2272 0.4057 0.5867 0.7644 0.3655 0.3968 0.3930 0.3067 0.8574 \uD835\uDC39\uD835\uDC3C\uD835\uDC46\uD835\uDC40 0.1410 0.5849 0.7489 0.7610 0.3760 0.4203 0.4279 0.3293 0.8532 \uD835\uDC41\uD835\uDC34\uD835\uDC3C\uD835\uDC46 0.078 0.4112 0.6624 0.8649 0.2392 0.3201 0.3793 0.2392 0.8863 \uD835\uDC41\uD835\uDC34\uD835\uDC46\uD835\uDC45 0.1382 0.4437 0.6215 0.7475 0.2364 0.3172 0.3821 0.2117 0.8215 \uD835\uDC5A\uD835\uDC52\uD835\uDC61\uD835\uDC4E\uD835\uDC5D\uD835\uDC4E\uD835\uDC61ℎ2\uD835\uDC63\uD835\uDC52\uD835\uDC50 0.2476 0.5983 0.7598 0.8689 0.4194 0.4422 0.4602 0.3873 0.8909 \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50ℎ 0.2092 0.5388 0.7139 0.8665 0.3783 0.4348 0.4738 0.3634 0.8927 \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50\uD835\uDC50 0.2457 0.5917 0.7542 0.8778 0.4216 0.4763 0.5079 0.4026 0.8974 \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50\uD835\uDC60 0.2195 0.5917 0.7476 0.8553 0.4154 0.4659 0.4933 0.3891 0.8848 \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50\uD835\uDC5F 0.2588 0.6427 0.7911 0.8909 0.4591 0.5074 0.5329 0.4285 0.9035 \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50\uD835\uDC60+\uD835\uDC5F 0.2645 0.6470 0.8122 0.9255 0.4635 0.5170 0.5459 0.4352 0.9232\nFigure 6: Performance of different number of layers. • \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50\uD835\uDC60 : Content feature-based ACKRec . The input of this model is just the content feature of entities.\n• \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50\uD835\uDC5F : Context feature-based ACKRec . Similar to the model \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50\uD835\uDC60 , the context feature of entities in MOOCs are fed into this model. • \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50\uD835\uDC60+\uD835\uDC5F : The proposed method, which combines heterogeneous context feature and content feature of entities to maximally depict the entities in the HIN. For the MOOCs dataset, we split the user history behavior data into a training set and a test set. The training time for our method and the baseline methods are followed: BPR 2hrs,MLP 2hrs, FM 2.5hrs, FISM 4hrs, NAIS 3.5 hrs, NASR 4.5 hrs, metapath2vec 5.5 hrs, ACKRec (our method) 4.5 hrs. As shown in Table 4, we compare ACKRec with other machine learning methods. For the HIN based methods, We select meta-paths combination given the best performance in Section 3.1.2. As shown in Table 4, HIN based methods outperform all the other methods. It indicates the importance of the heterogeneity in MOOCs data Furthermore, the results show that\uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50\uD835\uDC60+\uD835\uDC5F , which integrates content feature and context\nfeature, gives the best performance. Different from metapath2vec [3] generating representations based on random walk strategy and skip-gram method to generate representations of nodes, our model utilizes the graph convolutional networks to learn representations and adaptive attention mechanism to learn the different meta-paths weights and can better capture the heterogeneity within the data.\nIn addition, compared with \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50ℎ , it obviously demonstrates that ACKRec utilizing the meta-paths based method on the HIN can more effectively capture the heterogeneous relationships. Compared with\uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50\uD835\uDC50 , we can see that adaptively fuse representation learned in different meta-path is better than simple concatenation, since different meta-path has different importance corrsponds to the task. Moreover, compared with \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50\uD835\uDC60 and \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50\uD835\uDC5F , it demonstrates that methods utilizing either content feature or context feature alone will lose information needed for the representation of entities; thus, they cannot comprehensively depict the feature of users and knowledge concepts in MOOCs. The final method \uD835\uDC34\uD835\uDC36\uD835\uDC3E\uD835\uDC45\uD835\uDC52\uD835\uDC50\uD835\uDC60+\uD835\uDC5F , which uses adaptive weights and the meta-path based approach over the HIN, can integrate rich content feature of entities and structural relations between different types of entities in a more comprehensive and effective manner, and achieves the best performance."
    }, {
      "heading" : "4.5 Case Study",
      "text" : "In this part, we conduct one case to demonstrate the effectiveness of our proposed method ACKRec . We randomly select a student:2481307 and obtain two top 10 recommend lists based on single meta-path\uD835\uDC40\uD835\uDC432 and combined meta-paths\uD835\uDC40\uD835\uDC431−\uD835\uDC40\uD835\uDC432−\uD835\uDC40\uD835\uDC433−\uD835\uDC40\uD835\uDC434, respectively. As shown in Figure 7, we can intuitively observe that the proposed model generates different results with different reality conditions. With more meaningful relationships among user and knowledge concept, the recommend list will contain more related knowledge concepts for the corresponding user. For example, from the click history list of \uD835\uDC60\uD835\uDC61\uD835\uDC62\uD835\uDC51\uD835\uDC52\uD835\uDC5B\uD835\uDC61 : 2481307, we know that the student is especially interested in the field of computer network, the result of meta-paths\uD835\uDC40\uD835\uDC431−\uD835\uDC40\uD835\uDC432−\uD835\uDC40\uD835\uDC433−\uD835\uDC40\uD835\uDC434 shows that theACKRec can capture the student’s interests of knowledge concept, matching his real next click, asynchronous transfer mode, shown in blue. The other recommendations such as protocol data unit, switched telephone network, switch, and IPv4 are also highly related. In particularly, the recommended results will be significantly different for different meta-paths."
    }, {
      "heading" : "5 RELATEDWORK",
      "text" : ""
    }, {
      "heading" : "5.1 Graph Neural Network in Heterogeneous Information Network",
      "text" : "Graphs play a crucial role in modern machine learning[5, 6]. Recently, graph neural networks[1, 4, 15, 26, 30, 31, 36] have become recurrent topics in machine learning, and both have broad applicability. However, in the real world, the graphs are usually heterogeneous. There are a few attempts heterogeneous information network setting. Wang et al. [28] proposed DeepHGNN, an attentional heterogeneous graph neural network model to learn from the heterogeneous program behavior graph to guide the reidentification process. Wang et al. [29] presented HAGNN, a Hierarchical Attentional Graph Neural Encoder and used it for program behavior\ngraph analysis. Additionally, the GEM[17] model, a heterogeneous graph neural network approach for detecting malicious accounts at Alipay, has been presented. Unlike these approaches, our proposed model utilizes attentional graph convolutional networks for the representations of users and knowledge concepts in heterogeneous information networks."
    }, {
      "heading" : "5.2 Recommendation System in",
      "text" : "Heterogeneous Information Network Some information recommendation models are based on heterogeneous information networks. [19] proposed Heaters, a graph-based model, to solve the general recommendation problem in heterogeneous networks. Yu et al.[32] proposed to use meta-paths based latent features to represent the connectivity between users and items along with different types of paths. Additionally, Follow precious work, Shi et al. [10, 23, 24] proposed to use meta-path concept to mode the heterogeneous information in HIN. Different from previous methods, this study focuses on capture the representations of different types of entities on the heterogeneous information network and fuses themselves content feature of different types of entities and the structure features of entities in MOOCs data together for the recommendation task of the knowledge concept."
    }, {
      "heading" : "6 CONCLUSION",
      "text" : "In this work, we investigate the problem of the knowledge concept recommendation in MOOCs system, which is often overlooked by MOOCs recommendation system.We proposeACKRec , an end-toend graph neural network based approach that naturally incorporates rich heterogeneous context side information into knowledge concept recommendation. To make use of rich context information in a more natural and intuitive way, we model the MOOCs as a heterogeneous information network. We design an attention-based graph convolutional network to learn the representation of different entities via propagate context information under the guide of meta-path in an attentional way. With the help of proposed attention-based graph convolutional network, the users’ potential interests can be effectively explored and aggregated. Comprehensive experimental study on real data collected from XuetangX is\nconducted. The proposed approaches outperform the strong baseline. The promising experimental results illustrate the effectiveness of the proposed method."
    }, {
      "heading" : "7 ACKNOWLEDGMENTS",
      "text" : "This work is supported by NSF under grants III-1526499, III-1763325, III-1909323, CNS-1930941, by Science and Technology Project of the Headquarters of State Grid co., LTD under Grant No. 5700- 202055267A-0-0-0, and by NKPs under grants 2018YFC0830804. The authors also would like to thank XuetangX for data collection and supports."
    } ],
    "references" : [ {
      "title" : "FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling",
      "author" : [ "Jie Chen", "Tengfei Ma", "Cao Xiao" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2018
    }, {
      "title" : "Task-guided and path-augmented heterogeneous network embedding for author identification",
      "author" : [ "Ting Chen", "Yizhou Sun" ],
      "venue" : "In Proceedings of the Tenth ACM International Conference on Web Search and Data",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2017
    }, {
      "title" : "metapath2vec: Scalable representation learning for heterogeneous networks",
      "author" : [ "Yuxiao Dong", "Nitesh V Chawla", "Ananthram Swami" ],
      "venue" : "In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2017
    }, {
      "title" : "Convolutional Neural Network Architectures for Signals Supported on Graphs",
      "author" : [ "F. Gama", "A.G. Marques", "G. Leus", "A. Ribeiro" ],
      "venue" : "IEEE Transactions on Signal Processing 67,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2019
    }, {
      "title" : "A new model for learning in graph domains",
      "author" : [ "M. Gori", "G. Monfardini", "F. Scarselli" ],
      "venue" : "In Proceedings",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2005
    }, {
      "title" : "Representation Learning on Graphs: Methods and Applications",
      "author" : [ "William L. Hamilton", "Rex Ying", "Jure Leskovec" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2017
    }, {
      "title" : "NAIS: Neural Attentive Item Similarity Model for Recommendation",
      "author" : [ "Xiangnan He", "Zhankui He", "Jingkuan Song", "Zhenguang Liu", "Yu-Gang Jiang", "Tat-Seng Chua" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2018
    }, {
      "title" : "Session-based recommendations with recurrent neural networks",
      "author" : [ "Balázs Hidasi", "Alexandros Karatzoglou", "Linas Baltrunas", "Domonkos Tikk" ],
      "venue" : "arXiv preprint arXiv:1511.06939",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2015
    }, {
      "title" : "Leveraging metapath based context for top-n recommendation with a neural co-attention model",
      "author" : [ "Binbin Hu", "Chuan Shi", "Wayne Xin Zhao", "Philip S Yu" ],
      "venue" : "In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2018
    }, {
      "title" : "A matrix factorization technique with trust propagation for recommendation in social networks",
      "author" : [ "Mohsen Jamali", "Martin Ester" ],
      "venue" : "In Proceedings of the fourth ACM conference on Recommender systems",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2010
    }, {
      "title" : "IR evaluation methods for retrieving highly relevant documents",
      "author" : [ "Kalervo Järvelin", "Jaana Kekäläinen" ],
      "venue" : "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2000
    }, {
      "title" : "Guess You Like: Course Recommendation in MOOCs",
      "author" : [ "Xia Jing", "Jie Tang" ],
      "venue" : "In Proceedings of the International Conference on Web Intelligence (WI ’17)",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2017
    }, {
      "title" : "FISM: Factored Item Similarity Models for top-N Recommender Systems",
      "author" : [ "Santosh Kabbur", "Xia Ning", "George Karypis" ],
      "venue" : "In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD ’13)",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2013
    }, {
      "title" : "Kipf and MaxWelling",
      "author" : [ "N Thomas" ],
      "venue" : "arXiv preprint arXiv:1609.02907",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2016
    }, {
      "title" : "Neural Attentive Session-based Recommendation",
      "author" : [ "Jing Li", "Pengjie Ren", "Zhumin Chen", "Zhaochun Ren", "Tao Lian", "Jun Ma" ],
      "venue" : "In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, CIKM 2017,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2017
    }, {
      "title" : "Heterogeneous Graph Neural Networks for Malicious Account Detection",
      "author" : [ "Ziqi Liu", "Chaochao Chen", "Xinxing Yang", "Jun Zhou", "Xiaolong Li", "Le Song" ],
      "venue" : "In Proceedings of the 27th ACM International Conference on Information and Knowledge Management (CIKM ’18)",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2018
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2013
    }, {
      "title" : "A General Recommendation Model for Heterogeneous Networks",
      "author" : [ "T.N. Pham", "X. Li", "G. Cong", "Z. Zhang" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering 28,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2016
    }, {
      "title" : "Modeling and Predicting Learning Behavior in MOOCs",
      "author" : [ "Jiezhong Qiu", "Jie Tang", "Tracy Xiao Liu", "Jie Gong", "Chenhui Zhang", "Qian Zhang", "Yufei Xue" ],
      "venue" : "In Proceedings of the Ninth ACM International Conference on Web Search and Data Mining (WSDM ’16)",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2016
    }, {
      "title" : "Factorization Machines with libFM",
      "author" : [ "Steffen Rendle" ],
      "venue" : "ACM TIST 3,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2012
    }, {
      "title" : "BPR: Bayesian Personalized Ranking from Implicit Feedback",
      "author" : [ "S. Rendle", "C. Freudenthaler", "Z. Gantner", "L. Schmidt-Thieme" ],
      "venue" : "arXiv e-prints (May",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2012
    }, {
      "title" : "Heterogeneous Information Network Embedding for Recommendation",
      "author" : [ "C. Shi", "B. Hu", "W.X. Zhao", "P.S. Yu" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering 31,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2019
    }, {
      "title" : "Semantic Path Based Personalized Recommendation onWeighted Heterogeneous Information Networks",
      "author" : [ "Chuan Shi", "Zhiqiang Zhang", "Ping Luo", "Philip S. Yu", "Yading Yue", "Bin Wu" ],
      "venue" : "In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management (CIKM ’15)",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2015
    }, {
      "title" : "Collaborative intent prediction with real-time contextual data",
      "author" : [ "Yu Sun", "Nicholas Jing Yuan", "Xing Xie", "Kieran McDonald", "Rui Zhang" ],
      "venue" : "ACM Transactions on Information Systems (TOIS) 35,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2017
    }, {
      "title" : "Adaptive graphconvolutional neural networks",
      "author" : [ "Feiyun Zhu T Ruoyu Li", "Sheng Wang", "Junzhou Huang" ],
      "venue" : null,
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2018
    }, {
      "title" : "Shine: Signed heterogeneous information network embedding for sentiment link prediction",
      "author" : [ "Hongwei Wang", "Fuzheng Zhang", "Min Hou", "Xing Xie", "Minyi Guo", "Qi Liu" ],
      "venue" : "In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2018
    }, {
      "title" : "Attentional heterogeneous graph neural network: Application to program reidentification",
      "author" : [ "Shen Wang", "Zhengzhang Chen", "Ding Li", "Zhichun Li", "Lu-An Tang", "Jingchao Ni", "Junghwan Rhee", "Haifeng Chen", "Philip S Yu" ],
      "venue" : "In Proceedings of the 2019 SIAM International Conference on Data Mining",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2019
    }, {
      "title" : "Heterogeneous graph matching networks for unknown malware detection",
      "author" : [ "ShenWang", "Zhengzhang Chen", "Xiao Yu", "Ding Li", "JingchaoNi", "Lu-An Tang", "Jiaping Gui", "Zhichun Li", "Haifeng Chen", "Philip S Yu" ],
      "venue" : "In Proceedings of the 28th International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2019
    }, {
      "title" : "Session-based Recommendation with Graph Neural Networks",
      "author" : [ "Shu Wu", "Yuyuan Tang", "Yanqiao Zhu", "Liang Wang", "Xing Xie", "Tieniu Tan" ],
      "venue" : null,
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2018
    }, {
      "title" : "Graph Convolutional Neural Networks for Web-Scale Recommender Systems",
      "author" : [ "Rex Ying", "Ruining He", "Kaifeng Chen", "Pong Eksombatchai", "William L. Hamilton", "Jure Leskovec" ],
      "venue" : "In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery  Data Mining (KDD ’18)",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2018
    }, {
      "title" : "Personalized Entity Recommendation: A Heterogeneous Information Network Approach",
      "author" : [ "Xiao Yu", "Xiang Ren", "Yizhou Sun", "Quanquan Gu", "Bradley Sturt", "Urvashi Khandelwal", "Brandon Norick", "Jiawei Han" ],
      "venue" : "In Proceedings of the 7th ACM International Conference on Web Search and Data Mining (WSDM ’14)",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2014
    }, {
      "title" : "Collaborative knowledge base embedding for recommender systems",
      "author" : [ "Fuzheng Zhang", "Nicholas Jing Yuan", "Defu Lian", "Xing Xie", "Wei-Ying Ma" ],
      "venue" : "In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2016
    }, {
      "title" : "Smart Jump: Automated Navigation Suggestion for Videos in MOOCs",
      "author" : [ "Han Zhang", "Maosong Sun", "Xiaochen Wang", "Zhengyang Song", "Jie Tang", "Jimeng Sun" ],
      "venue" : "In Proceedings of the 26th International Conference on World Wide Web Companion,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2017
    }, {
      "title" : "Hierarchical Reinforcement Learning for Course Recommendation in MOOCs",
      "author" : [ "Jing Zhang", "Bowen Hao", "Bo Chen", "Cuiping Li", "Hong Chen", "Jimeng Sun" ],
      "venue" : "In Proceedings of the AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2019
    }, {
      "title" : "Graph Neural Networks: A Review of Methods and Applications",
      "author" : [ "Jie Zhou", "Ganqu Cui", "Zhengyan Zhang", "Cheng Yang", "Zhiyuan Liu", "Maosong Sun" ],
      "venue" : "CoRR abs/1812.08434",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 18,
      "context" : "In China, millions of users study in XuetangX1, which is one of the largest MOOC platforms[20], where thousands of courses are offered on various subjects.",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 11,
      "context" : "To understand and capture student interests on MOOCs platforms, multiple efforts have been done, including course recommendation [13, 35], behavior prediction [20], user intentions understanding [34], etc.",
      "startOffset" : 129,
      "endOffset" : 137
    }, {
      "referenceID" : 33,
      "context" : "To understand and capture student interests on MOOCs platforms, multiple efforts have been done, including course recommendation [13, 35], behavior prediction [20], user intentions understanding [34], etc.",
      "startOffset" : 129,
      "endOffset" : 137
    }, {
      "referenceID" : 18,
      "context" : "To understand and capture student interests on MOOCs platforms, multiple efforts have been done, including course recommendation [13, 35], behavior prediction [20], user intentions understanding [34], etc.",
      "startOffset" : 159,
      "endOffset" : 163
    }, {
      "referenceID" : 32,
      "context" : "To understand and capture student interests on MOOCs platforms, multiple efforts have been done, including course recommendation [13, 35], behavior prediction [20], user intentions understanding [34], etc.",
      "startOffset" : 195,
      "endOffset" : 199
    }, {
      "referenceID" : 9,
      "context" : "To overcome this problem, a number of efforts have been done by leveraging side information, such as social networks [11], user/item attributes [27], images [33], contexts [25], etc.",
      "startOffset" : 117,
      "endOffset" : 121
    }, {
      "referenceID" : 25,
      "context" : "To overcome this problem, a number of efforts have been done by leveraging side information, such as social networks [11], user/item attributes [27], images [33], contexts [25], etc.",
      "startOffset" : 144,
      "endOffset" : 148
    }, {
      "referenceID" : 31,
      "context" : "To overcome this problem, a number of efforts have been done by leveraging side information, such as social networks [11], user/item attributes [27], images [33], contexts [25], etc.",
      "startOffset" : 157,
      "endOffset" : 161
    }, {
      "referenceID" : 23,
      "context" : "To overcome this problem, a number of efforts have been done by leveraging side information, such as social networks [11], user/item attributes [27], images [33], contexts [25], etc.",
      "startOffset" : 172,
      "endOffset" : 176
    }, {
      "referenceID" : 21,
      "context" : "To capture heterogeneous complex relationships, we model the MOOCs platform data as a heterogeneous information network (HIN) [23].",
      "startOffset" : 126,
      "endOffset" : 130
    }, {
      "referenceID" : 23,
      "context" : "To address this issue, we use meta-paths [25] as the guidance to capture the heterogeneous context information in a HIN via GCN.",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 16,
      "context" : "Specifically, we use Word2vector [18] to generate the word embedding.",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 21,
      "context" : "Heterogeneous information network (HIN) [23].",
      "startOffset" : 40,
      "endOffset" : 44
    }, {
      "referenceID" : 1,
      "context" : "Fortunately, there are some algorithms [2] proposed recently for automatically selecting the meta-paths for particular tasks.",
      "startOffset" : 39,
      "endOffset" : 42
    }, {
      "referenceID" : 6,
      "context" : "To evaluate the recommendation performance, each positive instance in the test set is paired with 99 randomly sampled negative instances, and outputs prediction scores for the 100 instances (1 positive and 99 negatives)[7].",
      "startOffset" : 219,
      "endOffset" : 222
    }, {
      "referenceID" : 10,
      "context" : "We evaluate all the methods in terms of the widely used metrics, including Hit Ratio of top-K items (HR@K) and Normalized Discounted Cumulative Gain of top-K items (NDCG@K) [12].",
      "startOffset" : 173,
      "endOffset" : 177
    }, {
      "referenceID" : 6,
      "context" : "From the definition, we can see that a larger MRR value indicates a better performance of the model[7].",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 21,
      "context" : "In this part of the experiments, we analyze how selection of meta-path combinations affect the performance of ACKRec , since a small number of high-quality meta-paths can lead to considerable performance [23].",
      "startOffset" : 204,
      "endOffset" : 208
    }, {
      "referenceID" : 20,
      "context" : "• BPR [22]: It optimizes a pairwise ranking loss for the recommendation task in a Bayesian manner.",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 19,
      "context" : "• FM [21]: This is a principled approach that can easily incorporate any heuristic features.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 12,
      "context" : "• FISM [14]: This is an item-to-item collaborative filtering algorithm that conducts recommendations based on the average embeddings of all behavior histories and the embeddings of the target knowledge concept.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 6,
      "context" : "• NAIS [7]: This is also an item-to-item collaborative filtering algorithm, but distinguishes the weights of different online learning behaviors using an attention mechanism method.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 14,
      "context" : "• NASR [16]: This is an improved GRU [9] model that estimates an attention coefficient for each behavior history based on the corresponding hidden vector output by GRU.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 7,
      "context" : "• NASR [16]: This is an improved GRU [9] model that estimates an attention coefficient for each behavior history based on the corresponding hidden vector output by GRU.",
      "startOffset" : 37,
      "endOffset" : 40
    }, {
      "referenceID" : 2,
      "context" : "• metapath2vec [3]: This is a meta-paths based representation method in heterogeneous information network by random walk and skip-gram.",
      "startOffset" : 15,
      "endOffset" : 18
    }, {
      "referenceID" : 2,
      "context" : "Different from metapath2vec [3] generating representations based on random walk strategy and skip-gram method to generate representations of nodes, our model utilizes the graph convolutional networks to learn representations and adaptive attention mechanism to learn the different meta-paths weights and can better capture the heterogeneity within the data.",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 4,
      "context" : "Graphs play a crucial role in modern machine learning[5, 6].",
      "startOffset" : 53,
      "endOffset" : 59
    }, {
      "referenceID" : 5,
      "context" : "Graphs play a crucial role in modern machine learning[5, 6].",
      "startOffset" : 53,
      "endOffset" : 59
    }, {
      "referenceID" : 0,
      "context" : "Recently, graph neural networks[1, 4, 15, 26, 30, 31, 36] have become recurrent topics in machine learning, and both have broad applicability.",
      "startOffset" : 31,
      "endOffset" : 57
    }, {
      "referenceID" : 3,
      "context" : "Recently, graph neural networks[1, 4, 15, 26, 30, 31, 36] have become recurrent topics in machine learning, and both have broad applicability.",
      "startOffset" : 31,
      "endOffset" : 57
    }, {
      "referenceID" : 13,
      "context" : "Recently, graph neural networks[1, 4, 15, 26, 30, 31, 36] have become recurrent topics in machine learning, and both have broad applicability.",
      "startOffset" : 31,
      "endOffset" : 57
    }, {
      "referenceID" : 24,
      "context" : "Recently, graph neural networks[1, 4, 15, 26, 30, 31, 36] have become recurrent topics in machine learning, and both have broad applicability.",
      "startOffset" : 31,
      "endOffset" : 57
    }, {
      "referenceID" : 28,
      "context" : "Recently, graph neural networks[1, 4, 15, 26, 30, 31, 36] have become recurrent topics in machine learning, and both have broad applicability.",
      "startOffset" : 31,
      "endOffset" : 57
    }, {
      "referenceID" : 29,
      "context" : "Recently, graph neural networks[1, 4, 15, 26, 30, 31, 36] have become recurrent topics in machine learning, and both have broad applicability.",
      "startOffset" : 31,
      "endOffset" : 57
    }, {
      "referenceID" : 34,
      "context" : "Recently, graph neural networks[1, 4, 15, 26, 30, 31, 36] have become recurrent topics in machine learning, and both have broad applicability.",
      "startOffset" : 31,
      "endOffset" : 57
    }, {
      "referenceID" : 26,
      "context" : "[28] proposed DeepHGNN, an attentional heterogeneous graph neural network model to learn from the heterogeneous program behavior graph to guide the reidentification process.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 27,
      "context" : "[29] presented HAGNN, a Hierarchical Attentional Graph Neural Encoder and used it for program behavior Figure 7: The case study of ACKRec bases different meta-",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 15,
      "context" : "Additionally, the GEM[17] model, a heterogeneous graph neural network approach for detecting malicious accounts at Alipay, has been presented.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 17,
      "context" : "[19] proposed Heaters, a graph-based model, to solve the general recommendation problem in heterogeneous networks.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 30,
      "context" : "Yu et al.[32] proposed to use meta-paths based latent features to represent the connectivity between users and items along with different types of paths.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 8,
      "context" : "[10, 23, 24] proposed to use meta-path concept to mode the heterogeneous information in HIN.",
      "startOffset" : 0,
      "endOffset" : 12
    }, {
      "referenceID" : 21,
      "context" : "[10, 23, 24] proposed to use meta-path concept to mode the heterogeneous information in HIN.",
      "startOffset" : 0,
      "endOffset" : 12
    }, {
      "referenceID" : 22,
      "context" : "[10, 23, 24] proposed to use meta-path concept to mode the heterogeneous information in HIN.",
      "startOffset" : 0,
      "endOffset" : 12
    } ],
    "year" : 2020,
    "abstractText" : "Massive open online courses (MOOCs) are becoming a modish way for education, which provides a large-scale and open-access learning opportunity for students to grasp the knowledge. To attract students’ interest, the recommendation system is applied by MOOCs providers to recommend courses to students. However, as a course usually consists of a number of video lectures, with each one covering some specific knowledge concepts, directly recommending courses overlook students’ interest to some specific knowledge concepts. To fill this gap, in this paper, we study the problem of knowledge concept recommendation. We propose an end-to-end graph neural network based approach called Attentional Heterogeneous Graph Convolutional Deep Knowledge Recommender (ACKRec) for knowledge concept recommendation in MOOCs. Like other recommendation problems, it suffers from sparsity issue. To address this issue, we leverage both content information and context information to learn the representation of entities via graph convolution network. In addition to students and knowledge concepts, we consider other types of entities (e.g., courses, videos, teachers) and construct a heterogeneous information network (HIN) to capture the corresponding fruitful semantic relationships among different types of entities and incorporate them into the representation learning process. Specifically, we use meta-path on the HIN to guide the propagation of students’ preferences. With the help of these meta-paths, the students’ preference distribution with respect to a candidate knowledge concept can be captured. Furthermore, we propose an attention mechanism to adaptively fuse the context ∗The first two authors contributed equally. †Corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR ’20, July 25–30, 2020, Virtual Event, China © 2020 Association for Computing Machinery. ACM ISBN 978-1-4503-8016-4/20/07. . . $15.00 https://doi.org/10.1145/11221.27 information from different meta-paths, in order to capture the different interests of different students. To learn the parameters of the proposedmodel, we propose to utilize extendedmatrix factorization (MF). A series of experiments are conducted, demonstrating the effectiveness of ACKRec across multiple popular metrics compared with state-of-the-art baseline methods. The promising results show that the proposedACKRec is able to effectively recommend knowledge concepts to students pursuing online learning in MOOCs.",
    "creator" : "TeX"
  }
}