{
  "name" : "3397271.3401188.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Choppy: Cut Transformer for Ranked List Truncation",
    "authors" : [ "Dara Bahri", "Yi Tay", "Che Zheng", "Andrew Tomkins" ],
    "emails" : [ "dbahri@google.com", "yitay@google.com", "chezheng@google.com", "metzler@google.com", "tomkins@google.com", "permissions@acm.org." ],
    "sections" : [ {
      "heading" : null,
      "text" : "CCS CONCEPTS • Information systems → Presentation of retrieval results; Retrieval effectiveness.\nKEYWORDS ranked list truncation; neural networks; Transformer; information retrieval; deep learning\nACM Reference Format: Dara Bahri, Yi Tay, Che Zheng, Donald Metzler, and Andrew Tomkins. 2020. Choppy: Cut Transformer for Ranked List Truncation. In 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’20), July 25–30, 2020, Virtual Event, China. ACM, New York, NY, USA, 4 pages. https://doi.org/10.1145/3397271.3401188"
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "While much of the work in information retrieval has been centered around ranking, there is growing interest in methods for ranked list truncation - the problem of determining the appropriate cutoff \uD835\uDC58 of candidate results [1, 9]. This problem has garnered attention\n∗Corresponding author\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR ’20, July 25–30, 2020, Virtual Event, China © 2020 Association for Computing Machinery. ACM ISBN 978-1-4503-8016-4/20/07. . . $15.00 https://doi.org/10.1145/3397271.3401188\nin fields like legal search [14] and sponsored search [3, 16], where there could be a monetary cost for users looking into an irrelevant tail of documents or where showing too many irrelevant ads could result in ad blindness. The fundamental importance of this problem has led to development of methods that are automatically able to learn \uD835\uDC58 in a data-driven fashion [9]. The focus of this paper is to design more effective models for accurate and dynamic truncation of ranked lists.\nThe present state-of-the-art for this task is BiCut [9], a recurrentbased neural model that formulates the problem as a sequential decision process over the list. BiCut trains a bidirectional LSTM [8] model with a predefined loss that serves as a proxy to the userdefined target evaluation metric. At every position in the ranked list, BiCut makes a binary decision conditioned on both forward and backward context: to continue to the next position, or to end the output list.\nWhile BiCut outperforms non-neural methods [1], we argue it has several drawbacks. Firstly, the model is trained with teacherforcing, i.e. with ground truth context, but it is deployed autoregressively at test time, where it is conditioned on its own predictions. Thus, the model suffers from a train / test distribution mismatch, often referred to as exposure bias [12], resulting in poor model generalization. Secondly, the loss function used does not capture the mutual exclusivity among the candidate cut positions. In other words, the loss does not capture the condition that the list can only be cut in at most one position. Furthermore, the proposed training loss is unaligned with the user-defined evaluation metric. Last but not least, BiCut employs BiLSTMs which are not only slow and non-parallelizable, but also do not take into account global long-range dependencies.\nThis paper proposes Choppy, a newmethod that not only ameliorates the limitations of the BiCut model but also achieves state-ofthe-art performance on the ranked list truncation task. Our method comprises two core technical contributions. The first is a Transformer model [15] that is able to capture long-range dyadic interactions between relevance scores. To the best of our knowledge, this is the first successful application of self-attentive models on scalar ranking scores. The second technical contribution is the development of a loss function that optimizes the expected metric value over all candidate cut positions. Overall, Choppy not only improves the predictive performance on this task but also improves the model inference speed by > 3 times.\nOur contributions. The key contributions of the paper are summarized as follows:\n• We frame the ranked list truncation task as modeling the joint distribution among all candidate cut positions, and we\nconstruct our training loss to be the expected metric value over cut positions, for any choice of user-definedmetric, such as F1, precision, or discounted cumulative gain. As such, our training loss and evaluation metric are fully aligned. • We propose Choppy, a Cut Transformer model that achieves a state-of-the-art 11.5% relative improvement over the BiCut model. To predict the joint distribution over candidate cut positions, our method learns a positional embedding and leverages expressive bidirectional multi-headed attention."
    }, {
      "heading" : "2 RELATEDWORK",
      "text" : "Across the rich history of information retrieval research, there has been extensive work focused on modeling score distributions of IR systems. Early work in this area primarily focused on fitting parametric probability distributions to score distributions [1, 10]. This is often achieved by making the assumption that the overall distribution can be expressed as a mixture of a relevant and a non-relevant distribution. The expectation-maximization (EM) algorithm is often adopted to learn the parameters.\nThere has been considerable recent interest in adopting machine learning based models to optimize and improve the ranked list truncation problem. For instance, cascade-style IR systems [17] seek to achieve a balance between efficiency and effectiveness. Notably, [5] investigates a number of machine learning approaches for learning dynamic cutoffs within cascade-style ranking systems. Another recent study investigated how to leverage bidirectional Long Short-Term Memory (LSTM) models to identify the best position to truncate a given list [9]. This model, BiCut, can be considered the present state-of-the-art approach.\nOur work is closely related to the task of query performance prediction [4]. In this task, the objective is to automatically determine the effectiveness of a given query. This could be leveraged\nto determine the optimal set of results to the user for any given measure. Methods for query performance prediction include preretrieval-based approaches [7], relevance-based approaches [4, 19], and neural approaches [18].\nA system that determines the best number of results to display to users has the potential to benefit a wide number of applications. For example, in sponsored search, displaying too many irrelevant ads to users may cause frustration, resulting in so-called query blindness. This motivated research that investigated whether any ads should be displayed at all [3]. It is also easy to see that a similar and related problem formulation is to determine how many ads should be displayed to the users [16]. Moreover, determining the optimal number of ranked results is also important in a number of other IR applications such as legal e-discovery [14], where there is an significant financial or labor cost associated with reviewing results. Finally, the ability to calibrate scores across queries and different corpora has also been studied in the context of federated search tasks [13] such as meta-search [11]."
    }, {
      "heading" : "3 CHOPPY",
      "text" : "We now describe Choppy, our proposed Cut Transformer approach for ranked list truncation.\nLet (r1, . . . , r\uD835\uDC5B) denote the sequence of results, ranked in decreasing order of relevance, and let r\uD835\uDC56 have relevance score s\uD835\uDC56 and ground truth relevance label y\uD835\uDC56 (1 if relevant, −1 if non-relevant). We now describe our model piecemeal."
    }, {
      "heading" : "3.1 Transformer Layer",
      "text" : "We briefly review the Transformer layer. In our work, we let all model dimensions be \uD835\uDC51 . Let \uD835\uDC4B ∈ R\uD835\uDC5B×\uD835\uDC51 represent the input to the layer and\uD835\uDC4A\uD835\uDC5E,\uD835\uDC4A\uD835\uDC58 ,\uD835\uDC4A\uD835\uDC63 ∈ R\uD835\uDC51×\uD835\uDC51 . We define\nAttn ( \uD835\uDC4B ;\uD835\uDC4A\uD835\uDC5E,\uD835\uDC4A\uD835\uDC58 ,\uD835\uDC4A\uD835\uDC63 ) = Act ( \uD835\uDC4B\uD835\uDC4A\uD835\uDC5E\uD835\uDC4A \uD835\uDC47 \uD835\uDC58 \uD835\uDC4B\uD835\uDC47 ) (\uD835\uDC4B\uD835\uDC4A\uD835\uDC63)\nwhere Act is an activation function. As done in [15], we take it to perform row-wise softmax and normalize by √ \uD835\uDC51 . Attention is often augmented using multiple heads. In multi-headed attention, the model dimension is split into multiple heads, each one performing attention independently, and the result is concatenated together. Let ℎ be the number of heads and suppose \uD835\uDC51 is divisible by ℎ. Then,\nMultiAttn ( \uD835\uDC4B ;\uD835\uDC4A\uD835\uDC5E,\uD835\uDC4A\uD835\uDC58 ,\uD835\uDC4A\uD835\uDC63 ) = rConcat\n1≤\uD835\uDC56≤ℎ\n[ Attn ( \uD835\uDC4B ;\uD835\uDC4A (\uD835\uDC56)\uD835\uDC5E ,\uD835\uDC4A (\uD835\uDC56) \uD835\uDC58 ,\uD835\uDC4A (\uD835\uDC56) \uD835\uDC63 )] where\uD835\uDC4A (\uD835\uDC56)\uD835\uDC5E ,\uD835\uDC4A (\uD835\uDC56) \uD835\uDC58 ,\uD835\uDC4A (\uD835\uDC56) \uD835\uDC63 ∈ R\uD835\uDC51×(\uD835\uDC51/ℎ) . rConcat performs row-wise concatenation. The output of multi-headed attention is\n\uD835\uDC34 = LayerNorm ( \uD835\uDC4B +MultiAttn ( \uD835\uDC4B ;\uD835\uDC4A\uD835\uDC5E,\uD835\uDC4A\uD835\uDC58 ,\uD835\uDC4A\uD835\uDC63 ) ) where LayerNorm is layer normalization [2]. Finally, the output of the Transformer layer is\n\uD835\uDC42trans = LayerNorm (\uD835\uDC34 + rFF (\uD835\uDC34)) where rFF applies a single learnable feed-forward layer with ReLU activation to each row of \uD835\uDC34."
    }, {
      "heading" : "3.2 Positional Embedding",
      "text" : "The vanilla Transformer incorporates positional encoding by adding fixed sinusoidal values to the input token embeddings. As the token embeddings are trained, they have the flexibility to learn how to\nbest utilize the fixed positional information. In our setting however, the inputs are fixed 1-dimensional relevance scores. Attempting to apply a Transformer layer directly on the raw scores can limit its complexity. To that end, we introduce a learnable positional embedding \uD835\uDC43 ∈ R\uD835\uDC5B×(\uD835\uDC51−1) and feed in \uD835\uDC4B = rConcat [s, \uD835\uDC43] to the the first Transformer layer only, where s is the column vector of relevance scores."
    }, {
      "heading" : "3.3 Loss",
      "text" : "So far, Choppy takes the \uD835\uDC5B-length vector of scores, augments it with a positional embedding, and feeds the result into \uD835\uDC5Blayers Transformer layers. This produces\uD835\uDC42trans ∈ R\uD835\uDC5B×\uD835\uDC51 . We arrive at the output of Choppy by applying a final linear projection followed by a softmax over positions:\no = Softmax (\uD835\uDC42trans\uD835\uDC4A\uD835\uDC5C )\nwhere\uD835\uDC4A\uD835\uDC5C ∈ R\uD835\uDC51×1. We interpret the output o to be a probability distribution over candidate cutoff positions. More concretely, we take o\uD835\uDC56 = Prob [(r1, . . . , r\uD835\uDC56 )]. Let \uD835\uDC36 be any user-defined evaluation metric that should be maximized, such as F1 or precision. For each training example \uD835\uDC57 and every candidate cutoff position \uD835\uDC56 we compute \uD835\uDC36\uD835\uDC56 (y( \uD835\uDC57) ), the value of themetric if the result list were to be truncated at position \uD835\uDC56 , using the ground-truth relevance labels. Our proposed loss follows as:\n\uD835\uDC3F ( s( \uD835\uDC57) , y( \uD835\uDC57) ) = − \uD835\uDC5B∑ \uD835\uDC56=1 o\uD835\uDC56 ( s( \uD835\uDC57) ) \uD835\uDC36\uD835\uDC56 ( y( \uD835\uDC57) ) = −E\uD835\uDC4D∼Categorical(o(s( \uD835\uDC57 ) )) \uD835\uDC36\uD835\uDC4D ( y( \uD835\uDC57) ) .\nWith this loss, our model learns the conditional joint distribution over candidate cut positions that maximizes the expected evaluation metric on the training samples. We depict the loss and the predicted distribution for a few training samples in Figure 1. We see that the model tends to weight positions according to their corresponding metric value. At test time we choose to cut at the argmax position. Note that unlike BiCut, our loss has no tune-able hyperparameters."
    }, {
      "heading" : "4 EXPERIMENTS",
      "text" : "This section describes our experimental setup and results."
    }, {
      "heading" : "4.1 Dataset",
      "text" : "We evaluate our method using the TREC collection Robust04, used in the TREC 2004 Robust Track. It consists of 250 queries over 528k news articles, where each query has 1000 total results and an average of 70 relevant ones. This is the same dataset used in [9]. We use a random 80/20 train/test that achieves comparable performance to the reported results in [9]. We evaluate the efficacy of our truncation model using two different retrieval approaches - BM25, a traditional tf-idf based model, and DRMM [6], a neural model."
    }, {
      "heading" : "4.2 Baselines",
      "text" : "We evaluate our method against the following baselines:\n• Fixed-\uD835\uDC58 returns the top-\uD835\uDC58 results for a single value of \uD835\uDC58 across test queries.\n• Greedy-\uD835\uDC58 chooses the single \uD835\uDC58 that maximizes \uD835\uDC36 over the training set. • Oracle uses knowledge of each test query’s true label to optimize \uD835\uDC58 . It represents an upper-bound on the metric performance that can be achieved. • BiCut [9] learns a multi-layer bidirectional LSTM model on the entire training set, taking the score sequence as inputs. At position \uD835\uDC56 of the result list, the model predicts probability \uD835\uDC5D\uD835\uDC56 to continue and probability 1 − \uD835\uDC5D\uD835\uDC56 to end. At inference time, the cutoff is made before the first occurrence of end."
    }, {
      "heading" : "4.3 Setting",
      "text" : "We report F1 and Discounted Cumulative Gain (DCG) scores where we define DCG to penalize negative, or non-relevant results:\nDCG\uD835\uDC5B = \uD835\uDC5B∑ \uD835\uDC56=1\n\uD835\uDC66\uD835\uDC56\nlog2 (\uD835\uDC56 + 1) ,\nWe need to deviate from the usual definition of DCG since the usual definition always increases monotonically with the length of the returned ranked list and so the optimal solution under this definition would be to not truncate at all. For methods that optimize F1 or DCG, we report the performance of the model when it is optimized specifically for that metric. Note that DCG is unsupported by BiCut.\nFor Choppy, we blithely set \uD835\uDC5Blayers = 3, ℎ (# heads) = 8, and \uD835\uDC51 = 128 across all settings, without any tuning. We optimize the aforementioned custom loss function using Adam with default learning rate 0.001, and a batch size of 64. As in [9], we only consider the top-300 candidate results of each query."
    }, {
      "heading" : "5 RESULTS AND DISCUSSION",
      "text" : ""
    }, {
      "heading" : "5.1 Results",
      "text" : "As shown in Table 1, Choppy achieves a significant improvement over BiCut for both metrics and both retrieval types. This improvement arises from Choppy’s ability to model the joint distribution over all candidate cut positions and its direct optimization of the evaluation metric. Furthermore, the attention mechanism is able to effectively capture correlations between scores far apart in ranked order. This is in contrast to LSTMs, as used in BiCut, whose degradation with larger sequence length is well known."
    }, {
      "heading" : "5.2 Ablation Study",
      "text" : "Choppy has three hyperparameters: the model dimension \uD835\uDC51 , the number of heads ℎ, and the number of Transformer layers \uD835\uDC5Blayers.\nIn Figure 2 we plot the impact of \uD835\uDC51 and ℎ on predictive performance (while keeping \uD835\uDC5Blayers fixed to 3). We see that both F1 and DCG are strong and stable across settings. Extrapolating beyond Robust04, we expect Choppy to work out-of-the-box on many datasets. Unlike BiCut, which required much tuning in our experience, Choppy seems to work well while requiring little-to-no tuning."
    }, {
      "heading" : "6 CONCLUSION",
      "text" : "We propose Choppy, a Transformer architecture for ranked list truncation, that learns the score distribution of relevant and nonrelevant documents and is able to directly optimize any user-defined metric. We show that Choppy achieves state-of-the-art F1 and DCG performance on Robust04, under both a traditional tf-idf as well as modern neural ranking system. We then dig deeper into Choppy’s architecture settings, showing strong and stable performance across a range of values. We thus conclude that when faced with a ranked list truncation task, one can apply Choppy and expect competitive performance."
    }, {
      "heading" : "ACKNOWLEDGMENTS",
      "text" : "We would like to thank the authors of BiCut for providing us with the BM25 and DRMM ranked lists that were used for evaluation."
    } ],
    "references" : [ {
      "title" : "Where to Stop Reading a Ranked List?: Threshold Optimization Using Truncated Score Distributions",
      "author" : [ "Avi Arampatzis", "Jaap Kamps", "Stephen Robertson" ],
      "venue" : "In Proceedings of the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2009
    }, {
      "title" : "To Swing or Not to Swing: Learning when (Not) to Advertise",
      "author" : [ "Andrei Broder", "Massimiliano Ciaramita", "Marcus Fontoura", "Evgeniy Gabrilovich", "Vanja Josifovski", "Donald Metzler", "Vanessa Murdock", "Vassilis Plachouras" ],
      "venue" : "In Proceedings of the 17th ACM Conference on Information and Knowledge Management (Napa Valley, California,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2008
    }, {
      "title" : "Predicting Query Performance",
      "author" : [ "Steve Cronen-Townsend", "Yun Zhou", "W. Bruce Croft" ],
      "venue" : "In Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (Tampere,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2002
    }, {
      "title" : "Dynamic Cutoff Prediction inMulti-Stage Retrieval Systems. In Proceedings of the 21st Australasian Document Computing Symposium (Caulfield, VIC, Australia) (ADCS ’16)",
      "author" : [ "J. Shane Culpepper", "Charles L.A. Clarke", "Jimmy Lin" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2016
    }, {
      "title" : "A deep relevance matching model for ad-hoc retrieval",
      "author" : [ "Jiafeng Guo", "Yixing Fan", "Qingyao Ai", "W Bruce Croft" ],
      "venue" : "In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2016
    }, {
      "title" : "A Survey of Pre-retrieval Query Performance Predictors",
      "author" : [ "Claudia Hauff", "Djoerd Hiemstra", "Franciska de Jong" ],
      "venue" : "In Proceedings of the 17th ACM Conference on Information and Knowledge Management (Napa Valley, California,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2008
    }, {
      "title" : "Long short-termmemory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber" ],
      "venue" : "Neural computation 9,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1997
    }, {
      "title" : "An Assumption- Free Approach to the Dynamic Truncation of Ranked Lists",
      "author" : [ "Yen-Chieh Lien", "Daniel Cohen", "W. Bruce Croft" ],
      "venue" : "In Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval (Santa Clara, CA, USA) (ICTIR ’19)",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2019
    }, {
      "title" : "Modeling Score Distributions for Combining the Outputs of Search Engines",
      "author" : [ "R. Manmatha", "T. Rath", "F. Feng" ],
      "venue" : "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (New Orleans, Louisiana,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2001
    }, {
      "title" : "Relevance Score Normalization for Metasearch",
      "author" : [ "Mark Montague", "Javed A. Aslam" ],
      "venue" : "In Proceedings of the Tenth International Conference on Information and Knowledge Management (Atlanta, Georgia,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2001
    }, {
      "title" : "Sequence level training with recurrent neural networks",
      "author" : [ "Marc’Aurelio Ranzato", "Sumit Chopra", "Michael Auli", "Wojciech Zaremba" ],
      "venue" : "arXiv preprint arXiv:1511.06732",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2015
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Łukasz Kaiser", "Illia Polosukhin" ],
      "venue" : "In Advances in neural information processing systems",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2017
    }, {
      "title" : "Learning to Advertise: How Many Ads Are Enough",
      "author" : [ "Bo Wang", "Zhaonan Li", "Jie Tang", "Kuo Zhang", "Songcan Chen", "Liyun Ru" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2011
    }, {
      "title" : "A Cascade Ranking Model for Efficient Ranked Retrieval. In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval (Beijing, China) (SIGIR ’11)",
      "author" : [ "Lidan Wang", "Jimmy Lin", "Donald Metzler" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2011
    }, {
      "title" : "Neural Query Performance Prediction Using Weak Supervision from Multiple Signals",
      "author" : [ "Hamed Zamani", "W. Bruce Croft", "J. Shane Culpepper" ],
      "venue" : "In The 41st International ACM SIGIR Conference on Research",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2018
    }, {
      "title" : "Query Performance Prediction in Web Search Environments. In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (Amsterdam, The Netherlands) (SIGIR ’07)",
      "author" : [ "Yun Zhou", "W. Bruce Croft" ],
      "venue" : "Short Research Papers I SIGIR",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "While much of the work in information retrieval has been centered around ranking, there is growing interest in methods for ranked list truncation - the problem of determining the appropriate cutoff k of candidate results [1, 9].",
      "startOffset" : 221,
      "endOffset" : 227
    }, {
      "referenceID" : 7,
      "context" : "While much of the work in information retrieval has been centered around ranking, there is growing interest in methods for ranked list truncation - the problem of determining the appropriate cutoff k of candidate results [1, 9].",
      "startOffset" : 221,
      "endOffset" : 227
    }, {
      "referenceID" : 1,
      "context" : "3401188 in fields like legal search [14] and sponsored search [3, 16], where there could be a monetary cost for users looking into an irrelevant tail of documents or where showing too many irrelevant ads could result in ad blindness.",
      "startOffset" : 62,
      "endOffset" : 69
    }, {
      "referenceID" : 12,
      "context" : "3401188 in fields like legal search [14] and sponsored search [3, 16], where there could be a monetary cost for users looking into an irrelevant tail of documents or where showing too many irrelevant ads could result in ad blindness.",
      "startOffset" : 62,
      "endOffset" : 69
    }, {
      "referenceID" : 7,
      "context" : "The fundamental importance of this problem has led to development of methods that are automatically able to learn k in a data-driven fashion [9].",
      "startOffset" : 141,
      "endOffset" : 144
    }, {
      "referenceID" : 7,
      "context" : "The present state-of-the-art for this task is BiCut [9], a recurrentbased neural model that formulates the problem as a sequential decision process over the list.",
      "startOffset" : 52,
      "endOffset" : 55
    }, {
      "referenceID" : 6,
      "context" : "BiCut trains a bidirectional LSTM [8] model with a predefined loss that serves as a proxy to the userdefined target evaluation metric.",
      "startOffset" : 34,
      "endOffset" : 37
    }, {
      "referenceID" : 0,
      "context" : "While BiCut outperforms non-neural methods [1], we argue it has several drawbacks.",
      "startOffset" : 43,
      "endOffset" : 46
    }, {
      "referenceID" : 10,
      "context" : "Thus, the model suffers from a train / test distribution mismatch, often referred to as exposure bias [12], resulting in poor model generalization.",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 11,
      "context" : "The first is a Transformer model [15] that is able to capture long-range dyadic interactions between relevance scores.",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 0,
      "context" : "Early work in this area primarily focused on fitting parametric probability distributions to score distributions [1, 10].",
      "startOffset" : 113,
      "endOffset" : 120
    }, {
      "referenceID" : 8,
      "context" : "Early work in this area primarily focused on fitting parametric probability distributions to score distributions [1, 10].",
      "startOffset" : 113,
      "endOffset" : 120
    }, {
      "referenceID" : 13,
      "context" : "For instance, cascade-style IR systems [17] seek to achieve a balance between efficiency and effectiveness.",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 3,
      "context" : "Notably, [5] investigates a number of machine learning approaches for learning dynamic cutoffs within cascade-style ranking systems.",
      "startOffset" : 9,
      "endOffset" : 12
    }, {
      "referenceID" : 7,
      "context" : "Another recent study investigated how to leverage bidirectional Long Short-Term Memory (LSTM) models to identify the best position to truncate a given list [9].",
      "startOffset" : 156,
      "endOffset" : 159
    }, {
      "referenceID" : 2,
      "context" : "Our work is closely related to the task of query performance prediction [4].",
      "startOffset" : 72,
      "endOffset" : 75
    }, {
      "referenceID" : 5,
      "context" : "Methods for query performance prediction include preretrieval-based approaches [7], relevance-based approaches [4, 19], and neural approaches [18].",
      "startOffset" : 79,
      "endOffset" : 82
    }, {
      "referenceID" : 2,
      "context" : "Methods for query performance prediction include preretrieval-based approaches [7], relevance-based approaches [4, 19], and neural approaches [18].",
      "startOffset" : 111,
      "endOffset" : 118
    }, {
      "referenceID" : 15,
      "context" : "Methods for query performance prediction include preretrieval-based approaches [7], relevance-based approaches [4, 19], and neural approaches [18].",
      "startOffset" : 111,
      "endOffset" : 118
    }, {
      "referenceID" : 14,
      "context" : "Methods for query performance prediction include preretrieval-based approaches [7], relevance-based approaches [4, 19], and neural approaches [18].",
      "startOffset" : 142,
      "endOffset" : 146
    }, {
      "referenceID" : 1,
      "context" : "This motivated research that investigated whether any ads should be displayed at all [3].",
      "startOffset" : 85,
      "endOffset" : 88
    }, {
      "referenceID" : 12,
      "context" : "It is also easy to see that a similar and related problem formulation is to determine how many ads should be displayed to the users [16].",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 9,
      "context" : "Finally, the ability to calibrate scores across queries and different corpora has also been studied in the context of federated search tasks [13] such as meta-search [11].",
      "startOffset" : 166,
      "endOffset" : 170
    }, {
      "referenceID" : 7,
      "context" : "We use a random 80/20 train/test that achieves comparable performance to the reported results in [9].",
      "startOffset" : 97,
      "endOffset" : 100
    }, {
      "referenceID" : 4,
      "context" : "We evaluate the efficacy of our truncation model using two different retrieval approaches - BM25, a traditional tf-idf based model, and DRMM [6], a neural model.",
      "startOffset" : 141,
      "endOffset" : 144
    }, {
      "referenceID" : 7,
      "context" : "• BiCut [9] learns a multi-layer bidirectional LSTM model on the entire training set, taking the score sequence as inputs.",
      "startOffset" : 8,
      "endOffset" : 11
    }, {
      "referenceID" : 7,
      "context" : "As in [9], we only consider the top-300 candidate results of each query.",
      "startOffset" : 6,
      "endOffset" : 9
    } ],
    "year" : 2020,
    "abstractText" : "Work in information retrieval has traditionally focused on ranking and relevance: given a query, return some number of results ordered by relevance to the user. However, the problem of determining how many results to return, i.e. how to optimally truncate the ranked result list, has received less attention despite being of critical importance in a range of applications. Such truncation is a balancing act between the overall relevance, or usefulness of the results, with the user cost of processing more results. In this work, we propose Choppy, an assumption-free model based on the widely successful Transformer architecture, to the ranked list truncation problem. Needing nothing more than the relevance scores of the results, the model uses a powerful multi-head attention mechanism to directly optimize any user-defined IR metric. We show Choppy improves upon recent state-of-the-art methods.",
    "creator" : "LaTeX with acmart 2020/04/30 v1.71 Typesetting articles for the Association for Computing Machinery and hyperref 2020/01/14 v7.00d Hypertext links for LaTeX"
  }
}