{
  "name" : "3397271.3401330.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Sentiment-guided Sequential Recommendation",
    "authors" : [ "Lin Zheng", "Naicheng Guo", "Weihao Chen", "Jin Yu", "Dazhi Jiang" ],
    "emails" : [ "lzheng@stu.edu.cn", "19ncguo@stu.edu.cn", "19whchen@stu.edu.cn", "jinyu@stu.edu.cn", "dzjiang@stu.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "CCS CONCEPTS • Information systems→Recommender systems; Personalization; Sentiment analysis; Collaborative filtering.\nKEYWORDS sequential behavior; sequential recommendation; human temporal sentiment; sentiment-guided attention; sparse sentiment attention\nACM Reference Format: Lin Zheng, NaichengGuo,Weihao Chen, Jin Yu, Dazhi Jiang. 2020. Sentimentguided Sequential Recommendation. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’20), July 25–30, 2020, Virtual Event, China. ACM, New York, NY, USA, 4 pages. https://doi.org/10.1145/3397271.3401330"
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "In modern recommender systems such as Amazon and YouTube, users generate large amounts of sequential behavior and related information. Therefore, processing a large number of sequential behaviors is not only required to meet the actual scenario but also presents a new challenge to the traditional recommendation techniques. Fortunately, research on sequential recommendations that\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). SIGIR ’20, July 25–30, 2020, Virtual Event, China © 2020 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-8016-4/20/07. https://doi.org/10.1145/3397271.3401330\nspecifically model sequential behavior has yielded many fruitful results [9].\nAs an initial attempt at applying deep learning to sequential recommendation, GRU4Rec [2] concatenates the behavior sequences of different users in a reasonable manner, thereby solving the difficult problem of uniformly modeling user behavior sequences of different lengths. This method illustrates the important role of recurrent neural networks (RNNs) [7] in sequential recommendation. Taking this research as a starting point, subsequent advanced approaches, such as memory-based RNNs [3, 12] and self-attention-based RNNs [5, 11], have taken sequential recommendation technology to a new level. These advanced technologies not only complete the modeling of pure behavior (item) sequences but also fully characterize additional information such as knowledge [3] and features [11] related to items to improve the sequence prediction performance. Some recent models based on the self-attention mechanism [8] perform particularly well in sequential recommendation. For example, SASRec [5] effectively captures users’ long-term preferences from both sparse and dense data sets, and in FDSA [11], two separated self-attention blocks (one for item sequences and one for features) were designed that achieved remarkable predictive effects.\nDespite their enhanced performances,most existing methods consider only the objective information of sequential items; they rarely consider the subjective influence of human sentiments on sequential recommendation. Specifically, there is a potential correlation between the temporal changes in a user’s sentiments and that user’s sequential behavior. However, most of the existing models based on sentiment factors [4, 10] focus only on non-sequential recommendations. In other words, they ignore the influence of the temporal sentiment change pattern on the sequence of user behavior; however, this temporal influence sometimes plays a decisive role in generating the final preference. For example, under the influence of continuous positive sentiments, a user may review a series of purchased items positively; in contrast, under the influence of continuous negative sentiments, the same user is more likely to consume some items that can usher in a good mood.\nDifferent from the existing approaches, in this work, we focus on how to capitalize on sequential sentiments to improve the sequential recommendation task. To this end, we set up a new preference prediction mechanism from the perspective of users’ subjective sentiments and propose a sequential recommendation method that employs temporal sentiments to facilitate generating users’ future preferences. Our work makes the following contributions:\nNovelty: We design two types of fused sequential sentiment modeling channels: one uses temporal sentiment to guide user behavior; the other generates pure sentiment preferences based on sparse attention. To the best of our knowledge, this is the first work on human sentiment-guided sequential recommendation.\nEffectiveness: The dual-channel modeling structure can be easily transplanted into existing RNNs. We report the results of an ablation study to prove experimentally that either or both of the two sentiment channels can effectively improve the performance.\nPerformance:We report the results of a method comparison to demonstrate that our model outperforms other competing state-ofthe-art sequential methods."
    }, {
      "heading" : "2 SENTIMENT-GUIDED SEQUENTIAL RECOMMENDATION",
      "text" : "In this section, we formalize the sequential recommendation task based on the sentiment state, introduce the network architecture of the Sentiment-Guided Sequential (SGS) recommender, and then describe the model implementation details."
    }, {
      "heading" : "2.1 Problem Formalization",
      "text" : "In the traditional sequential recommendation setting, the goal is to recommend the next item given a user’s historical sequence of behaviorsIu = (iu1 , iu2 , · · · , iu|Iu |), whereI\nu represents a sequence of items in chronological order that useru has previously interacted with. When considering sentiment factors in sequential recommendation, however, the situation becomes somewhat more complicated. Specifically, each item in the sequence uniquely corresponds to a sentiment state Sut = (s1t , s2t , · · · , sMt )u , where Sut corresponds to the item iut at time t and M denotes the number of sentiment factors. In a simple case, a sentiment state consists of three factors: positive, neutral, and negative; in this case,M = 3, and each factor appears with a certain probability. For instance, at time t , the positive sentiment may account for a probability of 0.6 (represented as s1t = 0.6), and the neutral (represented by s 2 t ) and negative (represented as s3t ) sentiments may account for 0.3 and 0.1, respectively. Therefore, the sequential recommendation task based on the sentiment state can be formalized as follows: Given a sequence of (item, sentiment_state) tuples ( (iu1 ,Su1 ), (iu2 ,Su2 ), · · · , (iu|Iu |,S u |Iu |) ) , the task is to recommend the next item that user u is most likely to interact with. In the following sections, we omit the identity of user u and use a fixed-length sequence ( (i1,S1), (i2,S2), · · · , (in,Sn )\n) suitable for training to describe our approach."
    }, {
      "heading" : "2.2 The Network Architecture",
      "text" : "The network architecture of the sentiment-guided sequential recommender is shown in Figure 1. We use subscripts t1, t2, · · · to represent a sequence in chronological order. SGS models users’\nbehavior-sentiment sequences in two channels. In the first channel, to reflect the guiding role of sentiment on the behavior sequence, we design a special attention mechanism based on sentiment queries and then perform sequential preference mining on both self-attention and sentiment-guided attention to obtain the preference of the first channel, PGu . The second channel emphasizes capturing the sequential preference, PGe , which is independently generated by sentiments. To this end, we incorporate a variant sparse sentiment attention [1] to model the sentiment factors in the sequence separately because a certain behavior in the sequence corresponds toM sentiment factors, and sparse attention can improve the calculation efficiency by reducing the number of attention interactions in the sequence. Similar to PGu , we employ a layernormalization RNN to complete sequential preference modeling to obtain PGe . Finally, the two preferences are aggregated into a fully connected layer based on layer normalization to generate the final preference, PF ."
    }, {
      "heading" : "2.3 The Implementation Details",
      "text" : "2.3.1 Embedding Layer. We divide the fixed-length training sequence ( (i1,S1), (i2,S2), · · · , (in,Sn ) ) into one item sequence and M sentiment sequences to construct embedding matrices. Because the elements of these M + 1 sequences are aligned individually in chronological order, we add zero padding to the left of these sequences to ensure that they have a fixed length of n. Then, we created an item embedding matrix E ∈ R |I |×d andM sentiment embedding matrices {S1, S2, · · · , SM }, where S1, S2, · · · , SM ∈ R |S |×d and d is the number of latent dimensions. 2.3.2 Two types of sentiment attention. The self-attention mechanism has been shown to be highly effective at sequential recommendation [5, 11]. It is based on the scaled dot-product attention [8], which is defined as follows:\nAtt (Q,K,V) = softmax (QKT√\nd\n) V , (1)\nwhere Q, K, and V represent queries, keys, and values, respectively, and √ d is a scale factor that changes with the input dimension. Given the current item embedding E as input, the self-attention operation transforms E into queries, keys, and values through linear projection and feeds them to the attention layer:\nAE = SelfAtt (E) = Att (EWQ, EWK , EWV ) , (2) whereWQ,WK ,WV ∈ Rd×d are projectionmatrices. The self-attention mechanism considers only items as queries; it ignores the role of sentiment factors. To emphasize the guiding role of sentiment factors, we define the sentiment-guided attention of the m-th sentiment factor to items as follows:\nAmS = SentiAtt (Sm, E) = Att (SmW Q, EWK , EWV ) . (3)\nBecause there are M sentiment factors, we perform a linear projection transformation on item self-attention AE and sentimentguided attentions {A1S ,A 2 S , · · · ,A M S } and then concatenate them according to the last dimension as follows:\nGAES = ConCat ([AEW E,A1SW S1 ,A2SW S2 , · · · ,AMS W SM ]) , (4) where WE,WS 1 , · · · ,WSM ∈ Ro×o and o is the size of output dimension of the attention layer. GAES is the aggregation of attention\nto items and sentiments. To model the sentiment-generated preference, we applied a simplified sparse attention mechanism [1] to model pure sentiments and specifically designed its inputs to facilitate interactions between sentiment factors. In particular, we concatenate theM sentiment embedding matrices to obtain SC as the input for sparse sentiment attention:\nACP = SparseAtt (SC, r ) = Att (SCW Q, SCWK , SCWV ) | | r , (5)\nwhere the | | operator indicates that only two behaviors with a distance less than or equal to r are used to calculate the attention. We term r as the “sparsity rate” and adjust its value according to the different datasets in the experiments.\n2.3.3 Sequential Aggregation to Obtain a Final Preference. We first apply layer normalization to GAES and then use an RNN to model the attention on behavior sequence to obtain the user preferences guided by sentiment as follows.\nPGu = RNN ( LayerNorm (GAES ) ) . (6)\nHere, using a simple RNN for sequential modeling to obtain preference PGu involves excluding other factors to directly study the guiding effect of sentiment on behavior sequences.We capitalize on LSTM to instantiate RNN throughout the experiments.\nSimilar to sentiment-guided user preferences, the preference generated by pure sentiment is calculated as follows:\nPGe = RNN ( LayerNorm (ACPW P ) ) . (7)\nHere, WP ∈ Ro×o and o is the size of output dimension of the attention layer. The two types of preferences generated thus far by the two sequential channels are aggregated into the final preference as follows:\nPF =WF LayerNorm ( ConCat ([PGu , PGe ]) ) + BF , (8)\nThus, PGu and PGe are concatenated and then layer normalized as the input to the fully connected layer, which takes the weight WF and the bias BF as parameters. Finally, we employ binary cross entropy loss and the Adam optimizer to train the SGS network."
    }, {
      "heading" : "3 EXPERIMENTS",
      "text" : "In this section, we describe experiments intended to answer the following research questions:\nRQ1: Do temporal sentiments have a positive guiding effect on sequential recommendation?\nRQ2: Is pure sequential sentiment modeling helpful in generating user preferences?\nRQ3: Does SGS outperform current state-of-the-art models, including RNN-based methods?"
    }, {
      "heading" : "3.1 Datasets",
      "text" : "We conducted experiments on four publicly available datasets. The first two datasets, Restaurant and Bars, are from the Yelp Challenge Dataset1. The other two datasets, Baby and Videogames, were selected from the Amazon dataset2. We first extracted temporal sentiments from reviews corresponding to sequential behaviors by using the Stanford NLP tools [6] and obtained five categories\n1https://www.yelp.com/dataset/challenge 2http://jmcauley.ucsd.edu/data/amazon/\nof sentiment factors: Very Positive, Positive, Neutral, Negative, and Very Negative, which constitute a sentiment state. Then, to facilitate training, we adopted the data augmentation technique reported in [7] to generate subsequences as input data. The maximum length of the subsequences was set to 50 for all four datasets. Finally, the input data were randomly split into a training set, a validation set, and a test set (8 : 1 : 1) for five-fold cross validation. The dataset statistics after these preprocessing operations are listed in Table 1, where Avg.B/user and Avg.B/item denote “average behavior per user” and “average behavior per item”, respectively."
    }, {
      "heading" : "3.2 Baselines and Metrics",
      "text" : "In these experiments, we compare SGS with the following relevant RNN-based sequential recommendation models:\n• RNN - an LSTM-based recurrent neural network for sequential recommendation, • GRU4Rec[2] - a representative GRU-based sequential recommender, • GRU4Senti[2] - an improved GRU4Rec model by concatenating user sentiment embeddings with item embeddings, • SASRec[5] - a state-of-the-art self-attention-based sequential recommender, • CFSA[11] - a state-of-the-art self-attention-based sequential recommender that considers sentiments as its features,\n• SGS - our Sentiment-Guided Sequential recommender. We fixed {batch_size, embeddinд_dimension} of all models to {128, 20} on the two smaller datasets (Restaurant,Bars) and {256, 30} on the two larger datasets (Baby,Videogames), respectively. The initial learning rate was uniformly set to 0.001 and cooperated with the Adam optimizer to complete the training. For the multihead selfattention-based methods (SASRec, CFSA, SGS), we adopted a grid search to find the optimal values for the attention-based parameters. Subsequently, the {head_number , size_per_head} of attention were set to {5, 4} and {6, 5} for the small and large datasets, respectively. A hyperparameter specific to SGS is the sparsity rate r , whose optimal values are 3 and 5 for the small and large datasets, respectively. As evaluation metrics, we adopted HitRate (Hit for short) and NDCG to evaluate the performances of all the approaches, and we choose K = {10, 20} to report the different results for Hit@K and NDCG@K ."
    }, {
      "heading" : "3.3 Sentiment Ablation Study",
      "text" : "The goal of the sentiment ablation study is to answer both RQ1 and RQ2. We designed three variants of SGS and analyzed their performances:\n• 1) Remove Sentiment Attention: a version of SGS without sentiment-guided attention. • 2) Remove Sparse Attention: a version of SGS without sparse sentiment attention. • 3) Remove All Sentiments: a version of SGS without any sentiment factors.\nFigure 2 illustrates that the two SGS versions with sentiment factors outperformed the SGS version without sentiments, which indicates the effectiveness of temporal sentiments in sequential recommendations. On the one hand, adding a sparse attention of pure sentiments to the behavior sequence modeling channel is helpful for improving the preference prediction performance. On the other hand, the performance of the sentiment-guided attention mechanism is much better than that of the self-attention of only behaviors on several metrics, which means that it has a positive influence on the self-attention mechanism. Fusing two types of sentiment attention further improves the performance of SGS and provides positive answers to RQ1 and RQ2."
    }, {
      "heading" : "3.4 Method Comparisons",
      "text" : "Table 2 shows that SGS outperforms all baselines on the four datasets; gaining average improvements of {18.38%, 20.95%, 17.79%, and 20.125%} on {Hit@10,NDCG@10,Hit@20, and NDCG@20}, respectively, compared to the strongest baseline. In particular, SGS\nperforms relatively better on the datasets Restaurant andBarswhich include more average user behaviors. Because each user behavior corresponds to 5 sentiment factors, more behaviors means that the model can learn more sentiment information. To answer RQ3, we first observed two types of comparative models: {GRU4Rec, GRU4Senti} and {SASRec, CFSA}. As a representative model of sequential recommendation, GRU4Rec becomes GRU4Senti after concatenating the user sentiment embeddings with the item embeddings, and the latter achieves better results. Similarly, the selfattention network based on sentiment features (CFSA) performs relatively better than that without sentiments (SASRec). SGS is superior to both types of approaches because it does not simply organize sentiment factors but instead promotes sentiment factors as preference guides modeled in two channels. Thus, the resulting preferences are more human-centric and more meaningful to users."
    }, {
      "heading" : "4 CONCLUSION AND FUTUREWORK",
      "text" : "The intent of this work is to model the subjective preferences of users in sequential recommendation. In future work, we will further consider additional subjective factors (such as emotions) to improve sequential preference mining based on human study."
    }, {
      "heading" : "ACKNOWLEDGMENTS",
      "text" : "This work is supported by the National Natural Science Foundation of China under Grant No. 61902231, the Guangdong Basic and Applied Basic Research Foundation under Grant No. 2020A1515010531, and the Research Startup Fund Project of Shantou University under Grant No. NTF18017."
    } ],
    "references" : [ {
      "title" : "Generating Long Sequences with Sparse Transformers",
      "author" : [ "Rewon Child", "Scott Gray", "Alec Radford", "Ilya Sutskever" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2019
    }, {
      "title" : "Session-based Recommendations with Recurrent Neural Networks",
      "author" : [ "Balázs Hidasi", "Alexandros Karatzoglou", "Linas Baltrunas", "Domonkos Tikk" ],
      "venue" : "In Proceedings of ICLR 2016",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2016
    }, {
      "title" : "Improving Sequential Recommendation with Knowledge-Enhanced Memory Networks",
      "author" : [ "Jin Huang", "Wayne Xin Zhao", "Hongjian Dou", "Ji-Rong Wen", "Edward Y. Chang" ],
      "venue" : "In The 41st ACM SIGIR Conference (SIGIR",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2018
    }, {
      "title" : "Review Sentiment-Guided Scalable Deep Recommender System",
      "author" : [ "Dongmin Hyun", "Chanyoung Park", "Min-Chul Yang", "Ilhyeon Song", "Jung-Tae Lee", "Hwanjo Yu" ],
      "venue" : "In The 41st ACM SIGIR Conference (SIGIR",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2018
    }, {
      "title" : "Self-Attentive Sequential Recommendation",
      "author" : [ "W. Kang", "J. McAuley" ],
      "venue" : "IEEE International Conference on Data Mining (ICDM",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2018
    }, {
      "title" : "The Stanford CoreNLP Natural Language Processing Toolkit",
      "author" : [ "Christopher Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven Bethard", "David McClosky" ],
      "venue" : "In Proceedings of the 52nd ACL",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2014
    }, {
      "title" : "Improved recurrent neural networks for session-based recommendations",
      "author" : [ "Yong Kiam Tan", "Xinxing Xu", "Yong Liu" ],
      "venue" : "In Proceedings of the 1st Workshop on Deep Learning for Recommender Systems",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2016
    }, {
      "title" : "Attention is All you Need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Ł ukasz Kaiser", "Illia Polosukhin" ],
      "venue" : "In NeurIPS. Curran Associates,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2017
    }, {
      "title" : "Sequential Recommender Systems: Challenges, Progress and Prospects",
      "author" : [ "Shoujin Wang", "Liang Hu", "Yan Wang", "Longbing Cao", "Quan Z. Sheng", "Mehmet Orgun" ],
      "venue" : "In Proceedings of IJCAI",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2019
    }, {
      "title" : "NeuO: Exploiting the sentimental bias between ratings and reviews with neural networks",
      "author" : [ "Yuanbo Xu", "Yongjian Yang", "Jiayu Han", "En Wang", "Fuzhen Zhuang", "Jingyuan Yang", "Hui Xiong" ],
      "venue" : "Neural Networks",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2019
    }, {
      "title" : "Feature-level Deeper Self-Attention Network for Sequential Recommendation",
      "author" : [ "Tingting Zhang", "Pengpeng Zhao", "Yanchi Liu", "Victor S. Sheng", "Jiajie Xu", "Deqing Wang", "Guanfeng Liu", "Xiaofang Zhou" ],
      "venue" : "In Proceedings of IJCAI",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2019
    }, {
      "title" : "Memory Reorganization: A Symmetric Memory Network for Reorganizing Neighbors and Topics to Complete Rating Prediction",
      "author" : [ "Lin Zheng", "Naicheng Guo", "Jin Yu", "Dazhi Jiang" ],
      "venue" : "IEEE Access",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "3401330 specifically model sequential behavior has yielded many fruitful results [9].",
      "startOffset" : 81,
      "endOffset" : 84
    }, {
      "referenceID" : 1,
      "context" : "As an initial attempt at applying deep learning to sequential recommendation, GRU4Rec [2] concatenates the behavior sequences of different users in a reasonable manner, thereby solving the difficult problem of uniformly modeling user behavior sequences of different lengths.",
      "startOffset" : 86,
      "endOffset" : 89
    }, {
      "referenceID" : 6,
      "context" : "This method illustrates the important role of recurrent neural networks (RNNs) [7] in sequential recommendation.",
      "startOffset" : 79,
      "endOffset" : 82
    }, {
      "referenceID" : 2,
      "context" : "Taking this research as a starting point, subsequent advanced approaches, such as memory-based RNNs [3, 12] and self-attention-based RNNs [5, 11], have taken sequential recommendation technology to a new level.",
      "startOffset" : 100,
      "endOffset" : 107
    }, {
      "referenceID" : 11,
      "context" : "Taking this research as a starting point, subsequent advanced approaches, such as memory-based RNNs [3, 12] and self-attention-based RNNs [5, 11], have taken sequential recommendation technology to a new level.",
      "startOffset" : 100,
      "endOffset" : 107
    }, {
      "referenceID" : 4,
      "context" : "Taking this research as a starting point, subsequent advanced approaches, such as memory-based RNNs [3, 12] and self-attention-based RNNs [5, 11], have taken sequential recommendation technology to a new level.",
      "startOffset" : 138,
      "endOffset" : 145
    }, {
      "referenceID" : 10,
      "context" : "Taking this research as a starting point, subsequent advanced approaches, such as memory-based RNNs [3, 12] and self-attention-based RNNs [5, 11], have taken sequential recommendation technology to a new level.",
      "startOffset" : 138,
      "endOffset" : 145
    }, {
      "referenceID" : 2,
      "context" : "These advanced technologies not only complete the modeling of pure behavior (item) sequences but also fully characterize additional information such as knowledge [3] and features [11] related to items to improve the sequence prediction performance.",
      "startOffset" : 162,
      "endOffset" : 165
    }, {
      "referenceID" : 10,
      "context" : "These advanced technologies not only complete the modeling of pure behavior (item) sequences but also fully characterize additional information such as knowledge [3] and features [11] related to items to improve the sequence prediction performance.",
      "startOffset" : 179,
      "endOffset" : 183
    }, {
      "referenceID" : 7,
      "context" : "Some recent models based on the self-attention mechanism [8] perform particularly well in sequential recommendation.",
      "startOffset" : 57,
      "endOffset" : 60
    }, {
      "referenceID" : 4,
      "context" : "For example, SASRec [5] effectively captures users’ long-term preferences from both sparse and dense data sets, and in FDSA [11], two separated self-attention blocks (one for item sequences and one for features) were designed that achieved remarkable predictive effects.",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 10,
      "context" : "For example, SASRec [5] effectively captures users’ long-term preferences from both sparse and dense data sets, and in FDSA [11], two separated self-attention blocks (one for item sequences and one for features) were designed that achieved remarkable predictive effects.",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 3,
      "context" : "However, most of the existing models based on sentiment factors [4, 10] focus only on non-sequential recommendations.",
      "startOffset" : 64,
      "endOffset" : 71
    }, {
      "referenceID" : 9,
      "context" : "However, most of the existing models based on sentiment factors [4, 10] focus only on non-sequential recommendations.",
      "startOffset" : 64,
      "endOffset" : 71
    }, {
      "referenceID" : 0,
      "context" : "To this end, we incorporate a variant sparse sentiment attention [1] to model the sentiment factors in the sequence separately because a certain behavior in the sequence corresponds toM sentiment factors, and sparse attention can improve the calculation efficiency by reducing the number of attention interactions in the sequence.",
      "startOffset" : 65,
      "endOffset" : 68
    }, {
      "referenceID" : 4,
      "context" : "The self-attention mechanism has been shown to be highly effective at sequential recommendation [5, 11].",
      "startOffset" : 96,
      "endOffset" : 103
    }, {
      "referenceID" : 10,
      "context" : "The self-attention mechanism has been shown to be highly effective at sequential recommendation [5, 11].",
      "startOffset" : 96,
      "endOffset" : 103
    }, {
      "referenceID" : 7,
      "context" : "It is based on the scaled dot-product attention [8], which is defined as follows:",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 0,
      "context" : "To model the sentiment-generated preference, we applied a simplified sparse attention mechanism [1] to model pure sentiments and specifically designed its inputs to facilitate interactions between sentiment factors.",
      "startOffset" : 96,
      "endOffset" : 99
    }, {
      "referenceID" : 5,
      "context" : "We first extracted temporal sentiments from reviews corresponding to sequential behaviors by using the Stanford NLP tools [6] and obtained five categories",
      "startOffset" : 122,
      "endOffset" : 125
    }, {
      "referenceID" : 6,
      "context" : "Then, to facilitate training, we adopted the data augmentation technique reported in [7] to generate subsequences as input data.",
      "startOffset" : 85,
      "endOffset" : 88
    }, {
      "referenceID" : 1,
      "context" : "• RNN - an LSTM-based recurrent neural network for sequential recommendation, • GRU4Rec[2] - a representative GRU-based sequential recommender, • GRU4Senti[2] - an improved GRU4Rec model by concatenating user sentiment embeddings with item embeddings, • SASRec[5] - a state-of-the-art self-attention-based sequential recommender, • CFSA[11] - a state-of-the-art self-attention-based sequential recommender that considers sentiments as its features, • SGS - our Sentiment-Guided Sequential recommender.",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 1,
      "context" : "• RNN - an LSTM-based recurrent neural network for sequential recommendation, • GRU4Rec[2] - a representative GRU-based sequential recommender, • GRU4Senti[2] - an improved GRU4Rec model by concatenating user sentiment embeddings with item embeddings, • SASRec[5] - a state-of-the-art self-attention-based sequential recommender, • CFSA[11] - a state-of-the-art self-attention-based sequential recommender that considers sentiments as its features, • SGS - our Sentiment-Guided Sequential recommender.",
      "startOffset" : 155,
      "endOffset" : 158
    }, {
      "referenceID" : 4,
      "context" : "• RNN - an LSTM-based recurrent neural network for sequential recommendation, • GRU4Rec[2] - a representative GRU-based sequential recommender, • GRU4Senti[2] - an improved GRU4Rec model by concatenating user sentiment embeddings with item embeddings, • SASRec[5] - a state-of-the-art self-attention-based sequential recommender, • CFSA[11] - a state-of-the-art self-attention-based sequential recommender that considers sentiments as its features, • SGS - our Sentiment-Guided Sequential recommender.",
      "startOffset" : 260,
      "endOffset" : 263
    }, {
      "referenceID" : 10,
      "context" : "• RNN - an LSTM-based recurrent neural network for sequential recommendation, • GRU4Rec[2] - a representative GRU-based sequential recommender, • GRU4Senti[2] - an improved GRU4Rec model by concatenating user sentiment embeddings with item embeddings, • SASRec[5] - a state-of-the-art self-attention-based sequential recommender, • CFSA[11] - a state-of-the-art self-attention-based sequential recommender that considers sentiments as its features, • SGS - our Sentiment-Guided Sequential recommender.",
      "startOffset" : 336,
      "endOffset" : 340
    } ],
    "year" : 2020,
    "abstractText" : "The existing sequential recommendation methods focus on modeling the temporal relationships of user behaviors and are good at using additional item information to improve performance. However, these methods rarely consider the influences of users’ sequential subjective sentiments on their behaviors—and sometimes the temporal changes in human sentiment patterns plays a decisive role in users’ final preferences. To investigate the influence of temporal sentiments on user preferences, we propose generating preferences by guiding user behavior through sequential sentiments. Specifically, we design a dual-channel fusion mechanism. The main channel consists of sentiment-guided attention to match and guide sequential user behavior, and the secondary channel consists of sparse sentiment attention to assist in preference generation. In the experiments, we demonstrate the effectiveness of these two sentiment modelingmechanisms through ablation studies. Our approach outperforms current state-of-the-art sequential recommendation methods that incorporate sentiment factors.",
    "creator" : "LaTeX with acmart 2020/04/30 v1.71 Typesetting articles for the Association for Computing Machinery and hyperref 2018/11/30 v6.88e Hypertext links for LaTeX"
  }
}